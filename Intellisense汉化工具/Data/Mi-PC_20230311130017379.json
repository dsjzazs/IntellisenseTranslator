{"\r\n            Wrapped class of the C++ standard vector of Mat.\r\n            ":"\r\n            Mat 的 C++ 标准向量的包装类。\r\n            \r\n","Input GMat of the defined unary computation":"定义的一元计算的输入 GMat\r\n","\r\n            Pointer to horizontal crossings\r\n            ":"\r\n            指向水平交叉点的指针\r\n            \r\n","\r\n            Number of warpings per scale\r\n            ":"\r\n            每个尺度的翘曲数\r\n            \r\n","Block size":"块大小\r\n","Vector used to store markers location on the patterns.":"用于存储图案上标记位置的向量。\r\n","\r\n            Convert YUV (YUY2) to BGRA\r\n            ":"\r\n            将 YUV (YUY2) 转换成 BGRA\r\n            \r\n","\r\n            The size of CvPoint2D32f\r\n            ":"\r\n            CvPoint2D32f 的大小\r\n            \r\n","\r\n            No mapping is done, linear discrimination (or regression) is done in the original feature space. It is the fastest option. d(x,y) = x y == (x,y)\r\n            ":"\r\n            不做映射，在原始特征空间做线性判别（或回归）。这是最快的选择。 d(x,y) = x y == (x,y)\r\n            \r\n","Optional output vector of vertices of the found  barcode rectangle. Will be empty if not found.":"找到的条形码矩形的顶点的可选输出向量。如果找不到，将为空。\r\n","The second image for the Max operation":"最大操作的第二个图像\r\n","\r\n            OpenCV depth type\r\n            ":"\r\n            OpenCV深度类型\r\n            \r\n","\r\n            Find the good features to track\r\n            ":"\r\n            找到要跟踪的好特征\r\n            \r\n","\r\n            SByte\r\n            ":"\r\n            S字节\r\n            \r\n"," Convert the current image to the specific color and depth ":" 将当前图像转换为特定的颜色和深度\r\n","The second parameter of the activation function.":"激活函数的第二个参数。\r\n","Output face feature":"输出人脸特征\r\n"," Inplace flip the image":" 就地翻转图像\r\n","\r\n            Set the exposure compensator for this stitcher.\r\n            ":"\r\n            为这个拼接器设置曝光补偿器。\r\n            \r\n","\r\n            Gain of the image (only for those cameras that support).\r\n            ":"\r\n            图像增益（仅适用于支持的相机）。\r\n            \r\n","Method for solving a P3P problem: either P3P or AP3P":"解决 P3P 问题的方法：P3P 或 AP3P\r\n","\r\n            Create an standard vector of RotatedRect with the initial values\r\n            ":"\r\n            使用初始值创建 RotatedRect 的标准向量\r\n            \r\n","\r\n            Multi-scale variant of classical Hough transform. The lines are encoded the same way as in CV_HOUGH_STANDARD\r\n            ":"\r\n            经典霍夫变换的多尺度变体。这些线的编码方式与 CV_HOUGH_STANDARD 中的相同\r\n            \r\n","Absolute difference between matrix elements and given scalar value":"矩阵元素与给定标量值之间的绝对差\r\n","True if a QRCode is found.":"如果找到 QRCode，则为真。\r\n","\r\n            For TIFF, use to specify the image compression scheme. See libtiff for integer constants corresponding to compression formats. Note, for images whose depth is CV_32F, only libtiff's SGILOG compression scheme is used. For other supported depths, the compression scheme can be specified by this flag; LZW compression is the default.\r\n            ":"\r\n            对于 TIFF，用于指定图像压缩方案。有关与压缩格式对应的整数常量，请参阅 libtiff。请注意，对于深度为 CV_32F 的图像，仅使用 libtiff 的 SGILOG 压缩方案。对于其他支持的深度，可以通过该标志指定压缩方案； LZW 压缩是默认的。\r\n            \r\n","Distance function selector.":"距离函数选择器。\r\n","\r\n            Get the best color checker. By the best it means the one\r\n            detected with the highest confidence.\r\n            ":"\r\n            获得最好的颜色检查器。最好的意思是那个\r\n            以最高置信度检测到。\r\n            \r\n","\r\n            Byte\r\n            ":"\r\n            字节\r\n            \r\n","grid for coeff":"系数网格\r\n","Input image, 1- or 3-channel, 8-bit or 32-bit floating point (each channel of multi-channel image is processed independently)":"输入图像，1或3通道，8位或32位浮点数（多通道图像的每个通道独立处理）\r\n","width of the marker borders.":"标记边框的宽度。\r\n","\r\n            Use LK camera compensation\r\n            ":"\r\n            使用LK相机补偿\r\n            \r\n","\r\n            Function type\r\n            ":"\r\n            函数类型\r\n            \r\n","Range between 0 to 1":"范围在 0 到 1 之间\r\n","Vector of exposure time values for each image":"每个图像的曝光时间值向量\r\n","The threshold to filter out bounding boxes of score smaller than the given value":"过滤掉分数小于给定值的边界框的阈值\r\n","If true, arrow heads will be drawn.":"如果为真，将绘制箭头。\r\n","\r\n            Fisher face recognizer\r\n            ":"\r\n            Fisher人脸识别器\r\n            \r\n","The sourceImage":"来源图片\r\n"," \r\n            An array of single channel GpuMat where each element  \r\n            in the array represent a single channel of the original GpuMat \r\n            ":" \r\n            单通道 GpuMat 数组，其中每个元素\r\n            数组中代表原始 GpuMat 的单个通道\r\n            \r\n","vector of vectors of the projections of calibration pattern points. imagePoints.size() and objectPoints.size() and imagePoints[i].size() must be equal to objectPoints[i].size() for each i.":"校准图案点投影向量的向量。对于每个 i，imagePoints.size() 和 objectPoints.size() 以及 imagePoints[i].size() 必须等于 objectPoints[i].size()。\r\n","The other box to be compared":"另一个要比较的盒子\r\n","Threshold step in subsequent thresholds when extracting the component tree.":"提取组件树时后续阈值中的阈值步长。\r\n","\r\n            round to infinite\r\n            ":"\r\n            圆到无限\r\n            \r\n","\r\n            Automatic page segmentation with orientation and script detection. (OSD)\r\n            ":"\r\n            带有方向和脚本检测功能的自动页面分割。 （屏幕显示）\r\n            \r\n"," The up-sampled image":" 上采样图像\r\n","Number of times erosion is applied.":"应用侵蚀的次数。\r\n","3x3 transformation matrix":"3x3 变换矩阵\r\n","\r\n            Sets a new error handler that can be one of standard handlers or a custom handler that has the certain interface. The handler takes the same parameters as cvError function. If the handler returns non-zero value, the program is terminated, otherwise, it continues. The error handler may check the current error mode with cvGetErrMode to make a decision.\r\n            ":"\r\n            设置一个新的错误处理程序，它可以是标准处理程序之一，也可以是具有特定接口的自定义处理程序。该处理程序采用与 cvError 函数相同的参数。如果处理程序返回非零值，则程序终止，否则继续。错误处理程序可以使用 cvGetErrMode 检查当前错误模式以做出决定。\r\n            \r\n","\r\n            Set the mat to the specific value\r\n            ":"\r\n            将垫子设置为特定值\r\n            \r\n","\r\n            The Non-maximum-suppression threshold to suppress bounding boxes that have IoU greater than the given value\r\n            ":"用于抑制 IoU 大于给定值的边界框的非最大抑制阈值\r\n            \r\n","Threshold on the squared Mahalanobis distance between the pixel and the model to decide whether a pixel is well described by the background model. This parameter does not affect the background update.":"像素和模型之间马氏距离平方的阈值，用于决定像素是否被背景模型很好地描述。该参数不影响后台更新。\r\n","\r\n            Calculates the per-element maximum of two matrices of the same size, number of channels and depth\r\n            ":"\r\n            计算相同大小、通道数和深度的两个矩阵的每个元素最大值\r\n            \r\n","The color for the OR operation":"OR 操作的颜色\r\n","\r\n            Convert YUV420i to BGR\r\n            ":"\r\n            将 YUV420i 转换为 BGR\r\n            \r\n","The result of the comparison":"比较结果\r\n","Smoothness term weight. Greater values produce smoother results, but can alter the response.":"平滑项权重。较大的值会产生更平滑的结果，但会改变响应。\r\n","\r\n            Create a backend given its id\r\n            ":"\r\n            给定 id 创建一个后端\r\n            \r\n","\r\n            Use the default criteria for the particular boosting method\r\n            ":"\r\n            使用特定增强方法的默认标准\r\n            \r\n","If pose estimation is valid, returns true, else returns false.":"如果姿势估计有效，则返回 true，否则返回 false。\r\n","\r\n            Fixed type\r\n            ":"\r\n            固定式\r\n            \r\n","\r\n            Create the standard vector of VectorOfPointF \r\n            ":"\r\n            创建 VectorOfPointF 的标准向量\r\n            \r\n","\r\n            Use adaptive thresholding to convert the image to black-n-white, rather than a fixed threshold level (computed from the average image brightness)\r\n            ":"\r\n            使用自适应阈值将图像转换为黑白，而不是固定阈值水平（根据平均图像亮度计算）\r\n            \r\n","\r\n            Separate luma quality level, 0 - 100, default is 0 - don't use.\r\n            ":"\r\n            单独的亮度质量级别，0 - 100，默认为 0 - 不要使用。\r\n            \r\n","Number of block levels. The more levels, the more accurate is the segmentation, but needs more memory and CPU time.":"块级数。级别越多，分割越准确，但需要更多的内存和 CPU 时间。\r\n","\r\n            Color Correction Matrix element [0][3]\r\n            ":"\r\n            颜色校正矩阵元素 [0][3]\r\n            \r\n","\r\n            Get the available streams\r\n            ":"\r\n            获取可用流\r\n            \r\n","\r\n            The maximum value of this range\r\n            ":"\r\n            该范围的最大值\r\n            \r\n","\r\n            (read-only) codec's pixel format. 4-character code - see VideoWriter::fourcc. Subset of [AV_PIX_FMT_*](https://github.com/FFmpeg/FFmpeg/blob/master/libavcodec/raw.c) or -1 if unknown\r\n            ":"\r\n            （只读）编解码器的像素格式。 4 字符代码 - 请参阅 VideoWriter::fourcc。 [AV_PIX_FMT_*](https://github.com/FFmpeg/FFmpeg/blob/master/libavcodec/raw.c) 的子集，如果未知则为 -1\r\n            \r\n","Depth type of the first output map that should be CV_16SC2 , CV_32FC1 , or CV_32FC2.":"第一个输出图的深度类型应该是 CV_16SC2 、 CV_32FC1 或 CV_32FC2 。\r\n","\r\n            The class identifier\r\n            ":"\r\n            类标识符\r\n            \r\n","\r\n            Release the memory associated with this detection model.\r\n            ":"\r\n            释放与此检测模型关联的内存。\r\n            \r\n","A CV_32SC1 integer array containing the labels of the superpixel segmentation. The labels are in the range [0, NumberOfSuperpixels].":"包含超像素分割标签的 CV_32SC1 整数数组。标签在 [0, NumberOfSuperpixels] 范围内。\r\n","The gemm operation type":"gemm操作类型\r\n","\r\n            For each keypoint the circle around keypoint with keypoint size and\r\n            orientation will be drawn.\r\n            ":"对于每个关键点，关键点周围的圆圈具有关键点大小和\r\n            将绘制方向。\r\n            \r\n","The calibration matrix to use":"要使用的校准矩阵\r\n","minimum margins (in pixels) of the marker in the output image":"输出图像中标记的最小边距（以像素为单位）\r\n","0 if src1 is a singular and CV_LU method is used":"0 如果 src1 是单数且使用 CV_LU 方法\r\n","\r\n            The function initializes a SuperpixelLSC object for the input image. \r\n            ":"\r\n            该函数为输入图像初始化一个 SuperpixelLSC 对象。\r\n            \r\n","\r\n            Beblid size\r\n            ":"\r\n            大小\r\n            \r\n","\r\n            Intelperc Depth Confidence Threshold\r\n            ":"\r\n            Intelperc 深度置信阈值\r\n            \r\n","\r\n            L2\r\n            ":"\r\n            L2\r\n            \r\n","\r\n            Up sample input image to improve sub-pixel accuracy due to aliasing effects. This should be used if an accurate camera calibration is required.\r\n            ":"\r\n            由于混叠效应，向上采样输入图像以提高子像素精度。如果需要精确的相机校准，则应使用此选项。\r\n            \r\n","\r\n            Load a network from Intel's Model Optimizer intermediate representation.\r\n            ":"\r\n            从 Intel 的模型优化器中间表示加载网络。\r\n            \r\n","Output image depth":"输出图像深度\r\n","The recognized text is returned as coded in the same format as a box file used in training.":"识别的文本以与训练中使用的框文件相同的格式编码返回。\r\n","A row by row matrix of descriptors to be query for nearest neighbours":"要查询最近邻居的描述符的逐行矩阵\r\n","\r\n            (open-only) Hardware acceleration type (see #VideoAccelerationType). Setting supported only via `params` parameter in cv::VideoCapture constructor / .open() method. Default value is backend-specific.\r\n            ":"\r\n            （仅开放）硬件加速类型（参见#VideoAccelerationType）。仅通过 cv::VideoCapture 构造函数/.open() 方法中的“params”参数支持设置。默认值是特定于后端的。\r\n            \r\n","The programming language to output code":"输出代码的编程语言\r\n","This identifier is deprecated, use DEPTH_16F instead.":"此标识符已弃用，请改用 DEPTH_16F。\r\n","\r\n            Create an empty standard vector of Mat\r\n            ":"\r\n            创建一个空的 Mat 标准向量\r\n            \r\n","\r\n            This class provides the functionality of text bounding box detection. This class find bounding boxes of text words given an input image.\r\n            ":"\r\n            该类提供文本边界框检测功能。此类在给定输入图像的情况下查找文本单词的边界框。\r\n            \r\n","The GpuMat to be copied to":"要复制到的 GpuMat\r\n","The points that defines the contour of this facet":"定义此小平面轮廓的点\r\n","\r\n            Hint buffer grid size is 1x1.\r\n            ":"\r\n            提示缓冲区网格大小为 1x1。\r\n            \r\n","\r\n            Get the size of the input array\r\n            ":"\r\n            获取输入数组的大小\r\n            \r\n","The branching factor to use for the hierarchical k-means tree":"用于分层 k-means 树的分支因子\r\n","\r\n            Decodes QR codes in image once it's found by the detect() method.\r\n            ":"\r\n            一旦通过 detect() 方法找到图像中的 QR 码，就对其进行解码。\r\n            \r\n"," The center of the ellipse":" 椭圆的中心\r\n","\r\n            DC1394 mode one push auto\r\n            ":"\r\n            DC1394模式一键自动\r\n            \r\n","The selected generic parameter typ":"选定的通用参数类型\r\n","The maximum area (% of image size) allowed for retreived ER’s.":"允许检索 ER 的最大区域（图像大小的百分比）。\r\n","\r\n            First call Grab() function follows by Retrieve()\r\n            ":"\r\n            首先调用 Grab() 函数，然后调用 Retrieve()\r\n            \r\n","\r\n            The size of RangF\r\n            ":"\r\n            RangF 的大小\r\n            \r\n","\r\n            The first value\r\n            ":"\r\n            第一个值\r\n            \r\n","Compression code. Usually computed using CvInvoke.CV_FOURCC. \r\n            On windows use -1 to open a codec selection dialog.\r\n            On Linux, use VideoWriter.Fourcc('I', 'Y', 'U', 'V') for default codec for the specific file name.\r\n            ":"压缩码。通常使用 CvInvoke.CV_FOURCC 计算。\r\n            在 Windows 上使用 -1 打开编解码器选择对话框。\r\n            在 Linux 上，使用 VideoWriter.Fourcc('I', 'Y', 'U', 'V') 作为特定文件名的默认编解码器。\r\n            \r\n","\r\n            Convert the standard vector to arrays of arrays of Point\r\n            ":"\r\n            将标准向量转换为 Point 数组的数组\r\n            \r\n","\r\n            Release the unmanaged memory associated with this output array.\r\n            ":"\r\n            释放与此输出数组关联的非托管内存。\r\n            \r\n","Output GMat of the defined binary computation":"定义的二进制计算的输出 GMat\r\n","\r\n            Stub seam estimator which does nothing.\r\n            ":"\r\n            什么都不做的存根接缝估计器。\r\n            \r\n","\r\n            Get or set the intensity of the x color channel\r\n            ":"\r\n            获取或设置 x 颜色通道的强度\r\n            \r\n","\r\n            Thin prism model\r\n            ":"\r\n            薄棱镜模型\r\n            \r\n","\r\n            Convert Bayer RGGB pattern to BGR color using VNG\r\n            ":"\r\n            使用 VNG 将 Bayer RGGB 模式转换为 BGR 颜色\r\n            \r\n","Length of the cone.":"锥体的长度。\r\n","The optional output 2d array of labels of integer type and the same size as src and dst. Can be null if not needed":"整数类型的可选输出二维标签数组，大小与 src 和 dst 相同。如果不需要可以为空\r\n","\r\n            Inverse camera response function is extracted for each brightness value by minimizing an objective function as linear system. Objective function is constructed using pixel values on the same position in all images, extra term is added to make the result smoother.\r\n            ":"\r\n            通过最小化作为线性系统的目标函数，为每个亮度值提取逆相机响应函数。目标函数是使用所有图像中相同位置的像素值构造的，添加了额外的项以使结果更平滑。\r\n            \r\n","The first matrix to be added.":"要添加的第一个矩阵。\r\n","\r\n            Maximum tracklets\r\n            ":"\r\n            最大轨迹\r\n            \r\n","Desired output matrix depth.":"所需的输出矩阵深度。\r\n","Padding":"填充\r\n","\r\n            Class implementing the SLIC (Simple Linear Iterative Clustering) superpixels algorithm described in Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Susstrunk. Slic superpixels compared to state-of-the-art superpixel methods. IEEE Trans. Pattern Anal. Mach. Intell., 34(11):2274-2282, nov 2012.\r\n            ":"\r\n            实现 Radhakrishna Achanta、Appu Shaji、Kevin Smith、Aurelien Lucchi、Pascal Fua 和 Sabine Susstrunk 中描述的 SLIC（简单线性迭代聚类）超像素算法的类。与最先进的超像素方法相比，切片超像素。 IEEE 跨。模式肛门。马赫。情报，34(11):2274-2282，2012 年 11 月。\r\n            \r\n","\r\n            This class represents high-level API for text detection DL networks compatible with EAST model.\r\n            ":"\r\n            此类代表与 EAST 模型兼容的文本检测 DL 网络的高级 API。\r\n            \r\n","\r\n            The named window type\r\n            ":"\r\n            命名的窗口类型\r\n            \r\n","Attribute name.":"属性名称。\r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are not equal to elements in second.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否不等于第二个矩阵中的元素。\r\n            \r\n","\r\n            Get the RGB charts\r\n            ":"\r\n            获取 RGB 图表\r\n            \r\n","\r\n            Release the unmanaged memory associated with this WCircle object\r\n            ":"\r\n            释放与此 WCircle 对象关联的非托管内存\r\n            \r\n","\r\n            Release the unmanaged memory associated with this PCTSignatures object\r\n            ":"\r\n            释放与此 PCTSignatures 对象关联的非托管内存\r\n            \r\n","Value added to the filtered results before storing them.":"在存储之前将值添加到过滤结果中。\r\n","The second source image. If it is null, the absolute norm of arr1 is calculated, otherwise absolute or relative norm of arr1-arr2 is calculated":"第二个源图像。如果为空，则计算arr1的绝对范数，否则计算arr1-arr2的绝对范数或相对范数\r\n","The step":"这一步\r\n","\r\n            Get the detector parameters with default values\r\n            ":"\r\n            获取具有默认值的检测器参数\r\n            \r\n","\r\n            Set the blender for this stitcher\r\n            ":"\r\n            为这个缝合器设置搅拌器\r\n            \r\n","\r\n            Return the cross product of two 3D point\r\n            ":"\r\n            返回两个 3D 点的叉积\r\n            \r\n","determines if we're parallelizing the algorithm":"确定我们是否正在并行化算法\r\n",") rows of the GpuMat":") 行的 GpuMat\r\n","Maximal radius of the circles to search for":"要搜索的圆的最大半径\r\n","Optional delta value that is added to the results prior to storing them in dst.":"在将结果存储到 dst 之前添加到结果中的可选增量值。\r\n","0-based maximal pyramid level number; if set to 0, pyramids are not used (single level), if set to 1, two levels are used, and so on; if pyramids are passed to input then algorithm will use as many levels as pyramids have but no more than maxLevel.":"从 0 开始的最大金字塔层数；如果设置为 0，则不使用金字塔（单层），如果设置为 1，则使用两层，依此类推；如果将金字塔传递给输入，则算法将使用与金字塔一样多的级别，但不超过 maxLevel。\r\n","Operation mask, 8-bit single channel array; specifies elements of destination array to be changed. ":"操作掩码，8位单通道数组；指定要更改的目标数组的元素。\r\n","\r\n            Performs downsampling step of Gaussian pyramid decomposition. \r\n            ":"\r\n            执行高斯金字塔分解的下采样步骤。\r\n            \r\n","\r\n            Release this memory associated with this Dnn super resolution model.\r\n            ":"\r\n            释放与此 Dnn 超分辨率模型关联的此内存。\r\n            \r\n","Computed flow image that has the same size as prev and type CV_32FC2 ":"与 prev 具有相同大小且类型为 CV_32FC2 的计算流图像\r\n","\r\n            A one pass video stabilizer\r\n            ":"\r\n            一次性视频稳定器\r\n            \r\n","\r\n            Create a compressed rectilinear warper\r\n            ":"\r\n            创建一个压缩的直线变形器\r\n            \r\n","\r\n            Activates/deactivates Region selected by Region Selector\r\n            ":"\r\n            激活/停用区域选择器选择的区域\r\n            \r\n","\r\n            Draw a wireframe of a triangle mesh\r\n            ":"\r\n            绘制三角形网格的线框\r\n            \r\n","\r\n            The location of the keypoint\r\n            ":"\r\n            关键点的位置\r\n            \r\n","\r\n            Monochrome\r\n            ":"\r\n            单色\r\n            \r\n","\r\n            Returns the baseline of the current object at the given level. The baseline is the line that passes through (x1, y1) and (x2, y2). WARNING: with vertical text, baselines may be vertical! Returns null if there is no baseline at the current position.\r\n            ":"\r\n            返回给定级别的当前对象的基线。基线是通过 (x1, y1) 和 (x2, y2) 的线。警告：对于垂直文本，基线可能是垂直的！如果当前位置没有基线，则返回 null。\r\n            \r\n","\r\n            Use mesh\r\n            ":"\r\n            使用网格\r\n            \r\n","\r\n            Performs anisotropic diffusion on an image.\r\n            ":"\r\n            对图像执行各向异性扩散。\r\n            \r\n","\r\n            Buffer size in bytes sufficient for output image returned by xiGetImage\r\n            ":"\r\n            足以容纳 xiGetImage 返回的输出图像的缓冲区大小（以字节为单位）\r\n            \r\n","\r\n            Create a new GrayCodePattern\r\n            ":"\r\n            创建一个新的 GrayCodePattern\r\n            \r\n","Similarity function selector.":"相似函数选择器。\r\n","The color of the line segment ":"线段的颜色\r\n","\r\n            True if the output array is fixed size\r\n            ":"\r\n            如果输出数组是固定大小则为真\r\n            \r\n","Type of array elements":"数组元素的类型\r\n","Declare amount of columns":"声明列数\r\n","\r\n            The generated pattern: a VectorOfMat, in which each image is a CV_8U Mat at projector's resolution.\r\n            ":"\r\n            生成的图案：一个 VectorOfMat，其中每个图像都是投影仪分辨率的 CV_8U 垫。\r\n            \r\n","Overall ticks for model inference.":"模型推理的整体刻度。\r\n","\r\n            Load font data.\r\n            ":"\r\n            加载字体数据。\r\n            \r\n","Size of the output image in pixels.":"输出图像的大小（以像素为单位）。\r\n","\r\n            Hierarchical Clustering Index Parameters\r\n            ":"\r\n            层次聚类索引参数\r\n            \r\n","\r\n            Get the data as InputOutputArray\r\n            ":"\r\n            获取数据作为 InputOutputArray\r\n            \r\n","\r\n            Textiles\r\n            ":"\r\n            纺织品\r\n            \r\n","\r\n            Transforms the image to compensate radial and tangential lens distortion. \r\n            ":"\r\n            变换图像以补偿径向和切向镜头失真。\r\n            \r\n"," The result is the colormapped source image":" 结果是彩色映射源图像\r\n","Specify the amount of keypoints that will be written into dataset.":"指定将写入数据集的关键点数量。\r\n","\r\n            The algorithm inplace normalizes brightness and increases contrast of the image.\r\n            For color images, a HSV representation of the image is first obtained and the V (value) channel is histogram normalized\r\n            ":"\r\n            该算法就地标准化亮度并增加图像的对比度。\r\n            对于彩色图像，首先得到图像的HSV表示，对V（值）通道进行直方图归一化\r\n            \r\n"," \r\n            Create a line segment with the specific start point and end point \r\n            ":"创建具有特定起点和终点的线段\r\n            \r\n","\r\n            The device single floating point configuration\r\n            ":"\r\n            设备单浮点配置\r\n            \r\n","\r\n            number of columns\r\n            ":"\r\n            列数\r\n            \r\n","Maximum number of output lines.":"最大输出行数。\r\n"," The satuation for this color ":" 这种颜色的饱和度\r\n","Feature parameters.":"特征参数。\r\n","\r\n            The backend for video\r\n            ":"\r\n            视频后台\r\n            \r\n","Optional depth of the output matrix":"输出矩阵的可选深度\r\n","The min value of this range":"该范围的最小值\r\n","\r\n            Decomposes a projection matrix into a rotation matrix and a camera intrinsic matrix.\r\n            ":"\r\n            将投影矩阵分解为旋转矩阵和相机固有矩阵。\r\n            \r\n","The locale":"语言环境\r\n","\r\n            Return a matrix of the same size with all elements equals 0\r\n            ":"\r\n            返回一个所有元素都为 0 的相同大小的矩阵\r\n            \r\n","Destination array to place Hann coefficients in":"放置 Hann 系数的目标数组\r\n","Type of the border to create around the copied source image rectangle":"在复制的源图像矩形周围创建的边框类型\r\n","\r\n            NC\r\n            ":"\r\n            数控\r\n            \r\n","\r\n            The confident\r\n            ":"\r\n            自信的\r\n            \r\n","\r\n            Closes the file and releases all the memory buffers\r\n            Call this method after all I/O operations with the storage are finished. If the storage was\r\n            opened for writing data and FileStorage.Mode.Write was specified\r\n            ":"\r\n            关闭文件并释放所有内存缓冲区\r\n            在对存储的所有 I/O 操作完成后调用此方法。如果存储是\r\n            为写入数据而打开，并指定了 FileStorage.Mode.Write\r\n            \r\n","\r\n            Flips the GpuMat<Byte> in one of different 3 ways (row and column indices are 0-based). \r\n            ":"以 3 种不同方式之一翻转 GpuMat<Byte>（行和列索引从 0 开始）。\r\n            \r\n","\r\n            Convert BGR555 color to RGBA color\r\n            ":"\r\n            将 BGR555 颜色转换为 RGBA 颜色\r\n            \r\n","The name of a file, or an url pointed to a stream.":"文件名或指向流的 url。\r\n","\r\n            Allows access to sensor feature value currently selected by XI_PRM_SENSOR_FEATURE_SELECTOR.\r\n            ":"\r\n            允许访问当前由 XI_PRM_SENSOR_FEATURE_SELECTOR 选择的传感器特征值。\r\n            \r\n","Output where the ERStat regions are stored.":"存储 ERStat 区域的输出。\r\n","Weather or not use the initial flow in the input matrix.":"天气或不使用输入矩阵中的初始流量。\r\n","Border value in case of a constant border":"边界不变时的边界值\r\n","\r\n            Create an instance of Boost Descriptor\r\n            ":"\r\n            创建一个 Boost 描述符的实例\r\n            \r\n","\r\n            Determin which side of the line the 2D point is at\r\n            ":"\r\n            确定 2D 点位于直线的哪一侧\r\n            \r\n","Input image of CV_8U type.":"CV_8U 类型的输入图像。\r\n","Number of columns in the matrix.":"矩阵中的列数。\r\n","\r\n            Create a mapper using a gaussian pyramid\r\n            ":"\r\n            使用高斯金字塔创建映射器\r\n            \r\n","\r\n            The Image Hash base class\r\n            ":"\r\n            图像哈希基类\r\n            \r\n","\r\n            Constant\r\n            ":"\r\n            持续的\r\n            \r\n","Output translation vector.":"输出翻译向量。\r\n","Matches. Each matches[i] is k or less matches for the same query descriptor.":"火柴。每个 matches[i] 是相同查询描述符的 k 或更少匹配项。\r\n","\r\n            FrameMetadata\r\n            ":"\r\n            帧元数据\r\n            \r\n","The first method-specific parameter. In case of CV_HOUGH_GRADIENT it is the higher threshold of the two passed to Canny edge detector (the lower one will be twice smaller). ":"第一个特定于方法的参数。在 CV_HOUGH_GRADIENT 的情况下，它是传递给 Canny 边缘检测器的两个阈值中的较高阈值（较低的阈值将小两倍）。\r\n","\r\n            End index\r\n            ":"\r\n            结束索引\r\n            \r\n","Gray image used to find chessboard corners":"用于寻找棋盘角的灰色图像\r\n","\r\n            Release all the unmanaged resource associated with VGG\r\n            ":"\r\n            释放与 VGG 关联的所有非托管资源\r\n            \r\n","\r\n            Specify input image and extract image features.\r\n            ":"\r\n            指定输入图像并提取图像特征。\r\n            \r\n","The color to compute absolute different with":"计算绝对不同的颜色\r\n","The 2D locations of the control points":"控制点的二维位置\r\n","An image to detect":"要检测的图像\r\n","\r\n            Set the axis color\r\n            ":"\r\n            设置坐标轴颜色\r\n            \r\n","\r\n            The size of the item in this Vector, counted as size in bytes.\r\n            ":"\r\n            此 Vector 中项目的大小，以字节计。\r\n            \r\n","\r\n            Creates a KCF Tracker\r\n            ":"\r\n            创建一个 KCF 跟踪器\r\n            \r\n","\r\n            Base interface for Objectness algorithms\r\n            ":"\r\n            Objectness 算法的基础接口\r\n            \r\n","The pointer to the unmanaged outputArray":"指向非托管 outputArray 的指针\r\n","The equivalent RotatedRect":"等效的 RotatedRect\r\n","Source image. Only CV_32FC1 images are supported for now.":"源图像。目前仅支持 CV_32FC1 图像。\r\n","Text string to be drawn.":"要绘制的文本字符串。\r\n","Optional scale factor ":"可选比例因子\r\n","\r\n            Applies weighted median filter to an image.\r\n            ":"\r\n            对图像应用加权中值滤波器。\r\n            \r\n","\r\n            No output scale\r\n            ":"\r\n            无输出刻度\r\n            \r\n","\r\n            Downloads data from device to host memory. Blocking calls.\r\n            ":"\r\n            将数据从设备下载到主机内存。阻止呼叫。\r\n            \r\n","\r\n            The diffusivity\r\n            ":"\r\n            扩散率\r\n            \r\n","The sum of two points":"两点之和\r\n","\r\n            The function mean calculates the mean value M of matrix elements, independently for each channel, and return it.\r\n            ":"\r\n            函数 mean 计算矩阵元素的平均值 M，独立于每个通道，并返回它。\r\n            \r\n","\r\n            transpose src1\r\n            ":"\r\n            转置 src1\r\n            \r\n","A normalized vector collinear to the line ":"与直线共线的归一化向量\r\n","the matrix":"矩阵\r\n"," If true crosshair of selection rectangle will be shown.":" 如果选择矩形的真正十字线将被显示。\r\n","Optional data pointer assigned to the matrix header":"分配给矩阵头的可选数据指针\r\n","Scale factor along the horizontal axis. If it is zero, it is computed as: (double)dsize.width/src.cols":"沿水平轴的比例因子。如果它为零，则计算为：(double)dsize.width/src.cols\r\n","\r\n            Top to bottom\r\n            ":"\r\n            从上到下\r\n            \r\n","The mask for setting color":"设置颜色的遮罩\r\n","The detected keypoints will be stored in this vector":"检测到的关键点将存储在此向量中\r\n","\r\n            DC1394 mode auto\r\n            ":"\r\n            DC1394模式自动\r\n            \r\n","indicates the type of markers that will be searched":"指示将要搜索的标记的类型\r\n","\r\n            Set/get bandwidth(datarate)(in Megabits)\r\n            ":"\r\n            设置/获取带宽（数据速率）（以兆位为单位）\r\n            \r\n","\r\n            Class that contains entry points for the Ccm module.\r\n            ":"\r\n            包含 Ccm 模块入口点的类。\r\n            \r\n","The rotation angle in degrees. Positive values mean couter-clockwise rotation (the coordiate origin is assumed at image centre). ":"以度为单位的旋转角度。正值表示逆时针旋转（坐标原点假定在图像中心）。\r\n","\r\n            The layer type\r\n            ":"\r\n            图层类型\r\n            \r\n","\r\n            Get the scale factor of the model.\r\n            ":"\r\n            获取模型的比例因子。\r\n            \r\n","\r\n            The rapid tracker interface\r\n            ":"\r\n            快速追踪器界面\r\n            \r\n","\r\n            EpsY\r\n            ":"\r\n            EPSY\r\n            \r\n","\r\n            Transposes matrix src1:\r\n            dst(i,j)=src(j,i)\r\n            Note that no complex conjugation is done in case of complex matrix. Conjugation should be done separately: look at the sample code in cvXorS for example\r\n            ":"转置矩阵 src1：\r\n            dst(i,j)=src(j,i)\r\n            请注意，在复杂矩阵的情况下，不会进行复杂的共轭。共轭应单独进行：例如查看 cvXorS 中的示例代码\r\n            \r\n","Quality score per channel":"每个渠道的质量得分\r\n","\r\n            Area\r\n            ":"\r\n            区域\r\n            \r\n","\r\n            Calculates weighted sum of input ":"\r\n            计算输入的加权和\r\n","The default detector parameters":"默认检测器参数\r\n","The loaded image":"加载的图像\r\n","Flags setting decoding algorithms.":"标志设置解码算法。\r\n","\r\n            Rotates a 2D array in multiples of 90 degrees.\r\n            ":"\r\n            以 90 度的倍数旋转二维数组。\r\n            \r\n","\r\n            Convert RGB color to XYZ color\r\n            ":"\r\n            将 RGB 颜色转换为 XYZ 颜色\r\n            \r\n"," and marks them in the output image edges using the Canny algorithm. \r\n            ":" 并使用 Canny 算法在输出图像边缘标记它们。\r\n            \r\n","The trimap":"三角图\r\n","\r\n            after rotating the block so the text orientation is upright, how many radians does one have to rotate the block anti-clockwise for it to be level? -Pi/4 <= deskew_angle <= Pi/4\r\n            ":"\r\n            旋转块使文本方向直立后，逆时针旋转块需要多少弧度才能使其水平？ -Pi/4 <= deskew_angle <= Pi/4\r\n            \r\n","The destination CudaImage":"目的地CudaImage\r\n","Mat containing a the disparity image in grayscale.":"包含灰度视差图像的垫子。\r\n","internal parameter, defining how much lambda decreases after each iteration. Normally, it should be 0.25. Setting it to 1.0 may lead to streaking artifacts.":"内部参数，定义每次迭代后 lambda 减少多少。通常，它应该是 0.25。将其设置为 1.0 可能会导致条纹伪影。\r\n","\r\n            Change image resolution by binning or skipping.\r\n            ":"\r\n            通过合并或跳过更改图像分辨率。\r\n            \r\n","Pointer to an array of single channel GpuMat pointers":"指向单通道 GpuMat 指针数组的指针\r\n","\r\n            Image capture timeout in milliseconds\r\n            ":"\r\n            以毫秒为单位的图像捕获超时\r\n            \r\n","\r\n            Decimation engine selector.\r\n            ":"\r\n            抽取引擎选择器。\r\n            \r\n","\r\n            priori error estimate covariance matrix (P'(k)): P'(k)=A*P(k-1)*At + Q)\r\n            ":"\r\n            先验误差估计协方差矩阵(P'(k)): P'(k)=A*P(k-1)*At + Q)\r\n            \r\n","The type of weight definition":"重量定义的类型\r\n"," The alpha value for this color":" 此颜色的 alpha 值\r\n","\r\n            If it is set, the function finds the largest object (if any) in the image. That is, the output sequence will contain one (or zero) element(s)\r\n            ":"\r\n            如果已设置，该函数将查找图像中最大的对象（如果有）。也就是说，输出序列将包含一个（或零个）元素\r\n            \r\n","\r\n            Object ID, that can be used to cluster keylines by the line they represent\r\n            ":"\r\n            对象 ID，可用于按它们代表的行对关键线进行聚类\r\n            \r\n","The array to check":"要检查的数组\r\n","The pointer to the unmanaged data":"指向非托管数据的指针\r\n","The pointer to the Feature2D object":"指向 Feature2D 对象的指针\r\n","Name of the file to open or the text string to read the data from. Extension of the\r\n            file (.xml or .yml/.yaml) determines its format (XML or YAML respectively). Also you can append .gz\r\n            to work with compressed files, for example myHugeMatrix.xml.gz. If both FileStorage::WRITE and\r\n            FileStorage::MEMORY flags are specified, source is used just to specify the output file format (e.g.\r\n            mydata.xml, .yml etc.).":"要打开的文件的名称或要从中读取数据的文本字符串。的延伸\r\n            文件（.xml 或 .yml/.yaml）决定其格式（分别为 XML 或 YAML）。您也可以附加 .gz\r\n            使用压缩文件，例如 myHugeMatrix.xml.gz。如果 FileStorage::WRITE 和\r\n            指定了 FileStorage::MEMORY 标志，source 仅用于指定输出文件格式（例如\r\n            mydata.xml、.yml 等）。\r\n","\r\n            Compute the conjugate of the quaternions\r\n            ":"\r\n            计算四元数的共轭\r\n            \r\n","specifying the termination criteria of the iterative search algorithm (after the specified maximum number of iterations criteria.maxCount or when the search window moves by less than criteria.epsilon.":"指定迭代搜索算法的终止条件（在指定的最大迭代次数 criteria.maxCount 之后或当搜索窗口移动小于 criteria.epsilon 时。\r\n","Maximal radius of the circles to search for. By default the maximal radius is set to max(image_width, image_height). ":"要搜索的圆的最大半径。默认情况下，最大半径设置为 max(image_width, image_height)。\r\n","\r\n            Load the cascade classifier from a file node\r\n            ":"\r\n            从文件节点加载级联分类器\r\n            \r\n","3x3 floating-point transformation matrix.":"3x3 浮点变换矩阵。\r\n","Value added to the scaled source array elements":"添加到缩放的源数组元素的值\r\n","\r\n            In\r\n            ":"\r\n            在\r\n            \r\n","Output 3x4 projection matrix in the new (rectified) coordinate systems for the second camera.":"在新的（修正的）坐标系中为第二台摄像机输出 3x4 投影矩阵。\r\n","how many leafs to visit when searching for neighbors (-1 for unlimited)":"搜索邻居时要访问多少叶子（-1 表示无限制）\r\n"," Is a number between 0 and 1 specifying the percentage of the approximate nearest-neighbor searches that return the exact nearest-neighbor. Using a higher value for this parameter gives more accurate results, but the search takes longer. The optimum value usually depends on the application.":" 是一个介于 0 和 1 之间的数字，指定返回精确最近邻的近似最近邻搜索的百分比。为该参数使用更高的值可提供更准确的结果，但搜索时间更长。最佳值通常取决于应用。\r\n","The cluster centers":"聚类中心\r\n"," \r\n            Perform an binary XOR operation with some color\r\n            ":" \r\n            对某种颜色进行二元异或运算\r\n            \r\n","\r\n            Finds an object pose from 3 3D-2D point correspondences.\r\n            ":"\r\n            从 3 个 3D-2D 点对应中找到一个对象姿势。\r\n            \r\n","\r\n            Merges images.\r\n            ":"\r\n            合并图像。\r\n            \r\n","Number of period along the patterns direction.":"沿形态方向的周期数。\r\n","The local path of the file":"文件的本地路径\r\n","\r\n            CS\r\n            ":"\r\n            CS\r\n            \r\n","\r\n            Create an empty standard vector of TesseractResult\r\n            ":"\r\n            创建 TesseractResult 的空标准向量\r\n            \r\n","\r\n            Linearization transformation type.\r\n            ":"\r\n            线性化变换类型。\r\n            \r\n","\r\n            Upsample via neural network.\r\n            ":"\r\n            通过神经网络上采样。\r\n            \r\n","First image. Supports CV_8UC4 , CV_16UC4 , CV_32SC4 and CV_32FC4 types.":"第一张图片。支持 CV_8UC4 、 CV_16UC4 、 CV_32SC4 和 CV_32FC4 类型。\r\n","Original paper is here: http://davheld.github.io/GOTURN/GOTURN.pdf As long as original authors implementation: https://github.com/davheld/GOTURN#train-the-tracker Implementation of training algorithm is placed in separately here due to 3d-party dependencies: https://github.com/Auron-X/GOTURN_Training_Toolkit GOTURN architecture goturn.prototxt and trained model goturn.caffemodel are accessible on opencv_extra GitHub repository.":"原论文在这里：http://davheld.github.io/GOTURN/GOTURN.pdf 只要原作者实现：https://github.com/davheld/GOTURN#train-the-tracker 放置训练算法的实现由于 3d 方依赖性，此处单独列出：https://github.com/Auron-X/GOTURN_Training_Toolkit GOTURN 架构 goturn.prototxt 和训练模型 goturn.caffemodel 可在 opencv_extra GitHub 存储库上访问。\r\n","\r\n            Sync sequence numbers\r\n            ":"\r\n            同步序列号\r\n            \r\n","Radius of the cylinder.":"圆柱体的半径。\r\n","The number of octave layers.":"八度音程层数。\r\n","\r\n            Create a mat header for the specific ROI\r\n            ":"\r\n            为特定的 ROI 创建垫头\r\n            \r\n","filtering image with any numbers of channels.":"使用任意数量的通道过滤图像。\r\n","Pointer to cv::gpu::TemplateMatching":"指向 cv::gpu::TemplateMatching 的指针\r\n","The x value to be offseted":"要偏移的 x 值\r\n","\r\n            Returns true if the node is a \"none\" object\r\n            ":"\r\n            如果节点是“无”对象，则返回 true\r\n            \r\n","\r\n            The pointer to the unmanaged Algorithm object\r\n            ":"\r\n            指向非托管算法对象的指针\r\n            \r\n","True if the size matches":"如果大小匹配则为真\r\n","\r\n            Compute the minimum and maximum value from the points\r\n            ":"\r\n            计算点的最小值和最大值\r\n            \r\n","\r\n            If set, the function checks that every value of array is within [minVal,maxVal) range, otherwise it just checks that every element is neither NaN nor Infinity\r\n            ":"\r\n            如果设置，该函数检查数组的每个值是否在 [minVal,maxVal) 范围内，否则它只检查每个元素既不是 NaN 也不是 Infinity\r\n            \r\n","Text file contains network configuration":"文本文件包含网络配置\r\n","\r\n            Get the pointer to the frame source\r\n            ":"\r\n            获取指向帧源的指针\r\n            \r\n","\r\n            stepDecreasingPower of a SVMSGD optimization problem\r\n            ":"\r\n            SVMSGD 优化问题的 stepDecreasingPower\r\n            \r\n","y coordinate of the image pixel.":"图像像素的 y 坐标。\r\n","The output array to copy to":"要复制到的输出数组\r\n","\r\n            FPS\r\n            ":"\r\n            第一人称射击\r\n            \r\n","\r\n            The MCvMatND structure\r\n            ":"\r\n            MCvMatND 结构\r\n            \r\n","\r\n            The position in meters\r\n            ":"\r\n            以米为单位的位置\r\n            \r\n","\r\n            Expr\r\n            ":"\r\n            表达式\r\n            \r\n","Aperture size.":"光圈大小。\r\n","The output array; in-place operation is supported":"输出数组；支持就地操作\r\n","\r\n            Calculates one or more integral images for the source image\r\n            ":"\r\n            计算源图像的一个或多个积分图像\r\n            \r\n","The 2D Cross to be drawn":"要绘制的二维十字\r\n","The matrix to initialize. It should be single-channel 32-bit, integer or floating-point":"要初始化的矩阵。应该是单通道32位，整数或者浮点数\r\n","\r\n            Hole area ratio\r\n            ":"\r\n            孔面积比\r\n            \r\n"," Track whether Dispose has been called. ":" 跟踪是否已调用 Dispose。\r\n","\r\n            Get the specific column of the matrix\r\n            ":"\r\n            获取矩阵的特定列\r\n            \r\n","\r\n            Undefined\r\n            ":"\r\n            不明确的\r\n            \r\n","\r\n            More accurate for the case of linearly separable sets.\r\n            ":"\r\n            对于线性可分集的情况更准确。\r\n            \r\n","\r\n            Performs blocking upload data to GpuMat.\r\n            ":"\r\n            执行阻止上传数据到 GpuMat。\r\n            \r\n","Operation mask, 8-bit single channel GpuMat; specifies elements of destination GpuMat to be changed. Can be IntPtr.Zero if not used":"运算掩码，8位单通道GpuMat；指定要更改的目标 GpuMat 的元素。如果不使用可以是 IntPtr.Zero\r\n","gamma value for gamma correction":"伽玛校正的伽玛值\r\n","Output 3x3 camera intrinsic matrix A":"输出 3x3 相机固有矩阵 A\r\n","the thickness of the line":"线的粗细\r\n","The program source code":"程序源码\r\n","Order of multipliers":"乘数顺序\r\n","True if successfully retrieve the preview image.":"如果成功检索预览图像，则为真。\r\n","0 if the word is invalid, non-zero if valid":"如果单词无效则为 0，如果有效则为非零\r\n","Neighbouring size is 2-size+1":"相邻尺寸为 2-size+1\r\n","The stitching status":"拼接状态\r\n","\r\n            Create an empty Image\r\n            ":"\r\n            创建一个空图像\r\n            \r\n","\r\n            Extremal Region Filter for the 1st stage classifier of N&M algorithm\r\n            ":"\r\n            N&M 算法第一阶段分类器的极值区域滤波器\r\n            \r\n","The maximum value":"最大值\r\n","\r\n            Create an standard vector of Point with the initial values\r\n            ":"\r\n            使用初始值创建 Point 的标准向量\r\n            \r\n","The optional value added to the filtered pixels before storing them in dst":"在将它们存储在 dst 之前添加到过滤像素的可选值\r\n","\r\n            Calculates exponent of every element of input array:\r\n            dst(I)=exp(src(I))\r\n            Maximum relative error is 7e-6. Currently, the function converts denormalized values to zeros on output\r\n            ":"\r\n            计算输入数组的每个元素的指数：\r\n            dst(I)=exp(源(I))\r\n            最大相对误差为 7e-6。目前，该函数在输出时将非规范化值转换为零\r\n            \r\n","\r\n            Creates CalibrateRobertson object.\r\n            ":"\r\n            创建 CalibrateRobertson 对象。\r\n            \r\n","The pointer to the raw data":"指向原始数据的指针\r\n","The images used for updating the face recognizer":"用于更新人脸识别器的图像\r\n","\r\n            OpenCL queue\r\n            ":"\r\n            OpenCL队列\r\n            \r\n","\r\n            Push multiple values from the other vector into this vector\r\n            ":"\r\n            将另一个向量中的多个值推入此向量\r\n            \r\n"," Selected ROIs.":" 选定的投资回报率。\r\n","\r\n            A vertical 1D box filter.\r\n            ":"\r\n            垂直一维盒式过滤器。\r\n            \r\n","ROI.Width * ColorType.Dimension":"ROI.Width * ColorType.Dimension\r\n","\r\n            Debug draw search lines onto an image\r\n            ":"\r\n            调试在图像上绘制搜索线\r\n            \r\n","\r\n            For help on using this class, take a look at the Motion Detection example\r\n            ":"\r\n            有关使用此类的帮助，请查看运动检测示例\r\n            \r\n","\r\n            Distance transform algorithm flags\r\n            ":"\r\n            距离变换算法标志\r\n            \r\n","\r\n            Convert XYZ color to RGB color\r\n            ":"\r\n            将 XYZ 颜色转换为 RGB 颜色\r\n            \r\n","\r\n            No change is made\r\n            ":"\r\n            没有做任何改变\r\n            \r\n","The MCvScalar":"MCv标量\r\n","Fill value":"填充值\r\n","\r\n            Divides a 4-channel matrix into 4 single-channel matrices.\r\n            ":"\r\n            将一个 4 通道矩阵分成 4 个单通道矩阵。\r\n            \r\n","The image to search in":"要搜索的图片\r\n","\r\n            Release the standard vector\r\n            ":"\r\n            释放标准载体\r\n            \r\n","\r\n            Cuda compute 3.5\r\n            ":"\r\n            Cuda 计算 3.5\r\n            \r\n","\r\n            Image inpainting.\r\n            ":"\r\n            图像修复。\r\n            \r\n","\r\n            Initialize the class with the 'Single stragegy' parameters\r\n            ":"\r\n            使用“单一策略”参数初始化类\r\n            \r\n","Usage flags":"使用标志\r\n","\r\n            Return the pointer to the Facemark object\r\n            ":"\r\n            返回指向 Facemark 对象的指针\r\n            \r\n","the particular array element":"特定的数组元素\r\n","\r\n            Android focal length\r\n            ":"\r\n            安卓焦距\r\n            \r\n","Minimum window size. Use Size.Empty for default, where it is set to the size of samples the classifier has been trained on (~20x20 for face detection)":"最小窗口大小。默认情况下使用 Size.Empty，它设置为分类器训练过的样本大小（人脸检测约为 20x20）\r\n","\r\n            Class implementing the Tree Based Morse Regions\r\n            ":"\r\n            实现基于树的莫尔斯区域的类\r\n            \r\n","Input blob":"输入 blob\r\n","\r\n            number of refinement stages\r\n            ":"\r\n            细化阶段数\r\n            \r\n","The y value to be offseted":"要偏移的 y 值\r\n","Amount of radial range division quantity.":"径向范围划分数量。\r\n","\r\n            True if the device use unified memory\r\n            ":"如果设备使用统一内存则为真\r\n            \r\n","\r\n            The type of descriptor\r\n            ":"\r\n            描述符类型\r\n            \r\n","\r\n            Perform quaternions linear interpolation\r\n            ":"\r\n            执行四元数线性插值\r\n            \r\n","path to the .pbtxt file that contains text graph definition in protobuf format. Resulting Net object is built by text graph using weights from a binary one that let us make it more flexible.":"包含 protobuf 格式的文本图定义的 .pbtxt 文件的路径。生成的 Net 对象是使用二进制权重的文本图构建的，这让我们使其更加灵活。\r\n","\r\n            Run the full-scale two-pass dynamic programming algorithm. It will consume O(W*H*numDisparities) bytes, which is large for 640x480 stereo and huge for HD-size pictures.\r\n            ":"\r\n            运行全面的两遍动态规划算法。它将消耗 O(W*H*numDisparities) 字节，这对于 640x480 立体图像来说很大，对于高清尺寸的图片来说很大。\r\n            \r\n","\r\n            Each matrix row is sorted in the ascending order.\r\n            ":"\r\n            每个矩阵行按升序排序。\r\n            \r\n",", should be either float or double":", 应该是 float 或 double\r\n","If true, the input angle is in degrees, otherwise in radian":"如果为真，则输入角度以度为单位，否则以弧度为单位\r\n","\r\n            Create an instance of DeepFlow optical flow algorithm.\r\n            ":"\r\n            创建一个 DeepFlow 光流算法实例。\r\n            \r\n","The third zero-based component of the element index ":"元素索引的第三个从零开始的组成部分\r\n","The type of location for the point":"点的位置类型\r\n","\r\n            The ID of the backend.\r\n            ":"\r\n            后台ID。\r\n            \r\n","Vector of output Mat objects to produce by the computation.":"由计算产生的输出 Mat 对象的向量。\r\n","\r\n            Custom svm kernel type\r\n            ":"\r\n            自定义 svm 内核类型\r\n            \r\n","\r\n            A point with Bgr color information\r\n            ":"\r\n            具有 Bgr 颜色信息的点\r\n            \r\n","\r\n            The return value for solveLP function\r\n            ":"\r\n            solveLP 函数的返回值\r\n            \r\n","The ith row of the GpuMat":"GpuMat 的第 i 行\r\n","Minimum area of boxes.":"盒子的最小面积。\r\n","list of identifiers for each corner in charucoCorners":"charucoCorners 中每个角的标识符列表\r\n","\r\n            Release all unmanaged memory associated with the NNetAndDataPackets.\r\n            ":"\r\n            释放与 NNetAndDataPackets 关联的所有非托管内存。\r\n            \r\n","The resized image":"调整后的图像\r\n","\r\n            Release all the unmanaged memory associated with this object.\r\n            ":"\r\n            释放与此对象关联的所有非托管内存。\r\n            \r\n","\r\n            Computes squared integral image \r\n            ":"\r\n            计算平方积分图像\r\n            \r\n","The area threshold to cause re-initialize":"重新初始化的区域阈值\r\n","Max aspect ratio of boxes.":"框的最大纵横比。\r\n","\r\n            Create 2D plot from data\r\n            ":"\r\n            从数据创建二维图\r\n            \r\n","The point to be multiplied":"要乘的点\r\n","\r\n            Create instance of DisparityWLSFilter and execute basic initialization routines. When using this method you will need to set-up the ROI, matchers and other parameters by yourself.\r\n            ":"\r\n            创建 DisparityWLSFilter 的实例并执行基本的初始化例程。使用此方法时，您需要自行设置 ROI、匹配器和其他参数。\r\n            \r\n","8-bit, single-channel grayscale input image.":"8 位单通道灰度输入图像。\r\n","\r\n            Chromaticity gamma\r\n            ":"\r\n            色度伽玛\r\n            \r\n","\r\n            Smartek Giganetix Ethernet Vision: frame offset Y\r\n            ":"\r\n            Smartek Giganetix Ethernet Vision：帧偏移 Y\r\n            \r\n","adjust the sampling window of detected keypoints 6.25f is default and fits for KAZE, SURF detected keypoints window ratio 6.75f should be the scale for SIFT detected keypoints window ratio 5.00f should be the scale for AKAZE, MSD, AGAST, FAST, BRISK keypoints window ratio 0.75f should be the scale for ORB keypoints ratio 1.50f was the default in original implementation":"调整检测到的关键点的采样窗口 6.25f 是默认值，适用于 KAZE、SURF 检测到的关键点窗口比率 6.75f 应该是 SIFT 检测到的关键点窗口比率的比例 5.00f 应该是 AKAZE、MSD、AGAST、FAST、BRISK 关键点的比例窗口比率 0.75f 应该是 ORB 关键点比率的比例 1.50f 是原始实现中的默认值\r\n","\r\n            Create a Random Number Generator.\r\n            ":"\r\n            创建一个随机数生成器。\r\n            \r\n","\r\n            White balance red coefficient\r\n            ":"\r\n            白平衡红色系数\r\n            \r\n","Second threshold for the hysteresis procedure.":"滞后程序的第二个阈值。\r\n","\r\n            OpenNI (for Kinect)\r\n            ":"\r\n            OpenNI（用于 Kinect）\r\n            \r\n","\r\n            Type of a SVM kernel\r\n            ":"\r\n            SVM 内核的类型\r\n            \r\n","\r\n            The target\r\n            ":"\r\n            目标\r\n            \r\n","\r\n            The pixel\r\n            ":"像素\r\n            \r\n"," \r\n            An array of single channel GpuMat where each item\r\n            in the array represent a single channel of the original GpuMat \r\n            ":" \r\n            单通道 GpuMat 数组，其中每个项目\r\n            数组中代表原始 GpuMat 的单个通道\r\n            \r\n","\r\n            If true then variable importance will be calculated\r\n            ":"\r\n            如果为真，则将计算变量重要性\r\n            \r\n","The other point":"另一点\r\n","The result GpuMat.":"结果 GpuMat。\r\n","\r\n            The coordinate of the upper corner\r\n            ":"\r\n            上角坐标\r\n            \r\n","\r\n            Pixels are weighted using contrast, saturation and well-exposedness measures, than images are combined using laplacian pyramids.\r\n            The resulting image weight is constructed as weighted average of contrast, saturation and well-exposedness measures.\r\n            The resulting image doesn't require tonemapping and can be converted to 8-bit image by multiplying by 255, but it's recommended to apply gamma correction and/or linear tonemapping.\r\n            ":"\r\n            使用对比度、饱和度和曝光度测量对像素进行加权，然后使用拉普拉斯金字塔组合图像。\r\n            生成的图像权重被构造为对比度、饱和度和曝光度测量值的加权平均值。\r\n            生成的图像不需要色调映射，可以通过乘以 255 转换为 8 位图像，但建议应用伽马校正和/或线性色调映射。\r\n            \r\n","the length of the markers' side. The returning translation vectors will be in the same unit. Normally, unit is meters.":"标记边的长度。返回的翻译向量将在同一个单元中。通常，单位是米。\r\n","\r\n            The matrix is reduced to a single row\r\n            ":"\r\n            矩阵减少为单行\r\n            \r\n","\r\n            IPL_DEPTH\r\n            ":"\r\n            IPL_DEPTH\r\n            \r\n","cGrid":"网格\r\n","\r\n            Unsupported format\r\n            ":"\r\n            不支持的格式\r\n            \r\n"," The radius of this circle ":" 这个圆的半径\r\n","\r\n            Finds global minimum and maximum matrix elements and returns their values with locations.\r\n            ":"\r\n            查找全局最小和最大矩阵元素并返回它们的值和位置。\r\n            \r\n","\r\n            Pointer to the unmanaged Saliency object\r\n            ":"\r\n            指向非托管 Saliency 对象的指针\r\n            \r\n","\r\n            Release the unmanaged memory associated with this EigenFaceRecognizer\r\n            ":"\r\n            释放与此 EigenFaceRecognizer 关联的非托管内存\r\n            \r\n","\r\n            Release all the unmanaged memory associate with this Canny edge detector.\r\n            ":"\r\n            释放与此 Canny 边缘检测器关联的所有非托管内存。\r\n            \r\n","Source chessboard view":"源棋盘视图\r\n","computed flow image that has the same size as I0 and type CV_32FC2.":"与 I0 大小相同且类型为 CV_32FC2 的计算流图像。\r\n","Scalar to be subtracted.":"要减去的标量。\r\n","  \r\n            next_o, next_d, vtx_o, vtx_d \r\n            ":"  \r\n            next_o, next_d, vtx_o, vtx_d\r\n            \r\n","Input image, 1- or 3-channel, Byte or Single (each channel of multi-channel image is processed independently). ":"输入图像，1 通道或 3 通道，字节或单通道（多通道图像的每个通道独立处理）。\r\n","The number of level's for the pyramid; Level 0 referes to the current image, level n is computed by calling the PyrDown() function on level n-1":"金字塔的层数；第 0 层指的是当前图像，第 n 层是通过调用第 n-1 层上的 PyrDown() 函数计算的\r\n","\r\n            A vertical or horizontal Scharr operator.\r\n            ":"\r\n            垂直或水平 Scharr 算子。\r\n            \r\n","\r\n            The weight of the shape context distance in the final distance value.\r\n            ":"\r\n            形状上下文距离在最终距离值中的权重。\r\n            \r\n","\r\n            Convert RGBA to YUV_IYUV\r\n            ":"\r\n            RGBA转YUV_IYUV\r\n            \r\n","\r\n            train it on positive features compute the mace filter: h = D(-1) * X * (X(+) * D(-1) * X)(-1) * C also calculate a minimal threshold for this class, the smallest self-similarity from the train images\r\n            ":"\r\n            在正特征上训练它 计算 mace 过滤器： h = D(-1) * X * (X(+) * D(-1) * X)(-1) * C 还计算此类的最小阈值，火车图像的最小自相似性\r\n            \r\n"," The flipped copy of ":" 的翻转副本\r\n"," \r\n            Dispose(bool disposing) executes in two distinct scenarios.\r\n            If disposing equals true, the method has been called directly\r\n            or indirectly by a user's code. Managed and unmanaged resources\r\n            can be disposed.\r\n            If disposing equals false, the method has been called by the\r\n            runtime from inside the finalizer and you should not reference\r\n            other objects. Only unmanaged resources can be disposed.\r\n            ":" \r\n            Dispose(bool disposing) 在两个不同的场景中执行。\r\n            如果 disposing 等于 true，则直接调用了该方法\r\n            或间接通过用户代码。托管和非托管资源\r\n            可以处置。\r\n            如果 disposing 等于 false，则该方法已被调用\r\n            来自终结器内部的运行时，你不应该引用\r\n            其他对象。只能释放非托管资源。\r\n            \r\n","\r\n            Applies fixed-level thresholding to single-channel array. The function is typically used to get bi-level (binary) image out of grayscale image or for removing a noise, i.e. filtering out pixels with too small or too large values. There are several types of thresholding the function supports that are determined by thresholdType\r\n            ":"\r\n            将固定级别的阈值应用于单通道阵列。该函数通常用于从灰度图像中获取二值（二进制）图像或用于去除噪声，即过滤掉值太小或太大的像素。函数支持的阈值类型有多种，由 thresholdType 决定\r\n            \r\n"," + alpha*img\r\n            ":" + 阿尔法*img\r\n            \r\n","The index to the Mat data":"Mat数据的索引\r\n","Specifies the image scale (!1) to build the pyramids for each image. pyrScale=0.5 means the classical pyramid, where each next layer is twice smaller than the previous":"指定图像比例 (!1) 以构建每个图像的金字塔。 pyrScale=0.5 表示经典金字塔，其中每个下一层都比前一层小两倍\r\n","\r\n            Get the dimension of this color\r\n            ":"\r\n            得到这个颜色的维度\r\n            \r\n","\r\n            Pointer to the unmanaged RotationWarper object\r\n            ":"\r\n            指向非托管 RotationWarper 对象的指针\r\n            \r\n","The labels of the images.":"图片的标签。\r\n","\r\n            the type of flipping\r\n            ":"\r\n            翻转的类型\r\n            \r\n","\r\n            Shuffles the matrix by swapping randomly chosen pairs of the matrix elements on each iteration (where each element may contain several components in case of multi-channel arrays)\r\n            ":"\r\n            通过在每次迭代中交换随机选择的矩阵元素对来打乱矩阵（在多通道数组的情况下，每个元素可能包含多个组件）\r\n            \r\n","A 0-based column index.":"从 0 开始的列索引。\r\n","Color of the arrow.":"箭头的颜色。\r\n","\r\n            Algorithm type\r\n            ":"\r\n            算法类型\r\n            \r\n","Optional depth of the output matrix.":"输出矩阵的可选深度。\r\n","Angle resolution of the accumulator in radians.":"累加器的角度分辨率（以弧度为单位）。\r\n","Returns true if the Algorithm is empty. e.g. in the very beginning or after unsuccessful read.":"如果算法为空，则返回真。例如在一开始或阅读失败后。\r\n","\r\n            Convert some generic vector to vector of Bytes\r\n            ":"\r\n            将一些通用向量转换为字节向量\r\n            \r\n","\r\n            ChArUco board\r\n            ":"\r\n            炭黑板\r\n            \r\n","\r\n            Create an standard vector of KeyPoint of the specific size\r\n            ":"\r\n            创建特定大小的 KeyPoint 标准向量\r\n            \r\n","\r\n            Calculates the matrix of an affine transform such that:\r\n            (x'_i,y'_i)^T=map_matrix (x_i,y_i,1)^T\r\n            where dst(i)=(x'_i,y'_i), src(i)=(x_i,y_i), i=0..2.\r\n            ":"\r\n            计算仿射变换的矩阵，使得：\r\n            (x'_i,y'_i)^T=map_matrix (x_i,y_i,1)^T\r\n            其中 dst(i)=(x'_i,y'_i), src(i)=(x_i,y_i), i=0..2。\r\n            \r\n","\r\n            Represents a 3D visualizer window. \r\n            ":"\r\n            表示 3D 可视化窗口。\r\n            \r\n"," with the current image":" 与当前图像\r\n","Output array of image points, 1xN/Nx1 2-channel, or vector<Point2f>.":"输出图像点数组，1xN/Nx1 2 通道，或矢量<Point2f>。\r\n","Zero-based index of the ending column (exclusive) of the span":"跨度的结束列（不包括）的从零开始的索引\r\n","\r\n            Unmatched sizes\r\n            ":"\r\n            无与伦比的尺寸\r\n            \r\n","The type of data":"数据类型\r\n","\r\n            The code which is used for color conversion\r\n            ":"\r\n            用于颜色转换的代码\r\n            \r\n","Image to detect lines in.":"用于检测线的图像。\r\n","\r\n            Central Moment Mu21\r\n            ":"\r\n            中心矩 Mu21\r\n            \r\n"," Create a CIE Lab color using the specific values":" 使用特定值创建 CIE Lab 颜色\r\n","Do gamma correction preprocessing or not.":"是否进行伽玛校正预处理。\r\n","\r\n            Interpolation types\r\n            ":"\r\n            插值类型\r\n            \r\n","\r\n            Create a norm based cost extraction.\r\n            ":"\r\n            创建基于规范的成本提取。\r\n            \r\n"," image by injecting even zero rows and columns and then convolves \r\n            result with the specified filter multiplied by 4 for interpolation. \r\n            So the resulting image is four times larger than the source image.\r\n            ":" 通过注入甚至零行和零列然后卷积的图像\r\n            将指定过滤器的结果乘以 4 进行插值。\r\n            因此生成的图像比源图像大四倍。\r\n            \r\n","Method for solving a PnP problem":"解决 PnP 问题的方法\r\n","The data type of the matrix":"矩阵的数据类型\r\n","The destination 2x3 matrix":"目标 2x3 矩阵\r\n","\r\n            Monetary\r\n            ":"\r\n            货币\r\n            \r\n","\r\n            Create a planar subdivision from the given points. The ROI is computed as the minimum bounding Rectangle for the input points\r\n            ":"\r\n            从给定的点创建平面细分。 ROI 计算为输入点的最小边界矩形\r\n            \r\n","\r\n            Auto format\r\n            ":"\r\n            自动格式化\r\n            \r\n","The calculated norm":"计算出的范数\r\n","The minimum values for each channel":"每个通道的最小值\r\n","Is used to specify the trade off between time (index build time and search time) and memory used by the index. A value less than 1 gives more importance to the time spent and a value greater than 1 gives more importance to the memory usage.":"用于指定时间（索引构建时间和搜索时间）和索引使用的内存之间的权衡。小于 1 的值更重视花费的时间，大于 1 的值更重视内存使用。\r\n","\r\n            Release the resource used by this object\r\n            ":"\r\n            释放此对象使用的资源\r\n            \r\n","The point to be checked":"要检查的点\r\n","Output ROI size":"输出 ROI 大小\r\n","\r\n            The matcher for computing the right-view disparity map that is required in case of filtering with confidence.\r\n            ":"用于计算有信心过滤时所需的右视视差图的匹配器。\r\n            \r\n","\r\n            Using brute force\r\n            ":"\r\n            使用蛮力\r\n            \r\n","\r\n            Luminosity gamma\r\n            ":"\r\n            亮度伽玛\r\n            \r\n","\r\n            Interface to the TesseractResultRender\r\n            ":"\r\n            TesseractResultRender 的接口\r\n            \r\n","Result of the divide operation":"除法运算的结果\r\n","\r\n            Cuda compute 1.0\r\n            ":"\r\n            Cuda计算1.0\r\n            \r\n","\r\n            Convert Bayer RG to BGRA \r\n            ":"\r\n            将 Bayer RG 转换为 BGRA\r\n            \r\n","\r\n            Extension methods for IInputArrays\r\n            ":"\r\n            IInputArrays 的扩展方法\r\n            \r\n","Prototxt file path for the detector":"检测器的 Prototxt 文件路径\r\n","\r\n            OpenCV's KeyPoint class\r\n            ":"\r\n            OpenCV 的 KeyPoint 类\r\n            \r\n","\r\n            Do not apply transpose to neither matrices\r\n            ":"\r\n            不要对两个矩阵都应用转置\r\n            \r\n","Size of the image used for stereo calibration":"用于立体校准的图像大小\r\n","\r\n            The Gravity Center of this Moment\r\n            ":"\r\n            这一刻的重心\r\n            \r\n","The triangles subdivision in the current planar subdivision":"当前平面细分中的三角形细分\r\n","The size of the input array":"输入数组的大小\r\n","Order of the derivative x ":"导数 x 的阶数\r\n","The output value":"输出值\r\n","\r\n            Managed structure equivalent to CvSlice\r\n            ":"\r\n            等效于 CvSlice 的托管结构\r\n            \r\n","The XmlWriter":"XmlWriter\r\n","\r\n            Set MiniBatchSize to a positive integer when using this method.\r\n            ":"\r\n            使用此方法时，将 MiniBatchSize 设置为正整数。\r\n            \r\n","\r\n            Line within a paragraph.\r\n            ":"\r\n            段落内的行。\r\n            \r\n","\r\n            Create a Mat header from existing data\r\n            ":"\r\n            从现有数据创建 Mat 标头\r\n            \r\n","Transposed matrix of right singular vectors.":"右奇异向量的转置矩阵。\r\n","The depth type of the image":"图片的深度类型\r\n","\r\n            The 2nd distortion coefficient (k2) is fixed to 0 or to the initial passed value if CV_CALIB_USE_INTRINSIC_GUESS is passed\r\n            ":"\r\n            如果传递了 CV_CALIB_USE_INTRINSIC_GUESS，则第二个失真系数 (k2) 固定为 0 或初始传递值\r\n            \r\n","The output image of the same format and the same size as input":"与输入相同格式和相同大小的输出图像\r\n","Destination GpuMat. The same source and type as ":"目标 GpuMat。与相同的来源和类型\r\n","Even if it returns true this doesn't ensure that the property value has been accepted by the capture device.":"即使它返回 true，也不能确保属性值已被捕获设备接受。\r\n","Scalar value to subtracted.":"要减去的标量值。\r\n"," Get or Set the center of the circle ":" 获取或设置圆心\r\n","Output for the 1st stage and Input/Output for the 2nd. The selected Extremal Regions are stored here.":"第一阶段的输出和第二阶段的输入/输出。选定的极值区域存储在这里。\r\n",". The data is shared between the two GpuMat\r\n            ":".数据在两个 GpuMat 之间共享\r\n            \r\n","\r\n            The url where this file can be downloaded from\r\n            ":"\r\n            可以从中下载此文件的 url\r\n            \r\n","The image that is used to update the background model":"用于更新背景模型的图像\r\n","Allows to specify API backends to use. Use 0 if you don't have any specific preference.":"允许指定要使用的 API 后端。如果您没有任何特定偏好，请使用 0。\r\n","\r\n            Y,V,U (4:2:0)\r\n            ":"\r\n            Y,V,U (4:2:0)\r\n            \r\n","\r\n            StdVector\r\n            ":"\r\n            标准向量\r\n            \r\n","\r\n            Convert YUV (YVYU) to RGBA\r\n            ":"\r\n            将 YUV (YVYU) 转换为 RGBA\r\n            \r\n","\r\n            Bundle adjuster that expects affine transformation represented in homogeneous coordinates in R for each camera param. Implements camera parameters refinement algorithm which minimizes sum of the reprojection error squares.\r\n            ":"\r\n            束调整器期望每个相机参数在 R 中以齐次坐标表示的仿射变换。实现相机参数细化算法，使重投影误差平方和最小化。\r\n            \r\n","\r\n            The function constructs a vector of images and builds the Gaussian pyramid by recursively applying pyrDown to the previously built pyramid layers, starting from dst[0]==src.\r\n            ":"\r\n            该函数构造图像向量并通过递归地将 pyrDown 应用于先前构建的金字塔层来构建高斯金字塔，从 dst[0]==src 开始。\r\n            \r\n","\r\n            Create a binary File Storage\r\n            ":"\r\n            创建二进制文件存储\r\n            \r\n","The number of rows taken into consideration ROI":"考虑 ROI 的行数\r\n","The function to be applied to the image pixels":"应用于图像像素的函数\r\n"," The width of the Gaussian kernel":" 高斯核的宽度\r\n","vector of distortion coefficients, 4, 5, 8 or 12 elements":"失真系数向量，4、5、8 或 12 个元素\r\n","\r\n            Element wise add ":"\r\n            元素明智地添加\r\n","\r\n            Find Candidates Approx Poly DP Eps Multiplier\r\n            ":"\r\n            查找候选人近似 Poly DP Eps 乘数\r\n            \r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are less than the scalar value.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否小于标量值。\r\n            \r\n","\r\n            Checks if array elements lie between two scalars.\r\n            ":"\r\n            检查数组元素是否位于两个标量之间。\r\n            \r\n","\r\n            Create a default RFFeatureGetter\r\n            ":"\r\n            创建一个默认的 RFFeatureGetter\r\n            \r\n","Performs lines sort by votes.":"按投票执行行排序。\r\n","\r\n            Create an empty GpuMat\r\n            ":"\r\n            创建一个空的 GpuMat\r\n            \r\n","The quality level":"品质等级\r\n","\r\n            Ocl Device Type\r\n            ":"\r\n            Ocl 设备类型\r\n            \r\n","\r\n            Summation over a pixel param1 x param2 neighborhood with subsequent scaling by 1/(param1 x param2)\r\n            ":"\r\n            对像素 param1 x param2 邻域求和，随后缩放 1/(param1 x param2)\r\n            \r\n","The bounding box that represent the new target location, if true was returned, not modified otherwise":"表示新目标位置的边界框，如果返回 true，否则不修改\r\n","\r\n            Applies the bilateral texture filter to an image. It performs structure-preserving texture filter. \r\n            ":"\r\n            将双边纹理过滤器应用于图像。它执行结构保留纹理过滤器。\r\n            \r\n","The multi-channel gpuMat":"多通道 gpuMat\r\n","The first 8-bit single-channel input image":"第一个8位单通道输入图像\r\n","\r\n            Acquisition buffer size unit in bytes. Default 1. E.g. Value 1024 means that buffer_size is in KiBytes\r\n            ":"\r\n            以字节为单位的采集缓冲区大小单位。默认 1。值 1024 表示 buffer_size 以千字节为单位\r\n            \r\n","\r\n            Applies range-level thresholding to a single- or multiple-channel matrix. It sets output pixel value to OxFF if the corresponding pixel value of input matrix is in specified range,or 0 otherwise.\r\n            ":"\r\n            将范围级阈值应用于单通道或多通道矩阵。如果输入矩阵的相应像素值在指定范围内，则将输出像素值设置为 OxFF，否则为 0。\r\n            \r\n","\r\n            Kind of training method to be applied\r\n            ":"\r\n            适用的训练方法\r\n            \r\n","\r\n            LOGOS (Local geometric support for high-outlier spatial verification) feature matching strategy\r\n            ":"\r\n            LOGOS（Local geometric support for high-outlier spatial verification）特征匹配策略\r\n            \r\n","The power":"动力\r\n","\r\n            number of bits (per dimension) for each cell of the marker when removing the perspective (default 8).\r\n            ":"\r\n            删除透视图时标记的每个单元格的位数（每个维度）（默认为 8）。\r\n            \r\n","The input symmetric square matrix, modified during the processing":"输入对称方阵，在处理过程中修改\r\n","Optional depth of the output array.":"输出数组的可选深度。\r\n","\r\n            Create an standard vector of OclPlatformInfo of the specific size\r\n            ":"\r\n            创建特定大小的 OclPlatformInfo 标准向量\r\n            \r\n","\r\n            Read the model from the given path.\r\n            ":"\r\n            从给定路径读取模型。\r\n            \r\n","\r\n            Create an standard vector of TesseractResult of the specific size\r\n            ":"\r\n            创建特定大小的 TesseractResult 的标准向量\r\n            \r\n","Grayscale or color (BGR) image containing QR codes.":"包含二维码的灰度或彩色 (BGR) 图像。\r\n","\r\n            Release the unmanaged memory associated with this FrameSource\r\n            ":"\r\n            释放与此 FrameSource 关联的非托管内存\r\n            \r\n","Type of the created matrices that should be Cv32F or Cv64F":"创建的矩阵类型应为 Cv32F 或 Cv64F\r\n","\r\n            Create a capture from file or a video stream\r\n            ":"\r\n            从文件或视频流创建捕获\r\n            \r\n","\r\n            Normalizes the norm or value range of an array\r\n            ":"\r\n            规范化数组的范数或值范围\r\n            \r\n","\r\n            Create an standard vector of Byte of the specific size\r\n            ":"\r\n            创建特定大小的标准字节向量\r\n            \r\n","number of iterations used for filtering, 3 is usually enough.":"用于过滤的迭代次数，通常 3 次就足够了。\r\n","Rotation vector used to initialize an iterative PnP refinement algorithm, when flag is SOLVEPNP_ITERATIVE and useExtrinsicGuess is set to true.":"当标志为 SOLVEPNP_ITERATIVE 且 useExtrinsicGuess 设置为 true 时，用于初始化迭代 PnP 细化算法的旋转向量。\r\n","The size of the hash key in bits (between 10 and 20 usually).":"哈希键的大小（通常在 10 到 20 位之间）。\r\n","Whether to use camera motion compensation.":"是否使用相机运动补偿。\r\n","\r\n            The value of the outer radius.\r\n            ":"\r\n            外半径的值。\r\n            \r\n","\r\n            Convert YUV (UYNV) to BGR\r\n            ":"\r\n            将 YUV (UYNV) 转换成 BGR\r\n            \r\n","The triangle's area":"三角形的面积\r\n","The skew coefficient.":"偏斜系数。\r\n","The name of the tesseract variable. e.g. use \"tessedit_char_blacklist\" to black list characters and \"tessedit_char_whitelist\" to white list characters. The full list of options can be found in the Tesseract OCR source code \"tesseractclass.h\"":"tesseract 变量的名称。例如使用“tessedit_char_blacklist”将字符列入黑名单，使用“tessedit_char_whitelist”将字符列入白名单。完整的选项列表可以在 Tesseract OCR 源代码“tesseractclass.h”中找到\r\n","\r\n            Intelperc Profile Idx\r\n            ":"\r\n            Intelperc 配置文件 IDx\r\n            \r\n","Per-element sum of matrix and given scalar.":"矩阵和给定标量的每个元素总和。\r\n"," Perform an binary AND operation with some color using a mask":" 使用掩码对某种颜色执行二元与运算\r\n","The number of bins in this 1-D histogram. ":"此一维直方图中的 bin 数。\r\n","prototxt file path for the super resolution model":"超分辨率模型的 prototxt 文件路径\r\n","The second signature.":"第二个签名。\r\n","The interpolated point":"插值点\r\n","\r\n            Confidence threshold\r\n            ":"\r\n            置信度阈值\r\n            \r\n","The image where model and observed image is displayed side by side. Matches are drawn as indicated by the flag":"并排显示模型和观察图像的图像。比赛如旗帜所示绘制\r\n","\r\n            The confidence\r\n            ":"\r\n            信心\r\n            \r\n","\r\n            32bit float (Single)\r\n            ":"\r\n            32 位浮点数（单）\r\n            \r\n"," The source image, grayscale or colored of type CV_8UC1 or CV_8UC3":" CV_8UC1 或 CV_8UC3 类型的源图像，灰度或彩色\r\n","\r\n            This function compare the current matrix with ":"\r\n            此函数将当前矩阵与\r\n","First input GMat of the defined binary computation":"定义的二进制计算的第一个输入 GMat\r\n","A matrix that is the horizontal concatening of this matrix and ":"一个矩阵，它是该矩阵的水平串联和\r\n","\r\n            Finds circles in grayscale image using some modification of Hough transform\r\n            ":"\r\n            使用 Hough 变换的一些修改在灰度图像中查找圆圈\r\n            \r\n","\r\n            Estimates extrinsic camera parameters using known intrinsic parameters and extrinsic parameters for each view. The coordinates of 3D object points and their correspondent 2D projections must be specified. This function also minimizes back-projection error. \r\n            ":"使用已知的内部参数和每个视图的外部参数来估计外部相机参数。必须指定 3D 对象点的坐标及其对应的 2D 投影。此功能还可以最大限度地减少反投影误差。\r\n            \r\n","Second input image of the same size and the same type as ":"相同大小和相同类型的第二个输入图像\r\n","\r\n            for 7-point algorithm. N == 7\r\n            ":"\r\n            对于 7 点算法。 N == 7\r\n            \r\n","\r\n            Create the standard vector of VectorOfPoint \r\n            ":"\r\n            创建 VectorOfPoint 的标准向量\r\n            \r\n","Block size. If you leave default value Size(0,0) then automatic estimation of block size will be used (which is optimized for speed). By varying user_block_size you can reduce memory requirements at the cost of speed.":"块大小。如果您保留默认值 Size(0,0)，则将使用块大小的自动估计（针对速度进行了优化）。通过改变 user_block_size，您可以以速度为代价来减少内存需求。\r\n","\r\n            Create a text representation for a binary network stored in protocol buffer format.\r\n            ":"\r\n            为以协议缓冲区格式存储的二进制网络创建文本表示。\r\n            \r\n","\r\n            Set the number of split points from bezier-curve to line. If you want to draw large glyph, large is better. If you want to draw small glyph, small is better.\r\n            ":"\r\n            设置从贝塞尔曲线到直线的分割点数。如果你想画大字形，大的更好。如果你想画小字形，小的更好。\r\n            \r\n","True if grid found.":"如果找到网格则为真。\r\n","\r\n            Create Hausdorff distance extractor\r\n            ":"\r\n            创建 Hausdorff 距离提取器\r\n            \r\n","Double pointer to the matrix.":"指向矩阵的双指针。\r\n","Admm iterations":"管理迭代\r\n","\r\n            A rectangular element.\r\n            ":"\r\n            一个矩形元素。\r\n            \r\n","Stopping criterion threshold used in the numerical scheme, which is a trade-off between precision and running time. A small value will yield more accurate solutions at the expense of a slower convergence.":"数值方案中使用的停止准则阈值，这是精度和运行时间之间的权衡。较小的值将以较慢的收敛为代价产生更准确的解决方案。\r\n"," and the accumulator acc so that acc becomes a running average of frame sequence:\r\n            acc(x,y)=(1-":" 和累加器 acc 使 acc 成为帧序列的运行平均值：\r\n            acc(x,y)=(1-\r\n","Suppressed image (grayscale, float, in [0;1])":"抑制图像（灰度，浮点数，在 [0;1] 中）\r\n","\r\n            Convert YUV (YUYV) to RGB\r\n            ":"\r\n            将 YUV (YUYV) 转换为 RGB\r\n            \r\n","file format, can be .xml or .yml":"文件格式，可以是 .xml 或 .yml\r\n","output image depth":"输出图像深度\r\n","\r\n            This represent a file that can be downloaded from the internet\r\n            ":"\r\n            这表示可以从 Internet 下载的文件\r\n            \r\n","Vector of rejected candidates during the marker detection process":"标记检测过程中被拒绝候选者的向量\r\n","\r\n            Pointer to cv::cuda::denseOpticalFlow\r\n            ":"\r\n            指向 cv::cuda::denseOpticalFlow 的指针\r\n            \r\n","\r\n            Standard bayer sampling\r\n            ":"标准拜耳取样\r\n            \r\n",") rows of the CudaImage. The data is shared with the current Image. \r\n            ":") CudaImage 的行。数据与当前图像共享。\r\n            \r\n","\r\n            Divides a 3-channel matrix into 3 single-channel matrices.\r\n            ":"将一个 3 通道矩阵分成 3 个单通道矩阵。\r\n            \r\n","The size of the Sobel kernel to be used.":"要使用的 Sobel 内核的大小。\r\n","\r\n            Weights (multiplicative constants) that linearly stretch individual axes of the feature space. (x,y = position. L,a,b = color in CIE Lab space. c = contrast. e = entropy)\r\n            ":"\r\n            线性拉伸特征空间的各个轴的权重（乘法常数）。 （x、y = 位置。L、a、b = CIE 实验室空间中的颜色。c = 对比度。e = 熵）\r\n            \r\n","\r\n            Create an instance of peak signal to noise ratio (PSNR) algorithm\r\n            ":"\r\n            创建峰值信噪比 (PSNR) 算法实例\r\n            \r\n","\r\n            Check if this quaternions equals to ":"\r\n            检查这个四元数是否等于\r\n","8-bit, single-channel binary source image. The image may be modified by the function.":"8 位、单通道二进制源图像。图像可能会被函数修改。\r\n","\r\n            Sinus\r\n            ":"\r\n            窦\r\n            \r\n","\r\n            RHO algorithm\r\n            ":"\r\n            RHO算法\r\n            \r\n","The size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, ... ":"用于计算像素阈值的像素邻域的大小：3, 5, 7, ...\r\n","\r\n            Class that contains entry points for the Mcc module.\r\n            ":"\r\n            包含 Mcc 模块入口点的类。\r\n            \r\n","\r\n            Segmentation with gpu\r\n            ":"\r\n            使用 gpu 分割\r\n            \r\n","First rectangle ":"第一个矩形\r\n","\r\n            Create an Image from unmanaged data. \r\n            ":"\r\n            从非托管数据创建图像。\r\n            \r\n","The UMat to be swapped":"要交换的 UMat\r\n","\r\n            Create an standard vector of ERStat with the initial values\r\n            ":"\r\n            使用初始值创建 ERStat 的标准向量\r\n            \r\n","\r\n            Sets number of frames acquired by burst. This burst is used only if trigger is set to FrameBurstStart\r\n            ":"\r\n            设置突发获取的帧数。仅当触发器设置为 FrameBurstStart 时才使用此突发\r\n            \r\n","\r\n            Convert BGRA to YUV_YV12\r\n            ":"\r\n            BGRA转YUV_YV12\r\n            \r\n","Second input 2D point set.":"第二个输入二维点集。\r\n","\r\n            A Brute force matcher using Cuda\r\n            ":"\r\n            使用 Cuda 的蛮力匹配器\r\n            \r\n","\r\n            Stylization aims to produce digital imagery with a wide variety of effects not focused on photorealism. Edge-aware filters are ideal for stylization, as they can abstract regions of low contrast while preserving, or enhancing, high-contrast features.\r\n            ":"\r\n            程式化旨在生成具有各种效果的数字图像，而不是专注于照片写实主义。边缘感知滤镜是风格化的理想选择，因为它们可以抽象低对比度区域，同时保留或增强高对比度特征。\r\n            \r\n","Second input matrix.":"第二个输入矩阵。\r\n","Minimum possible number of rectangles minus 1. The threshold is used in a group of rectangles to retain it.":"最小可能的矩形数减1。阈值用于一组矩形以保留它。\r\n","Output array of detected corners.":"检测角点的输出数组。\r\n","\r\n            Dilates an image by using a specific structuring element.\r\n            ":"\r\n            通过使用特定的结构元素来膨胀图像。\r\n            \r\n","\r\n            The size of CvScalar\r\n            ":"\r\n            CvScalar 的大小\r\n            \r\n","slicSpixelSize":"切片像素大小\r\n","\r\n            The implementation is based on Designing Effective Inter-Pixel Information Flow for Natural Image Matting by Yağız Aksoy, Tunç Ozan Aydın and Marc Pollefeys, CVPR 2019.\r\n            ":"\r\n            该实现基于 Yağız Aksoy、Tunç Ozan Aydın 和 Marc Pollefeys 的 Designing Effective Inter-Pixel Information Flow for Natural Image Matting，CVPR 2019。\r\n            \r\n","\r\n            SVD algorithm is numerically robust and its typical applications include: \r\n            1. accurate eigenvalue problem solution when matrix A is square, symmetric and positively defined matrix, for example, when it is a covariation matrix. W in this case will be a vector of eigen values, and U=V is matrix of eigen vectors (thus, only one of U or V needs to be calculated if the eigen vectors are required) \r\n            2. accurate solution of poor-conditioned linear systems \r\n            3. least-squares solution of overdetermined linear systems. This and previous is done by cvSolve function with CV_SVD method \r\n            4. accurate calculation of different matrix characteristics such as rank (number of non-zero singular values), condition number (ratio of the largest singular value to the smallest one), determinant (absolute value of determinant is equal to the product of singular values). All the things listed in this item do not require calculation of U and V matrices. \r\n            ":"\r\n            SVD 算法具有数值鲁棒性，其典型应用包括：\r\n            1. 矩阵A为正方形对称正定义矩阵时特征值问题的准确求解，例如协变矩阵时。在这种情况下，W 将是特征值向量，而 U=V 是特征向量矩阵（因此，如果需要特征向量，则只需计算 U 或 V 之一）\r\n            2. 条件差的线性系统的精确求解\r\n            3. 超定线性系统的最小二乘解。这个和之前的是通过 cvSolve 函数用 CV_SVD 方法完成的\r\n            4. 准确计算秩（非零奇异值的个数）、条件数（最大奇异值与最小奇异值之比）、行列式（行列式的绝对值等于奇异值的乘积）等不同矩阵特征).此项中列出的所有内容都不需要计算 U 和 V 矩阵。\r\n            \r\n","\r\n            Convert YUV (YUNV) to Gray\r\n            ":"\r\n            将 YUV (YUNV) 转换为灰色\r\n            \r\n","\r\n            Pointer to the OutputArray\r\n            ":"\r\n            指向 OutputArray 的指针\r\n            \r\n","\r\n            Fix Taux Tauy\r\n            ":"\r\n            修复 Taux Tauy\r\n            \r\n","\r\n            Iterates to find the sub-pixel accurate location of corners, or radial saddle points\r\n            ":"\r\n            迭代以找到角或径向鞍点的亚像素精确位置\r\n            \r\n","Buffer containing the content of the the .weights file with learned network.":"包含学习网络的 .weights 文件内容的缓冲区。\r\n","\r\n            Will not do any normalization (default)\r\n            ":"\r\n            不会做任何规范化（默认）\r\n            \r\n","\r\n            Marr-Hildreth Operator Based Hash, slowest but more discriminative.\r\n            ":"\r\n            基于 Marr-Hildreth 运算符的哈希，最慢但更具辨别力。\r\n            \r\n","\r\n            L2 norm\r\n            ":"\r\n            L2范数\r\n            \r\n","Source image whose depth is 8-bit UINT or 32-bit FLOAT":"深度为 8 位 UINT 或 32 位 FLOAT 的源图像\r\n","\r\n            Distance resolution of the accumulator in pixels\r\n            ":"\r\n            累加器的距离分辨率（以像素为单位）\r\n            \r\n","y coordinate of second point (r2, s2) in the transformation function.":"变换函数中第二个点 (r2, s2) 的 y 坐标。\r\n","The number of disparities. Use 128 as default":"差距的数量。默认使用 128\r\n","First compared histogram.":"首先比较直方图。\r\n","\r\n            Applies an affine transformation to an image.\r\n            ":"\r\n            对图像应用仿射变换。\r\n            \r\n","Vector of outputs GMats for this computation":"此计算的输出向量 GMats\r\n","\r\n            Returns list of available backends which works via cv::VideoCapture(filename)\r\n            ":"\r\n            返回通过 cv::VideoCapture(filename) 工作的可用后端列表\r\n            \r\n","Kmeans initialization flag. Use PPCenters for default.":"Kmeans 初始化标志。默认使用 PPCenters。\r\n","The number of dilate iterations":"扩张迭代次数\r\n","\r\n            Scale the image to the specific size: width *= scale; height *= scale  \r\n            ":"\r\n            将图像缩放到特定尺寸：width *= scale；高度 * = 比例\r\n            \r\n","\r\n            Return the sum of the elements in this matrix\r\n            ":"返回此矩阵中元素的总和\r\n            \r\n","\r\n            Release the unmanaged memory associated with the RightMatcher\r\n            ":"\r\n            释放与 RightMatcher 关联的非托管内存\r\n            \r\n"," \r\n            Defines a HSV (Hue Satuation Value) color\r\n            ":" \r\n            定义 HSV（色调饱和度值）颜色\r\n            \r\n","The GpuMat where the result will be stored.":"将存储结果的 GpuMat。\r\n","\r\n            marginRegularization of a SVMSGD optimization problem\r\n            ":"\r\n            SVMSGD 优化问题的 marginRegularization\r\n            \r\n","output image with the board. The size of this image will be outSize and the board will be on the center, keeping the board proportions.":"用板输出图像。此图像的大小将超出尺寸，并且板将位于中心，保持板的比例。\r\n","separation between two markers (same unit than markerLenght)":"两个标记之间的间隔（与 markerLenght 相同的单位）\r\n","Input vector of N-dimensional points.":"N维点的输入向量。\r\n","Optional scale value for derivative values":"衍生值的可选比例值\r\n","2xN array of corresponding points in the second image. It can be also a vector of feature points or two-channel matrix of size 1xN or Nx1.":"第二张图片中对应点的 2xN 数组。它也可以是特征点向量或大小为 1xN 或 Nx1 的双通道矩阵。\r\n","\r\n            Release all unmanaged resources associated with this object\r\n            ":"\r\n            释放与此对象关联的所有非托管资源\r\n            \r\n","\r\n            The maximum work group size\r\n            ":"\r\n            最大工作组大小\r\n            \r\n","\r\n            Convert an xml string to an object\r\n            ":"\r\n            将 xml 字符串转换为对象\r\n            \r\n","\r\n            Vertical Decimation - vertical sub-sampling of the image - reduces the vertical resolution of the image by the specified vertical decimation factor.\r\n            ":"\r\n            垂直抽取 - 图像的垂直子采样 - 通过指定的垂直抽取因子降低图像的垂直分辨率。\r\n            \r\n","\r\n            In Premul\r\n            ":"\r\n            在 Premul\r\n            \r\n","\r\n            Write\r\n            ":"\r\n            写\r\n            \r\n","The size of the bilateral kernel":"双边核的大小\r\n","\r\n            Convert Bayer GRBG color to RGB color\r\n            ":"\r\n            将 Bayer GRBG 颜色转换为 RGB 颜色\r\n            \r\n","\r\n            Basic Face Recognizer\r\n            ":"\r\n            基本人脸识别器\r\n            \r\n","\r\n            Returns the number of non-zero elements in arr:\r\n            result = sumI arr(I)!=0\r\n            In case of IplImage both ROI and COI are supported.\r\n            ":"\r\n            返回 arr 中非零元素的数量：\r\n            结果 = sumI arr(I)!=0\r\n            如果是 IplImage，则同时支持 ROI 和 COI。\r\n            \r\n","Margin in percentage by which the best (minimum) computed cost function value should “win” the second best value to consider the found match correct. Normally, a value within the 5-15 range is good enough.":"以百分比表示的最佳（最小）计算成本函数值应“赢得”第二最佳值以认为找到的匹配正确的百分比。通常，5-15 范围内的值就足够了。\r\n","non-compressed descriptors of TrackerKCF::MODE":"TrackerKCF::MODE 的非压缩描述符\r\n","Dimensionality of the measurement.":"测量的维度。\r\n","\r\n            Convert this Mat to UMat\r\n            ":"\r\n            将此 Mat 转换为 UMat\r\n            \r\n"," The scaled matrix ":" 缩放矩阵\r\n","\r\n            Converts an image from BGR color space to RGB color space.\r\n            ":"\r\n            将图像从 BGR 颜色空间转换为 RGB 颜色空间。\r\n            \r\n","The string from the node":"来自节点的字符串\r\n","\r\n            The native pointer to the BasicFaceRecognizer object \r\n            ":"\r\n            指向 BasicFaceRecognizer 对象的本机指针\r\n            \r\n","The all-black images needed for shadowMasks computation.":"shadowMasks 计算所需的全黑图像。\r\n","\r\n            bitdepth of data returned by function xiGetImage\r\n            ":"\r\n            函数 xiGetImage 返回数据的位深度\r\n            \r\n","Array of pointers to polylines":"指向折线的指针数组\r\n","\r\n            Magma\r\n            ":"\r\n            岩浆\r\n            \r\n","\r\n            No Conv\r\n            ":"\r\n            无转化\r\n            \r\n","\r\n            Get the default tesseract ocr directory. This should return the folder of the dll in most situations.\r\n            ":"\r\n            获取默认的 tesseract ocr 目录。在大多数情况下，这应该会返回 dll 的文件夹。\r\n            \r\n","Input array. ":"输入数组。\r\n","\r\n            Perform first degree interpolation give the sorted data ":"\r\n            执行一次插值给出排序的数据\r\n","\r\n            Minimum Contour Points Allowed\r\n            ":"\r\n            允许的最小轮廓点\r\n            \r\n","The name of the file to be written to":"要写入的文件的名称\r\n","\r\n            Create an instance of Variational Refinement.\r\n            ":"\r\n            创建变分优化的一个实例。\r\n            \r\n","A HTML-formatted string with hOCR markup from the internal data structures.":"带有来自内部数据结构的 hOCR 标记的 HTML 格式的字符串。\r\n","The index for the property":"物业索引\r\n","The opencv depth type":"opencv深度类型\r\n","Path to the .onnx file with text description of the network architecture.":"带有网络架构文本描述的 .onnx 文件的路径。\r\n","Optional output values for corresponding neighbors. It is a single- precision floating-point matrix of <number_of_samples> * k size.":"相应邻居的可选输出值。它是 <number_of_samples> * k 大小的单精度浮点矩阵。\r\n","The image to be added to the current image":"要添加到当前图像的图像\r\n","\r\n            Create a Cuda cascade classifier using the specific file\r\n            ":"\r\n            使用特定文件创建 Cuda 级联分类器\r\n            \r\n","\r\n            Hellinger\r\n            ":"\r\n            海灵格\r\n            \r\n","The image loading type":"图片加载类型\r\n","\r\n            8-connected\r\n            ":"\r\n            8连\r\n            \r\n","\r\n            Blurs an image using the median filter.\r\n            ":"\r\n            使用中值滤波器模糊图像。\r\n            \r\n","\r\n            The type of color distance\r\n            ":"\r\n            色距类型\r\n            \r\n","\r\n            Stores algorithm parameters in a file storage\r\n            ":"\r\n            将算法参数存储在文件存储中\r\n            \r\n","The second image to AND":"AND 的第二个图像\r\n","\r\n            Convert the color palette to four lookup tables\r\n            ":"\r\n            将调色板转换为四个查找表\r\n            \r\n","The int value":"整数值\r\n","\r\n            Max time duration\r\n            ":"\r\n            最大持续时间\r\n            \r\n","The name of the backend.":"后端的名称。\r\n","Camera view image size in pixels.":"相机视图图像大小（以像素为单位）。\r\n"," The result of elementwise subtracting img2 from the current image, using the specific mask":" 使用特定掩码从当前图像中逐元素减去 img2 的结果\r\n","The depth type of the image to be written":"要写入的图像的深度类型\r\n","\r\n            Create parameters for simple blob detector and use default values.\r\n            ":"\r\n            为简单的斑点检测器创建参数并使用默认值。\r\n            \r\n","size of the image in pixels":"图像的大小（以像素为单位）\r\n","\r\n             when ddepth=-1, the destination image will have the same depth as the source; in the case of 8-bit input images it will result in truncated derivatives.":"\r\n             当 ddepth=-1 时，目标图像将与源图像具有相同的深度；在 8 位输入图像的情况下，它将导致导数被截断。\r\n","Network object that ready to do forward, throw an exception in failure cases.":"准备转发的网络对象，在失败的情况下抛出异常。\r\n","Number to be divided by.":"要除以的数。\r\n","Source MxN matrix":"源 MxN 矩阵\r\n","Image with fisheye lens distortion.":"鱼眼镜头失真的图像。\r\n","\r\n            Offset of roi\r\n            ":"\r\n            投资回报率的偏移量\r\n            \r\n","\r\n            return the norm of this 3D point\r\n            ":"\r\n            返回这个 3D 点的范数\r\n            \r\n","win size NCC, use (30, 30) for default":"win size NCC, 默认使用 (30, 30)\r\n","\r\n            Face Recognizer\r\n            ":"\r\n            人脸识别器\r\n            \r\n","\r\n            Point coincides with one of subdivision vertices\r\n            ":"\r\n            点与细分顶点之一重合\r\n            \r\n","Specify cost of non-edge pixels (default: 0.43f)":"指定非边缘像素的成本（默认值：0.43f）\r\n","Filtering image with unsigned 8-bit or floating-point 32-bit depth and up to 4 channels.":"具有无符号 8 位或浮点 32 位深度和最多 4 个通道的过滤图像。\r\n"," The height of this capture ":" 这次捕获的高度\r\n","alpha in: res = this * alpha + img2 * beta + gamma":"alpha 输入：res = this * alpha + img2 * beta + gamma\r\n","\r\n            This 3D Widget defines a cone.\r\n            ":"\r\n            这个 3D Widget 定义了一个圆锥体。\r\n            \r\n","\r\n            Update the background model\r\n            ":"\r\n            更新背景模型\r\n            \r\n","The size of a box that contains the specified text.":"包含指定文本的框的大小。\r\n","\r\n            This algorithm decomposes image into two layers: base layer and detail layer using bilateral filter and compresses contrast of the base layer thus preserving all the details.\r\n            This implementation uses regular bilateral filter from opencv.\r\n            ":"\r\n            该算法使用双边滤波器将图像分解为两层：基础层和细节层，并压缩基础层的对比度，从而保留所有细节。\r\n            此实现使用来自 opencv 的常规双边过滤器。\r\n            \r\n","\r\n            Calculates the normalized sum of squares of the pixel values overlapping the filter.\r\n            For every pixel(x, y) in the source image, the function calculates the sum of squares of those neighboring pixel values which overlap the filter placed over the pixel(x, y).\r\n            The unnormalized square box filter can be useful in computing local image statistics such as the the local variance and standard deviation around the neighborhood of a pixel.\r\n            ":"\r\n            计算与过滤器重叠的像素值的归一化平方和。\r\n            对于源图像中的每个像素（x，y），该函数计算与放置在像素（x，y）上的过滤器重叠的那些相邻像素值的平方和。\r\n            非归一化方框滤波器可用于计算局部图像统计信息，例如像素邻域周围的局部方差和标准差。\r\n            \r\n","path to the .prototxt file with text description of the network architecture.":"带有网络架构文本描述的 .prototxt 文件的路径。\r\n","\r\n            Convert YUV420sp to BGRA\r\n            ":"\r\n            将 YUV420sp 转换为 BGRA\r\n            \r\n","\r\n            Morphology operation type\r\n            ":"\r\n            形态运算类型\r\n            \r\n","The preferred Capture API backends to use. Can be used to enforce a specific reader implementation if multiple are available.":"要使用的首选 Capture API 后端。如果有多个可用，可用于强制执行特定的阅读器实现。\r\n","\r\n            Calculates the first, second, third, or mixed image derivatives using an extended Sobel operator.\r\n            ":"\r\n            使用扩展的 Sobel 算子计算一阶、二阶、三阶或混合图像导数。\r\n            \r\n","Resolution of the cone.":"圆锥的分辨率。\r\n","Vector of signatures to measure distance from the source signature.":"用于测量与源签名的距离的签名向量。\r\n","true if the two MCvScalar equals":"如果两个 MCvScalar 相等则为真\r\n","\r\n            Convert BGRA to YUV_I420\r\n            ":"\r\n            BGRA转YUV_I420\r\n            \r\n","Maximum octave evolution of the image":"图像的最大倍频程演变\r\n","Inclusive lower boundary":"包容性下界\r\n","The algorithm implements a novel interest point detector stemming from the intuition that image patches which are highly dissimilar over a relatively large extent of their surroundings hold the property of being repeatable and distinctive. This concept of \"contextual self-dissimilarity\" reverses the key paradigm of recent successful techniques such as the Local Self-Similarity descriptor and the Non-Local Means filter, which build upon the presence of similar - rather than dissimilar - patches. Moreover, it extends to contextual information the local self-dissimilarity notion embedded in established detectors of corner-like interest points, thereby achieving enhanced repeatability, distinctiveness and localization accuracy.":"该算法实现了一种新颖的兴趣点检测器，该检测器源于一种直觉，即在其周围环境中相对较大范围内高度不同的图像块具有可重复和独特的特性。这种“上下文自相异”的概念颠覆了最近成功技术的关键范式，例如局部自相似描述符和非局部均值过滤器，它们建立在相似而不是不同的补丁的存在之上。此外，它将嵌入在已建立的角状兴趣点检测器中的局部自差异概念扩展到上下文信息，从而实现增强的可重复性、独特性和定位精度。\r\n","First camera matrix.":"第一个相机矩阵。\r\n","\r\n            An Image is a wrapper to IplImage of OpenCV. \r\n            ":"\r\n            图像是 OpenCV 的 IplImage 的包装器。\r\n            \r\n","Mean value (expectation) of the generated random numbers.":"生成的随机数的平均值（期望值）。\r\n","\r\n            Features matcher which finds two best matches for each feature and leaves the best one only if the ratio between descriptor distances is greater than the threshold match_conf.\r\n            ":"\r\n            特征匹配器，它为每个特征找到两个最佳匹配，并且仅当描述符距离之间的比率大于阈值 match_conf 时才留下最佳匹配。\r\n            \r\n","Path to destination model with updated weights.":"具有更新权重的目标模型的路径。\r\n","\r\n            HistIntersect\r\n            ":"\r\n            历史相交\r\n            \r\n","Use hog":"使用猪\r\n","The image to apply reflection on":"应用反射的图像\r\n","Allocated output blobs, which will store results of the computation.":"分配的输出 blob，它将存储计算结果。\r\n","\r\n            Panini warper\r\n            ":"\r\n            帕尼尼整经机\r\n            \r\n","The number of columns for the convolution kernel":"卷积核的列数\r\n","Rotation angle":"旋转角度\r\n","spatial standard deviation.":"空间标准偏差。\r\n","The quaternions to be multiplied":"要相乘的四元数\r\n","\r\n            Create a Block Mean Hash object\r\n            ":"\r\n            创建一个 Block Mean Hash 对象\r\n            \r\n","\r\n            Capture from file using HighGUI\r\n            ":"\r\n            使用 HighGUI 从文件中捕获\r\n            \r\n","\r\n            Alpha premultiplication\r\n            ":"\r\n            阿尔法预乘\r\n            \r\n","\r\n            Convert GRAY color to BGR565 color\r\n            ":"\r\n            将 GRAY 颜色转换为 BGR565 颜色\r\n            \r\n","\r\n            8bit unsigned (Byte)\r\n            ":"\r\n            8 位无符号（字节）\r\n            \r\n","The mat to be written to the file":"要写入文件的垫\r\n","Input image: 8-bit unsigned 3-channel image":"输入图像：8 位无符号 3 通道图像\r\n","Index step in the row span. That is, the function extracts every delta_row-th row from start_row and up to (but not including) end_row":"行跨度中的索引步长。也就是说，该函数提取从 start_row 到（但不包括）end_row 的每个 delta_row 行\r\n","The exponent of power":"权力的指数\r\n","Calculated standard deviation":"计算的标准偏差\r\n","\r\n            Move to the next point\r\n            ":"\r\n            移动到下一个点\r\n            \r\n","Phase offset.":"相位偏移。\r\n","Input vector of a 2D point":"二维点的输入向量\r\n","\r\n            Create a new instance of BestOf2NearestRangeMatcher\r\n            ":"\r\n            创建 BestOf2NearestRangeMatcher 的新实例\r\n            \r\n","\r\n            The weight of the Bending Energy in the final distance value.\r\n            ":"\r\n            弯曲能量在最终距离值中的权重。\r\n            \r\n","\r\n            Inpaint type\r\n            ":"\r\n            修复型\r\n            \r\n","\r\n            Both detects and decodes barcode\r\n            ":"\r\n            检测和解码条形码\r\n            \r\n","\r\n            Convert BGR color to GRAY color\r\n            ":"\r\n            将 BGR 颜色转换为 GRAY 颜色\r\n            \r\n","\r\n            Returns the difference of two matrices.\r\n            ":"\r\n            返回两个矩阵的差值。\r\n            \r\n","The image rotates by the specific angle":"图像旋转特定角度\r\n","Result of the mask operation":"屏蔽操作的结果\r\n","The detected QRCode.":"检测到的二维码。\r\n","result intensity in [-8, 8] range. Greater intensity produces brighter results.":"结果强度在 [-8, 8] 范围内。更大的强度产生更明亮的结果。\r\n","Scalar, added to each sum. ":"标量，添加到每个总和。\r\n","order of the derivative x.":"导数 x 的阶数。\r\n","\r\n            Domain Transform filter type\r\n            ":"\r\n            域转换过滤器类型\r\n            \r\n","Lookup table for the R channel":"R通道的查找表\r\n",", 0 otherwise":", 0 否则\r\n","\r\n            Convert the standard vector to arrays of arrays of MCvERStat\r\n            ":"\r\n            将标准向量转换为 MCvERStat 数组的数组\r\n            \r\n","\r\n            Returns the minimum number N that is greater to equal to size0, such that DFT of a vector of size N can be computed fast. In the current implementation N=2^p x 3^q x 5^r for some p, q, r. \r\n            ":"\r\n            返回大于等于 size0 的最小数 N，这样可以快速计算大小为 N 的向量的 DFT。在当前实现中，对于某些 p、q、r，N=2^p x 3^q x 5^r。\r\n            \r\n","\r\n            Get the number of multiprocessors on device\r\n            ":"\r\n            获取设备上的多处理器数量\r\n            \r\n","\r\n            The inteface for reading a file into a Mat\r\n            ":"\r\n            将文件读入 Mat 的接口\r\n            \r\n","The build option":"构建选项\r\n","\r\n            W\r\n            ":"\r\n            W\r\n            \r\n","Pointer to aligned image data, ":"指向对齐图像数据的指针，\r\n","\r\n            Generate numbers uniformly.\r\n            ":"\r\n            统一生成数字。\r\n            \r\n","Vertical filter coefficients. Support kernels with size <= 32 .":"垂直滤波器系数。支持大小 <​​= 32 的内核。\r\n","\r\n            Create an empty standard vector of UMat\r\n            ":"\r\n            创建 UMat 的空标准向量\r\n            \r\n","\r\n            Create a LineIterator that can be used to get each pixel of a raster line.  The line will be clipped on the image boundaries\r\n            ":"\r\n            创建一个可用于获取栅格线的每个像素的 LineIterator。该线将被剪裁在图像边界上\r\n            \r\n","Size of the extracted patch.":"提取的补丁的大小。\r\n","Value used in case of a constant border. By default, it is 0.":"在常量边界的情况下使用的值。默认情况下，它是 0。\r\n","single-channel input image which should be warped with the final warpMatrix in order to provide an image similar to templateImage, same type as temlateImage.":"应使用最终 warpMatrix 进行变形的单通道输入图像，以提供类似于 templateImage 的图像，与 temlateImage 的类型相同。\r\n","\r\n            Ok\r\n            ":"\r\n            好的\r\n            \r\n","\r\n            Seq magic val\r\n            ":"\r\n            序列魔术值\r\n            \r\n","\r\n            Threshold for the minimal eigenvalue of the gradient matrix defines when to abort the iterative refinement.\r\n            ":"\r\n            梯度矩阵的最小特征值的阈值定义了何时中止迭代优化。\r\n            \r\n","Kernel size":"内核大小\r\n","The location of the QR code in the image":"二维码在图片中的位置\r\n","\r\n            Modified-Local Difference Binary (M-LDB)\r\n            ":"\r\n            修改局部差分二进制 (M-LDB)\r\n            \r\n","The 2x3 rotation matrix that defines the Affine transform":"定义仿射变换的 2x3 旋转矩阵\r\n","\r\n            Stride\r\n            ":"\r\n            步幅\r\n            \r\n","\r\n            Get or set the number of threads that are used by parallelized OpenCV functions\r\n            ":"\r\n            获取或设置并行化 OpenCV 函数使用的线程数\r\n            \r\n","activate the pca method to compress the features":"激活 pca 方法来压缩特征\r\n","\r\n            Create a geodetic coordinate using the specific values\r\n            ":"\r\n            使用特定值创建大地坐标\r\n            \r\n","\r\n            The constructors initialize video writer.\r\n            ":"\r\n            构造函数初始化视频编写器。\r\n            \r\n","Input aligned image":"输入对齐图像\r\n","\r\n            Vertical\r\n            ":"\r\n            垂直的\r\n            \r\n","The warper creator":"翘曲创造者\r\n","\r\n            Pointer to the native cv::reg::Map object\r\n            ":"\r\n            指向本机 cv::reg::Map 对象的指针\r\n            \r\n","\r\n            Provide interfaces to the Open CV DPM functions\r\n            ":"\r\n            为 Open CV DPM 函数提供接口\r\n            \r\n","\r\n            Fully automatic page segmentation, but no OSD.\r\n            ":"\r\n            全自动页面分割，但没有 OSD。\r\n            \r\n","the algorithm calculates the minimum eigen value of a 2x2 normal matrix of optical flow equations (this matrix is called a spatial gradient matrix in [Bouguet00]), divided by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding feature is filtered out and its flow is not processed, so it allows to remove bad points and get a performance boost.":"该算法计算光流方程的 2x2 法线矩阵（该矩阵在 [Bouguet00] 中称为空间梯度矩阵）的最小特征值，除以窗口中的像素数；如果该值小于 minEigThreshold，则过滤掉相应的特征并且不处理其流，因此可以去除坏点并提高性能。\r\n"," The color to OR":" OR 的颜色\r\n"," to the current image":" 到当前图像\r\n","Output image, 8-bit unsigned 1-channel":"输出图像，8 位无符号 1 通道\r\n","\r\n            Return true if every element of this matrix equals elements in ":"\r\n            如果此矩阵的每个元素都等于中的元素，则返回 true\r\n","\r\n            Xor Premul\r\n            ":"\r\n            异或预乘\r\n            \r\n","Interpolation used to compute the dense optical flow.":"用于计算密集光流的插值。\r\n","\r\n            Wrapped BFMatcher\r\n            ":"\r\n            包装 BFMatcher\r\n            \r\n","\r\n            Parula\r\n            ":"\r\n            帕鲁拉\r\n            \r\n","\r\n            Parameters for the FacemarkLBF model\r\n            ":"\r\n            FacemarkLBF 模型的参数\r\n            \r\n","The number of levels in the scale pyramid. ":"比例金字塔中的级别数。\r\n","Size in pixels of the window that is used to perform block-matching. Affect performance linearly: greater searchWindowsSize - greater denoising time. Must be larger than templateWindowSize.":"用于执行块匹配的窗口的大小（以像素为单位）。线性影响性能：更大的 searchWindowsSize - 更长的去噪时间。必须大于 templateWindowSize。\r\n","\r\n            Provides parameters of a window.\r\n            ":"\r\n            提供窗口的参数。\r\n            \r\n","\r\n            Convert RGB to HLS\r\n            ":"\r\n            将 RGB 转换为 HLS\r\n            \r\n","\r\n            Calculates either x-coordinate, y-coordinate or both of every vector magnitude(I)* exp(angle(I)*j), j=sqrt(-1):\r\n            x(I)=magnitude(I)*cos(angle(I)),\r\n            y(I)=magnitude(I)*sin(angle(I))\r\n            ":"\r\n            计算每个向量 magnitude(I)* exp(angle(I)*j), j=sqrt(-1) 的 x 坐标、y 坐标或两者：\r\n            x(I)=幅度(I)*cos(角度(I)),\r\n            y(I)=幅度(I)*sin(角度(I))\r\n            \r\n","Thickness of the arrow. Thickness of arrow head is also adjusted accordingly.":"箭头的厚度。箭头的粗细也相应调整。\r\n","Optional Parameter. Flag to enable cost buffer output from calc(). Defaults to false.":"可选参数。启用 calc() 的成本缓冲区输出的标志。默认为假。\r\n","\r\n            Calculates Laplacian of the source image by summing second x- and y- derivatives calculated using Sobel operator:\r\n            dst(x,y) = d2src/dx2 + d2src/dy2\r\n            Specifying aperture_size=1 gives the fastest variant that is equal to convolving the image with the following kernel:\r\n            |0  1  0|\r\n            |1 -4  1|\r\n            |0  1  0|\r\n            Similar to cvSobel function, no scaling is done and the same combinations of input and output formats are supported. \r\n            ":"\r\n            通过对使用 Sobel 运算符计算的二阶 x 和 y 导数求和来计算源图像的拉普拉斯算子：\r\n            dst(x,y) = d2src/dx2 + d2src/dy2\r\n            指定 aperture_size=1 给出了最快的变体，它等于用以下内核对图像进行卷积：\r\n            |0 1 0|\r\n            |1 -4 1|\r\n            |0 1 0|\r\n            与 cvSobel 函数类似，不进行缩放，并且支持相同的输入和输出格式组合。\r\n            \r\n","\r\n            Wrapped ORB detector\r\n            ":"\r\n            包裹式 ORB 检测器\r\n            \r\n","The Mat to create the Pix object from":"从中创建 Pix 对象的 Mat\r\n","\r\n            Enter liveview mode.\r\n            ":"\r\n            进入实时取景模式。\r\n            \r\n","Output array of random numbers; the array must be pre-allocated.":"输出随机数数组；该数组必须预先分配。\r\n","\r\n            Release the unmanaged memory associated with the stabilizer\r\n            ":"\r\n            释放与稳定器关联的非托管内存\r\n            \r\n","The labels of the images":"图像的标签\r\n","The handle to the library":"图书馆的句柄\r\n","\r\n            Get or set the intensity of the Cb color channel\r\n            ":"\r\n            获取或设置 Cb 颜色通道的强度\r\n            \r\n","Array with detections' RotationRect results":"具有检测 RotationRect 结果的数组\r\n","Source image.":"源图像。\r\n","\r\n            Computes element-wise product of the two GpuMat: c = scale * a * b.\r\n            ":"\r\n            计算两个 GpuMat 的逐元素乘积：c = scale * a * b。\r\n            \r\n","The XmlReader":"XmlReader\r\n","The string representation of this color":"这种颜色的字符串表示\r\n","\r\n            BayerGR2RGB_MHT\r\n            ":"\r\n            拜耳GR2RGB_MHT\r\n            \r\n","color of the square surrounding each corner":"每个角周围的正方形的颜色\r\n","\r\n            An ellipse\r\n            ":"\r\n            一个椭圆\r\n            \r\n","Pointer to the resulting sub-array header":"指向结果子数组头的指针\r\n","The nearest subdivision vertex":"最近的细分顶点\r\n","\r\n            The motion history class\r\n            ":"\r\n            运动史课\r\n            \r\n","\r\n            OpenNI2 (for Asus Xtion and Occipital Structure sensors)\r\n            ":"\r\n            OpenNI2（用于 Asus Xtion 和 Occipital Structure 传感器）\r\n            \r\n","\r\n            Lens focal distance in mm.\r\n            ":"\r\n            以毫米为单位的镜头焦距。\r\n            \r\n","\r\n            Reset the native pointer upon object disposal\r\n            ":"\r\n            在处理对象时重置本机指针\r\n            \r\n","Buffer containing the content of the .prototxt file":"包含 .prototxt 文件内容的缓冲区\r\n","\r\n            For TIFF, use to specify which DPI resolution unit to set; see libtiff documentation for valid values\r\n            ":"\r\n            对于 TIFF，用于指定要设置的 DPI 分辨率单位；有关有效值，请参阅 libtiff 文档\r\n            \r\n","\r\n            Each matrix row is sorted independently\r\n            ":"\r\n            每个矩阵行独立排序\r\n            \r\n","\r\n            Returns orientation for the block the iterator points to. \r\n            ":"\r\n            返回迭代器指向的块的方向。\r\n            \r\n","Specify the offset location on dataset from where keypoints will be (over)written into dataset.":"指定数据集上的偏移位置，从该位置将（覆盖）写入数据集的关键点。\r\n","Arrays of arrays of the PointF":"PointF 的数组数组\r\n","\r\n            transpose src3\r\n            ":"\r\n            转置 src3\r\n            \r\n","\r\n            The List of the opencv modules\r\n            ":"\r\n            opencv模块列表\r\n            \r\n","The computed flow image for x-velocity; will have the same size as prevImg":"x 速度的计算流图像；将具有与 prevImg 相同的大小\r\n","Use Gray":"使用灰色\r\n","The 2D image location of the points for camera 1. The first index is the index of the image, second index is the index of the point":"相机1的点的二维图像位置。第一个索引是图像的索引，第二个索引是点的索引\r\n","The src array":"源数组\r\n","\r\n            latch Class for computing the LATCH descriptor.\r\n            If you find this code useful, please add a reference to the following paper in your work:\r\n            Gil Levi and Tal Hassner, \"LATCH: Learned Arrangements of Three Patch Codes\", arXiv preprint arXiv:1501.03719, 15 Jan. 2015\r\n            LATCH is a binary descriptor based on learned comparisons of triplets of image patches.\r\n            ":"\r\n            latch 用于计算 LATCH 描述符的类。\r\n            如果您觉得此代码有用，请在您的工作中添加对以下论文的引用：\r\n            Gil Levi 和 Tal Hassner，“LATCH：三个补丁码的学习安排”，arXiv 预印本 arXiv:1501.03719，2015 年 1 月 15 日\r\n            LATCH 是一种二进制描述符，基于对图像块三元组的学习比较。\r\n            \r\n","\r\n            Variable specifies the support region shape extraction or shrinking strategy\r\n            ":"\r\n            变量指定支持区域形状提取或收缩策略\r\n            \r\n","The number of frames used for initialization":"用于初始化的帧数\r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are equal to elements in second.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否等于第二个矩阵中的元素。\r\n            \r\n","The number of cols in the window. The window size parameters control the accuracy of the estimation. The sliding window moves over the entire image from the top-left corner to the bottom right corner. Each location of the window represents a sample. If the window is the size of the image, then this gives the exact covariance matrix. For all other cases, the sizes of the window will impact the number of samples and the number of elements in the estimated covariance matrix.":"窗口中的列数。窗口大小参数控制估计的准确性。滑动窗口从左上角到右下角在整个图像上移动。窗口的每个位置代表一个样本。如果窗口是图像的大小，那么这给出了精确的协方差矩阵。对于所有其他情况，窗口的大小将影响样本数和估计的协方差矩阵中的元素数。\r\n","The stereo matcher":"立体匹配器\r\n","optional scale factor for the computed derivative values; by default, no scaling is applied ":"计算导数值的可选比例因子；默认情况下，不应用缩放\r\n","The minimum number N that is greater to equal to size0, such that DFT of a vector of size N can be computed fast. In the current implementation N=2^p x 3^q x 5^r for some p, q, r. ":"大于等于 size0 的最小数 N，这样可以快速计算大小为 N 的向量的 DFT。在当前实现中，对于某些 p、q、r，N=2^p x 3^q x 5^r。\r\n","The rank proportion (or fractional value) that establish the Kth ranked value of the partial Hausdorff distance. Experimentally had been shown that 0.6 is a good value to compare shapes.":"建立部分 Hausdorff 距离的第 K 个排序值的排序比例（或分数值）。实验表明，0.6 是比较形状的良好值。\r\n","The source image, WxH, 8-bit or floating-point (32f or 64f) image.":"源图像，WxH，8 位或浮点（32f 或 64f）图像。\r\n"," from the current image":" 从当前图像\r\n","The colormap to apply of type CV_8UC1 or CV_8UC3 and size 256":"要应用类型 CV_8UC1 或 CV_8UC3 和大小 256 的颜色图\r\n","\r\n            Padding factor\r\n            ":"\r\n            填充因子\r\n            \r\n","Cheb attenuation":"切布衰减\r\n","The rotated image":"旋转后的图像\r\n","Next video frame.":"下一个视频帧。\r\n","\r\n            Finds out if there is any intersection between two rotated rectangles.\r\n            ":"\r\n            找出两个旋转的矩形之间是否有任何交集。\r\n            \r\n","\r\n            Calculates the per-element difference between given scalar and the matrix.\r\n            ":"\r\n            计算给定标量和矩阵之间的每个元素差异。\r\n            \r\n","Gain for the G channel":"G 通道的增益\r\n","\r\n            This 3D Widget defines a cylinder.\r\n            ":"\r\n            这个 3D Widget 定义了一个圆柱体。\r\n            \r\n","Wrapped phase map obtained through one of the three methods.":"通过三种方法之一获得的包裹相图。\r\n","Sigma":"西格玛\r\n"," \r\n            Backproject the histogram into a gray scale image\r\n            ":" \r\n            将直方图反向投影为灰度图像\r\n            \r\n","Array points":"阵列点\r\n","The source array, single-channel or multi-channel with COI set":"源阵列，单通道或带 COI 集的多通道\r\n","The absolute L1 norm of a matrix.":"矩阵的绝对 L1 范数。\r\n","\r\n            Corner refinement method\r\n            ":"\r\n            角点细化法\r\n            \r\n","\r\n            A ChArUco board is a planar board where the markers are placed\r\n            inside the white squares of a chessboard.The benefits of ChArUco boards is that they provide\r\n            both, ArUco markers versatility and chessboard corner precision, which is important for\r\n            calibration and pose estimation.\r\n            ":"\r\n            ChArUco 板是放置标记的平面板\r\n            在棋盘的白色方块内。ChArUco 棋盘的好处是它们提供\r\n            ArUco 标记的多功能性和棋盘角精度，这对于\r\n            校准和姿态估计。\r\n            \r\n","\r\n            This interface class allows to build new Layers - are building blocks of networks.\r\n            ":"\r\n            这个接口类允许构建新的层——是网络的构建块。\r\n            \r\n","\r\n            Calculates an essential matrix from the corresponding points in two images.\r\n            ":"\r\n            从两个图像中的对应点计算一个基本矩阵。\r\n            \r\n","\r\n            Value for bias function in [0, 1] range. Values from 0.7 to 0.9 usually give best results, default value is 0.85.\r\n            ":"\r\n            [0, 1] 范围内偏置函数的值。 0.7 到 0.9 之间的值通常会提供最佳结果，默认值为 0.85。\r\n            \r\n","\r\n            Renders the specified text string in the image. Symbols that cannot be rendered using the specified font are replaced by \"Tofu\" or non-drawn.\r\n            ":"\r\n            在图像中呈现指定的文本字符串。无法使用指定字体呈现的符号将替换为“豆腐”或不绘制。\r\n            \r\n","Left 8-bit single-channel image.":"左 8 位单通道图像。\r\n","Gaussian kernel standard deviation in Y direction; if sigmaY is zero, it is set to be equal to sigmaX, if both sigmas are zeros, they are computed from ksize.width and ksize.height, respectively.":"Y方向的高斯核标准差；如果 sigmaY 为零，则将其设置为等于 sigmaX，如果两个 sigma 均为零，则分别从 ksize.width 和 ksize.height 计算它们。\r\n","\r\n            Counter status\r\n            ":"\r\n            计数器状态\r\n            \r\n","grayscale or color (BGR) image containing (or not) Barcode.":"包含（或不包含）条码的灰度或彩色 (BGR) 图像。\r\n","\r\n            Alignment of image rows (4 or 8).\r\n            OpenCV ignores it and uses widthStep instead \r\n            ":"\r\n            对齐图像行（4 或 8）。\r\n            OpenCV 忽略它并使用 widthStep 代替\r\n            \r\n","The wrapped phase map computed from the pattern.":"从模式计算的包裹相位图。\r\n"," to the current matrix":" 到当前矩阵\r\n","Size of the grid to spawn the motion vectors. Use (6, 6) for default":"生成运动矢量的网格大小。默认使用 (6, 6)\r\n","The circle detected for each of the channels":"为每个通道检测到的圆\r\n","An action such that the first parameter is the a single channel of a pixel from the first image, the second parameter is the corresponding channel of the correspondind pixel from the second image ":"一个动作，第一个参数是第一个图像中像素的单个通道，第二个参数是第二个图像中对应像素的对应通道\r\n","Pointer to the native cv::Mat":"指向本机 cv::Mat 的指针\r\n","\r\n            Simple Polygon\r\n            ":"\r\n            简单多边形\r\n            \r\n","bilateral filter sigma in color space":"颜色空间中的双边滤波器西格玛\r\n","Input vector of distortion coefficients (k1,k2,p1,p2[,k3[,k4,k5,k6[,s1,s2,s3,s4[,τx,τy]]]]) of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed.":"4、5、8、12 的失真系数 (k1,k2,p1,p2[,k3[,k4,k5,k6[,s1,s2,s3,s4[,τx,τy]]]]) 的输入向量或 14 个元素。如果矢量为 NULL/空，则假定失真系数为零。\r\n","Number of iterations that the algorithm will run. Of course, as more iterations as better, but it is hard to quantitatively refine this statement, so just use the default and increase it if the results are poor.":"算法将运行的迭代次数。当然，迭代次数越多越好，但是这个说法很难量化提炼，所以就用默认的，如果效果不好就增加。\r\n","The keypoints from the observed image":"观察图像的关键点\r\n","The first image":"第一张图片\r\n","Vector of Quadrangle vertices found by detect() method (or some other algorithm).":"通过 detect() 方法（或其他算法）找到的四边形顶点向量。\r\n","The first 1D source vector":"第一个一维源向量\r\n","Harris detector free parameter.":"Harris 检测器自由参数。\r\n","Number of color co-occurrence vectors used to model normal background color variation at a given pixel.":"用于对给定像素处的正常背景颜色变化进行建模的颜色共现向量的数量。\r\n","The per-element scaled product of two matrices.":"两个矩阵的每个元素缩放乘积。\r\n","\r\n            Compare two triangles and return true if equal\r\n            ":"\r\n            比较两个三角形，如果相等则返回真\r\n            \r\n","Computed descriptors will be stored here":"计算的描述符将存储在这里\r\n","\r\n            Raises every element of input array to p\r\n            dst(I)=src(I)^p, if p is integer\r\n            dst(I)=abs(src(I))^p, otherwise\r\n            ":"\r\n            将输入数组的每个元素增加到 p\r\n            dst(I)=src(I)^p，如果p是整数\r\n            dst(I)=abs(src(I))^p，否则\r\n            \r\n","Contour defining second shape (Target).":"轮廓定义第二个形状（目标）。\r\n","\r\n            The focal length is fixed\r\n            ":"\r\n            焦距是固定的\r\n            \r\n","\r\n            Works only under Windows, Supports only H264 video codec and AVI files.\r\n            ":"\r\n            仅在 Windows 下工作，仅支持 H264 视频编解码器和 AVI 文件。\r\n            \r\n","Contains blobs for first outputs of specified layers.":"包含指定层的第一个输出的 blob。\r\n","\r\n            M\r\n            ":"\r\n            米\r\n            \r\n","When true (default value), CvMatND is converted to 2-dimensional Mat, if it is possible (see the discussion below); if it is not possible, or when the parameter is false, the function will report an error":"当为 true（默认值）时，如果可能的话，CvMatND 被转换为二维 Mat（见下面的讨论）；如果不可以，或者参数为false时，函数会报错\r\n","\r\n            src1(I) \"not equal to\" src2(I)\r\n            ":"\r\n            src1(I) “不等于” src2(I)\r\n            \r\n","\r\n            The unmanaged pointer to the output array\r\n            ":"\r\n            指向输出数组的非托管指针\r\n            \r\n"," \r\n            Clear this histogram\r\n            ":" \r\n            清除此直方图\r\n            \r\n","\r\n            (min(r1,r2)+min(g1,g2)+min(b1,b2))/(max(r1,r2)+max(g1,g2)+max(b1,b2))\r\n            ":"\r\n            (最小值(r1,r2)+最小值(g1,g2)+最小值(b1,b2))/(最大值(r1,r2)+最大值(g1,g2)+最大值(b1,b2))\r\n            \r\n","\r\n            Fills the destination array with source array tiled:\r\n            dst(i,j)=src(i mod rows(src), j mod cols(src))So the destination array may be as larger as well as smaller than the source array\r\n            ":"\r\n            用平铺的源数组填充目标数组：\r\n            dst(i,j)=src(i mod rows(src), j mod cols(src))所以目标数组可能比源数组大也可能小\r\n            \r\n","The UnmanagedObject":"非托管对象\r\n","Parameter used when the mask (or masks) is not empty. If compactResult is false, the matches vector has the same size as queryDescriptors rows. If compactResult is true, the matches vector does not contain matches for fully masked-out query descriptors.":"当掩码（或掩码）不为空时使用的参数。如果 compactResult 为 false，则匹配向量的大小与 queryDescriptors 行的大小相同。如果 compactResult 为真，则匹配向量不包含完全屏蔽的查询描述符的匹配项。\r\n","\r\n            Inner Plexiform Layer Magnocellular channel (IplMagno)\r\n            ":"\r\n            内网状层大细胞通道 (IplMagno)\r\n            \r\n","\r\n            convert a series of System.Drawing.Point to LineSegment2D\r\n            ":"\r\n            将一系列 System.Drawing.Point 转换为 LineSegment2D\r\n            \r\n","the resultant sub-array header":"结果子数组头\r\n","The border value.":"边界值。\r\n","maximum allowed credit for a pixel in history":"历史上一个像素的最大允许信用\r\n","The number of bytes in a row taken into consideration ROI":"考虑 ROI 的一行中的字节数\r\n","\r\n            Applies white balancing to the input image.\r\n            ":"\r\n            对输入图像应用白平衡。\r\n            \r\n","\r\n            Create a new instance of Rapid tracker\r\n            ":"\r\n            创建一个新的 Rapid tracker 实例\r\n            \r\n","\r\n            Estimates the sharpness of a detected chessboard.\r\n            Image sharpness, as well as brightness, are a critical parameter for accuracte camera calibration. For accessing these parameters for filtering out problematic calibraiton images, this method calculates edge profiles by traveling from black to white chessboard cell centers. Based on this, the number of pixels is calculated required to transit from black to white. This width of the transition area is a good indication of how sharp the chessboard is imaged and should be below ~3.0 pixels.\r\n            ":"\r\n            估计检测到的棋盘的锐度。\r\n            图像清晰度和亮度是精确相机校准的关键参数。为了访问这些参数以过滤掉有问题的校准图像，此方法通过从黑色棋盘格中心移动到白色棋盘格中心来计算边缘轮廓。以此为基础，计算出从黑色过渡到白色所需的像素数。过渡区域的宽度很好地表明了棋盘成像的清晰度，应该低于 ~3.0 像素。\r\n            \r\n","The width of the resulting image":"结果图像的宽度\r\n","\r\n            One of the vertex of the triangle\r\n            ":"\r\n            三角形的顶点之一\r\n            \r\n","\r\n            Create a MCvPoint3D32f structure with the specific x and y coordinates\r\n            ":"\r\n            创建具有特定 x 和 y 坐标的 MCvPoint3D32f 结构\r\n            \r\n","\r\n            Check if the size of the C structures match those of C#\r\n            ":"\r\n            检查 C 结构的大小是否与 C# 的大小匹配\r\n            \r\n","\r\n            Release the DataLogger and all the unmanaged memory associated with it.\r\n            ":"\r\n            释放 DataLogger 和与其关联的所有非托管内存。\r\n            \r\n","The output (corrected) image":"输出（校正后）图像\r\n","number of nanoseconds (0 - infinite)":"纳秒数（0 - 无限）\r\n","The specific type of marker you want to use":"您要使用的特定标记类型\r\n","The higher threshold of the two passed to Canny edge detector (the lower one will be twice smaller).":"两者中较高的阈值传递给 Canny 边缘检测器（较低的阈值将小两倍）。\r\n","\r\n            Default equals to InferenceEngine if\r\n            OpenCV is built with Intel's Inference Engine library or\r\n            Opencv otherwise.\r\n            ":"\r\n            默认等于 InferenceEngine 如果\r\n            OpenCV 是用英特尔的推理引擎库构建的，或者\r\n            Opencv 否则。\r\n            \r\n","\r\n            Android expose lock\r\n            ":"\r\n            安卓暴露锁\r\n            \r\n","\r\n            Get the string that represent this oclPlatformInfo object\r\n            ":"\r\n            获取表示此 oclPlatformInfo 对象的字符串\r\n            \r\n","Image where the contours are to be drawn. Like in any other drawing function, the contours are clipped with the ROI":"要绘制轮廓的图像。与任何其他绘图功能一样，轮廓被 ROI 裁剪\r\n","Full Affine":"全仿射\r\n","\r\n            No intersection\r\n            ":"\r\n            无交集\r\n            \r\n","Full row width in bytes of the data assigned. By default, the minimal possible step is used, i.e., no gaps is assumed between subsequent rows of the matrix.":"分配的数据的完整行宽（以字节为单位）。默认情况下，使用最小可能步长，即假设矩阵的后续行之间没有间隙。\r\n","\r\n            Compute the different channels to be processed independently in the N&M algorithm.\r\n            ":"\r\n            在 N&M 算法中计算要独立处理的不同通道。\r\n            \r\n","\r\n            Writes the specified Mat to the node with the specific name\r\n            ":"\r\n            将指定的 Mat 写入具有特定名称的节点\r\n            \r\n","The text message to be draw":"要绘制的短信\r\n","ids of the diamonds in diamondCorners. The id of each diamond is in fact of type Vec4i, so each diamond has 4 ids, which are the ids of the aruco markers composing the diamond.":"diamondCorners 中钻石的 ID。每个菱形的id其实是Vec4i类型的，所以每个菱形都有4个id，也就是组成菱形的aruco标记的id。\r\n","\r\n            Maximum value\r\n            ":"\r\n            最大值\r\n            \r\n","Termination criteria: when to stop meanshift iterations. Use new MCvTermCriteria(5, 1) as default value":"终止标准：何时停止 meanshift 迭代。使用新的 MCvTermCriteria(5, 1) 作为默认值\r\n","\r\n            OpenNI2 Mirror\r\n            ":"\r\n            OpenNI2镜像\r\n            \r\n","\r\n            Get the array\r\n            ":"\r\n            获取数组\r\n            \r\n","\r\n            Class that contains entry points for the Rapid module.\r\n            ":"\r\n            包含 Rapid 模块入口点的类。\r\n            \r\n","\r\n            Intersection\r\n            ":"\r\n            路口\r\n            \r\n","Matches array stored in GPU memory. Internal representation is not defined.":"匹配存储在 GPU 内存中的数组。未定义内部表示。\r\n","Array of the element indices ":"元素索引数组\r\n","colors for the markers. Defaults to white.":"标记的颜色。默认为白色。\r\n"," Create a Gray color with the given intensity":" 创建具有给定强度的灰色\r\n","\r\n            Use reflection to find the base type. If such type do not exist, null is returned\r\n            ":"\r\n            使用反射来查找基类型。如果这种类型不存在，则返回 null\r\n            \r\n","\r\n            The NNet packet\r\n            ":"\r\n            NNet数据包\r\n            \r\n","\r\n            Indicates if this is an NVidia device\r\n            ":"\r\n            指示这是否是 NVidia 设备\r\n            \r\n","\r\n            This filter enhances the details of a particular image.\r\n            ":"\r\n            此滤镜可增强特定图像的细节。\r\n            \r\n","\r\n            B0factor\r\n            ":"\r\n            B0因子\r\n            \r\n","\r\n            Convert YUV (420p) to Gray\r\n            ":"\r\n            将 YUV (420p) 转换为灰色\r\n            \r\n","Optional vector with weights for each sample. It should have CV_32F type.":"带有每个样本权重的可选向量。它应该有 CV_32F 类型。\r\n","\r\n            Create a wrapper class which allows the tone mapping algorithm of Meylan & al(2007) to be used with OpenCV.\r\n            ":"\r\n            创建一个包装器类，允许将 Meylan & al(2007) 的色调映射算法与 OpenCV 一起使用。\r\n            \r\n","The size of histogram (number of levels)":"直方图的大小（水平数）\r\n","\r\n            Release the unmanaged memory associated with this FaceRecognizerSF\r\n            ":"\r\n            释放与此 FaceRecognizerSF 关联的非托管内存\r\n            \r\n","\r\n            Class that contains entry points for the Contrib module.\r\n            ":"\r\n            包含 Contrib 模块入口点的类。\r\n            \r\n","\r\n            Return the default people detector\r\n            ":"\r\n            返回默认的人员检测器\r\n            \r\n","The available NNet and data packets":"可用的NNet和数据包\r\n","The regions where positives are found":"发现阳性的区域\r\n","\r\n            Get the number of channels\r\n            ":"\r\n            获取通道数\r\n            \r\n","Parameter regulating filter strength. Big h value perfectly removes noise but also removes image details, smaller h value preserves details but also preserves some noise.":"调节过滤强度的参数。大的 h 值完美地去除了噪声但也去除了图像细节，较小的 h 值保留了细节但也保留了一些噪声。\r\n","The threshold to find initial segments of strong edges":"找到强边初始段的阈值\r\n","\r\n            Base class for a seam estimator.\r\n            ":"\r\n            接缝估计器的基类。\r\n            \r\n","Input image is resized so one side after resize is equal to corresponding dimension in size and another one is equal or larger. Then, crop from the center is performed.":"输入图像被调整大小，因此调整后的一侧等于相应尺寸的尺寸，另一侧等于或更大。然后，从中心进行裁剪。\r\n","Detection window size. Must be aligned to block size and block stride. Must match the size of the training image. Use (64, 128) for default.":"检测窗口大小。必须与块大小和块步幅对齐。必须匹配训练图像的大小。默认使用 (64, 128)。\r\n","\r\n            class of the detection\r\n            ":"\r\n            检测类别\r\n            \r\n","\r\n            Copy the pixel data in the line to a new Mat that is of the same type. \r\n            ":"\r\n            将行中的像素数据复制到同类型的新 Mat 中。\r\n            \r\n","\r\n            Convert Bayer GBRG to BGR (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 Bayer GBRG 转换为 BGR（边缘感知去马赛克）\r\n            \r\n","\r\n            Applies the bilateral filter to an image.\r\n            ":"\r\n            将双边过滤器应用于图像。\r\n            \r\n","The vocabulary":"词汇\r\n","The first input feature":"第一个输入特征\r\n","\r\n            Composites two images using alpha opacity values contained in each image.\r\n            ":"\r\n            使用每个图像中包含的 alpha 不透明度值合成两个图像。\r\n            \r\n","\r\n            BayerBG2RGB_MHT\r\n            ":"\r\n            拜耳BG2RGB_MHT\r\n            \r\n","Number of charts in the image, if you don't know the exact then keeping this number high helps.":"图像中的图表数量，如果您不知道确切的数量，那么保持这个数字高会有帮助。\r\n","\r\n            Threshold for the approximated laplacian,\r\n            used to eliminate weak features. The larger it is,\r\n            the less features will be retrieved\r\n            ":"\r\n            近似拉普拉斯算子的阈值，\r\n            用于消除弱特征。它越大，\r\n            将检索的功能越少\r\n            \r\n","Mode of operation.":"操作模式。\r\n"," \r\n            perform an generic action based on each element of the image\r\n            ":" \r\n            基于图像的每个元素执行通用操作\r\n            \r\n","\r\n            Diff C\r\n            ":"\r\n            差异C\r\n            \r\n","The number of erode iterations":"侵蚀迭代次数\r\n","If true, the method will skip the detection phase and will compute descriptors for the provided keypoints":"如果为真，该方法将跳过检测阶段并计算提供的关键点的描述符\r\n","The color in the specific ":"具体颜色\r\n","\r\n            Returns the actual superpixel segmentation from the last image processed using iterate. Returns zero if no image has been processed.\r\n            ":"\r\n            返回使用迭代处理的最后一个图像的实际超像素分割。如果未处理任何图像，则返回零。\r\n            \r\n","spatial size for output image":"输出图像的空间大小\r\n","\r\n            Dict5X5_100\r\n            ":"\r\n            字典5X5_100\r\n            \r\n","mage in color space BGR":"色彩空间法师 BGR\r\n","\r\n            No input scale\r\n            ":"\r\n            无输入比例\r\n            \r\n","\r\n            Static Constructor to setup opencv environment\r\n            ":"\r\n            设置opencv环境的静态构造函数\r\n            \r\n","Source 8-bit or 16bit image, 1-channel or 3-channel image.":"源 8 位或 16 位图像、1 通道或 3 通道图像。\r\n","\r\n            Given the source and destination color type, compute the color conversion code for CvInvoke.cvCvtColor function\r\n            ":"\r\n            给定源和目标颜色类型，计算 CvInvoke.cvCvtColor 函数的颜色转换代码\r\n            \r\n","Source matrices, all are of the same size and type":"源矩阵，都具有相同的大小和类型\r\n","\r\n            A Map is similar to an Image, except that the location of the pixels is defined by \r\n            its area and resolution\r\n            ":"\r\n            地图类似于图像，不同之处在于像素的位置由定义\r\n            它的面积和分辨率\r\n            \r\n","\r\n            Size of the keypoint\r\n            ":"\r\n            关键点的大小\r\n            \r\n","\r\n            Minimum Contours Area\r\n            ":"\r\n            最小轮廓面积\r\n            \r\n","Threshold value":"阈值\r\n","Second input image of the same size and the same type as prev.":"与上一张相同大小和相同类型的第二个输入图像。\r\n","The second mat to be added":"要添加的第二个垫子\r\n","\r\n            Get or Set the seam estimation resolution\r\n            ":"\r\n            获取或设置接缝估计分辨率\r\n            \r\n","Accumulator threshold parameter. Only those lines are returned that get enough votes (> threshold)":"累加器阈值参数。只返回那些获得足够票数的行（> 阈值）\r\n","\r\n            Similarity function selector.\r\n             ":"\r\n            相似函数选择器。\r\n             \r\n","\r\n            The scalar values as a vector (of size 4)\r\n            ":"\r\n            作为向量（大小为 4）的标量值\r\n            \r\n","\r\n              distance = |x|<c ? x^2/2 : c(|x|-c/2), c=1.345 \r\n            ":"\r\n              距离 = |x|<c ? x^2/2 : c(|x|-c/2), c=1.345\r\n            \r\n","The parent CudaImage should never be released before the returned CudaImage that represent the subregion":"父 CudaImage 不应在代表子区域的返回 CudaImage 之前释放\r\n","\r\n            Computes the connected components labeled image of boolean image\r\n            ":"\r\n            计算布尔图像的标记图像的连接组件\r\n            \r\n","Use 1.6 as default":"默认使用 1.6\r\n","\r\n            The function merge component that is too small, assigning the previously found adjacent label\r\n            to this component.Calling this function may change the final number of superpixels.\r\n            ":"\r\n            太小的功能合并组件，分配之前找到的相邻标签\r\n            到这个组件。调用这个函数可能会改变最终的超像素数。\r\n            \r\n","\r\n            Simple Blob detector\r\n            ":"\r\n            简单的斑点检测器\r\n            \r\n","\r\n            Project the matrices to the histogram bins \r\n            ":"\r\n            将矩阵投影到直方图箱\r\n            \r\n","The default mat.":"默认垫子。\r\n","\r\n            Set the default opencl device\r\n            ":"\r\n            设置默认的opencl设备\r\n            \r\n","Number of dummies":"假人数量\r\n","The rotation angle in degrees. Positive values mean couter-clockwise rotation (the coordiate origin is assumed at top-left corner). ":"以度为单位的旋转角度。正值表示逆时针旋转（坐标原点假定在左上角）。\r\n","A 0-1 mask that has the same size with I. This mask is used to ignore the effect of some pixels. If the pixel value on mask is 0, the pixel will be ignored when maintaining the joint-histogram. This is useful for applications like optical flow occlusion handling.":"与 I 大小相同的 0-1 掩码。此掩码用于忽略某些像素的影响。如果 mask 上的像素值为 0，则在维护联合直方图时将忽略该像素。这对于像光流遮挡处理这样的应用程序很有用。\r\n","\r\n            Fisheye Warper\r\n            ":"\r\n            鱼眼整经机\r\n            \r\n","The returned minimum value":"返回的最小值\r\n","\r\n            The cost function\r\n            ":"代价函数\r\n            \r\n","\r\n            Draws a set of Charuco corners\r\n            ":"\r\n            绘制一组 Charuco 角\r\n            \r\n","The return type":"返回类型\r\n","Scalar, for which per-lemenet \"logical or\" operation on elements of src1 will be performed.":"标量，将对 src1 的元素执行每个 lemenet 的“逻辑或”操作。\r\n","\r\n            The pointer to the unamanged Algorith object\r\n            ":"\r\n            指向未管理的 Algorith 对象的指针\r\n            \r\n","\r\n            Weickert\r\n            ":"\r\n            维克特\r\n            \r\n","\r\n            Release the unmanaged memory associated with this FaceRecognizer\r\n            ":"\r\n            释放与此 FaceRecognizer 关联的非托管内存\r\n            \r\n"," res[i,j] = 255 if ":" res[i,j] = 255 如果\r\n","First input 2D point set.":"首先输入二维点集。\r\n","\r\n            (**open-only**) Hardware acceleration type (see #VideoAccelerationType). Setting supported only via `params` parameter in VideoWriter constructor / .open() method. Default value is backend-specific.\r\n            ":"\r\n            (**open-only**) 硬件加速类型（参见#VideoAccelerationType）。仅通过 VideoWriter 构造函数/.open() 方法中的“params”参数支持设置。默认值是特定于后端的。\r\n            \r\n","8-bit input image.":"8 位输入图像。\r\n","optional operation mask; it must have the same size as src and CV_8UC1 type.":"可选操作面罩；它必须与 src 和 CV_8UC1 类型具有相同的大小。\r\n","\r\n            Android - not used\r\n            ":"\r\n            Android - 未使用\r\n            \r\n","The optional mask that is used to select a subarray. Use IntPtr.Zero if not needed":"用于选择子数组的可选掩码。如果不需要，使用 IntPtr.Zero\r\n","\r\n            Convert YUV (iYUV) to BGRA\r\n            ":"\r\n            将 YUV (iYUV) 转换成 BGRA\r\n            \r\n","\r\n            Detect the keypoints from the image\r\n            ":"\r\n            从图像中检测关键点\r\n            \r\n","Integer vector specifying the number of neurons in each layer including the input and output layers. The very first element specifies the number of elements in the input layer. The last element - number of elements in the output layer.":"指定每一层（包括输入层和输出层）中神经元数量的整数向量。第一个元素指定输入层中的元素数。最后一个元素 - 输出层中的元素数。\r\n","\r\n            Convert BayerGB pattern to RGB color using VNG\r\n            ":"\r\n            使用 VNG 将 BayerGB 模式转换为 RGB 颜色\r\n            \r\n","\r\n            Minimum Group Size\r\n            ":"\r\n            最小团体人数\r\n            \r\n","The word to be checked.":"要检查的单词。\r\n","\r\n            The type of capture source\r\n            ":"\r\n            捕获源的类型\r\n            \r\n","\r\n            PageOrientation and script detection only.\r\n            ":"\r\n            仅限页面方向和脚本检测。\r\n            \r\n"," The width and height of the ellipse":" 椭圆的宽度和高度\r\n","The boolean image":"布尔图像\r\n","the threshold for the Difference-of-Gaussians scale selection":"高斯差分尺度选择的阈值\r\n","\r\n            Sets the error status to the specified value. Mostly, the function is used to reset the error status (set to it CV_StsOk) to recover after error. In other cases it is more natural to call cvError or CV_ERROR.\r\n            ":"\r\n            将错误状态设置为指定值。大多数情况下，该函数用于重置错误状态（设置为 CV_StsOk）以在错误后恢复。在其他情况下，调用 cvError 或 CV_ERROR 更为自然。\r\n            \r\n","\r\n            Unwrap the wrapped phase map to remove phase ambiguities.\r\n            ":"\r\n            打开包装的相位图以消除相位歧义。\r\n            \r\n","\r\n            pointer to aligned image data \r\n            ":"\r\n            指向对齐图像数据的指针\r\n            \r\n"," Output vector of lines. Each line is represented by a 4-element vector (x1, y1, x2, y2)":" 线的输出向量。每条线由一个 4 元素向量 (x1, y1, x2, y2) 表示\r\n","\r\n            A GpuMat, use the generic version if possible. The non generic version is good for use as buffer in stream calls.\r\n            ":"\r\n            GpuMat，尽可能使用通用版本。非通用版本适合用作流调用中的缓冲区。\r\n            \r\n","True if the GPU module is targeted for the specific PTX version.":"如果 GPU 模块针对特定 PTX 版本，则为真。\r\n"," Find the elementwise minimum value ":" 找到元素最小值\r\n","\r\n            Create a tiff writer to save an image\r\n            ":"\r\n            创建一个 tiff writer 来保存图像\r\n            \r\n","Second input 3D point set.":"第二个输入 3D 点集。\r\n"," \r\n            The base threshold method shared by public threshold functions \r\n            ":" \r\n            公共阈值函数共享的基本阈值方法\r\n            \r\n","Gain for the virtual visual servoing control law, equivalent to the α gain in the Damped Gauss-Newton formulation.":"虚拟视觉伺服控制律的增益，相当于阻尼高斯-牛顿公式中的α增益。\r\n","\r\n            Twilight\r\n            ":"\r\n            暮\r\n            \r\n","2D 8-bit structuring element for the morphological operation.":"用于形态学运算的 2D 8 位结构元素。\r\n","\r\n            Sensor clock frequency index. Sensor with selected frequencies have possibility to set the frequency only by this index.\r\n            ":"\r\n            传感器时钟频率索引。具有选定频率的传感器有可能仅通过该索引来设置频率。\r\n            \r\n","Allocated class prediction for each pixel":"为每个像素分配类别预测\r\n","resulting list of point sets":"结果点集列表\r\n","The mat plus the value":"垫子加值\r\n","\r\n            Image hash based on color moments.\r\n            ":"\r\n            基于颜色矩的图像哈希。\r\n            \r\n","\r\n            Specific if it is back or front\r\n            ":"\r\n            具体是背面还是正面\r\n            \r\n","\r\n            Activates LUT.\r\n            ":"\r\n            激活 LUT。\r\n            \r\n","\r\n            Cuda compute 1.2\r\n            ":"\r\n            Cuda 计算 1.2\r\n            \r\n","\r\n            Convert Bayer BGGR pattern to BGR color using VNG\r\n            ":"\r\n            使用 VNG 将 Bayer BGGR 图案转换为 BGR 颜色\r\n            \r\n","number of markers in X direction":"X方向的标记数\r\n","average (mean) of array elements":"数组元素的平均值\r\n","\r\n            Camera\r\n            ":"\r\n            相机\r\n            \r\n","The color to be subtracted":"要减去的颜色\r\n","The source GpuMat, supports only CV_8UC1 source type":"源GpuMat，仅支持CV_8UC1源类型\r\n","\r\n            The base class algorithms that can merge exposure sequence to a single image.\r\n            ":"\r\n            可以将曝光序列合并到单个图像的基类算法。\r\n            \r\n","The type of elements in this matrix":"此矩阵中元素的类型\r\n","\r\n            Finds convex hull of 2D point set using Sklansky's algorithm\r\n            ":"\r\n            使用 Sklansky 算法查找 2D 点集的凸包\r\n            \r\n","\r\n            Computes the estimated covariance matrix of an image using the sliding window forumlation.\r\n            ":"\r\n            使用滑动窗口公式计算图像的估计协方差矩阵。\r\n            \r\n","dictionary of markers indicating the type of markers":"指示标记类型的标记字典\r\n","\r\n            Create a Freak descriptor extractor.\r\n            ":"\r\n            创建一个 Freak 描述符提取器。\r\n            \r\n","The caller is responsible for allocating and freeing the block of memory specified by the data parameter, however, the memory should not be released until the related Matrix is released. ":"调用者负责分配和释放由 data 参数指定的内存块，但是，在释放相关 Matrix 之前不应释放内存。\r\n","\r\n            Min Y\r\n            ":"\r\n            敏宇\r\n            \r\n","\r\n            The type of checker\r\n            ":"\r\n            检查器的类型\r\n            \r\n","\r\n            Map a point to a position in the internal image\r\n            ":"\r\n            将一个点映射到内部图像中的一个位置\r\n            \r\n","An optional normalization scale.":"一个可选的归一化尺度。\r\n","\r\n            Angle resolution of the accumulator in radians\r\n            ":"\r\n            累加器的角度分辨率（以弧度为单位）\r\n            \r\n"," \r\n            Threshold the image such that: dst(x,y) = 0, if src(x,y)>threshold;  src(x,y), otherwise \r\n            ":" \r\n            对图像进行阈值处理：dst(x,y) = 0，如果 src(x,y)>threshold； src(x,y)，否则\r\n            \r\n","Optional value added to the filtered pixels before storing them in dst.":"在将它们存储在 dst 之前添加到过滤像素的可选值。\r\n","Number of scales used to create the pyramid of images.":"用于创建图像金字塔的比例数。\r\n","Second input scalar.":"第二个输入标量。\r\n","Pointer to the output array of corners(PointF) detected":"指向检测到的角输出数组 (PointF) 的指针\r\n","\r\n            V0 compression parameter. Use 0.95 for default\r\n            ":"\r\n            V0 压缩参数。默认使用 0.95\r\n            \r\n","The Laplacian of the image":"图像的拉普拉斯算子\r\n","\r\n            Converts image from one color space to another\r\n            ":"\r\n            将图像从一种颜色空间转换为另一种颜色空间\r\n            \r\n","Projector's height.":"投影仪的高度。\r\n","\r\n            R(x,y)=sumx',y'[T'(x',y') I'(x+x',y+y')],\r\n            where T'(x',y')=T(x',y') - 1/(wxh) sumx\",y\"T(x\",y\")\r\n               I'(x+x',y+y')=I(x+x',y+y') - 1/(wxh) sumx\",y\"I(x+x\",y+y\")\r\n            ":"\r\n            R(x,y)=sumx',y'[T'(x',y') I'(x+x',y+y')],\r\n            其中 T'(x',y')=T(x',y') - 1/(wxh) sumx\",y\"T(x\",y\")\r\n               I'(x+x',y+y')=I(x+x',y+y') - 1/(wxh) sumx\",y\"I(x+x\",y+y\")\r\n            \r\n","\r\n            Releases the header and the image data.\r\n            ":"\r\n            释放标题和图像数据。\r\n            \r\n","\r\n            The function initializes a SuperpixelSLIC object for the input image. It sets the parameters of choosed superpixel algorithm, which are: region_size and ruler. It preallocate some buffers for future computing iterations over the given image. \r\n            ":"\r\n            该函数为输入图像初始化一个 SuperpixelSLIC 对象。它设置了选择的超像素算法的参数，它们是：region_size 和 ruler。它为给定图像的未来计算迭代预分配一些缓冲区。\r\n            \r\n","\r\n            Computes the 'minimal work' distance between two weighted point configurations.\r\n            ":"\r\n            计算两个加权点配置之间的“最小工作”距离。\r\n            \r\n","The double value to be converted to InputArray":"要转换为 InputArray 的双精度值\r\n","\r\n            Creates a simple white balancer\r\n            ":"\r\n            创建一个简单的白平衡器\r\n            \r\n","The detected landmark points for each faces.":"检测到的每个面孔的地标点。\r\n","Second contour or grayscale image":"第二个轮廓或灰度图像\r\n","\r\n            Android white balance\r\n            ":"\r\n            安卓白平衡\r\n            \r\n","The interpolated data":"插值数据\r\n","Optional camera distortion coefficients.":"可选的相机畸变系数。\r\n","multiplier for images values.":"图像值的乘数。\r\n","\r\n            Encode image and store the result as a byte vector.\r\n            ":"\r\n            编码图像并将结果存储为字节向量。\r\n            \r\n","Create a RGB color using the specific values":"使用特定值创建 RGB 颜色\r\n","Specifies how to flip the array.":"指定如何翻转数组。\r\n","\r\n            The type for cvSampleLine\r\n            ":"\r\n            cvSampleLine 的类型\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of Double.\r\n            ":"\r\n            Double 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Convert XYZ color to BGR color\r\n            ":"\r\n            将 XYZ 颜色转换为 BGR 颜色\r\n            \r\n","Gsl Sigma":"GSL西格玛\r\n","Get the output array":"获取输出数组\r\n","\r\n            Release the unmanaged memory\r\n            ":"\r\n            释放非托管内存\r\n            \r\n","Input array or vector of matrices. all of the matrices must have the same number of cols and the same depth":"输入数组或矩阵向量。所有矩阵必须具有相同数量的列和相同的深度\r\n","\r\n             use Otsu algorithm to choose the optimal threshold value;\r\n             combine the flag with one of the above CV_THRESH_* values \r\n            ":"\r\n             使用Otsu算法选择最优阈值；\r\n             将标志与上述 CV_THRESH_* 值之一组合\r\n            \r\n","\r\n            ReLU function: f(x)=max(0,x)\r\n            ":"\r\n            ReLU 函数：f(x)=max(0,x)\r\n            \r\n","\r\n            Vertical flipping of the image to switch between top-left and bottom-left image origin.\r\n            ":"\r\n            垂直翻转图像以在左上角和左下角图像原点之间切换。\r\n            \r\n","\r\n            Video codecs supported by VideoReader\r\n            ":"\r\n            VideoReader 支持的视频编解码器\r\n            \r\n","\r\n            Perform an elementwise XOR operation with another image, using a mask, and return the result\r\n            ":"\r\n            使用掩码与另一个图像执行逐元素 XOR 运算，并返回结果\r\n            \r\n","The first source array":"第一个源数组\r\n","The second input image of the same size and the same type as prevImg":"与prevImg相同大小和相同类型的第二个输入图像\r\n","\r\n            The class can calculate an optical flow for a sparse feature set using the iterative Lucas-Kanade method with pyramids.\r\n            ":"\r\n            该类可以使用带金字塔的迭代 Lucas-Kanade 方法计算稀疏特征集的光流。\r\n            \r\n","\r\n            Convert Bayer BGGR to RGB (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 Bayer BGGR 转换为 RGB（边缘感知去马赛克）\r\n            \r\n","The width of the window":"窗口的宽度\r\n","Create a CascadeClassifier from the specific file":"从特定文件创建 CascadeClassifier\r\n","Sufficient accuracy for angle, 0.01 would be a good default":"足够的角度精度，0.01 是一个很好的默认值\r\n","\r\n            Get tile size in pixels.\r\n            ":"\r\n            获取以像素为单位的图块大小。\r\n            \r\n","\r\n            Returns the calculated norm. The multiple-channel array are treated as single-channel, that is, the results for all channels are combined. \r\n            ":"\r\n            返回计算出的范数。多通道数组被视为单通道，即合并所有通道的结果。\r\n            \r\n","\r\n            Cuda\r\n            ":"\r\n            库达\r\n            \r\n","\r\n            The Y component of the vector: rotation axis * sin(rotation angle / 2)\r\n            ":"\r\n            矢量的Y分量：旋转轴*sin(旋转角度/2)\r\n            \r\n","Number of channels":"通道数\r\n","The training images, that means the faces you want to learn. The data has to be given as a VectorOfMat.":"训练图像，即您要学习的面孔。数据必须作为 VectorOfMat 给出。\r\n","\r\n            The total area (in pixels) of the connected component.\r\n            ":"\r\n            连接组件的总面积（以像素为单位）。\r\n            \r\n","The mat to OR":"OR 的垫子\r\n","\r\n            Implements an efficient fixed-point approximation for applying channel gains, which is the last step of multiple white balance algorithms.\r\n            ":"\r\n            实现用于应用通道增益的高效定点近似，这是多种白平衡算法的最后一步。\r\n            \r\n","\r\n            Create a Laplacian filter.\r\n            ":"\r\n            创建拉普拉斯滤波器。\r\n            \r\n","\r\n            Return the LayerNames\r\n            ":"\r\n            返回图层名称\r\n            \r\n","The pointer to the iplImage":"指向 iplImage 的指针\r\n"," An image where each pixel is the maximum of ":" 每个像素的最大值的图像\r\n","resulting bounding boxes":"结果边界框\r\n","The video frame is returned here. If no frames has been grabbed the image will be empty.":"此处返回视频帧。如果没有抓取帧，则图像将为空。\r\n","\r\n            In 1984, the Colour Measurement Committee of the Society of Dyers and Colourists defined a difference measure, also based on the L*C*h color model.\r\n            ":"\r\n            1984 年，染色师和调色师协会的颜色测量委员会定义了一种差异测量，同样基于 L*C*h 颜色模型。\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this tracker\r\n            ":"\r\n            释放与此跟踪器关联的所有非托管内存\r\n            \r\n","\r\n            Vulkan based backend\r\n            ":"\r\n            基于 Vulkan 的后端\r\n            \r\n","The source point used to find the paths":"用于查找路径的源点\r\n","\r\n            Binning engine selector.\r\n            ":"\r\n            装箱引擎选择器。\r\n            \r\n","\r\n            Creates 4-dimensional blob from series of images. Optionally resizes and crops images from center, subtract mean values, scales values by scalefactor, swap Blue and Red channels.\r\n            ":"\r\n            从一系列图像创建 4 维 blob。可选择从中心调整大小和裁剪图像、减去平均值、按比例因子缩放值、交换蓝色和红色通道。\r\n            \r\n","The function first calculates the minimal eigenvalue for every source image pixel using cvCornerMinEigenVal function and stores them in eig_image. Then it performs non-maxima suppression (only local maxima in 3x3 neighborhood remain). The next step is rejecting the corners with the minimal eigenvalue less than quality_level?max(eig_image(x,y)). Finally, the function ensures that all the corners found are distanced enough one from another by considering the corners (the most strongest corners are considered first) and checking that the distance between the newly considered feature and the features considered earlier is larger than min_distance. So, the function removes the features than are too close to the stronger features":"该函数首先使用 cvCornerMinEigenVal 函数计算每个源图像像素的最小特征值，并将它们存储在 eig_image 中。然后它执行非最大值抑制（仅保留 3x3 邻域中的局部最大值）。下一步是拒绝最小特征值小于 quality_level?max(eig_image(x,y)) 的角点。最后，该函数通过考虑角点（首先考虑最强的角点）并检查新考虑的特征与之前考虑的特征之间的距离是否大于 min_distance 来确保找到的所有角点彼此之间的距离足够远。因此，该函数删除了比过于接近更强的特征的特征\r\n","Optional capture properties. e.g. new Tuple<CvEnum.CapProp>(CvEnum.CapProp.HwAcceleration, (int) VideoAccelerationType.Any)":"可选的捕获属性。例如新元组<CvEnum.CapProp>(CvEnum.CapProp.HwAcceleration, (int) VideoAccelerationType.Any)\r\n","Prune the area which smaller than min_area":"修剪小于 min_area 的区域\r\n","\r\n            Initializes scaled identity matrix:\r\n            arr(i,j)=value if i=j,\r\n            0 otherwise\r\n            ":"\r\n            初始化缩放单位矩阵：\r\n            arr(i,j)=值如果 i=j,\r\n            0否则\r\n            \r\n","\r\n            Managed structure equivalent to CvBox2D\r\n            ":"\r\n            等效于 CvBox2D 的托管结构\r\n            \r\n","Minimum circle radius.":"最小圆半径。\r\n","\tvalue for bias function in [0, 1] range. Values from 0.7 to 0.9 usually give best results, default value is 0.85.":"[0, 1] 范围内偏置函数的值。 0.7 到 0.9 之间的值通常会提供最佳结果，默认值为 0.85。\r\n","\r\n            Adds the whole image or its selected region to accumulator sum\r\n            ":"\r\n            将整个图像或其选定区域添加到累加器总和\r\n            \r\n","\r\n            must be NULL in OpenCV \r\n            ":"\r\n            在 OpenCV 中必须为 NULL\r\n            \r\n","The operation flags. ":"操作标志。\r\n","\r\n            Release the unmanaged memory associated with this PCTSignaturesSQFD object\r\n            ":"\r\n            释放与此 PCTSignaturesSQFD 对象关联的非托管内存\r\n            \r\n","\r\n            Solve given (non-integer) linear programming problem using the Simplex Algorithm (Simplex Method). \r\n            What we mean here by “linear programming problem” (or LP problem, for short) can be formulated as:\r\n            Maximize c x subject to: Ax <= b and x >= 0 \r\n            ":"\r\n            使用单纯形算法（单纯形法）解决给定（非整数）线性规划问题。\r\n            我们在这里所说的“线性规划问题”（或简称 LP 问题）的意思可以表述为：\r\n            最大化 c x 服从：Ax <= b 和 x >= 0\r\n            \r\n","A new image that is the vertical concatening of this image and ":"一个新的图像是这个图像的垂直连接和\r\n","\r\n            Will fall back to OPENCL if the hardware does not support FP16\r\n            ":"\r\n            如果硬件不支持 FP16，将回退到 OPENCL\r\n            \r\n","\r\n            Hierarchical Data Format version 5 interface.\r\n            ":"\r\n            分层数据格式版本 5 接口。\r\n            \r\n","The input rotation vector (3x1 or 1x3) or rotation matrix (3x3). ":"输入旋转向量（3x1 或 1x3）或旋转矩阵 (3x3)。\r\n","The matrix to be shifted.":"要移动的矩阵。\r\n","\r\n            Clear the matcher\r\n            ":"\r\n            清除匹配器\r\n            \r\n","\r\n            Format of the %Mat objects returned by VideoCapture::retrieve().\r\n            ":"\r\n            VideoCapture::retrieve() 返回的 %Mat 对象的格式。\r\n            \r\n","\r\n            Estimates transformation between the 2 cameras making a stereo pair. If we have a stereo camera, where the relative position and orientatation of the 2 cameras is fixed, and if we computed poses of an object relative to the fist camera and to the second camera, (R1, T1) and (R2, T2), respectively (that can be done with cvFindExtrinsicCameraParams2), obviously, those poses will relate to each other, i.e. given (R1, T1) it should be possible to compute (R2, T2) - we only need to know the position and orientation of the 2nd camera relative to the 1st camera. That's what the described function does. It computes (R, T) such that:\r\n            R2=R*R1,\r\n            T2=R*T1 + T\r\n            ":"\r\n            估计构成立体对的 2 个摄像机之间的转换。如果我们有一个立体相机，其中两个相机的相对位置和方向是固定的，如果我们计算一个物体相对于第一个相机和第二个相机的姿势，(R1, T1) 和 (R2, T2) ，分别（可以用cvFindExtrinsicCameraParams2完成），显然，这些姿势将相互关联，即给定（R1，T1）应该可以计算（R2，T2） - 我们只需要知道位置和方向第二台摄像机相对于第一台摄像机。这就是所描述的函数的作用。它计算 (R, T) 这样：\r\n            R2=R*R1,\r\n            T2=R*T1 + T\r\n            \r\n","\r\n            Vec length error\r\n            ":"\r\n            Vec长度错误\r\n            \r\n","\r\n            Convert BGR555 color to RGB color\r\n            ":"\r\n            将 BGR555 颜色转换为 RGB 颜色\r\n            \r\n","regularization term of Guided Filter. eps^2 is similar to the sigma in the color space into bilateralFilter.":"引导滤波器的正则化项。 eps^2类似于颜色空间中的sigma进入bilateralFilter。\r\n","\r\n            Release the managed resources. This function will be called during the disposal of the current object.\r\n            override ride this function if you need to call the Dispose() function on any managed IDisposable object created by the current object\r\n            ":"\r\n            释放托管资源。在处理当前对象期间将调用此函数。\r\n            如果需要对当前对象创建的任何托管 IDisposable 对象调用 Dispose() 函数，则重写此函数\r\n            \r\n","The second map of y values having the type CV_16UC1, CV_32FC1, or none (empty map if map1 is (x,y) points), respectively.":"y 值的第二个映射分别具有 CV_16UC1、CV_32FC1 或无类型（如果 map1 是 (x,y) 点，则为空映射）。\r\n","The mask for the running average":"运行平均值的掩码\r\n","\r\n            Given a rectangle area of the motion, output the angle of the motion and the number of pixels that are considered to be motion pixel \r\n            ":"\r\n            给定运动的矩形区域，输出运动的角度和被认为是运动像素的像素数\r\n            \r\n","The double scalar":"双标量\r\n","numSlicIter":"numSlicIter\r\n","The optimized points2.":"优化点2。\r\n","\r\n            Sensor clock frequency in Hz.\r\n            ":"\r\n            以 Hz 为单位的传感器时钟频率。\r\n            \r\n","\r\n            Get or Set the (3x3) rotation matrix represented by this rotation vector.\r\n            ":"\r\n            获取或设置由此旋转向量表示的 (3x3) 旋转矩阵。\r\n            \r\n","\r\n            Photoreceptors temporal constant. Use 0.5 for default\r\n            ":"\r\n            光感受器时间常数。默认使用 0.5\r\n            \r\n","Input text string.":"输入文本字符串。\r\n","\r\n            The maximum possible depth of the tree\r\n            ":"树的最大可能深度\r\n            \r\n","kernel for blurring image prior to descriptor construction, where 1=3x3, 2=5x5, 3=7x7 and so forth":"在描述符构造之前用于模糊图像的内核，其中 1=3x3、2=5x5、3=7x7 等等\r\n","\r\n            An opencl kernel\r\n            ":"\r\n            一个opencl内核\r\n            \r\n","Enhancement ratio.":"增强比例。\r\n","The function finds minimum (m(x,y)) and maximum (M(x,y)) mhi values over each pixel (x,y) neihborhood and assumes the gradient is valid only if min(delta1,delta2) <= M(x,y)-m(x,y) <= max(delta1,delta2).":"该函数找到每个像素 (x,y) 邻域的最小 (m(x,y)) 和最大 (M(x,y)) mhi 值，并假设梯度仅在 min(delta1,delta2) <= M 时有效(x,y)-m(x,y) <= max(delta1,delta2)。\r\n","\r\n            BRISQUE (Blind/Referenceless Image Spatial Quality Evaluator) is a No Reference Image Quality Assessment (NR-IQA) algorithm.\r\n            ":"\r\n            BRISQUE（盲/无参考图像空间质量评估器）是一种无参考图像质量评估 (NR-IQA) 算法。\r\n            \r\n","\r\n            Dense Optical flow\r\n            ":"\r\n            密集光流\r\n            \r\n","param1 passed to setRpropDW0 for ANN_MLP::RPROP and to setBackpropWeightScale for ANN_MLP::BACKPROP and to initialT for ANN_MLP::ANNEAL.":"param1 传递给 ANN_MLP::RPROP 的 setRpropDW0 和 ANN_MLP::BACKPROP 的 setBackpropWeightScale 以及 ANN_MLP::ANNEAL 的 initialT。\r\n","If TRUE we ignore holes within foreground blobs. Defaults to TRUE.":"如果为 TRUE，我们将忽略前景斑点中的孔洞。默认为真。\r\n","The number of octave layers. Use 3 for default":"八度音程层数。默认使用 3\r\n","first input image.":"第一个输入图像。\r\n","the color in the ":"中的颜色\r\n","Camera matrix of the distorted image. By default, it is the identity matrix but you may additionally scale and shift the result by using a different matrix.":"失真图像的相机矩阵。默认情况下，它是单位矩阵，但您可以使用不同的矩阵另外缩放和移动结果。\r\n","\r\n            Microsoft Windows Runtime using Media Foundation\r\n            ":"\r\n            使用媒体基础的 Microsoft Windows 运行时\r\n            \r\n","\r\n            The type9_16\r\n            ":"\r\n            类型9_16\r\n            \r\n","The second input map of type CV_16UC1 , CV_32FC1 , or none (empty matrix), respectively.":"类型分别为 CV_16UC1 、 CV_32FC1 或无（空矩阵）的第二个输入映射。\r\n","\r\n            Navier-Stokes based method.\r\n            ":"\r\n            基于 Navier-Stokes 的方法。\r\n            \r\n","\r\n            Create a quaternion with the specific values\r\n            ":"\r\n            创建具有特定值的四元数\r\n            \r\n","Edge preserving filters":"边缘保留过滤器\r\n","Number of search lines":"搜索行数\r\n","\r\n            Wrapped SIFT detector\r\n            ":"\r\n            包裹式 SIFT 检测器\r\n            \r\n","The input image to be processed":"待处理的输入图像\r\n","\r\n            Estimates extrinsic camera parameters using known intrinsic parameters and extrinsic parameters for each view. The coordinates of 3D object points and their correspondent 2D projections must be specified. This function also minimizes back-projection error\r\n            ":"\r\n            使用已知的内部参数和每个视图的外部参数来估计外部相机参数。必须指定 3D 对象点的坐标及其对应的 2D 投影。此功能还可以最大限度地减少反投影误差\r\n            \r\n","Number of source images.":"源图像的数量。\r\n","Inclusive upper boundary":"包容性上限\r\n","The attribute name to be checked.":"要检查的属性名称。\r\n","If true, it will try to create video frame source using gpu":"如果为真，它将尝试使用 gpu 创建视频帧源\r\n","Output translation vectors.":"输出翻译向量。\r\n","The input point cloud for the model. Expected to have the normals (Nx6). Currently, CV_32F is the only supported data type.":"模型的输入点云。预期具有法线 (Nx6)。目前，CV_32F 是唯一支持的数据类型。\r\n","Flags for defining the type of RTrees.":"用于定义 RTree 类型的标志。\r\n","\r\n            Interface for all widgets\r\n            ":"\r\n            所有小部件的界面\r\n            \r\n","\r\n            Create an standard vector of Triangle2DF of the specific size\r\n            ":"\r\n            创建特定大小的 Triangle2DF 标准向量\r\n            \r\n","True if decode is successful":"如果解码成功则为真\r\n","\r\n            Unwraps a 2D phase map.\r\n            ":"\r\n            展开 2D 相位图。\r\n            \r\n","array of output translation vectors (e.g. VectorOfPoint3D32F ). Each element in tvecs corresponds to the specific marker in imgPoints.":"输出平移向量数组（例如 VectorOfPoint3D32F ）。 tvecs 中的每个元素对应于 imgPoints 中的特定标记。\r\n","The number of times the tree(s) in the index should be recursively traversed. A\r\n            higher value for this parameter would give better search precision, but also take more\r\n            time. If automatic configuration was used when the index was created, the number of\r\n            checks required to achieve the specified precision was also computed, in which case\r\n            this parameter is ignored ":"应该递归遍历索引中的树的次数。 A\r\n            此参数的值越高，搜索精度越高，但也需要更多\r\n            时间。如果在创建索引时使用了自动配置，则\r\n            还计算了达到指定精度所需的检查，在这种情况下\r\n            这个参数被忽略\r\n","input matrix to be converted from.":"要转换的输入矩阵。\r\n","Samples stored either as separate matrices or as rows/columns of a single matrix.":"样本存储为单独的矩阵或单个矩阵的行/列。\r\n","Output 3x3 rectification transform (rotation matrix) for the first camera.":"为第一台摄像机输出 3x3 整流变换（旋转矩阵）。\r\n","Determine the number of bits in the descriptor. ":"确定描述符中的位数。\r\n","A zero array of the specified size and type.":"指定大小和类型的零数组。\r\n","Flags to evaluate cross-correlation instead of convolution.":"评估互相关而不是卷积的标志。\r\n","a flag, indicating whether a more accurate L2 norm should be used to calculate the image gradient magnitude ( L2gradient=true ), or whether the default L1 norm is enough ( L2gradient=false ).":"一个标志，指示是否应使用更准确的 L2 范数来计算图像梯度幅度（L2gradient=true），或者默认的 L1 范数是否足够（L2gradient=false）。\r\n","\r\n            Row by row\r\n            ":"\r\n            逐行\r\n            \r\n","Pixel extrapolation method, use DEFAULT for default":"像素外推法，默认使用DEFAULT\r\n","Thresholding type":"阈值类型\r\n","Maximum value to use ":"使用的最大值\r\n","\r\n            A combination of red (R), green (G), blue (B), lightness (L), and gradient\r\n            magnitude (Grad).\r\n            ":"\r\n            红色 (R)、绿色 (G)、蓝色 (B)、亮度 (L) 和渐变的组合\r\n            幅度（毕业）。\r\n            \r\n","\r\n            Medium perf level results in low performance and medium quality\r\n            ":"\r\n            中等性能水平导致低性能和中等质量\r\n            \r\n","\r\n            This class implements a very efficient and robust variant of the iterative closest point (ICP) algorithm. The task is to register a 3D model (or point cloud) against a set of noisy target data. The variants are put together by myself after certain tests. The task is to be able to match partial, noisy point clouds in cluttered scenes, quickly. You will find that my emphasis is on the performance, while retaining the accuracy. \r\n            ":"\r\n            此类实现了迭代最近点 (ICP) 算法的一种非常有效且稳健的变体。任务是针对一组嘈杂的目标数据注册 3D 模型（或点云）。经过某些测试后，变体由我自己组合在一起。任务是能够在杂乱的场景中快速匹配部分、嘈杂的点云。你会发现我强调的是性能，同时保持准确性。\r\n            \r\n","The result vector of keypoints":"关键点的结果向量\r\n","\r\n            Create a MOSSE tracker\r\n            ":"\r\n            创建一个 MOSSE 跟踪器\r\n            \r\n","\r\n            Inference Engine NGraph\r\n            ":"\r\n            推理机 NGraph\r\n            \r\n","Filter sigma in the color space. Larger value of the parameter means that farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting in larger areas of semi-equal color":"在颜色空间中过滤 sigma。参数值越大意味着像素邻域内更远的颜色（参见 sigmaSpace）将混合在一起，从而产生更大的半等色区域\r\n","\r\n            Finds the k best matches for each descriptor from a query set.\r\n            ":"\r\n            从查询集中为每个描述符找到 k 个最佳匹配项。\r\n            \r\n","\r\n            Perimeter\r\n            ":"\r\n            周长\r\n            \r\n","Size of the search window of each pyramid level":"每个金字塔级别的搜索窗口的大小\r\n","\r\n            Convert YUV (YUNV) to BGRA\r\n            ":"\r\n            将 YUV (YUNV) 转换成 BGRA\r\n            \r\n","\r\n            Kmeans-based class to train visual vocabulary using the bag of visual words approach.\r\n            ":"\r\n            基于 Kmeans 的类使用视觉词袋方法训练视觉词汇。\r\n            \r\n","If true, will try to use gpu":"如果为真，将尝试使用 gpu\r\n","the other triangles to compare with":"其他要比较的三角形\r\n","\r\n            A two pass video stabilizer\r\n            ":"\r\n            两次通过视频稳定器\r\n            \r\n","The size of descriptor. It can be equal 16, 32 or 64 bytes.":"描述符的大小。它可以等于 16、32 或 64 字节。\r\n","\r\n            Get or Set the interpolation type.\r\n            ":"\r\n            获取或设置插值类型。\r\n            \r\n","\r\n            Pointer to the unmanaged StaticSaliency object\r\n            ":"\r\n            指向非托管 StaticSaliency 对象的指针\r\n            \r\n","\r\n            e^{ -alpha * d^2(c_i, c_j)}\r\n            ":"\r\n            e^{ -alpha * d^2(c_i, c_j)}\r\n            \r\n","\r\n            Orientation of the line\r\n            ":"\r\n            线的方向\r\n            \r\n"," The down-sampled image":" 下采样图像\r\n","Array of single channel images from which the regions were extracted":"从中提取区域的单通道图像数组\r\n","\r\n            Determines whether the specified input array is umat.\r\n            ":"\r\n            确定指定的输入数组是否为 umat。\r\n            \r\n","If true, will include the virtual points in the resulting triangles":"如果为真，将在生成的三角形中包含虚拟点\r\n","\r\n            Neural network\r\n            ":"\r\n            神经网络\r\n            \r\n","\r\n            Hershey triplex\r\n            ":"\r\n            好时三联\r\n            \r\n","Deriv Aperture":"导出孔径\r\n","\r\n            Maximum limit of gain in AEAG procedure\r\n            ":"\r\n            AEAG 过程中增益的最大限制\r\n            \r\n","Segmented Image. Will have the same size and type as src. Note that this is an Image type and not CudaImage type":"分割图像。将具有与 src 相同的大小和类型。请注意，这是一个图像类型而不是 CudaImage 类型\r\n","\r\n            Convert the standard vector to an array of Size\r\n            ":"\r\n            将标准向量转换为 Size 的数组\r\n            \r\n","True on success, false otherwise":"成功时为真，否则为假\r\n","The source 8-bit single channel image. Non-zero pixels are treated as 1s, zero pixels remain 0s - that is image treated as binary. To get such a binary image from grayscale, one may use cvThreshold, cvAdaptiveThreshold or cvCanny. The function modifies the source image content":"源 8 位单通道图像。非零像素被视为 1，零像素保持为 0 - 即图像被视为二进制。要从灰度中获取这样的二值图像，可以使用 cvThreshold、cvAdaptiveThreshold 或 cvCanny。函数修改源图片内容\r\n","\r\n            Convert BGR565 color to GRAY color\r\n            ":"\r\n            将 BGR565 颜色转换为 GRAY 颜色\r\n            \r\n","Point coordinates in the original plane, 2xN, Nx2, 3xN or Nx3 array (the latter two are for representation in homogeneous coordinates), where N is the number of points. ":"原始平面中的点坐标，2xN、Nx2、3xN或Nx3数组（后两者用于齐次坐标表示），其中N为点数。\r\n","\r\n            Calculates a similarity transformation between two images (scale, rotation, and shift)\r\n            ":"\r\n            计算两个图像之间的相似性变换（缩放、旋转和移位）\r\n            \r\n","\r\n            A 45 degree tilted crosshair marker shape\r\n            ":"\r\n            45 度倾斜的十字准线标记形状\r\n            \r\n","Dimensionality of the control vector.":"控制向量的维数。\r\n","\r\n            Get or set if OpenCL should be used\r\n            ":"\r\n            获取或设置是否应使用 OpenCL\r\n            \r\n","\r\n            Convert BayerGB to RGB (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 BayerGB 转换为 RGB（边缘感知去马赛克）\r\n            \r\n","\r\n             pointer to a very origin of image data (not necessarily aligned) - it is needed for correct image deallocation \r\n            ":"\r\n             指向图像数据来源的指针（不一定对齐）-正确的图像重新分配需要它\r\n            \r\n","\r\n            Create a new segmentation model\r\n            ":"\r\n            创建新的细分模型\r\n            \r\n","Mask image. It may be a conjunction of valid gradient mask, obtained with cvCalcMotionGradient and mask of the region, whose direction needs to be calculated. ":"蒙版图像。它可能是有效梯度掩码的结合，通过 cvCalcMotionGradient 和需要计算方向的区域掩码获得。\r\n","The blob":"斑点\r\n","Parameter defining the smooth term weight.":"定义平滑项权重的参数。\r\n","Maximum difference between neighbor disparity pixels to put them into the same blob. Note that since StereoBM, StereoSGBM and may be other algorithms return a fixed-point disparity map, where disparity values are multiplied by 16, this scale factor should be taken into account when specifying this parameter value.":"将相邻视差像素放入同一个 blob 之间的最大差异。请注意，由于 StereoBM、StereoSGBM 和可能的其他算法返回定点视差图，其中视差值乘以 16，因此在指定此参数值时应考虑此比例因子。\r\n","The algorithm uses a parallelised DBSCAN cluster search that is resistant to noise, competitive in segmentation quality, and faster than existing superpixel segmentation methods. When tested on the Berkeley Segmentation Dataset, the average processing speed is 175 frames/s with a Boundary Recall of 0.797 and an Achievable Segmentation Accuracy of 0.944. The computational complexity is quadratic O(n2) and more suited to smaller images, but can still process a 2MP colour image faster than the SEEDS algorithm in OpenCV. The output is deterministic when the number of processing threads is fixed, and requires the source image to be in Lab colour format.":"该算法使用并行化的 DBSCAN 聚类搜索，具有抗噪声、分割质量有竞争力的特点，并且比现有的超像素分割方法更快。在伯克利分割数据集上进行测试时，平均处理速度为 175 帧/秒，边界召回率为 0.797，可达到的分割精度为 0.944。计算复杂度为二次 O(n2)，更适合较小的图像，但仍然可以比 OpenCV 中的 SEEDS 算法更快地处理 2MP 彩色图像。当处理线程数固定时，输出具有确定性，要求源图像为 Lab 颜色格式。\r\n","Name of the output video file. Only AVI file format is supported.":"输出视频文件的名称。仅支持 AVI 文件格式。\r\n","\r\n            Release the unmanaged memory associated with this sparse matrix\r\n            ":"\r\n            释放与此稀疏矩阵关联的非托管内存\r\n            \r\n","The type of the array":"数组的类型\r\n","\r\n            Gets the first element of the top-level mapping.\r\n            ":"\r\n            获取顶级映射的第一个元素。\r\n            \r\n","Order of the derivative y.":"导数 y 的阶数。\r\n","\r\n            The page seg mode.\r\n            ":"\r\n            页段模式。\r\n            \r\n","The number of rows (height)":"行数（高）\r\n","\r\n            Bilateral filter sigma in color space\r\n            ":"\r\n            颜色空间中的双边滤波器西格玛\r\n            \r\n","The desired number of features. Use 0 for un-restricted number of features":"所需的功能数量。使用 0 表示不受限制的功能数量\r\n","Maximal lower brightness/color difference\r\n            between the currently observed pixel and one of its neighbor belong to the component\r\n            or seed pixel to add the pixel to component.\r\n            In case of 8-bit color images it is packed value.":"最大下亮度/色差\r\n            当前观察到的像素与其相邻像素之一之间属于该组件\r\n            或种子像素以将像素添加到组件。\r\n            对于 8 位彩色图像，它是打包值。\r\n","\r\n            Pointer to the native data\r\n            ":"\r\n            指向本机数据的指针\r\n            \r\n","\r\n            Create an standard vector of GpuMat with the initial values\r\n            ":"\r\n            使用初始值创建 GpuMat 的标准向量\r\n            \r\n","Offset, by which every contour point is shifted. This is useful if the contours are extracted from the image ROI and then they should be analyzed in the whole image context":"偏移量，每个轮廓点移动的偏移量。如果从图像 ROI 中提取轮廓然后应在整个图像上下文中分析它们，这将很有用\r\n","\r\n            Color Conversion code\r\n            ":"\r\n            颜色转换代码\r\n            \r\n","\r\n            Create an standard vector of OclPlatformInfo with the initial values\r\n            ":"\r\n            使用初始值创建 OclPlatformInfo 的标准向量\r\n            \r\n","Image data of the source frame (CV_8UC1)":"源帧图像数据（CV_8UC1）\r\n","\r\n            The color grad\r\n            ":"\r\n            颜色渐变\r\n            \r\n","\r\n            ParasolCells_beta. Use 0.0 for default\r\n            ":"\r\n            ParasolCells_beta。默认使用 0.0\r\n            \r\n","2x3 transformation matrix":"2x3 变换矩阵\r\n","The target point":"目标点\r\n","The type of the data to be interpolated":"要插值的数据类型\r\n","Output array of magnitudes of the same size and type as x.":"大小和类型与 x 相同的量级输出数组。\r\n","\r\n            Create a blank Image of the specified width, height, depth and color.\r\n            ":"\r\n            创建指定宽度、高度、深度和颜色的空白图像。\r\n            \r\n","\r\n            norm = ||arr1-arr2||_C/||arr2||_C\r\n            ":"\r\n            范数 = ||arr1-arr2||_C/||arr2||_C\r\n            \r\n","Vector of text detection regions of interest (Rect, CV_32SC4). ROIs is be cropped as the network inputs":"感兴趣的文本检测区域向量（Rect，CV_32SC4）。 ROI 被裁剪为网络输入\r\n","\r\n            IO type for eigen object related functions\r\n            ":"\r\n            特征对象相关函数的 IO 类型\r\n            \r\n","The bounding rectangle for the array of points":"点数组的边界矩形\r\n","mask (CV_8UC1), where non-zero pixels indicate valid image area, while zero pixels indicate area to be inpainted":"掩码 (CV_8UC1)，其中非零像素表示有效图像区域，而零像素表示要修复的区域\r\n","\r\n            The class implements the following algorithm:\r\n            \"Improved adaptive Gaussian mixture model for background subtraction\"\r\n            Z.Zivkovic\r\n            International Conference Pattern Recognition, UK, August, 2004.\r\n            http://www.zoranz.net/Publications/zivkovic2004ICPR.pdf\r\n            ":"\r\n            该类实现了以下算法：\r\n            “用于背景减除的改进型自适应高斯混合模型”\r\n            日夫科维奇\r\n            模式识别国际会议，英国，2004 年 8 月。\r\n            http://www.zoranz.net/Publications/zivkovic2004ICPR.pdf\r\n            \r\n","The type of interpolation":"插值类型\r\n","The output array ":"输出数组\r\n","The four vertices of rectangles.":"矩形的四个顶点。\r\n","\r\n            The pointer to the sparse optical flow object.\r\n            ":"\r\n            指向稀疏光流对象的指针。\r\n            \r\n","Operation flag. In case of a matrix, when the flag is true, the function returns convex hull points. Otherwise, it returns indices of the convex hull points. When the output array is std::vector, the flag is ignored, and the output depends on the type of the vector":"操作标志。在矩阵的情况下，当标志为真时，函数返回凸包点。否则，它返回凸包点的索引。当输出数组为std::vector时，该标志被忽略，输出取决于vector的类型\r\n","\r\n            Calculates the per-element bit-wise logical disjunction of two matrices of the same size.\r\n            ":"\r\n            计算两个相同大小的矩阵的每个元素的按位逻辑或。\r\n            \r\n","The source GpuMat. Supports only floating-point type":"来源 GpuMat。仅支持浮点类型\r\n","\r\n            Descriptors computation.\r\n            ":"\r\n            描述符计算。\r\n            \r\n","Bias coefficient for threshold.":"阈值的偏置系数。\r\n","\r\n            The minimum element size in percents that should be absorbed into a bigger\r\n            superpixel.Given resulted average superpixel size valid value should be in 0-100 range, 25 means\r\n            that less then a quarter sized superpixel should be absorbed, this is default.\r\n            ":"\r\n            应该吸收到更大的元素中的最小元素大小百分比\r\n            superpixel.Given 结果平均超像素大小有效值应在 0-100 范围内，25 表示\r\n            应该吸收小于四分之一大小的超像素，这是默认设置。\r\n            \r\n","Name for layer which output is needed to get":"需要获取输出的层的名称\r\n","\r\n            number of tree in the model for each landmark point refinement\r\n            ":"\r\n            每个地标点细化的模型中的树数\r\n            \r\n","Maximum value to use with CV_THRESH_BINARY and CV_THRESH_BINARY_INV thresholding types":"与 CV_THRESH_BINARY 和 CV_THRESH_BINARY_INV 阈值类型一起使用的最大值\r\n","Number of pixels in each direction from the source image rectangle to extrapolate.":"要外推的源图像矩形每个方向的像素数。\r\n","\r\n            The initial variance of each gaussian component\r\n            ":"每个高斯分量的初始方差\r\n            \r\n","\r\n            When passing an object of this type, the index will perform a linear, brute-force search.\r\n            ":"\r\n            当传递这种类型的对象时，索引将执行线性、强力搜索。\r\n            \r\n","The access type":"访问类型\r\n","Threshold for contrast limiting. Use 40.0 for default":"对比度限制的阈值。默认使用 40.0\r\n","\r\n            The pointer to the input array\r\n            ":"\r\n            指向输入数组的指针\r\n            \r\n","Tile grid size, use (8, 8) for default":"平铺网格大小，默认使用 (8, 8)\r\n","\r\n            Interpolation type\r\n            ":"\r\n            插值类型\r\n            \r\n"," The color of the ellipse ":" 椭圆的颜色\r\n","\r\n            Create a hough lines detector\r\n            ":"\r\n            创建一个霍夫线检测器\r\n            \r\n","\r\n            DualTvl1 optical flow\r\n            ":"\r\n            DualTvl1 光流\r\n            \r\n","The height of the window":"窗户的高度\r\n","\r\n            MOSSE Visual Object Tracking using Adaptive Correlation Filters\r\n            ":"\r\n            使用自适应相关滤波器的 MOSSE 视觉对象跟踪\r\n            \r\n","Half sizes of the search window. For example, if win=(5,5) then 5*2+1 x 5*2+1 = 11 x 11 search window is used":"搜索窗口的一半大小。例如，如果 win=(5,5) 则使用 5*2+1 x 5*2+1 = 11 x 11 搜索窗口\r\n","\r\n            Class implements both functionality for detection of lines and computation of their binary descriptor.\r\n            ":"\r\n            类实现了检测线和计算其二进制描述符的功能。\r\n            \r\n","\r\n            DirectShow (via videoInput)\r\n            ":"DirectShow（通过视频输入）\r\n            \r\n","\r\n            JPEG restart interval, 0 - 65535, default is 0 - no restart.\r\n            ":"\r\n            JPEG 重启间隔，0 - 65535，默认为 0 - 不重启。\r\n            \r\n","Input keypoints of image2.":"输入 image2 的关键点。\r\n","\r\n            Release all the memory associated with the SVMSGD model\r\n            ":"\r\n            释放与 SVMSGD 模型关联的所有内存\r\n            \r\n","\r\n            Calculates per-element bit-wise logical or of two GpuMats:\r\n            dst(I)=src1(I) | src2(I) if mask(I)!=0\r\n            In the case of floating-point GpuMats their bit representations are used for the operation. All the GpuMats must have the same type, except the mask, and the same size\r\n            ":"\r\n            计算每个元素的按位逻辑或两个 GpuMats：\r\n            dst（我）= src1（我） | src2(I) 如果掩码(I)!=0\r\n            在浮点 GpuMats 的情况下，它们的位表示用于操作。所有 GpuMats 必须具有相同的类型（掩码除外）和相同的大小\r\n            \r\n","size of search window":"搜索窗口的大小\r\n","the scaling factor to apply during conversion (defaults to 1.0 -- no scaling)":"转换期间应用的比例因子（默认为 1.0——无比例）\r\n","\r\n            Pointer to the native white balancer object\r\n            ":"\r\n            指向本机白平衡器对象的指针\r\n            \r\n","\r\n            The green color\r\n            ":"\r\n            绿色\r\n            \r\n","The point to locate":"定位点\r\n","The id of target device":"目标设备id\r\n","\r\n            bilateral filter sigma in coordinate space\r\n            ":"\r\n            坐标空间中的双边滤波器西格玛\r\n            \r\n","The frame to be written to the video writer":"要写入视频编写器的帧\r\n","\r\n            Parameters for the simple blob detector\r\n            ":"\r\n            简单斑点检测器的参数\r\n            \r\n","\r\n            Convert YUV (i420) to BGR\r\n            ":"\r\n            将 YUV (i420) 转换成 BGR\r\n            \r\n","\r\n            KernelArg flags\r\n            ":"\r\n            KernelArg 标志\r\n            \r\n","Second signature of the same format as signature1 , though the number of rows may be different. The total weights may be different. In this case an extra 'dummy' point is added to either signature1 or signature2":"与 signature1 格式相同的第二个签名，但行数可能不同。总重量可能不同。在这种情况下，一个额外的“虚拟”点被添加到 signature1 或 signature2\r\n","the second byte vector to be merged":"要合并的第二个字节向量\r\n","\r\n            Select values from either first or second of input matrices by given mask. The function set to the output matrix either the value from the first input matrix if corresponding value of mask matrix is 255, or value from the second input matrix (if value of mask matrix set to 0).\r\n            ":"\r\n            通过给定的掩码从第一个或第二个输入矩阵中选择值。如果掩码矩阵的对应值为 255，则函数将输出矩阵设置为第一个输入矩阵的值，或者第二个输入矩阵的值（如果掩码矩阵的值设置为 0）。\r\n            \r\n","Draw a 2D Cross using the specific color and thickness ":"使用特定颜色和厚度绘制二维十字\r\n","\r\n            Stochastic Gradient Descent\r\n            ":"\r\n            随机梯度下降\r\n            \r\n","\r\n            Returns true if the node is a mapping\r\n            ":"\r\n            如果节点是映射，则返回 true\r\n            \r\n","Input keypoints of image1.":"输入 image1 的关键点。\r\n"," A Bgr image frame that is half width and half height":" 一半宽度和一半高度的 Bgr 图像框架\r\n","\r\n            ANNEAL: Update iteration per step.\r\n            ":"\r\n            ANNEAL：每步更新迭代。\r\n            \r\n","Output the current forground mask":"输出当前前景遮罩\r\n","\r\n            Paragraph within a block.\r\n            ":"\r\n            块中的段落。\r\n            \r\n","\r\n            Convert BGR565 color to RGBA color\r\n            ":"\r\n            将 BGR565 颜色转换为 RGBA 颜色\r\n            \r\n","\r\n            Reads the float from the node.\r\n            ":"\r\n            从节点读取浮点数。\r\n            \r\n","Input images (all with 1- or 3-channels).":"输入图像（均具有 1 或 3 通道）。\r\n","\r\n            Openni IR generator present\r\n            ":"\r\n            存在 Openni IR 发生器\r\n            \r\n","The point the arrow starts from.":"箭头开始的点。\r\n","8-connected or 4-connected":"8-连接或4-连接\r\n","\r\n            Check if the GPU module is targeted for equal or less PTX version\r\n            ":"\r\n            检查 GPU 模块是否针对相同或更低的 PTX 版本\r\n            \r\n","Single-channel source image.":"单通道源图像。\r\n","The column border type.":"列边框类型。\r\n","The standard deviation for each channel":"每个通道的标准偏差\r\n","\r\n            Threshold step\r\n            ":"\r\n            阈值步骤\r\n            \r\n","\r\n            Managed structure equivalent to CvMatND\r\n            ":"\r\n            等效于 CvMatND 的托管结构\r\n            \r\n","\r\n            SRI\r\n            ":"\r\n            社会责任研究所\r\n            \r\n","\r\n            Create a Rgb color using the system color\r\n            ":"\r\n            使用系统颜色创建 Rgb 颜色\r\n            \r\n","Patch radius":"斑块半径\r\n","\r\n            A wrapper class which allows the tone mapping algorithm of Meylan & al(2007) to be used with OpenCV.\r\n            ":"\r\n            一个包装类，它允许将 Meylan & al(2007) 的色调映射算法与 OpenCV 一起使用。\r\n            \r\n","interpolation type":"插值型\r\n","The pix is the image processed.":"pix 是处理后的图像。\r\n","\r\n            data pointers\r\n            ":"\r\n            数据指针\r\n            \r\n","\r\n            Indicates whether the curve is closed or not.\r\n            ":"\r\n            指示曲线是否闭合。\r\n            \r\n","The degree-length output array of real or complex roots (CV_32FC2 or CV_64FC2)":"实根或复根的度长输出数组（CV_32FC2 或 CV_64FC2）\r\n","\r\n            Simple one-line Fast Global Smoother filter call.\r\n            ":"\r\n            简单的一行快速全局平滑器过滤器调用。\r\n            \r\n","The input samples":"输入样本\r\n","\r\n            This class wraps the functional calls to the opencv_gpu module\r\n            ":"\r\n            此类包装了对 opencv_gpu 模块的功能调用\r\n            \r\n","Threshold value.":"阈值。\r\n","Size of the filter returned.":"返回的过滤器的大小。\r\n","The maximum number of gaussian mixtures.":"高斯混合的最大数量。\r\n","\r\n             QuickTime (obsolete, removed)\r\n            ":"\r\n             QuickTime（已过时，已删除）\r\n            \r\n","True if the GPU module is build with the specific feature set.":"如果 GPU 模块是使用特定功能集构建的，则为真。\r\n","\r\n            Set the decoding method options for \"CTC-prefix-beam-search\" decode usage\r\n            ":"\r\n            为“CTC-prefix-beam-search”解码使用设置解码方法选项\r\n            \r\n","FileNode for input":"输入文件节点\r\n","The name of the layer":"层的名称\r\n","\r\n            Calculates per-element bit-wise logical conjunction of two GpuMats:\r\n            dst(I)=src1(I)^src2(I) if mask(I)!=0\r\n            In the case of floating-point GpuMats their bit representations are used for the operation. All the GpuMats must have the same type, except the mask, and the same size\r\n            ":"\r\n            计算两个 GpuMat 的每个元素的按位逻辑合取：\r\n            dst(I)=src1(I)^src2(I) 如果掩码(I)!=0\r\n            在浮点 GpuMats 的情况下，它们的位表示用于操作。所有 GpuMats 必须具有相同的类型（掩码除外）和相同的大小\r\n            \r\n","Relative difference between sides of the rectangles to merge them into a group.":"矩形边之间的相对差异以将它们合并为一个组。\r\n","Maximal duration of motion track in the same units as timestamp. ":"以与时间戳相同的单位表示的运动轨迹的最大持续时间。\r\n","\r\n            Hamming distance functor - counts the bit differences between two strings - useful for the Brief descriptor, \r\n            bit count of A exclusive XOR'ed with B. \r\n            ":"\r\n            汉明距离函子 - 计算两个字符串之间的位差 - 对 Brief 描述符很有用，\r\n            A 与 B 异或的位数。\r\n            \r\n","1xN array containing the second set of points.":"包含第二组点的 1xN 数组。\r\n","\r\n            Convert the standard vector to an array of Int\r\n            ":"\r\n            将标准向量转换为 Int 数组\r\n            \r\n","New number of rows.":"新的行数。\r\n","\r\n            A 3D triangle\r\n            ":"\r\n            一个 3D 三角形\r\n            \r\n","\r\n            The default border interpolation type.\r\n            ":"\r\n            默认的边框插值类型。\r\n            \r\n","Set DecodeType and Vocabulary after constructor to initialize the decoding method.":"在构造函数后设置 DecodeType 和 Vocabulary 以初始化解码方法。\r\n","\r\n            Create an empty standard vector of GMat\r\n            ":"\r\n            创建一个空的 GMat 标准向量\r\n            \r\n","The widget to be displayed in the window.":"要在窗口中显示的小部件。\r\n","The result image":"结果图像\r\n","the number of octaves in the scale-space pyramid":"尺度空间金字塔中的八度数\r\n","\r\n            Generic (unspecified) kind of sequence \r\n            ":"\r\n            通用（未指定）种类的序列\r\n            \r\n","Original image":"原图\r\n","Quantized levels per 'color co-occurrence' component. Power of two, typically 16, 32 or 64.":"每个“颜色共现”组件的量化级别。 2 的幂，通常为 16、32 或 64。\r\n","First input 3D point set.":"首先输入 3D 点集。\r\n","\r\n            Computes bitwise conjunction of a matrix and a scalar. Calculates the per-element bit-wise logical conjunction of a matrix and a scalar.\r\n            ":"\r\n            计算矩阵和标量的按位结合。计算矩阵和标量的每个元素的按位逻辑合取。\r\n            \r\n","\r\n            Euclidean distance of rgbl color space\r\n            ":"rgbl颜色空间的欧式距离\r\n            \r\n","Level of scale factor":"比例因子的水平\r\n","The unmanaged pointer for this object":"此对象的非托管指针\r\n","\r\n            (read-only) Frame rotation defined by stream meta (applicable for FFmpeg back-end only)\r\n            ":"\r\n            （只读）由流元定义的帧旋转（仅适用于 FFmpeg 后端）\r\n            \r\n","gaussian kernel value for image blur":"图像模糊的高斯核值\r\n","\r\n            Similar to Marshal.SizeOf function\r\n            ":"\r\n            类似于 Marshal.SizeOf 函数\r\n            \r\n","Integer specifying the upscale factor":"指定放大系数的整数\r\n"," Elementwise multiply another image with the current image and the ":" 按元素将另一个图像与当前图像和\r\n","Amount of angular range division quantity.":"角度范围划分量。\r\n","\r\n            Class that contains entry points for the Stereo module.\r\n            ":"\r\n            包含立体模块入口点的类。\r\n            \r\n","\tOutput 4×4 disparity-to-depth mapping matrix (see reprojectImageTo3D ).":"输出 4×4 视差到深度映射矩阵（参见 reprojectImageTo3D ）。\r\n","Camera matrix":"相机矩阵\r\n","the collection to iterate over":"要迭代的集合\r\n","\r\n            Applies a fixed-level threshold to each matrix element.\r\n            ":"\r\n            对每个矩阵元素应用固定级别的阈值。\r\n            \r\n","\r\n            Create an standard vector of Rect of the specific size\r\n            ":"创建特定大小的 Rect 标准向量\r\n            \r\n","input matrix (image)":"输入矩阵（图像）\r\n","\r\n            Calculates a mean and standard deviation of array elements.\r\n            ":"\r\n            计算数组元素的均值和标准差。\r\n            \r\n","\r\n            Convert BGRA color to RGBA color\r\n            ":"\r\n            将 BGRA 颜色转换为 RGBA 颜色\r\n            \r\n","\r\n            Interface to the BackgroundSubtractor class\r\n            ":"\r\n            BackgroundSubtractor 类的接口\r\n            \r\n","Weight parameter for the data term, attachment parameter. This is the most relevant parameter, which determines the smoothness of the output. The smaller this parameter is, the smoother the solutions we obtain. It depends on the range of motions of the images, so its value should be adapted to each image sequence.":"数据项的权重参数，附件参数。这是最相关的参数，它决定了输出的平滑度。这个参数越小，我们得到的解就越平滑。它取决于图像的运动范围，因此它的值应该适应每个图像序列。\r\n","Input mask matrix.":"输入掩码矩阵。\r\n","Size of input image in pixels.":"输入图像的大小（以像素为单位）。\r\n","\r\n            Cuda implementation of GoodFeaturesToTrackDetector\r\n            ":"\r\n            GoodFeaturesToTrackDetector 的 Cuda 实现\r\n            \r\n","Input array that should have from 1 to 4 channels so that the results can be stored in MCvScalar":"应该有 1 到 4 个通道的输入数组，以便结果可以存储在 MCvScalar 中\r\n","A CV_32UC1 integer array containing the labels of the superpixel segmentation. The labels are in the range [0, NumberOfSuperpixels].":"包含超像素分割标签的 CV_32UC1 整数数组。标签在 [0, NumberOfSuperpixels] 范围内。\r\n","\r\n            Accessors of the motion channel of the retina (models peripheral vision)\r\n            ":"\r\n            视网膜运动通道的访问器（模拟周边视觉）\r\n            \r\n","Mask specifying permissible matches between an input query and train matrices of descriptors.":"掩码指定输入查询和描述符训练矩阵之间的允许匹配。\r\n","Matrix of different depth":"不同深度的矩阵\r\n","\r\n            Black hat\r\n            ":"\r\n            黑帽\r\n            \r\n","\r\n            Create a transverse mercator warper\r\n            ":"\r\n            创建横向墨卡托变形器\r\n            \r\n","Bit depth of image elements":"图像元素的位深度\r\n","Size of block side where dct is computed":"计算 dct 的块边的大小\r\n","\r\n            Hit or miss. Only supported for CV_8UC1 binary images.\r\n            ":"\r\n            击中或没打中。仅支持 CV_8UC1 二值图像。\r\n            \r\n","\r\n            Exhaustive Linearization for Robust Camera Pose and Focal Length Estimation\r\n            ":"\r\n            用于稳健相机姿态和焦距估计的详尽线性化\r\n            \r\n","The final value of the re-projection error.":"重投影误差的最终值。\r\n","\r\n            Collate\r\n            ":"\r\n            整理\r\n            \r\n","\r\n            Create an standard vector of KeyLine of the specific size\r\n            ":"\r\n            创建特定大小的 KeyLine 的标准向量\r\n            \r\n","sample patterns using keypoints orientation":"使用关键点方向的样本模式\r\n","Projection map for the y axis":"y 轴的投影图\r\n","\r\n            Sample aspect ratio: num/den (den)\r\n            ":"\r\n            样本纵横比：num/den（den）\r\n            \r\n","\r\n            Create a GPU image from a regular image\r\n            ":"\r\n            从常规图像创建 GPU 图像\r\n            \r\n","Optional output 2Nx15 jacobian matrix of derivatives of image points with respect to components of the focal lengths, coordinates of the principal point, distortion coefficients, rotation vector, translation vector, and the skew. In the old interface different components of the jacobian are returned via different output parameters.":"可选输出 2Nx15 图像点关于焦距、主点坐标、畸变系数、旋转矢量、平移矢量和偏斜分量的雅可比矩阵。在旧界面中，jacobian 的不同组件通过不同的输出参数返回。\r\n","\r\n            Generate points with normal (gaussian) distribution.\r\n        ":"\r\n            生成具有正态（高斯）分布的点。\r\n        \r\n","\r\n            Set flag crop for frame.\r\n            ":"\r\n            为框架设置标志裁剪。\r\n            \r\n","Supports grayscale or color (BGR) image":"支持灰度或彩色 (BGR) 图像\r\n","\r\n            Wave correction kind\r\n            ":"\r\n            波浪校正类\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this white balancer\r\n            ":"释放与此白平衡器关联的所有非托管内存\r\n            \r\n","\r\n            The FREAK (Fast Retina Keypoint) keypoint descriptor:\r\n            Alahi, R. Ortiz, and P. Vandergheynst. FREAK: Fast Retina Keypoint. In IEEE Conference on Computer\r\n            Vision and Pattern Recognition, 2012. CVPR 2012 Open Source Award Winner.\r\n            The algorithm\r\n            propose a novel keypoint descriptor inspired by the human visual system and more precisely the retina, coined Fast\r\n            Retina Key- point (FREAK). A cascade of binary strings is computed by efficiently comparing image intensities over a\r\n            retinal sampling pattern. FREAKs are in general faster to compute with lower memory load and also more robust than\r\n            SIFT, SURF or BRISK. They are competitive alternatives to existing keypoints in particular for embedded applications.\r\n            ":"FREAK（快速视网膜关键点）关键点描述符：\r\n            Alahi、R. Ortiz 和 P. Vandergheynst。 FREAK：快速视网膜关键点。在 IEEE 计算机会议上\r\n            视觉和模式识别，2012 年。CVPR 2012 开源奖获得者。\r\n            算法\r\n            提出一种新颖的关键点描述符，其灵感来自人类视觉系统，更准确地说是视网膜，创造了 Fast\r\n            视网膜关键点 (FREAK)。二进制字符串的级联是通过有效地比较图像强度来计算的\r\n            视网膜采样模式。 FREAKs 通常在内存负载较低的情况下计算速度更快，而且比\r\n            筛选、冲浪或轻快。它们是现有关键点的竞争替代品，特别是对于嵌入式应用程序。\r\n            \r\n","\r\n            Get an empty InputOutputArray\r\n            ":"\r\n            获取一个空的 InputOutputArray\r\n            \r\n","Final 32-b kernel.":"最终的 32-b 内核。\r\n","\r\n            Calculates a sparse optical flow.\r\n            ":"\r\n            计算稀疏光流。\r\n            \r\n","Enable back-face culling based on CCW order":"启用基于 CCW 顺序的背面剔除\r\n","\r\n            Create image from the specific multi-dimensional data, where the 1st dimension is # of rows (height), the 2nd dimension is # cols (width) and the 3rd dimension is the channel\r\n            ":"\r\n            从特定的多维数据创建图像，其中第一维是行数（高度），第二维是列数（宽度），第三维是通道\r\n            \r\n","\r\n            Write the image to the tiff file\r\n            ":"\r\n            将图像写入tiff文件\r\n            \r\n","The vector of distortion coefficients, 4x1, 1x4, 5x1 or 1x5. ":"失真系数的矢量，4x1、1x4、5x1 或 1x5。\r\n","\r\n            FrameStartTriggerMode: Determines how a frame is initiated\r\n            ":"\r\n            FrameStartTriggerMode：确定帧的启动方式\r\n            \r\n","\r\n            Max area\r\n            ":"\r\n            最大面积\r\n            \r\n","\r\n            Sharpness Strength\r\n            ":"\r\n            锐度强度\r\n            \r\n","Drawing font size by pixel unit.":"以像素为单位绘制字体大小。\r\n","\r\n            If set, always convert image to the 3 channel BGR color image and the image size reduced 1/4.\r\n            ":"\r\n            如果设置，则始终将图像转换为 3 通道 BGR 彩色图像并且图像尺寸减小 1/4。\r\n            \r\n","The distance used for fitting ":"用于拟合的距离\r\n","negative samples to use during init":"初始化期间使用的负样本\r\n","\r\n            The result type of cvSubdiv2DLocate.\r\n            ":"\r\n            cvSubdiv2DLocate 的结果类型。\r\n            \r\n","The name of the video file to be written to ":"要写入的视频文件的名称\r\n","The multiplication of two quaternions":"两个四元数的乘法\r\n","vector of BarcodeType, specifies the type of these barcodes":"BarcodeType 的向量，指定这些条形码的类型\r\n","Use channel weights":"使用通道权重\r\n","size of the chessboard squares in pixels.":"棋盘方块的大小（以像素为单位）。\r\n","\r\n            FrameBytesPP\r\n            ":"\r\n            帧字节PP\r\n            \r\n","The optional temporary buffer to avoid memory allocation within the function.":"可选的临时缓冲区，以避免函数内的内存分配。\r\n","The managed array where data will be copied from":"从中复制数据的托管数组\r\n","\r\n            The interface for cv::reg::Mapper\r\n            ":"\r\n            cv::reg::Mapper 的接口\r\n            \r\n","\r\n            Gets the sparse optical flow pointer.\r\n            ":"\r\n            获取稀疏光流指针。\r\n            \r\n","First input 2D point set containing (X,Y).":"首先输入包含 (X,Y) 的 2D 点集。\r\n","The optional output matrix of results.":"结果的可选输出矩阵。\r\n","The size of the images to process":"要处理的图像的大小\r\n","\r\n            Calculates a part of the line segment which is entirely in the rectangle.\r\n            ":"\r\n            计算完全在矩形中的线段的一部分。\r\n            \r\n","The string representation":"字符串表示\r\n","Type of filter coefficients. It can be CV_32F or CV_64F ":"滤波器系数的类型。它可以是 CV_32F 或 CV_64F\r\n","The initial rectangle region for the foreground":"前景的初始矩形区域\r\n","\r\n            Train data\r\n            ":"\r\n            训练数据\r\n            \r\n","\r\n            MSER detector\r\n            ":"\r\n            MSER检测器\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this Pix\r\n            ":"\r\n            释放与此 Pix 关联的所有非托管内存\r\n            \r\n","Image where the circle is drawn":"绘制圆圈的图像\r\n","\r\n            Create an opencl kernel\r\n            ":"\r\n            创建一个 opencl 内核\r\n            \r\n","(For images only) If the flag is true, all the zero pixel values are treated as zeroes, all the others are treated as 1s":"（仅适用于图像）如果标志为真，所有零像素值被视为零，所有其他被视为 1s\r\n","\r\n            Allocates header for the new matrix and underlying data, and returns a pointer to the created matrix. Matrices are stored row by row. All the rows are aligned by 4 bytes. \r\n            ":"\r\n            为新矩阵和基础数据分配标头，并返回指向创建的矩阵的指针。矩阵逐行存储。所有行都按 4 个字节对齐。\r\n            \r\n","\r\n            This class represents high-level API for object detection networks.\r\n            ":"\r\n            此类代表对象检测网络的高级 API。\r\n            \r\n","\r\n            Same as DisparityFixed16_12_4\r\n            ":"\r\n            与 DisparityFixed16_12_4 相同\r\n            \r\n","\r\n            Finds minimum area rectangle that contains both input rectangles inside\r\n            ":"\r\n            查找包含两个输入矩形的最小面积矩形\r\n            \r\n","\r\n            Get the data dimension\r\n            ":"\r\n            获取数据维度\r\n            \r\n","The first source array. If the pointer is IntPtr.Zero, the array is assumed to be all 1s. ":"第一个源数组。如果指针为 IntPtr.Zero，则假定数组全为 1。\r\n","Output image, 8-bit unsigned 3-channel":"输出图像，8 位无符号 3 通道\r\n","\r\n            Calculates the superpixel segmentation on a given image with the initialized parameters in the ScanSegment object. This function can be called again for other images without the need of initializing the algorithm with createScanSegment(). This save the computational cost of allocating memory for all the structures of the algorithm.\r\n            ":"\r\n            使用 ScanSegment 对象中的初始化参数计算给定图像的超像素分割。可以为其他图像再次调用此函数，而无需使用 createScanSegment() 初始化算法。这节省了为算法的所有结构分配内存的计算成本。\r\n            \r\n","\r\n            Photoreceptors local adaptation sensitivity. Use 0.7 for default\r\n            ":"\r\n            光感受器局部适应敏感性。默认使用 0.7\r\n            \r\n","\r\n            Debug draw markers of matched correspondences onto a lineBundle\r\n            ":"\r\n            调试将匹配对应关系的绘制标记绘制到 lineBundle 上\r\n            \r\n","\r\n            Return true if Cuda is found on the system\r\n            ":"\r\n            如果在系统上找到 Cuda，则返回真\r\n            \r\n","\r\n            Computes an RQ decomposition of 3x3 matrices.\r\n            ":"\r\n            计算 3x3 矩阵的 RQ 分解。\r\n            \r\n","Gabor filter coefficients.":"Gabor 滤波器系数。\r\n","The camera matrix (A) [fx 0 cx; 0 fy cy; 0 0 1]. ":"相机矩阵 (A) [fx 0 cx; 0 个周期； 0 0 1]。\r\n","Number of bins between \"histThresh\" and 32*pi*pi (highest edge reliability value). Default value is 5.":"“histThresh”和 32*pi*pi（最高边缘可靠性值）之间的箱数。默认值为 5。\r\n","\r\n            Returns the default new camera matrix.\r\n            ":"\r\n            返回默认的新相机矩阵。\r\n            \r\n","\r\n            Color Correction Matrix element [0][2]\r\n            ":"\r\n            颜色校正矩阵元素 [0][2]\r\n            \r\n","Contour (set of points) to apply the transformation.":"应用变换的轮廓（点集）。\r\n","A TSV-formatted string from the internal data structures.":"来自内部数据结构的 TSV 格式字符串。\r\n","Output Mat for unary computation":"一元计算的输出矩阵\r\n","\r\n            Attempts to load opencv modules from the specific location\r\n            ":"\r\n            尝试从特定位置加载 opencv 模块\r\n            \r\n","\r\n            Extrinsic will be recomputed after each iteration of intrinsic optimization.\r\n            ":"\r\n            每次内在优化迭代后都会重新计算外在。\r\n            \r\n","The disparity map":"视差图\r\n","Input 8-bit 1-channel, 2-channel or 3-channel image.":"输入 8 位 1 通道、2 通道或 3 通道图像。\r\n","\r\n            Central Moment Mu30\r\n            ":"\r\n            中心矩 Mu30\r\n            \r\n","\r\n            Release the unmanaged memory associated with this Flann Index\r\n            ":"\r\n            释放与此 Flann 索引关联的非托管内存\r\n            \r\n","Right image of the same size and the same type as the left one.":"右图与左图大小和类型相同。\r\n","The 3x3 Homography matrix":"3x3 单应矩阵\r\n","The Mat to be written to. If no more frame is available, the resulting Mat will be empty.":"要写入的 Mat。如果没有更多的框架可用，则生成的 Mat 将为空。\r\n","\r\n            Capture from camera\r\n            ":"\r\n            从相机捕捉\r\n            \r\n","\r\n            The variance threshold for the pixel-model match used for new mixture component generation. Threshold for the squared Mahalanobis distance that helps decide when a sample is close to the existing components (corresponds to Tg in the paper). If a pixel is not close to any component, it is considered foreground or added as a new component. 3 sigma =%gt\r\n            ":"\r\n            用于新混合成分生成的像素模型匹配的方差阈值。马氏距离平方的阈值有助于确定样本何时接近现有成分（对应于论文中的 Tg）。如果像素不靠近任何组件，则将其视为前景或添加为新组件。 3西格玛=%gt\r\n            \r\n"," Minimum line length. Line segments shorter than that are rejected.":" 最小行长度。短于此的线段将被拒绝。\r\n","Fundamental matrix ":"基本矩阵\r\n","\r\n            Calculates an optical flow.\r\n            ":"\r\n            计算光流。\r\n            \r\n","\r\n            Release the unmanaged memory associated with this FaceDetectorYN\r\n            ":"\r\n            释放与此 FaceDetectorYN 关联的非托管内存\r\n            \r\n","Coefficient by which we divide the dimensions from one scale pyramid level to the next.":"我们将维度从一个比例金字塔级别划分到下一个级别的系数。\r\n","Number of inner corners per a chessboard row and column ( patternSize = cv::Size(points_per_row,points_per_colum) = cv::Size(columns,rows) ).":"每个棋盘行和列的内角数（patternSize = cv::Size(points_per_row,points_per_colum) = cv::Size(columns,rows)）。\r\n","Number of pixels between two consecutive markers on the same row.":"同一行上两个连续标记之间的像素数。\r\n","\r\n            Create a new CCheckerDetector.\r\n            ":"\r\n            创建一个新的 CCheckerDetector。\r\n            \r\n","\r\n            Creates a graph based segmentor.\r\n            ":"\r\n            创建基于图形的分割器。\r\n            \r\n","\r\n            Compute the sum of two 3D points\r\n            ":"\r\n            计算两个 3D 点的总和\r\n            \r\n","\r\n            Get the names of the channels\r\n            ":"\r\n            获取频道名称\r\n            \r\n","The rotation matrix that rotate the source image to the destination image.":"将源图像旋转到目标图像的旋转矩阵。\r\n","\r\n            Create an instance of VGG\r\n            ":"\r\n            创建 VGG 实例\r\n            \r\n","The center of the region":"该地区的中心\r\n","the weight of ":"的重量\r\n","Source array, real or complex":"源数组，实数或复数\r\n","\r\n            Initialize the class with the 'Selective search quality' parameters\r\n            ":"\r\n            使用“选择性搜索质量”参数初始化类\r\n            \r\n","\r\n            Dump net to String\r\n            ":"\r\n            将网络转储到字符串\r\n            \r\n","An empty InputOutputArray":"一个空的 InputOutputArray\r\n","\r\n            Finds circles in a grayscale image using the Hough transform.\r\n            ":"\r\n            使用 Hough 变换在灰度图像中查找圆。\r\n            \r\n","\r\n            Chroma formats supported by VideoReader.\r\n            ":"\r\n            VideoReader 支持的色度格式。\r\n            \r\n","\r\n            Given the input frame, create input blob, run net and return result detections.\r\n            ":"\r\n            给定输入帧，创建输入 blob，运行网络并返回结果检测。\r\n            \r\n","The data which will be stored in the storage":"将存储在存储中的数据\r\n","\r\n            Bad tile size\r\n            ":"\r\n            瓷砖尺寸错误\r\n            \r\n","\r\n            Class that contains extension methods for Feature2DAsync\r\n            ":"\r\n            包含 Feature2DAsync 扩展方法的类\r\n            \r\n","True if the location of the two points are equal":"如果两点的位置相等则为真\r\n","\r\n            Get the normal of this triangle\r\n            ":"\r\n            得到这个三角形的法线\r\n            \r\n","Gaussian kernel standard deviation in Y direction; if sigmaY is zero, it is set to be equal to sigmaX, if both sigmas are zeros, they are computed from ksize.width and ksize.height , respectively (see getGaussianKernel() for details); to fully control the result regardless of possible future modifications of all this semantics, it is recommended to specify all of ksize, sigmaX, and sigmaY.":"Y方向的高斯核标准差；如果 sigmaY 为零，则将其设置为等于 sigmaX，如果两个 sigma 均为零，则分别从 ksize.width 和 ksize.height 计算（有关详细信息，请参见 getGaussianKernel()）；为了完全控制结果而不考虑所有这些语义的未来可能修改，建议指定所有 ksize、sigmaX 和 sigmaY。\r\n","\r\n            Assign the new value to the particular element of single-channel array\r\n            ":"\r\n            将新值分配给单通道数组的特定元素\r\n            \r\n","The second source array.":"第二个源数组。\r\n","The xml document as a string":"作为字符串的 xml 文档\r\n","\r\n            Specify weights of feature functions.\r\n            Consider keeping weights normalized (sum of weights equals to 1.0) Discrete dynamic programming (DP) goal is minimization of costs between pixels.\r\n            ":"\r\n            指定特征函数的权重。\r\n            考虑保持权重标准化（权重之和等于 1.0） 离散动态规划 (DP) 目标是像素之间的成本最小化。\r\n            \r\n","\r\n            White balance red v\r\n            ":"\r\n            白平衡红v\r\n            \r\n","feature size after compression":"压缩后的特征尺寸\r\n","The thresholded image":"阈值图像\r\n","\r\n            Lr check\r\n            ":"\r\n            检查\r\n            \r\n","\r\n            Weight type\r\n            ":"\r\n            重量类型\r\n            \r\n","\r\n            Writing direction\r\n            ":"\r\n            书写方向\r\n            \r\n","\r\n            The equivalent of cv::Moments\r\n            ":"\r\n            相当于 cv::Moments\r\n            \r\n","the binary map":"二进制映射\r\n"," Default number of sublevels per scale level":" 每个比例级别的默认子级别数\r\n","\r\n            Slow perf level results in lowest performance and best quality\r\n            ":"\r\n            低性能水平导致最低性能和最佳质量\r\n            \r\n","\r\n            Properties of cameras available through GStreamer interface. Default is 1\r\n            ":"\r\n            通过 GStreamer 接口可用的相机属性。默认为 1\r\n            \r\n","Number of fractional bits in the vertex coordinates":"顶点坐标中的小数位数\r\n","\r\n            Apply Probabilistic Hough transform to find line segments.\r\n            The current image must be a binary image (eg. the edges as a result of the Canny edge detector)\r\n            ":"\r\n            应用概率霍夫变换来查找线段。\r\n            当前图像必须是二值图像（例如，作为 Canny 边缘检测器结果的边缘）\r\n            \r\n","If it is true, the histogram is not cleared in the beginning. This feature allows user to compute a single histogram from several images, or to update the histogram online. ":"如果为真，则直方图一开始不会被清除。此功能允许用户从多个图像计算单个直方图，或在线更新直方图。\r\n","\r\n            Fourier transform profilometry\r\n            ":"\r\n            傅里叶变换轮廓测量\r\n            \r\n","\r\n            Calculates optical flow for a sparse feature set using iterative Lucas-Kanade method in pyramids\r\n            ":"\r\n            使用金字塔中的迭代 Lucas-Kanade 方法计算稀疏特征集的光流\r\n            \r\n","Output 3x3 rectification transform (rotation matrix) for the second camera.":"为第二个摄像头输出 3x3 整流变换（旋转矩阵）。\r\n","\r\n            The number of neighbours, the k in the kNN. K is the number of samples that need to be within dist2Threshold in order to decide that pixel is matching the kNN background model.\r\n            ":"\r\n            邻居的数量，kNN 中的 k。 K 是需要在 dist2Threshold 内的样本数，以便确定像素与 kNN 背景模型匹配。\r\n            \r\n","\r\n            Interpolation type used to compute the dense optical flow.\r\n            ":"\r\n            用于计算密集光流的插值类型。\r\n            \r\n","\r\n            Returns overall time for inference and timings (in ticks) for layers.\r\n            Indexes in returned vector correspond to layers ids. Some layers can be fused with others, in this case zero ticks count will be return for that skipped layers.\r\n            Supported by DNN_BACKEND_OPENCV on DNN_TARGET_CPU only.\r\n            ":"\r\n            返回层的推理和计时（以滴答为单位）的总时间。\r\n            返回向量中的索引对应于层 ID。一些层可以与其他层融合，在这种情况下，跳过的层将返回零滴答计数。\r\n            仅在 DNN_TARGET_CPU 上受 DNN_BACKEND_OPENCV 支持。\r\n            \r\n","\r\n            When measureDist = false, the return value is >0 (inside), <0 (outside) and =0 (on edge), respectively. \r\n            When measureDist != true, it is a signed distance between the point and the nearest contour edge\r\n            ":"\r\n            当 measureDist = false 时，返回值分别为 >0（内部）、<0（外部）和 =0（边缘）。\r\n            当measureDist != true时，是点到最近轮廓边的有符号距离\r\n            \r\n","\r\n            status bar and tool bar\r\n            ":"\r\n            状态栏和工具栏\r\n            \r\n","The other matrix to compare with":"另一个要比较的矩阵\r\n","The probs0.":"概率0。\r\n","\r\n            Disparity map refinement using joint bilateral filtering given a single color image.\r\n            Qingxiong Yang, Liang Wang†, Narendra Ahuja\r\n            http://vision.ai.uiuc.edu/~qyang6/\r\n            ":"\r\n            给定单个彩色图像使用联合双边滤波的视差图细化。\r\n            Qingxiong Yang、Liang Wang†、Narendra Ahuja\r\n            http://vision.ai.uiuc.edu/~qyang6/\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of DMatch.\r\n            ":"\r\n            DMatch 的 C++ 标准向量的包装类。\r\n            \r\n","The color for the rectangle":"矩形的颜色\r\n","Orientation flag. If it is true, the output convex hull is oriented clockwise. Otherwise, it is oriented counter-clockwise. The assumed coordinate system has its X axis pointing to the right, and its Y axis pointing upwards.":"方向标志。如果为真，则输出凸包为顺时针方向。否则，它是逆时针方向的。假定坐标系的 X 轴指向右侧，Y 轴指向上方。\r\n","Two GMats, first one is the tilted integral image, second one is the integral image of squared pixel values.":"两个 GMats，第一个是倾斜的积分图像，第二个是平方像素值的积分图像。\r\n","\r\n            Computes the weighted sum of two arrays (dst = alpha*src1 + beta*src2 + gamma)\r\n            ":"\r\n            计算两个数组的加权和 (dst = alpha*src1 + beta*src2 + gamma)\r\n            \r\n","\r\n            Get the OCR Engine Mode\r\n            ":"\r\n            获取 OCR 引擎模式\r\n            \r\n","\r\n            Pointer to the unmanaged Facemark object\r\n            ":"\r\n            指向非托管 Facemark 对象的指针\r\n            \r\n","Allow to choose between FTP, PSP and FAPS.":"允许在 FTP、PSP 和 FAPS 之间进行选择。\r\n","\r\n            Convert HLS color to RGB color\r\n            ":"\r\n            将 HLS 颜色转换为 RGB 颜色\r\n            \r\n","\r\n            Confident threshold\r\n            ":"\r\n            置信阈值\r\n            \r\n","The file name of the storage, all data in the existing file will be replaced":"存储的文件名，现有文件中的所有数据将被替换\r\n","the maximum number of corners to consider":"要考虑的最大角数\r\n","\r\n            Estimate the transformation parameters of the current transformer algorithm, based on point matches.\r\n            ":"\r\n            基于点匹配估计电流互感器算法的变换参数。\r\n            \r\n","\r\n            Create a new Intelligent Scissors for image segmentation.\r\n            ":"\r\n            为图像分割创建一个新的智能剪刀。\r\n            \r\n","The first point on the line segment":"线段上的第一个点\r\n","Filter range standard deviation for the joint image.":"联合图像的过滤范围标准偏差。\r\n","The matrix without a specified column span of the input array":"输入数组没有指定列跨度的矩阵\r\n","x coordinate of the image pixel.":"图像像素的 x 坐标。\r\n","Number of rows in the matrix.":"矩阵中的行数。\r\n","\r\n            Copies a 2D array to a larger destination array and pads borders with the given constant.\r\n            ":"\r\n            将 2D 数组复制到更大的目标数组，并用给定常量填充边框。\r\n            \r\n","Specifies the parallel granularity of the workload. This parameter should be used GPU experts when optimizing performance.":"指定工作负载的并行粒度。这个参数应该是 GPU 专家在优化性能时使用的。\r\n","\r\n            Automatic exposure/gain ROI offset X\r\n            ":"\r\n            自动曝光/增益 ROI 偏移量 X\r\n            \r\n","Element shape":"元素形状\r\n","The function which acepts the src IntPtr, dest IntPtr and index of the channel as input":"接受 src IntPtr、dest IntPtr 和通道索引作为输入的函数\r\n","\r\n            True if the input array is a Mat\r\n            ":"\r\n            如果输入数组是 Mat，则为真\r\n            \r\n","\r\n            Copies the source 2D array into interior of destination array and makes a border of the specified type around the copied area. The function is useful when one needs to emulate border type that is different from the one embedded into a specific algorithm implementation. For example, morphological functions, as well as most of other filtering functions in OpenCV, internally use replication border type, while the user may need zero border or a border, filled with 1's or 255's\r\n            ":"\r\n            将源二维数组复制到目标数组的内部，并在复制区域周围制作指定类型的边框。当需要模拟不同于嵌入到特定算法实现中的边框类型时，该函数很有用。例如，形态函数，以及 OpenCV 中的大多数其他过滤函数，内部使用复制边界类型，而用户可能需要零边界或边界，填充 1 或 255\r\n            \r\n","  \r\n            index of element of some other sequence \r\n            ":"  \r\n            其他序列的元素索引\r\n            \r\n","A string representation of this oclDevice":"此 oclDevice 的字符串表示形式\r\n","\r\n            The function computes the superpixels segmentation of an image with the parameters initialized with the function createSuperpixelSEEDS().\r\n            ":"\r\n            该函数使用函数 createSuperpixelSEEDS() 初始化的参数计算图像的超像素分割。\r\n            \r\n","\r\n            Calculates per-element bit-wise logical conjunction of two arrays:\r\n            dst(I)=src1(I)^src2(I) if mask(I)!=0\r\n            In the case of floating-point arrays their bit representations are used for the operation. All the arrays must have the same type, except the mask, and the same size\r\n            ":"\r\n            计算两个数组的每个元素的按位逻辑合取：\r\n            dst(I)=src1(I)^src2(I) 如果掩码(I)!=0\r\n            在浮点数组的情况下，它们的位表示用于操作。除掩码外，所有数组必须具有相同的类型和相同的大小\r\n            \r\n","Number of motion pixels within silhouette ROI":"轮廓 ROI 内的运动像素数\r\n","input image.":"输入图像。\r\n","Detection results stored in a Mat":"检测结果存储在 Mat 中\r\n","Specifies the importance of the index build time reported to the nearest-neighbor search time. In some applications it’s acceptable for the index build step to take a long time if the subsequent searches in the index can be performed very fast. In other applications it’s required that the index be build as fast as possible even if that leads to slightly longer search times.":"指定报告给最近邻搜索时间的索引构建时间的重要性。在某些应用程序中，如果可以非常快速地执行索引中的后续搜索，则索引构建步骤花费很长时间是可以接受的。在其他应用程序中，要求尽可能快地构建索引，即使这会导致搜索时间稍长。\r\n","The type of the method":"方法的类型\r\n","UTF8-encoded output vector of string(s) or empty vector of string if the codes cannot be decoded.":"UTF8 编码的字符串输出向量或字符串的空向量（如果代码无法解码）。\r\n","\r\n            Convert YUV (i420) to RGBA\r\n            ":"\r\n            将 YUV (i420) 转换为 RGBA\r\n            \r\n","\r\n            Write or overwrite a Mat object into specified dataset of hdf5 file.\r\n            ":"\r\n            将 Mat 对象写入或覆盖到 hdf5 文件的指定数据集中。\r\n            \r\n","Use color names":"使用颜色名称\r\n","\r\n            Apply filtering to the disparity map.\r\n            ":"\r\n            对视差图应用过滤。\r\n            \r\n"," \r\n            Split current Image into an array of gray scale images where each element \r\n            in the array represent a single color channel of the original image\r\n            ":" \r\n            将当前图像拆分为灰度图像数组，其中每个元素\r\n            在数组中表示原始图像的单个颜色通道\r\n            \r\n","\r\n            Calculates the superpixel segmentation on a given image with the initialized parameters in the SuperpixelSEEDS object.\r\n            ":"\r\n            使用 SuperpixelSEEDS 对象中的初始化参数计算给定图像的超像素分割。\r\n            \r\n","\r\n            Returns the textual description for the specified error status code. In case of unknown status the function returns NULL pointer. \r\n            ":"\r\n            返回指定错误状态代码的文本描述。在未知状态的情况下，该函数返回 NULL 指针。\r\n            \r\n","Keep at most ":"最多保留\r\n","source image for filtering with unsigned 8-bit or signed 16-bit or floating-point 32-bit depth and up to 4 channels.":"用于使用无符号 8 位或有符号 16 位或浮点 32 位深度和最多 4 个通道进行过滤的源图像。\r\n"," image and ":" 图像和\r\n","Optical flow algorithm may optionally involve cuda preprocessing on the input buffers. The input cuda stream can be used to pipeline and synchronize the cuda preprocessing tasks with OF HW engine. If input stream is not set, the execute function will use default stream which is NULL stream":"光流算法可以选择涉及输入缓冲区的 cuda 预处理。输入 cuda 流可用于将 cuda 预处理任务与 OF HW 引擎进行流水线化和同步。如果未设置输入流，则执行函数将使用默认流，即 NULL 流\r\n","Optional information about hierarchy. It is only needed if you want to draw only some of the contours":"有关层次结构的可选信息。仅当您只想绘制部分轮廓时才需要\r\n","\r\n            Convert all weights of Caffe network to half precision floating point\r\n            ":"\r\n            将Caffe网络的所有权重转换为半精度浮点数\r\n            \r\n","The dstination GpuMat. Supports CV_8UC1, CV_8UC3 source types. ":"目的地 GpuMat。支持 CV_8UC1、CV_8UC3 源类型。\r\n","Pixel extrapolation method in the vertical direction":"垂直方向的像素外推法\r\n","\r\n            Norm L2\r\n            ":"\r\n            范数 L2\r\n            \r\n","\r\n            The pointer to memory address at the end of the vector. In case of an empty vector, IntPtr.Zero will be returned.\r\n            ":"\r\n            指向向量末尾的内存地址的指针。如果是空向量，将返回 IntPtr.Zero。\r\n            \r\n","\r\n            The index parameter pointer.\r\n            ":"\r\n            索引参数指针。\r\n            \r\n","\r\n            image ROI. when it is not NULL, this specifies image region to process \r\n            ":"\r\n            图像投资回报率。当它不为 NULL 时，这指定要处理的图像区域\r\n            \r\n","\r\n            Preset\r\n            ":"\r\n            预设\r\n            \r\n","The subsample rate":"子采样率\r\n","\r\n            Finds perspective transformation H=||hij|| between the source and the destination planes\r\n            ":"\r\n            寻找透视变换 H=||hij||在源平面和目标平面之间\r\n            \r\n","\r\n            Get the depth representation for Open CV\r\n            ":"\r\n            获取 Open CV 的深度表示\r\n            \r\n","\r\n            Used by some cuda methods, will pass the value -1 to the function\r\n            ":"\r\n            由某些 cuda 方法使用，会将值 -1 传递给函数\r\n            \r\n","\tOutput array of image points, 1xN/Nx1 2-channel, or vector<Point2f> .":"输出图像点数组，1xN/Nx1 2 通道，或 vector<Point2f> 。\r\n","\r\n            Release the memory associated with this Hausdorff distance extractor\r\n            ":"\r\n            释放与此 Hausdorff 距离提取器关联的内存\r\n            \r\n","The solution will be returned here as a column-vector - it corresponds to c in the formulation above. It will contain 64-bit floating point numbers.":"解决方案将在此处作为列向量返回 - 它对应于上面公式中的 c。它将包含 64 位浮点数。\r\n","\r\n            output contours in the Freeman chain code. All other methods output polygons (sequences of vertices). \r\n            ":"\r\n            Freeman 链码中的输出轮廓。所有其他方法输出多边形（顶点序列）。\r\n            \r\n","a circumscribed rectangle of the minimal area for 2D point set":"二维点集最小面积的外接矩形\r\n","\r\n            Decode image stored in the buffer\r\n            ":"\r\n            解码存储在缓冲区中的图像\r\n            \r\n","the mask for coping":"应对的面具\r\n","\r\n            Performs advanced morphological transformations.\r\n            ":"\r\n            执行高级形态转换。\r\n            \r\n","\r\n            moves iterator to the next node\r\n            ":"\r\n            将迭代器移动到下一个节点\r\n            \r\n","\r\n            Pointer to the unamanged Algorithm object\r\n            ":"\r\n            指向未管理的 Algorithm 对象的指针\r\n            \r\n","\r\n            Compare this circle with ":"\r\n            比较这个圈子\r\n","\r\n            Coefficient to regulate the similarity threshold. When detected, some objects can be covered by many rectangles. 0 means not to perform grouping. See groupRectangles.\r\n            ":"\r\n            调节相似度阈值的系数。检测到时，某些对象可以被许多矩形覆盖。 0 表示不进行分组。请参见组矩形。\r\n            \r\n","\r\n            Constructs repositioned planar circle.\r\n            ":"\r\n            构造重新定位的平面圆。\r\n            \r\n","The assigned value":"赋值\r\n","grayscale or color (BGR) image containing barcode.":"包含条形码的灰度或彩色 (BGR) 图像。\r\n","The values for the convolution kernel":"卷积核的值\r\n","\r\n            Blob file config\r\n            ":"\r\n            Blob 文件配置\r\n            \r\n"," Elementwise subtract another matrix from the current matrix ":" Elementwise 从当前矩阵中减去另一个矩阵\r\n","\r\n            Create a empty OclDevice object\r\n            ":"\r\n            创建一个空的 OclDevice 对象\r\n            \r\n"," transformation 2x2 or 2x3 floating-point matrix.":" 转换 2x2 或 2x3 浮点矩阵。\r\n","\r\n            Structure contains the bounding box and confidence level for detected object\r\n            ":"\r\n            结构包含检测到的对象的边界框和置信度\r\n            \r\n","Optional vector of reprojection error, that is the RMS error between the input image points and the 3D object points projected with the estimated pose.":"重投影误差的可选向量，即输入图像点与使用估计姿态投影的 3D 对象点之间的 RMS 误差。\r\n","\r\n            Calculates histogram with evenly distributed bins for single channel source.\r\n            ":"\r\n            为单通道源计算具有均匀分布箱的直方图。\r\n            \r\n","\r\n            Return true if the input array is empty\r\n            ":"\r\n            如果输入数组为空则返回真\r\n            \r\n","The minimum location":"最小位置\r\n","\r\n            Create a background subtractor module based on GMG\r\n            ":"\r\n            基于GMG创建背景减法器模块\r\n            \r\n","\r\n            Polygon\r\n            ":"\r\n            多边形\r\n            \r\n"," Threshold the image inplace such that: dst(x,y) = src(x,y), if src(x,y)>threshold;  0, otherwise ":" 将图像阈值设置为：dst(x,y) = src(x,y)，如果 src(x,y)>threshold； 0，否则\r\n","\r\n            Find the ColorCharts in the given image. The found charts are not returned but instead stored in the\r\n            detector, these can be accessed later on using BestColorChecker\r\n            and GetListColorChecker()\r\n            ":"\r\n            在给定图像中找到 ColorCharts。找到的图表不会返回，而是存储在\r\n            检测器，这些可以稍后使用 BestColorChecker 访问\r\n            和 GetListColorChecker()\r\n            \r\n","Use -1 for default":"默认使用-1\r\n","\r\n            Point 3D set\r\n            ":"\r\n            点 3D 集\r\n            \r\n","\r\n            Create an standard vector of VectorOfPointF with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfPointF 的标准向量\r\n            \r\n","\r\n            variation of Gradient to get better accuracy\r\n            ":"\r\n            梯度的变化以获得更好的准确性\r\n            \r\n","\r\n            The default constructor which allows Data to be set later on\r\n            ":"\r\n            允许稍后设置数据的默认构造函数\r\n            \r\n","The length of the history.":"历史的长度。\r\n","\r\n            The classic method, color-based selection and alpha masking might be time consuming and often leaves an undesirable halo. Seamless cloning, even averaged with the original image, is not effective. Mixed seamless cloning based on a loose selection proves effective.\r\n            ":"\r\n            经典方法、基于颜色的选择和 alpha 蒙版可能非常耗时，而且常常会留下不受欢迎的光晕。无缝克隆，即使与原始图像平均，也是无效的。基于松散选择的混合无缝克隆被证明是有效的。\r\n            \r\n","Default cost":"默认成本\r\n","The sorted data that will be interpolated from":"将从中插值的排序数据\r\n","\r\n            The number of mixtures\r\n            ":"\r\n            混合物数\r\n            \r\n","single-channel template image; CV_8U or CV_32F array.":"单通道模板图像； CV_8U 或 CV_32F 数组。\r\n","\r\n            Release unmanaged memory associated with this binary descriptor\r\n            ":"\r\n            释放与此二进制描述符关联的非托管内存\r\n            \r\n","See: K. Simonyan, A. Vedaldi, and A. Zisserman. Learning local feature descriptors using convex optimisation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2014.":"参见：K. Simonyan、A. Vedaldi 和 A. Zisserman。使用凸优化学习局部特征描述符。 IEEE 模式分析和机器智能汇刊，2014 年。\r\n","0 if no device found. sizeof(cl_device_id) if device is found.":"0 如果没有找到设备。 sizeof(cl_device_id) 如果找到设备。\r\n","\r\n            Do forward or inverse transform of every individual row of the input matrix. This flag allows user to transform multiple vectors simultaneously and can be used to decrease the overhead (which is sometimes several times larger than the processing itself), to do 3D and higher-dimensional transforms etc\r\n            ":"\r\n            对输入矩阵的每一行进行正向或反向变换。此标志允许用户同时变换多个向量，可用于减少开销（有时比处理本身大几倍），进行 3D 和更高维变换等\r\n            \r\n","\r\n            Parse Error\r\n            ":"\r\n            解析错误\r\n            \r\n","Linear part of the affine transformation":"仿射变换的线性部分\r\n","\r\n            Refines coordinates of corresponding points.\r\n            ":"\r\n            细化对应点的坐标。\r\n            \r\n","Number of disparities.":"差距的数量。\r\n","Uniformly distributed random double number from [a,b) range":"来自 [a,b) 范围的均匀分布的随机双数\r\n","\r\n            The number of kneepoints in the PWLR.\r\n            ":"\r\n            PWLR 中的拐点数。\r\n            \r\n","segEgbThresholdII":"segb阈值II\r\n","\r\n            show the training print-out\r\n            ":"\r\n            显示培训打印输出\r\n            \r\n","The number of channels of the the destination image":"目标图像的通道数\r\n","On successful termination, the function returns 0.":"成功终止后，该函数返回 0。\r\n","Color type of this image (either Gray, Bgr, Bgra, Hsv, Hls, Lab, Luv, Xyz, Ycc, Rgb or Rbga)":"此图像的颜色类型（Gray、Bgr、Bgra、Hsv、Hls、Lab、Luv、Xyz、Ycc、Rgb 或 Rbga）\r\n","\r\n            Bad argument\r\n            ":"\r\n            错误的论点\r\n            \r\n","  \r\n            (x,y,z)  \r\n            ":"  \r\n            (x,y,z)\r\n            \r\n","\r\n            The module brings implementation of the image processing algorithms based on fuzzy mathematics.\r\n            ":"\r\n            该模块实现了基于模糊数学的图像处理算法。\r\n            \r\n"," \r\n            Defines a Xyz color (CIE XYZ.Rec 709 with D65 white point)\r\n            ":" \r\n            定义 Xyz 颜色（具有 D65 白点的 CIE XYZ.Rec 709）\r\n            \r\n","\r\n            CIE 2000\r\n            ":"\r\n            中国国际教育学院 2000\r\n            \r\n","The square of the Eculidean distance between the neighbours":"邻居之间欧库里德距离的平方\r\n"," Get or set the intensity of the lightness color channel ":" 获取或设置亮度颜色通道的强度\r\n","\r\n            Header reference count\r\n            ":"\r\n            标头引用计数\r\n            \r\n","\r\n            Create a BRISK keypoint detector and descriptor extractor.\r\n            ":"\r\n            创建 BRISK 关键点检测器和描述符提取器。\r\n            \r\n","\r\n            Concate the current image with another image vertically.\r\n            ":"\r\n            将当前图像与另一个图像垂直连接。\r\n            \r\n","\r\n            Release the stream\r\n            ":"\r\n            释放流\r\n            \r\n"," is IntPtr.Zero. Otherwise the norm of the difference between two GpuMats.":" 是 IntPtr.Zero。否则两个 GpuMats 之间差异的范数。\r\n"," \r\n            Get or Set the region of interest for this image. To clear the ROI, set it to System.Drawing.Rectangle.Empty\r\n            ":" \r\n            获取或设置此图像的感兴趣区域。要清除 ROI，请将其设置为 System.Drawing.Rectangle.Empty\r\n            \r\n","\r\n            Intel Perceptual Computing SDK\r\n            ":"\r\n            英特尔感知计算SDK\r\n            \r\n","\r\n            Correction of column FPN\r\n            ":"\r\n            列FPN的修正\r\n            \r\n","\r\n            Find as much text as possible in no particular order.\r\n            ":"\r\n            尽可能多地查找没有特定顺序的文本。\r\n            \r\n","FindHomography method":"FindHomography 方法\r\n","Size of a found chessboard pattern":"找到的棋盘图案的大小\r\n","input image necesary for corner refinement. Note that markers are not detected and should be sent in corners and ids parameters.":"角点细化所需的输入图像。请注意，未检测到标记，应在角和 ids 参数中发送。\r\n","\r\n            Entry points for the cv::reg functions\r\n            ":"\r\n            cv::reg 函数的入口点\r\n            \r\n","\r\n            Create a mat of the specific type.\r\n            ":"\r\n            创建特定类型的垫子。\r\n            \r\n","The line bundle":"线束\r\n","\r\n            Set scalefactor value for frame.\r\n            ":"\r\n            设置框架的比例因子值。\r\n            \r\n","Stream for the asynchronous version":"异步版本的流\r\n","The umat":"乌玛特\r\n","\r\n            The color checker type\r\n            ":"\r\n            颜色检查器类型\r\n            \r\n","\r\n            Get the GpuMat type\r\n            ":"\r\n            获取 GpuMat 类型\r\n            \r\n","the col of the element":"元素的列\r\n","\r\n            Termination criteria of the algorithm\r\n            ":"\r\n            算法的终止标准\r\n            \r\n","\r\n            Morphology filter\r\n            ":"\r\n            形态过滤器\r\n            \r\n","\r\n            To apply the global motion prior motion vectors will be computed on a regularly sampled which are the basis for Homography estimation using RANSAC. The reprojection threshold is based on n-th percentil (given by this value [0 ... 100]) of the motion vectors magnitude.\r\n            ":"\r\n            为了应用全局运动先验运动矢量，将在定期采样的基础上计算运动矢量，这是使用 RANSAC 进行单应性估计的基础。重投影阈值基于运动矢量幅度的第 n 个百分位（由此值 [0 ... 100] 给出）。\r\n            \r\n","blob for first output of specified layer":"指定层的第一个输出的 blob\r\n","Vector of inputs GMats for this computation":"此计算的输入向量 GMats\r\n","The maximum number of keypoints to be extracted.":"要提取的最大关键点数。\r\n","\r\n            Updates the background model\r\n            ":"\r\n            更新背景模型\r\n            \r\n","\r\n            Simple one-line Domain Transform filter call. \r\n            ":"\r\n            简单的一行域转换过滤器调用。\r\n            \r\n","\r\n            Convert Bayer GRBG to RGB (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 Bayer GRBG 转换为 RGB（边缘感知去马赛克）\r\n            \r\n","\r\n            This class represents high-level API for keypoints models.\r\n            ":"\r\n            此类代表关键点模型的高级 API。\r\n            \r\n","\r\n            This function is not implemented for MatND\r\n            ":"\r\n            MatND 未实现此功能\r\n            \r\n","\r\n            Get the area of this map as a rectangle\r\n            ":"\r\n            获取此地图的面积为矩形\r\n            \r\n","Angle resolution measured in radians":"以弧度测量的角度分辨率\r\n","\r\n            Create an InputOutputArray from an existing unmanaged inputOutputArray pointer\r\n            ":"\r\n            从现有的非托管 inputOutputArray 指针创建 InputOutputArray\r\n            \r\n","True if successfully added":"如果成功添加则为真\r\n","Adjust the sampling window around detected keypoints: 1.00f should be the scale for ORB keypoints; 6.75f should be the scale for SIFT detected keypoints; 6.25f is default and fits for KAZE, SURF detected keypoints; 5.00f should be the scale for AKAZE, MSD, AGAST, FAST, BRISK keypoints":"调整检测到的关键点周围的采样窗口：1.00f 应该是 ORB 关键点的比例； 6.75f 应该是 SIFT 检测到的关键点的比例； 6.25f 是默认值，适用于 KAZE、SURF 检测到的关键点； 5.00f 应该是 AKAZE、MSD、AGAST、FAST、BRISK 关键点的比例\r\n","\r\n            Gets a value indicating whether this device have open CL compatible gpu device.\r\n            ":"\r\n            获取一个值，该值指示此设备是否具有开放的 CL 兼容 gpu 设备。\r\n            \r\n","Destination vector of maxlevel+1 images of the same type as src. dst[0] will be the same as src. dst[1] is the next pyramid layer, a smoothed and down-sized src, and so on.":"与 src 相同类型的 maxlevel+1 个图像的目标向量。 dst[0] 将与 src 相同。 dst[1] 是下一个金字塔层，一个平滑和缩小的 src，等等。\r\n","\r\n            Width\r\n            ":"\r\n            宽度\r\n            \r\n","\r\n            Create an EdgeBox\r\n            ":"\r\n            创建一个边缘框\r\n            \r\n","\r\n            Convert BGR color to BGR555 color\r\n            ":"\r\n            将 BGR 颜色转换为 BGR555 颜色\r\n            \r\n","Function type":"函数类型\r\n","The optional output mask set by a robust method (RANSAC or LMEDS). ":"由稳健方法（RANSAC 或 LMEDS）设置的可选输出掩码。\r\n","\r\n            Performs camera calibaration.\r\n            ":"\r\n            执行相机校准。\r\n            \r\n"," The color of the line segment ":" 线段的颜色\r\n","\r\n            Transforms a color image to a grayscale image. It is a basic tool in digital printing, stylized black-and-white photograph rendering, and in many single channel image processing applications \r\n            ":"\r\n            将彩色图像转换为灰度图像。它是数字打印、风格化黑白照片渲染以及许多单通道图像处理应用程序中的基本工具\r\n            \r\n","\r\n            Perform an element wise AND operation using a mat and a color\r\n            ":"\r\n            使用垫子和颜色执行元素明智的 AND 操作\r\n            \r\n","\r\n            Gain selector for parameter Gain allows to select different type of gains.\r\n            ":"\r\n            参数增益的增益选择器允许选择不同类型的增益。\r\n            \r\n","\r\n            Predict the probability of the ":"\r\n            预测的概率\r\n","\r\n            Class for computing the optical flow vectors between two images using NVIDIA Optical Flow hardware and Optical Flow SDK 2.0.\r\n            ":"\r\n            使用 NVIDIA 光流硬件和光流 SDK 2.0 计算两个图像之间的光流向量的类。\r\n            \r\n","Parameter to optimize big vocabulary search, only take top ":"优化大词汇搜索的参数，只取top\r\n","\r\n             minimun standard deviation in pixels values during the decodification step to apply Otsu thresholding (otherwise, all the bits are set to 0 or 1 depending on mean higher than 128 or not) (default 5.0)\r\n            ":"\r\n             在应用 Otsu 阈值的解码步骤中像素值的最小标准偏差（否则，所有位都设置为 0 或 1，具体取决于是否高于 128）（默认 5.0）\r\n            \r\n","\r\n            Rotate the ":"\r\n            旋转\r\n","The header, corresponding to a specified row of the input array":"表头，对应输入数组的指定行\r\n","\r\n            16 bit signed: first bit for sign, 10 bits for integer part, 5 bits for fractional part.\r\n            ":"\r\n            16 位有符号：第一位为符号，10 位为整数部分，5 位为小数部分。\r\n            \r\n","\r\n            Pointer to the native algorithm object\r\n            ":"\r\n            指向本机算法对象的指针\r\n            \r\n","The scalar values as an array":"作为数组的标量值\r\n","\r\n            Min threshold\r\n            ":"\r\n            最小阈值\r\n            \r\n","\r\n            Computes per-element maximum of two GpuMats (dst = max(src1, src2))\r\n            ":"\r\n            计算两个 GpuMat 的每个元素最大值 (dst = max(src1, src2))\r\n            \r\n","End point of the arrow.":"箭头的终点。\r\n","\r\n            Motion type for the FindTransformECC function\r\n            ":"\r\n            FindTransformECC 函数的运动类型\r\n            \r\n","\r\n            Create an ellipse with specific parameters\r\n            ":"\r\n            创建具有特定参数的椭圆\r\n            \r\n","\r\n            Convert YUV (UYVY) to BGR\r\n            ":"\r\n            将 YUV (UYVY) 转换成 BGR\r\n            \r\n","\r\n            Pointer to the beginning of the raw data\r\n            ":"\r\n            指向原始数据开头的指针\r\n            \r\n","  \r\n            first_edge, (x,y) \r\n            ":"  \r\n            第一边，（x，y）\r\n            \r\n","The output registration error.":"输出注册错误。\r\n","\r\n            Mean square error algorithm\r\n            ":"\r\n            均方误差算法\r\n            \r\n","The second image to apply bitwise OR operation":"应用按位或运算的第二个图像\r\n","\r\n            Create an object which calculates quality via mean square error.\r\n            ":"\r\n            创建一个通过均方误差计算质量的对象。\r\n            \r\n","A string the repsent the OpenCL value type":"代表 OpenCL 值类型的字符串\r\n","Center of the rotation in the source image":"源图像中的旋转中心\r\n","\r\n            Image Stitching.\r\n            ":"\r\n            图像拼接。\r\n            \r\n","A rectangle represents ROI of the tracked object":"矩形表示被跟踪对象的 ROI\r\n","\r\n            Class implementing the LSC (Linear Spectral Clustering) superpixels algorithm described in \"Zhengqin Li and Jiansheng Chen. Superpixel segmentation using linear spectral clustering. June 2015.\"\r\n            ":"\r\n            实现“Zhengqin Li 和 Jiansheng Chen。使用线性光谱聚类的超像素分割。2015 年 6 月”中描述的 LSC（线性光谱聚类）超像素算法的类。\r\n            \r\n","\r\n            Over\r\n            ":"\r\n            超过\r\n            \r\n","\r\n            Central Normalized Moment Nu03\r\n            ":"\r\n            中心归一化矩 Nu03\r\n            \r\n","Border value in case of a constant border.":"边界不变时的边界值。\r\n","Sharpness":"清晰度\r\n","The ideal point coordinates, after undistortion and reverse perspective transformation. ":"理想点坐标，经过无畸变和逆透视变换。\r\n","\r\n            The functions will check validity of condition number.\r\n            ":"\r\n            这些函数将检查条件编号的有效性。\r\n            \r\n","\r\n            Trigger, only by set. Reload camera settings.\r\n            ":"\r\n            触发器，仅按组。重新加载相机设置。\r\n            \r\n","The stat model.":"状态模型。\r\n","\r\n            Target\r\n            ":"\r\n            目标\r\n            \r\n","\r\n            Harris\r\n            ":"\r\n            哈里斯\r\n            \r\n","\r\n            Get the default OclDevice. Do not dispose this device.\r\n            ":"\r\n            获取默认的 OclDevice。请勿丢弃此设备。\r\n            \r\n","\r\n            Viridis\r\n            ":"\r\n            绿藻属\r\n            \r\n","\r\n            Standard Macbeth Chart with 24 squares\r\n            ":"\r\n            带有 24 个正方形的标准麦克白图表\r\n            \r\n","Path to the model weights file.":"模型权重文件的路径。\r\n","Image where the mask found should be stored, single-channel, 32-bit floating-point":"应存储找到的掩码的图像，单通道，32 位浮点数\r\n","See Ximgproc.EdgeAwareInterpolator().":"参见 Ximgproc.EdgeAwareInterpolator()。\r\n","\r\n            The pointer to the calibrateCRF object\r\n            ":"\r\n            指向 calibrateCRF 对象的指针\r\n            \r\n","\r\n            The language is (usually) an ISO 639-3 string or NULL will default to eng.\r\n            It is entirely safe (and eventually will be efficient too) to call\r\n            Init multiple times on the same instance to change language, or just\r\n            to reset the classifier.\r\n            The language may be a string of the form [~]%lt;lang>[+[~]<lang>]* indicating\r\n            that multiple languages are to be loaded. Eg hin+eng will load Hindi and\r\n            English. Languages may specify internally that they want to be loaded\r\n            with one or more other languages, so the ~ sign is available to override\r\n            that. Eg if hin were set to load eng by default, then hin+~eng would force\r\n            loading only hin. The number of loaded languages is limited only by\r\n            memory, with the caveat that loading additional languages will impact\r\n            both speed and accuracy, as there is more work to do to decide on the\r\n            applicable language, and there is more chance of hallucinating incorrect\r\n            words.\r\n            ":"\r\n            语言（通常）是 ISO 639-3 字符串，否则 NULL 将默认为 eng。\r\n            打电话是完全安全的（最终也会很有效）\r\n            在同一个实例上多次初始化以更改语言，或者只是\r\n            重置分类器。\r\n            语言可以是 [~]%lt;lang>[+[~]<lang>]* 形式的字符串，表示\r\n            要加载多种语言。例如 hin+eng 将加载印地语和\r\n            英语。语言可能会在内部指定它们想要加载\r\n            与一种或多种其他语言，因此 ~ 符号可用于覆盖\r\n            那。例如，如果 hin 被设置为默认加载 eng，那么 hin+~eng 将强制\r\n            只加载hin。加载语言的数量仅受限于\r\n            内存，需要注意的是加载其他语言会影响\r\n            速度和准确性，因为有更多的工作要做来决定\r\n            适用的语言，并且有更多的机会产生不正确的幻觉\r\n            字。\r\n            \r\n","maximal number of Gauss-Seidel solver iterations.":"Gauss-Seidel 求解器迭代的最大次数。\r\n","\r\n            UYVY\r\n            ":"\r\n            优优优优\r\n            \r\n","\r\n            Data packing type. Some cameras supports only specific packing type.\r\n            ":"\r\n            数据打包类型。有些相机只支持特定的包装类型。\r\n            \r\n","Output image of the same size and type as src.":"输出与 src 相同大小和类型的图像。\r\n","\r\n            Each pixel position is either R, G or B in a random choice\r\n            ":"\r\n            每个像素位置随机选择 R、G 或 B\r\n            \r\n","This determines the different in scale for neighbor hood bins, a good value might be 1.5 (which means matched features in bin i+1 is scaled 1.5 times larger than matched features in bin i":"这决定了邻居罩箱的比例不同，一个好的值可能是 1.5（这意味着箱 i+1 中的匹配特征比箱 i 中的匹配特征缩放 1.5 倍\r\n","\r\n            Convert Bayer BGGR to GRAY\r\n            ":"\r\n            将 Bayer BGGR 转换为 GREY\r\n            \r\n","\r\n            Get or set the equivalent axis angle representation. (x,y,z) is the rotation axis and |(x,y,z)| is the rotation angle in radians\r\n            ":"\r\n            获取或设置等效轴角度表示。 (x,y,z) 是旋转轴，|(x,y,z)|是以弧度为单位的旋转角度\r\n            \r\n","Accumulator threshold parameter. Only those lines are returned that get enough votes":"累加器阈值参数。只返回那些获得足够选票的行\r\n","CudaImage of the specific color and depth ":"CudaImage的具体颜色和深度\r\n","the number of non-zero elements in image":"图像中非零元素的数量\r\n","\r\n            Warp rectify\r\n            ":"\r\n            整经\r\n            \r\n","The number of pyramid layers, including the initial image. levels=1 means that no extra layers are created and only the original images are used":"金字塔层数，包括初始图像。 levels=1 表示不创建额外层，只使用原始图像\r\n","Count of best matches found per each query descriptor or less if a query descriptor has less than k possible matches in total.":"如果查询描述符总共少于 k 个可能的匹配项，则每个查询描述符或更少找到的最佳匹配项的计数。\r\n","\r\n            Get the information about video file format.\r\n            ":"\r\n            获取有关视频文件格式的信息。\r\n            \r\n","\r\n            Intelperc Image Generator\r\n            ":"\r\n            Intelperc 图像生成器\r\n            \r\n","Aperture parameter for Sobel operator (see cvSobel). format. In the case of floating-point input format this parameter is the number of the fixed float filter used for differencing. ":"Sobel 算子的孔径参数（参见 cvSobel）。格式。在浮点输入格式的情况下，此参数是用于差分的固定浮点过滤器的编号。\r\n","Each individual channel of this matrix":"该矩阵的每个单独通道\r\n","The second matrix to be added.":"要添加的第二个矩阵。\r\n","\r\n            Create the Cuda implementation of GoodFeaturesToTrackDetector\r\n            ":"\r\n            创建 GoodFeaturesToTrackDetector 的 Cuda 实现\r\n            \r\n","\r\n            Create a motion history object\r\n            ":"\r\n            创建运动历史对象\r\n            \r\n","Sampling points used in image sampling.":"图像采样中使用的采样点。\r\n","the url to download the tessdata file for the specific language":"下载特定语言的 tessdata 文件的 url\r\n","Return: CV_8UC1 image mask where -1 indicates that the pixel is a superpixel border, and 0 otherwise.":"返回：CV_8UC1 图像掩码 其中 -1 表示该像素是超像素边界，否则为 0。\r\n","\r\n            When we build our model of black & white pixels, we add an extra check that\r\n            the white model must be(overall) brighter than the black model.How much brighter? (in pixel values, [0, 255]).\r\n            ":"\r\n            当我们构建我们的黑白像素模型时，我们添加了一个额外的检查\r\n            白色模型必须（整体）比黑色模型亮。亮多少？ （在像素值中，[0, 255]）。\r\n            \r\n","The input image.":"输入图像。\r\n","\r\n            Dict6X6_250\r\n            ":"\r\n            Dict6X6_250\r\n            \r\n","\r\n            Save multiple images to a specified file (e.g. \".tiff\" that support multiple images).\r\n            ":"\r\n            将多个图像保存到指定文件（例如支持多个图像的“.tiff”）。\r\n            \r\n","the algorithm calculates the minimum eigen value of a 2x2 normal matrix of optical flow equations, divided by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding feature is filtered out and its flow is not processed, so it allows to remove bad points and get a performance boost.":"该算法计算光流方程的 2x2 法线矩阵的最小特征值，除以窗口中的像素数；如果该值小于 minEigThreshold，则过滤掉相应的特征并且不处理其流，因此可以去除坏点并提高性能。\r\n","\r\n            Push a value into the standard vector\r\n            ":"\r\n            将一个值压入标准向量\r\n            \r\n","\r\n            Release all the unmanaged memory associated with the GScalar\r\n            ":"\r\n            释放与 GScalar 关联的所有非托管内存\r\n            \r\n","\r\n            Write or overwrite list of KeyPoint into specified dataset of hdf5 file.\r\n            ":"将关键点列表写入或覆盖到 hdf5 文件的指定数据集中。\r\n            \r\n","Both parameters prev_pyr and curr_pyr comply with the following rules: if the image pointer is 0, the function allocates the buffer internally, calculates the pyramid, and releases the buffer after processing. Otherwise, the function calculates the pyramid and stores it in the buffer unless the flag CV_LKFLOW_PYR_A[B]_READY is set. The image should be large enough to fit the Gaussian pyramid data. After the function call both pyramids are calculated and the readiness flag for the corresponding image can be set in the next call (i.e., typically, for all the image pairs except the very first one CV_LKFLOW_PYR_A_READY is set). ":"prev_pyr和curr_pyr这两个参数都遵守以下规则：如果图像指针为0，则函数内部分配缓冲区，计算金字塔，处理完释放缓冲区。否则，该函数将计算金字塔并将其存储在缓冲区中，除非设置了标志 CV_LKFLOW_PYR_A[B]_READY。图像应该足够大以适合高斯金字塔数据。在函数调用之后，两个金字塔都被计算出来，并且可以在下一次调用中设置相应图像的就绪标志（即，通常，对于除了第一个图像对之外的所有图像对设置 CV_LKFLOW_PYR_A_READY）。\r\n","\r\n            DEGREE\r\n            ":"\r\n            程度\r\n            \r\n","\r\n            Create an empty standard vector of OclPlatformInfo\r\n            ":"\r\n            创建 OclPlatformInfo 的空标准向量\r\n            \r\n","Space sigma":"空间西格玛\r\n","\r\n            Extract control points from the projected silhouette of a mesh\r\n            ":"\r\n            从网格的投影轮廓中提取控制点\r\n            \r\n","Output vector (e.g. cv::Mat) corresponding to the rotation vector of the board (see cv::Rodrigues). Used as initial guess if not empty.":"输出向量（例如 cv::Mat）对应于板的旋转向量（参见 cv::Rodrigues）。如果不为空，则用作初始猜测。\r\n","The compiled program":"编译好的程序\r\n","\r\n            Normalizes the input array so that it's norm or value range takes the certain value(s).\r\n            ":"\r\n            规范化输入数组，使其规范或值范围采用特定值。\r\n            \r\n","Positions of marker corners on input image. (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers, the dimensions of this array should be Nx4. The order of the corners should be clockwise.":"输入图像上标记角的位置。 （例如 std::vector<std::vector<cv::Point2f> > ）。对于 N 个检测到的标记，此数组的维度应为 Nx4。角的顺序应该是顺时针的。\r\n","The standard output":"标准输出\r\n","The points":"积分\r\n","Phase shift between two consecutive patterns.":"两个连续模式之间的相移。\r\n","\r\n            (read-only) Number of audio streams.\r\n            ":"\r\n            （只读）音频流的数量。\r\n            \r\n","\r\n             kernel and the second one corresponds to\r\n             ":"\r\n             内核，第二个对应于\r\n             \r\n","\r\n            True if the output array is fixed type\r\n            ":"\r\n            如果输出数组是固定类型则为真\r\n            \r\n","\r\n            Convert BGR to HSV\r\n            ":"\r\n            BGR 转换成 HSV\r\n            \r\n","\r\n            Create an affine transformer\r\n            ":"\r\n            创建仿射变换器\r\n            \r\n","Hint buffer if client provides external hints. Must have same size as flow buffer. Caller can provide flow vectors as hints for optical flow calculation.":"如果客户端提供外部提示，则提示缓冲区。必须与流缓冲区具有相同的大小。调用者可以提供流向量作为光流计算的提示。\r\n","\r\n            Accessors of the details channel of the retina (models foveal vision)\r\n            ":"\r\n            视网膜细节通道的访问器（模拟中央凹视觉）\r\n            \r\n","\r\n            Pointer to the unmanaged DenseOpticalFlow object\r\n            ":"\r\n            指向非托管 DenseOpticalFlow 对象的指针\r\n            \r\n","\r\n            The output is the maximum (column/row-wise) of all the matrix rows/columns\r\n            ":"输出是所有矩阵行/列的最大值（列/行）\r\n            \r\n","\r\n            The storage is open for append\r\n            ":"\r\n            存储已打开以供追加\r\n            \r\n","Name of the output video file.":"输出视频文件的名称。\r\n","Number of bytes each matrix row occupies. The value should include the padding bytes at the end of each row, if any.":"每个矩阵行占用的字节数。该值应包括每行末尾的填充字节（如果有）。\r\n","\r\n            Copy data from managed array to this Mat\r\n            ":"\r\n            将数据从托管数组复制到此 Mat\r\n            \r\n","Array with detections' quadrangles (4 points per result) in this order: bottom-left, top-left, top-right, bottom-right":"具有检测四边形（每个结果 4 个点）的数组，顺序为：左下、左上、右上、右下\r\n","\r\n            Draws the line segments on a given image.\r\n            ":"\r\n            在给定图像上绘制线段。\r\n            \r\n","\r\n            The point this facet associates to\r\n            ":"\r\n            这个方面关联的点\r\n            \r\n","Default border value.":"默认边界值。\r\n","The destination image depth type":"目标图像深度类型\r\n","\r\n            Apply converter and compute result for each channel of the image, for single channel image, apply converter directly, for multiple channel image, make a copy of each channel to a temperary image and apply the convertor\r\n            ":"\r\n            为图像的每个通道应用转换器和计算结果，对于单通道图像，直接应用转换器，对于多通道图像，将每个通道复制到临时图像并应用转换器\r\n            \r\n","Array of y-coordinates, that must have the same size and same type as x.":"y 坐标数组，必须与 x 具有相同的大小和相同的类型。\r\n","\r\n            The stereo matcher interface\r\n            ":"立体声匹配器界面\r\n            \r\n","The integral image":"整体形象\r\n","\r\n            Vertical sub-sampling of the image\r\n            ":"\r\n            图像的垂直子采样\r\n            \r\n","\r\n            Thinning type\r\n            ":"\r\n            间苗型\r\n            \r\n","The kept indices of bboxes after NMS.":"NMS 之后保留的 bboxes 索引。\r\n","\r\n            The id of the device\r\n            ":"\r\n            设备的id\r\n            \r\n","\r\n            Creates a uniform multi-dimension histogram of the specified size\r\n            ":"\r\n            创建指定大小的统一多维直方图\r\n            \r\n","\r\n            Calculates histogram for one channel 8-bit image.\r\n            ":"\r\n            计算一个通道 8 位图像的直方图。\r\n            \r\n","\r\n            Create a range of the specific min/max value\r\n            ":"\r\n            创建特定最小/最大值的范围\r\n            \r\n","\r\n            The z value of the 3d location\r\n            ":"\r\n            3d位置的z值\r\n            \r\n","A set of corresponding updated confidences.":"一组相应的更新置信度。\r\n","Basic function used in axis y.":"y 轴使用的基本功能。\r\n","\r\n            Generate points in a regular grid.\r\n            ":"\r\n            在规则网格中生成点。\r\n            \r\n","The train data.":"火车数据。\r\n","\r\n            Release the unmanaged memory associated with this CalibrateCRF object\r\n            ":"\r\n            释放与此 CalibrateCRF 对象关联的非托管内存\r\n            \r\n","The integral image for squared pixel values":"平方像素值的积分图像\r\n","Segmentation result":"分割结果\r\n","\r\n            Shape of the Structuring Element\r\n            ":"\r\n            结构元素的形状\r\n            \r\n","Number of times dilation is applied.":"应用膨胀的次数。\r\n","\r\n            Right\r\n            ":"\r\n            正确的\r\n            \r\n","The number of desired features.":"所需功能的数量。\r\n","\r\n            Extract the line bundle from an image\r\n            ":"\r\n            从图像中提取线束\r\n            \r\n","\r\n            use completely different contour retrieval algorithm via linking of horizontal segments of 1s. Only LIST retrieval mode can be used with this method\r\n            ":"\r\n            通过链接 1s 的水平段使用完全不同的轮廓检索算法。此方法只能使用 LIST 检索模式\r\n            \r\n","Blurred image":"图像模糊\r\n","Lower boundary value.":"下边界值。\r\n","The mask for the matches. Use null for all matches.":"火柴的面具。对所有匹配项使用 null。\r\n","\r\n            Open CL kernel program source code\r\n            ":"\r\n            打开CL内核程序源码\r\n            \r\n","rotation vector":"旋转矢量\r\n","\r\n            The index of the point\r\n            ":"\r\n            点的索引\r\n            \r\n","\r\n            Create an empty cv::UMat\r\n            ":"\r\n            创建一个空的 cv::UMat\r\n            \r\n","\r\n            if arr2 is NULL, norm = ||arr1||_C = max_I abs(arr1(I));\r\n            if arr2 is not NULL, norm = ||arr1-arr2||_C = max_I abs(arr1(I)-arr2(I))\r\n            ":"\r\n            如果 arr2 为 NULL，norm = ||arr1||_C = max_I abs(arr1(I));\r\n            如果 arr2 不为 NULL，则 norm = ||arr1-arr2||_C = max_I abs(arr1(I)-arr2(I))\r\n            \r\n","Returns the next random number from the Gaussian distribution N(0,sigma) . That is, the mean value of the returned random numbers is zero and the standard deviation is the specified sigma .":"返回高斯分布 N(0,sigma) 中的下一个随机数。也就是说，返回的随机数的平均值为零，标准差为指定的 sigma 。\r\n","\r\n            Convert BGR color to HSV color\r\n            ":"\r\n            将 BGR 颜色转换为 HSV 颜色\r\n            \r\n","\r\n            Specifies the number of training samples taken in each step of Mini-Batch Gradient Descent\r\n            ":"\r\n            指定 Mini-Batch Gradient Descent 每一步取的训练样本数\r\n            \r\n","The output image of the same size and the same data type as src":"与 src 相同大小和相同数据类型的输出图像\r\n","The labels of the images. This can be a VectorOfInt":"图片的标签。这可以是一个 VectorOfInt\r\n","A threshold used in non maximum suppression.":"用于非最大抑制的阈值。\r\n","\r\n            Create instance to draw UTF-8 strings.\r\n            ":"\r\n            创建实例以绘制 UTF-8 字符串。\r\n            \r\n","\r\n            Camera housing back side temperature\r\n            ":"\r\n            相机外壳背面温度\r\n            \r\n","\r\n            CPU\r\n            ":"\r\n            中央处理器\r\n            \r\n","The source image width":"源图像宽度\r\n","\r\n            The recognized text is returned as coded in the same format as a box file used in training.\r\n            ":"\r\n            识别的文本以与训练中使用的框文件相同的格式编码返回。\r\n            \r\n"," If thickness is less than 1, the circle is filled up ":" 如果 thickness 小于 1，圆被填满\r\n","\r\n            translate all the points from the chain code into points;\r\n            ":"\r\n            将链码中的所有点翻译成点；\r\n            \r\n","\r\n            Calculates a histogram with bins determined by the levels array\r\n            ":"\r\n            计算具有由级别数组确定的 bin 的直方图\r\n            \r\n","The function transforms an image to compensate radial and tangential lens distortion.":"该函数变换图像以补偿径向和切向镜头失真。\r\n","\r\n            Create a new Voronoi diagram-based seam estimator\r\n            ":"\r\n            创建一个新的基于 Voronoi 图的接缝估计器\r\n            \r\n","Mask image; marks pixels where motion gradient data is correct. Output parameter.":"蒙版图像；标记运动梯度数据正确的像素。输出参数。\r\n","\r\n            Convert BGRA color to RGB color\r\n            ":"将 BGRA 颜色转换为 RGB 颜色\r\n            \r\n","Maximum radius":"最大半径\r\n","The (3x3) rotation matrix which values will be set to represent this quaternions":"(3x3) 旋转矩阵，其值将被设置为代表这个四元数\r\n","Interpolation method (see resize() ). The method 'Area' is not supported by this function. ":"插值方法（参见 resize() ）。此函数不支持“区域”方法。\r\n","\r\n            Create the look up table\r\n            ":"\r\n            创建查找表\r\n            \r\n","\r\n            window's aspect ration (can be set to WINDOW_FREERATIO or WINDOW_KEEPRATIO).\r\n            ":"\r\n            窗口的宽高比（可以设置为 WINDOW_FREERATIO 或 WINDOW_KEEPRATIO）。\r\n            \r\n","\r\n            For TIFF, use to specify the X direction DPI\r\n            ":"\r\n            对于 TIFF，用于指定 X 方向 DPI\r\n            \r\n","\r\n            Get the pointer the the native ShapeTransformer\r\n            ":"\r\n            获取本机 ShapeTransformer 的指针\r\n            \r\n","\r\n            Encode image and return the result as a byte vector.\r\n            ":"\r\n            编码图像并将结果作为字节向量返回。\r\n            \r\n","\r\n            maximum number of accepted erroneous bits in the border (i.e. number of allowed white bits in the border). Represented as a rate respect to the total number of bits per marker (default 0.35).\r\n            ":"\r\n            边界中可接受的错误位的最大数量（即边界中允许的白色位的数量）。表示为相对于每个标记的总位数的比率（默认为 0.35）。\r\n            \r\n","\r\n            Create a matrix of the specific size and channels\r\n            ":"\r\n            创建特定大小和通道的矩阵\r\n            \r\n","The barcode found. If nothing is found, an empty array is returned.":"找到的条形码。如果未找到任何内容，则返回一个空数组。\r\n","If input images are in color, the method assumes that are BGR and converts them to grayscale.":"如果输入图像是彩色的，该方法会假定它是 BGR 并将它们转换为灰度。\r\n","\r\n            Reset the pointer to the native white balancer object\r\n            ":"\r\n            重置指向本机白平衡器对象的指针\r\n            \r\n","\r\n            Execute an binary computation (with compilation on the fly)\r\n            ":"\r\n            执行二进制计算（即时编译）\r\n            \r\n","Filtering with confidence requires two disparity maps (for the left and right views) and is approximately two times slower. However, quality is typically significantly better.":"有信心的过滤需要两个视差图（用于左视图和右视图）并且大约慢两倍。但是，质量通常要好得多。\r\n","\r\n            True if left connected\r\n            ":"\r\n            如果保持连接则为真\r\n            \r\n","\r\n            Altitude (height) in meters\r\n            ":"\r\n            海拔高度（米）\r\n            \r\n","The output mask":"输出掩码\r\n","\r\n            Revert back to the old locale\r\n            ":"\r\n            恢复到旧的语言环境\r\n            \r\n","\r\n            White threshold is a number between 0-255 that represents the minimum brightness difference required for valid pixels, between the graycode pattern and its inverse images, used in getProjPixel method\r\n            ":"\r\n            白色阈值是一个介于 0-255 之间的数字，表示有效像素所需的最小亮度差，在灰度模式及其反图像之间，用于 getProjPixel 方法\r\n            \r\n","\r\n            Starts the event loop for a given time.\r\n            ":"\r\n            在给定时间启动事件循环。\r\n            \r\n","\r\n            The classifier size\r\n            ":"\r\n            分类器尺寸\r\n            \r\n","In second. Any change happens between a time interval larger than this will not be considered":"在第二。在大于此时间间隔之间发生的任何更改都不会被考虑\r\n","\r\n            Get the minimum enclosing rectangle for this Box\r\n            ":"\r\n            获取此 Box 的最小外接矩形\r\n            \r\n","\r\n            enable both Write and Base64\r\n            ":"\r\n            同时启用 Write 和 Base64\r\n            \r\n","Array of N (N >= 5) 2D points from the first image. The point coordinates should be floating-point (single or double precision).":"来自第一个图像的 N (N >= 5) 个二维点的数组。点坐标应该是浮点数（单精度或双精度）。\r\n","Bad Region penalty":"坏区惩罚\r\n","The image to OR":"或图像\r\n","Numerical parameter (C) for some types of distances, if 0 then some optimal value is chosen":"某些类型距离的数值参数 (C)，如果为 0，则选择某个最佳值\r\n","\r\n            Changes the shape and/or the number of channels of a 2D matrix without copying the data.\r\n            ":"\r\n            在不复制数据的情况下更改二维矩阵的形状和/或通道数。\r\n            \r\n","\r\n            (read-only) Audio position is measured in samples. Accurate audio sample timestamp of previous grabbed fragment. See AudioSamplesPerSecond and AudioShiftNsec.\r\n            ":"\r\n            （只读）音频位置以样本为单位测量。先前抓取片段的准确音频样本时间戳。请参见 AudioSamplesPerSecond 和 AudioShiftNsec。\r\n            \r\n","Range between 0 to 0.1":"范围在 0 到 0.1 之间\r\n","Source image. Check pyrDown for the list of supported types.":"源图像。检查 pyrDown 以获取支持的类型列表。\r\n","\r\n            Get the node name or an empty string if the node is nameless\r\n            ":"\r\n            如果节点是无名的，则获取节点名称或空字符串\r\n            \r\n","Iterations":"迭代\r\n","When true, the function calculates the angle in degrees, otherwise, they are measured in radians.":"当为真时，该函数以度为单位计算角度，否则，它们以弧度为单位进行测量。\r\n","\r\n            Wait for ready frames from VideoCapture.\r\n            ":"\r\n            等待来自 VideoCapture 的就绪帧。\r\n            \r\n","The first zero-based component of the element index ":"元素索引的第一个从零开始的组件\r\n","The features matcher":"特征匹配器\r\n","\r\n            Create a new CChecker\r\n            ":"\r\n            创建一个新的 CChecker\r\n            \r\n","The standard deviation":"标准偏差\r\n","\r\n            Release all the unmanaged memory associated with the GComputation\r\n            ":"\r\n            释放与 GComputation 关联的所有非托管内存\r\n            \r\n","terminates processing if any single page takes too long. Set to 0 for unlimited time.":"如果任何单个页面花费的时间太长，则终止处理。设置为 0 无限时间。\r\n","\r\n            Create the paramaters with the default values.\r\n            ":"\r\n            使用默认值创建参数。\r\n            \r\n","\r\n            Selected distortion coefficients are set to zeros and stay zero.\r\n            ":"\r\n            选定的失真系数被设置为零并保持为零。\r\n            \r\n","\r\n            Convert YUV (UYNV) to BGRA\r\n            ":"\r\n            将 YUV (UYNV) 转换成 BGRA\r\n            \r\n","About as fast as MOG2 on a high end system. More than twice faster than MOG2 on cheap hardware (benchmarked on Raspberry Pi3).":"在高端系统上与 MOG2 差不多快。在廉价硬件上比 MOG2 快两倍以上（在 Raspberry Pi3 上进行基准测试）。\r\n","\r\n            Detects circles and ellipses.\r\n            ":"\r\n            检测圆和椭圆。\r\n            \r\n","Coordinates of the vectors in the principal component subspace":"主成分子空间中向量的坐标\r\n","Sets the new focal length in range between the min focal length and the max focal length. Balance is in range of [0, 1]":"在最小焦距和最大焦距之间的范围内设置新的焦距。余额在 [0, 1] 范围内\r\n","The image to obtain pixel value from":"从中获取像素值的图像\r\n","\r\n            COEF\r\n            ":"\r\n            系数\r\n            \r\n","Chooses an average superpixel size measured in pixels":"选择以像素为单位测量的平均超像素大小\r\n","\r\n            Create a stub bundle adjuster that does nothing.\r\n            ":"\r\n            创建一个什么也不做的存根束调节器。\r\n            \r\n","\r\n            Returns the min / max locations and values for the matrix\r\n            ":"\r\n            返回矩阵的最小/最大位置和值\r\n            \r\n","\r\n            maximum window size for adaptive thresholding before finding contours (default 23).\r\n            ":"\r\n            找到轮廓之前自适应阈值的最大窗口大小（默认 23）。\r\n            \r\n","Second input Mat for binary computation":"用于二进制计算的第二个输入 Mat\r\n","\r\n            Returns indexes of layers with unconnected outputs.\r\n            ":"返回具有未连接输出的层的索引。\r\n            \r\n","\r\n            Aperture. Can be readonly, depends on camera program.\r\n            ":"\r\n            光圈。可以是只读的，取决于相机程序。\r\n            \r\n","\r\n            Extract the specific channel from the image\r\n            ":"\r\n            从图像中提取特定通道\r\n            \r\n"," Elementwise multiply ":" 按元素相乘\r\n","Input three-channel or one channel image (either CV_8UC3 or CV_8UC1)":"输入三通道或单通道图像（CV_8UC3 或 CV_8UC1）\r\n","The GpuMat":"Gpu垫\r\n",",\r\n            otherwise, make copy each channel of this image to a temperary one, apply action on it and another temperory image and copy the resulting image back to image2\r\n            ":",\r\n            否则，将此图像的每个通道复制到一个临时图像，对其和另一个临时图像应用操作并将生成的图像复制回 image2\r\n            \r\n","\r\n            RPROP: Update-values upper limit\r\n            ":"\r\n            RPROP：更新值上限\r\n            \r\n","\r\n            YUV422\r\n            ":"\r\n            YUV422\r\n            \r\n","\r\n             value = value > threshold ? threshold : value   \r\n            ":"\r\n             价值=价值>阈值？阈值：值\r\n            \r\n","Array of x-coordinates; this must be a single-precision or double-precision floating-point array.":"x 坐标数组；这必须是单精度或双精度浮点数组。\r\n","algorithm type":"算法类型\r\n","\r\n            Pointer to the NvidiaOpticalFlow object\r\n            ":"\r\n            指向 NvidiaOpticalFlow 对象的指针\r\n            \r\n","Pointer to the unmanaged gpuMat":"指向非托管 gpuMat 的指针\r\n","Output vector of average re-projection errors estimated for each pattern view.":"为每个模式视图估计的平均重投影误差的输出向量。\r\n","Page iterator":"页面迭代器\r\n","Output image, 8-bit unsigned 1-channel image. Width of I420 output image must be the same as width of input image. Height of I420 output image must be equal 3/2 from height of input image.":"输出图像，8 位无符号 1 通道图像。 I420 输出图像的宽度必须与输入图像的宽度相同。 I420 输出图像的高度必须等于输入图像高度的 3/2。\r\n","\r\n            Wrapper around silhouette based 3D object tracking function for uniform access\r\n            ":"\r\n            基于轮廓的 3D 对象跟踪功能的包装器，用于统一访问\r\n            \r\n","\r\n            contour approximation method\r\n            ":"\r\n            轮廓近似法\r\n            \r\n","\r\n            Convert YUV (YUY2) to BGR\r\n            ":"\r\n            将 YUV (YUY2) 转换成 BGR\r\n            \r\n","Output base":"输出底座\r\n","\r\n            Contrast of the image (only for cameras).\r\n            ":"\r\n            图像的对比度（仅适用于相机）。\r\n            \r\n","The XML or YAML file with the classifier model (e.g. trained_classifier_erGrouping.xml)":"带有分类器模型的 XML 或 YAML 文件（例如 trained_classifier_erGrouping.xml）\r\n","\r\n            initializes CvMat header so that it points to the same data as the original array but has different shape - different number of channels, different number of rows or both\r\n            ":"\r\n            初始化 CvMat 标头，使其指向与原始数组相同的数据但具有不同的形状 - 不同的通道数、不同的行数或两者\r\n            \r\n","\r\n            A shadow is detected if pixel is a darker version of the background. The shadow threshold (Tau in the paper) is a threshold defining how much darker the shadow can be. Tau= 0.5 means that if a pixel is more than twice darker then it is not shadow.\r\n            ":"\r\n            如果像素是背景的较暗版本，则会检测到阴影。阴影阈值（论文中的 Tau）是定义阴影可以变暗多少的阈值。 Tau= 0.5 意味着如果一个像素比暗两倍多那么它就不是阴影。\r\n            \r\n","\r\n            Number of fixed point iterations of variational refinement per scale. Set to zero to disable variational refinement completely. Higher values will typically result in more smooth and high-quality flow.\r\n            ":"\r\n            每个尺度的变分细化的定点迭代次数。设置为零以完全禁用变分细化。较高的值通常会产生更平滑和高质量的流。\r\n            \r\n","\r\n            Kyriakos Herakleous, Charalambos Poullis. \"3DUNDERWORLD-SLS: An Open-Source Structured-Light Scanning System for Rapid Geometry Acquisition\", arXiv preprint arXiv:1406.6595 (2014)\r\n            ":"\r\n            Kyriakos Herakleous，Charalambos Poulis。 “3DUNDERWORLD-SLS：用于快速几何采集的开源结构光扫描系统”，arXiv 预印本 arXiv:1406.6595 (2014)\r\n            \r\n","The second vertex":"第二个顶点\r\n","Arbitrary pointer that is transparently passed to the error handler.":"透明地传递给错误处理程序的任意指针。\r\n","Source 8-bit single-channel image, containing binary blobs, with blobs having 255 pixel values.":"源 8 位单通道图像，包含二进制斑点，斑点具有 255 个像素值。\r\n","The second threshold, used to find initial segments of strong edges":"第二个阈值，用于寻找强边的初始段\r\n","\r\n            Release unmanaged memory associated with this plot2d.\r\n            ":"\r\n            释放与此 plot2d 关联的非托管内存。\r\n            \r\n","Window property to edit.":"要编辑的窗口属性。\r\n","if true, unpon object disposal, we will cann the release function on the unmanaged ":"如果为真，在对象处理之前，我们将在非托管上取消释放功能\r\n","The file name of the classifier":"分类器的文件名\r\n","\r\n            Create a BRIEF descriptor extractor.\r\n            ":"\r\n            创建一个 BRIEF 描述符提取器。\r\n            \r\n","\r\n            Create an AlignMTB object\r\n            ":"\r\n            创建一个 AlignMTB 对象\r\n            \r\n","The image channels to be merged into a single image":"要合并为单个图像的图像通道\r\n","\r\n            The descriptor format\r\n            ":"\r\n            描述符格式\r\n            \r\n","\r\n            Pointer to the unmanaged MotionSaliency object\r\n            ":"\r\n            指向非托管 MotionSaliency 对象的指针\r\n            \r\n","x coordinate of first point (r1, s1) in the transformation function.":"变换函数中第一个点 (r1, s1) 的 x 坐标。\r\n","The raw data in byte":"以字节为单位的原始数据\r\n","\r\n            This function has several different purposes and thus has several synonyms. It copies one GpuMat to another with optional scaling, which is performed first, and/or optional type conversion, performed after:\r\n            dst(I)=src(I)*scale + (shift,shift,...)\r\n            All the channels of multi-channel GpuMats are processed independently.\r\n            The type conversion is done with rounding and saturation, that is if a result of scaling + conversion can not be represented exactly by a value of destination GpuMat element type, it is set to the nearest representable value on the real axis.\r\n            In case of scale=1, shift=0 no prescaling is done. This is a specially optimized case and it has the appropriate convertTo synonym.\r\n            ":"\r\n            这个函数有几个不同的用途，因此有几个同义词。它通过可选缩放将一个 GpuMat 复制到另一个 GpuMat，首先执行，和/或可选类型转换，之后执行：\r\n            dst(I)=src(I)*scale + (shift,shift,...)\r\n            多通道 GpuMats 的所有通道都是独立处理的。\r\n            类型转换是通过舍入和饱和完成的，也就是说，如果缩放 + 转换的结果不能用目标 GpuMat 元素类型的值准确表示，则将其设置为实轴上最接近的可表示值。\r\n            在 scale=1，shift=0 的情况下，不进行预缩放。这是一个特别优化的案例，它有适当的 convertTo 同义词。\r\n            \r\n","\r\n            A DPM detection\r\n            ":"\r\n            DPM检测\r\n            \r\n","The points to find convex hull from":"从中找到凸包的要点\r\n","0-based index of the channel to be inserted":"要插入的通道的从 0 开始的索引\r\n","\r\n            UYVY (4:2:2)\r\n            ":"\r\n            优维 (4:2:2)\r\n            \r\n","\r\n            Batch RPROP algorithm\r\n            ":"\r\n            批量 RPROP 算法\r\n            \r\n","Create a median flow tracker":"创建中值流量跟踪器\r\n","Ending angle of the elliptic arc":"椭圆弧的终止角\r\n"," Get or set the intensity of the z color channel ":" 获取或设置 z 颜色通道的强度\r\n","\r\n            Local\r\n            ":"\r\n            当地的\r\n            \r\n","\r\n            Pointer to the unmanaged SparseOpticalFlow object\r\n            ":"\r\n            指向非托管 SparseOpticalFlow 对象的指针\r\n            \r\n","\r\n            Eval\r\n            ":"\r\n            评价\r\n            \r\n","\r\n            Create an standard vector of Int of the specific size\r\n            ":"\r\n            创建特定大小的标准 Int 向量\r\n            \r\n","\r\n            Create a new Bundle adjuster.\r\n            ":"\r\n            创建一个新的捆绑调整器。\r\n            \r\n","\r\n            Initialize with rectangle\r\n            ":"\r\n            用矩形初始化\r\n            \r\n","well-exposedness measure weight":"曝光度测量重量\r\n","\r\n            Update the face recognizer with the specific images and labels\r\n            ":"\r\n            使用特定图像和标签更新人脸识别器\r\n            \r\n","\r\n            BINBOOST and subvariants are the binary extensions of LBGM where each bit is computed as a thresholded linear combination of a set of weak learners.\r\n            ":"\r\n            BINBOOST 和子变体是 LBGM 的二进制扩展，其中每个位都被计算为一组弱学习器的阈值线性组合。\r\n            \r\n","The point this facet associate with ":"该方面关联的点\r\n","Kernel size.":"内核大小。\r\n","An optional array, subtracted from ":"一个可选的数组，从\r\n","\r\n            Base class for 1st and 2nd stages of Neumann and Matas scene text detection algorithm\r\n            ":"\r\n            Neumann 和 Matas 场景文本检测算法第一阶段和第二阶段的基类\r\n            \r\n","The probability that the algorithm produces a useful result.":"算法产生有用结果的概率。\r\n","Destination image with the same type as src. Must be pre-allocated":"与 src 类型相同的目标图像。必须预先分配\r\n","\r\n            Print short cuda device info\r\n            ":"\r\n            打印简短的 cuda 设备信息\r\n            \r\n","The image such that: dst(x,y) = 0, if src(x,y)>threshold;  max_value, otherwise":"图像满足：dst(x,y) = 0，如果 src(x,y)>threshold；最大值，否则\r\n","\r\n            Reads a network model stored in Darknet model files.\r\n            ":"\r\n            读取存储在 Darknet 模型文件中的网络模型。\r\n            \r\n","\r\n            BM3D denoising transform types\r\n            ":"\r\n            BM3D去噪变换类型\r\n            \r\n","\r\n            Managed Structure equivalent to CvPoint3D64f\r\n            ":"\r\n            等效于 CvPoint3D64f 的托管结构\r\n            \r\n","\r\n            Mode for creating photo panoramas. Expects images under perspective transformation and projects resulting pano to sphere.\r\n            ":"\r\n            创建照片全景的模式。期望透视变换下的图像并将生成的全景投射到球体。\r\n            \r\n","Number of array dimensions":"数组维数\r\n","\r\n            Result of cvHaarDetectObjects\r\n            ":"\r\n            cvHaarDetectObjects 的结果\r\n            \r\n","\r\n            Convert Bayer RG to RGBA\r\n            ":"\r\n            将 Bayer RG 转换为 RGBA\r\n            \r\n","The epsilon value":"epsilon 值\r\n","Length of the ellipse axes":"椭圆轴的长度\r\n","Pointer to the destination 2x3 matrix":"指向目标 2x3 矩阵的指针\r\n","The output vector of eigenvalues, stored in the descending order (order of eigenvalues and eigenvectors is syncronized, of course)":"特征值的输出向量，按降序存储（当然，特征值和特征向量的顺序是同步的）\r\n","\r\n            Calculates White Balance(must be called during acquisition)\r\n            ":"\r\n            计算白平衡（采集时必须调用）\r\n            \r\n","Trees":"树木\r\n","\r\n            Stereo Block Matching Prefilter type\r\n            ":"\r\n            立体声块匹配前置滤波器类型\r\n            \r\n","Size of the image, used only to initialize intrinsic camera matrix":"图像的大小，仅用于初始化内部相机矩阵\r\n"," The value to OR":" 或的价值\r\n","Window stride. Must be a multiple of block stride. Use Size.Empty for default":"窗口步幅。必须是块步幅的倍数。默认使用 Size.Empty\r\n","True if the GPU module is targeted for equal or greater PTX version.":"如果 GPU 模块的目标是相同或更高的 PTX 版本，则为真。\r\n","Optional output array of vertices of the found QR code quadrangle. Will be empty if not found.":"找到的 QR 码四边形的顶点的可选输出数组。如果找不到，将为空。\r\n","rate between square and marker length: squareMarkerLengthRate = squareLength / markerLength.The real units are not necessary.":"正方形和标记长度之间的比率：squareMarkerLengthRate = squareLength / markerLength。不需要实际单位。\r\n","\r\n            Trains a Facemark algorithm using the given dataset.\r\n            ":"\r\n            使用给定的数据集训练 Facemark 算法。\r\n            \r\n","\r\n            The 1976 formula is the first formula that related a measured color difference to a known set of CIELAB coordinates.\r\n            ":"\r\n            1976 年的公式是第一个将测得的色差与一组已知的 CIELAB 坐标相关联的公式。\r\n            \r\n","\r\n            DST[x,y] = SRC[xmap[x,y],ymap[x,y]] with bilinear interpolation.\r\n            ":"\r\n            DST[x,y] = SRC[xmap[x,y],ymap[x,y]] 双线性插值。\r\n            \r\n","\r\n            Performs up-sampling step of Gaussian pyramid decomposition. First it upsamples the source image by injecting even zero rows and columns and then convolves result with the specified filter multiplied by 4 for interpolation. So the destination image is four times larger than the source image.\r\n            ":"\r\n            执行高斯金字塔分解的上采样步骤。首先，它通过注入甚至零行和零列对源图像进行上采样，然后将结果与指定的过滤器乘以 4 进行卷积以进行插值。所以目标图像比源图像大四倍。\r\n            \r\n","\r\n            Create a TitleTiffWriter.\r\n            ":"\r\n            创建一个 TitleTiffWriter。\r\n            \r\n","\r\n            Class implementing the Gray-code pattern, based on \r\n            Kyriakos Herakleous and Charalambos Poullis. 3DUNDERWORLD-SLS: An Open-Source Structured-Light Scanning System for Rapid Geometry Acquisition. arXiv preprint arXiv:1406.6595, 2014.\r\n            ":"\r\n            实现格雷码模式的类，基于\r\n            Kyriakos Herakleous 和 Charalambos Pullis。 3DUNDERWORLD-SLS：用于快速几何采集的开源结构光扫描系统。 arXiv 预印本 arXiv:1406.6595, 2014。\r\n            \r\n","\r\n            Returns a zero array of the specified size and type.\r\n            ":"\r\n            返回指定大小和类型的零数组。\r\n            \r\n","Window size of optical flow algorithm. Must be not less than winSize argument of calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.":"光流算法的窗口大小。必须不小于 calcOpticalFlowPyrLK 的 winSize 参数。需要计算金字塔级别所需的填充。\r\n","Camera intrinsic parameters":"相机固有参数\r\n","\r\n            Two source image, matches and single keypoints will be drawn.\r\n            For each keypoint only the center point will be drawn (without\r\n            the circle around keypoint with keypoint size and orientation).\r\n            ":"\r\n            将绘制两个源图像、匹配项和单个关键点。\r\n            对于每个关键点，只会绘制中心点（不\r\n            具有关键点大小和方向的关键点周围的圆圈）。\r\n            \r\n","parameter, that is similar to color space sigma in bilateralFilter.":"参数，类似于bilateralFilter中的颜色空间sigma。\r\n"," Threshold the image inplace such that: dst(x,y) = 0, if src(x,y)>threshold;  max_value, otherwise ":" 将图像阈值设置为：dst(x,y) = 0，如果 src(x,y)>threshold；最大值，否则\r\n","\r\n            DepthAI device\r\n            ":"\r\n            深度AI设备\r\n            \r\n","\r\n            Create an standard vector of VectorOfDMatch with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfDMatch 的标准向量\r\n            \r\n","\r\n            This matcher trains flann::Index_ on a train descriptor collection and calls its nearest search methods to find the best matches. So, this matcher may be faster when matching a large train collection than the brute force matcher. \r\n            ":"\r\n            此匹配器在火车描述符集合上训练 flann::Index_ 并调用其最近的搜索方法以找到最佳匹配。因此，在匹配大型火车集合时，此匹配器可能比蛮力匹配器更快。\r\n            \r\n","Parameter used for RANSAC. It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier and is not used for computing the final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise.":"用于 RANSAC 的参数。它是一个点到对极线的最大距离（以像素为单位），超过该距离的点被视为异常值，不用于计算最终的基本矩阵。它可以设置为 1-3 之类的值，具体取决于点定位的精度、图像分辨率和图像噪声。\r\n","\r\n            Get the size of the descriptor\r\n            ":"\r\n            获取描述符的大小\r\n            \r\n","\r\n            Release the unmanaged memory associated with this Renderer\r\n            ":"\r\n            释放与此渲染器关联的非托管内存\r\n            \r\n","\r\n            Convert BGR565 color to RGB color\r\n            ":"\r\n            将 BGR565 颜色转换为 RGB 颜色\r\n            \r\n","The second image to be subtracted from the current image":"要从当前图像中减去的第二个图像\r\n","Beam size for search":"搜索波束大小\r\n","Compression code. Usually computed using CvInvoke.CV_FOURCC. \r\n            On windows use -1 to open a codec selection dialog.\r\n            On Linux, use CvInvoke.CV_FOURCC('I', 'Y', 'U', 'V') for default codec for the specific file name.\r\n            ":"压缩码。通常使用 CvInvoke.CV_FOURCC 计算。\r\n            在 Windows 上使用 -1 打开编解码器选择对话框。\r\n            在 Linux 上，使用 CvInvoke.CV_FOURCC('I', 'Y', 'U', 'V') 作为特定文件名的默认编解码器。\r\n            \r\n","\r\n            Returns true if the two box are equal\r\n            ":"\r\n            如果两个框相等则返回真\r\n            \r\n","Value for the specified property. Value 0 is returned when querying a property that is\r\n            not supported by the backend used by the VideoCapture instance.":"指定属性的值。查询属性时返回值 0\r\n            VideoCapture 实例使用的后端不支持。\r\n"," The blue value for this color ":" 这种颜色的蓝色值\r\n","The Mat to be written to the file storage":"要写入文件存储的 Mat\r\n","\r\n            Step\r\n            ":"\r\n            步\r\n            \r\n","4-character code of codec used to compress the frames. For example, CV_FOURCC('P','I','M','1') is MPEG-1 codec, CV_FOURCC('M','J','P','G') is motion-jpeg codec etc.":"用于压缩帧的编解码器的 4 字符代码。例如，CV_FOURCC('P','I','M','1') 是 MPEG-1 编解码器，CV_FOURCC('M','J','P','G') 是 motion-jpeg 编解码器ETC。\r\n","The division scale":"分工规模\r\n","\r\n            Fonts\r\n            ":"\r\n            字体\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of Int.\r\n            ":"\r\n            Int 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Shows the image in the specified window\r\n            ":"在指定窗口显示图像\r\n            \r\n","\r\n            Uses the user-provided labels for K-Means initialization\r\n            ":"\r\n            使用用户提供的标签进行 K-Means 初始化\r\n            \r\n","\r\n            Finds minimum and maximum element values and their positions. The extremums are searched over the whole GpuMat or, if mask is not IntPtr.Zero, in the specified GpuMat region.\r\n            ":"\r\n            查找最小和最大元素值及其位置。在整个 GpuMat 上搜索极值，或者如果掩码不是 IntPtr.Zero，则在指定的 GpuMat 区域中搜索。\r\n            \r\n","\r\n            Release the Boost classifier and all memory associate with it\r\n            ":"\r\n            释放 Boost 分类器及其关联的所有内存\r\n            \r\n","Anchor position within the kernel. The default value (−1,−1) means that the anchor is at the kernel center.":"内核中的锚点位置。默认值 (-1,-1) 表示锚点位于内核中心。\r\n","The value to be pushed to the vector":"要推送到向量的值\r\n"," The initial color of the map":" 地图的初始颜色\r\n","Output array or vector of arrays":"输出数组或数组向量\r\n","standard deviation of the distribution.":"分布的标准偏差。\r\n","Weight of the first matrix elements.":"第一个矩阵元素的权重。\r\n","The image to be transformed":"要转换的图像\r\n","Output image of the first step of BM3D with the same size and type as src.":"BM3D第一步的输出图像，大小和类型与src相同。\r\n","\r\n            The detected QR code\r\n            ":"\r\n            检测到的二维码\r\n            \r\n","\r\n            Corrected state (x(k)): x(k)=x'(k)+K(k)*(z(k)-H*x'(k))\r\n            ":"\r\n            修正状态 (x(k))：x(k)=x'(k)+K(k)*(z(k)-H*x'(k))\r\n            \r\n","\r\n            Smartek Giganetix Ethernet Vision: frame offset X\r\n            ":"\r\n            Smartek Giganetix Ethernet Vision：帧偏移 X\r\n            \r\n","The rotated rectangle in which the ellipse is inscribed":"内接椭圆的旋转矩形\r\n","\r\n            Calculates the per-element bit-wise logical \"exclusive or\" of two matrices of the same size.\r\n            ":"\r\n            计算两个相同大小的矩阵的每个元素按位逻辑“异或”。\r\n            \r\n","\r\n            Applies Paillou filter to an image.\r\n            ":"\r\n            将 Paillou 滤镜应用于图像。\r\n            \r\n","The final re-projection error.":"最后的重投影误差。\r\n","Vector specifying which variables to use for training. It can be an integer vector (CV_32S) containing 0-based variable indices or byte vector (CV_8U) containing a mask of active variables.":"指定要用于训练的变量的向量。它可以是包含基于 0 的变量索引的整数向量 (CV_32S) 或包含活动变量掩码的字节向量 (CV_8U)。\r\n","Output array of N elements, every element of which is set to 0 for outliers and to 1 for the other points. The array is computed only in the RANSAC and LMedS methods.":"N 个元素的输出数组，其中的每个元素对于异常值设置为 0，对于其他点设置为 1。该数组仅在 RANSAC 和 LMedS 方法中计算。\r\n","\r\n            The pointer to the Model object\r\n            ":"\r\n            指向模型对象的指针\r\n            \r\n","\r\n            Order 1 raw moments to derive the centroid\r\n            ":"\r\n            订购 1 个原始矩来导出质心\r\n            \r\n","\r\n            Use Block Matching algorithm to find stereo correspondence\r\n            ":"\r\n            使用块匹配算法找到立体对应\r\n            \r\n","\r\n            RPROP: Increase factor\r\n            ":"\r\n            RPROP：增加因子\r\n            \r\n","Project image top-left corner":"投影图像左上角\r\n","The scale to resize":"要调整大小的比例\r\n","\r\n            Problem is unbounded (target function can achieve arbitrary high values)\r\n            ":"\r\n            问题是无界的（目标函数可以达到任意高值）\r\n            \r\n","\r\n            Represent an uninitialized RotatedRect\r\n            ":"\r\n            表示一个未初始化的 RotatedRect\r\n            \r\n","\r\n            Weight of the smoothness term\r\n            ":"\r\n            平滑项的权重\r\n            \r\n",") columns of the CudaImage. The data is shared with the current Image. \r\n            ":") CudaImage 的列。数据与当前图像共享。\r\n            \r\n"," The result of elementwise adding img2 to the current image, using the specific mask":" 将img2逐元素添加到当前图像的结果，使用特定的mask\r\n","Method for computing the fundamental matrix ":"基本矩阵的计算方法\r\n","\r\n            Create the OCL kernel arg\r\n            ":"\r\n            创建 OCL 内核参数\r\n            \r\n","\r\n            Specifies if (true) color is processed of not (false) to then processing gray level image\r\n            ":"\r\n            指定是否处理（真）颜色或不（假）处理灰度图像\r\n            \r\n","\r\n            Create a PDF renderer\r\n            ":"\r\n            创建 PDF 渲染器\r\n            \r\n","Number of levels in constructed pyramid. Can be less than maxLevel.":"构造金字塔中的层数。可以小于 maxLevel。\r\n","Block width":"块宽度\r\n","\r\n            The size of MCvMatND\r\n            ":"\r\n            MCvMatND 的大小\r\n            \r\n","\r\n            Reads a network model stored in TensorFlow framework's format.\r\n            ":"\r\n            读取以 TensorFlow 框架格式存储的网络模型。\r\n            \r\n","The identity affine 3d matrix":"恒等仿射 3d 矩阵\r\n","\r\n            The pointer to the native kernel\r\n            ":"\r\n            指向本机内核的指针\r\n            \r\n","\r\n            Release the unmanaged memory associated with this MergeRobertson object\r\n            ":"\r\n            释放与此 MergeRobertson 对象关联的非托管内存\r\n            \r\n","Mask that sets which pixels have to be used from the source frame (CV_8UC1)":"设置必须使用源帧 (CV_8UC1) 中哪些像素的掩码\r\n","\r\n            AGAST_5_8\r\n            ":"\r\n            AGAST_5_8\r\n            \r\n","Blurring kernel size.":"模糊内核大小。\r\n","Transformation between srcPC and dstPC.":"srcPC 和 dstPC 之间的转换。\r\n","\r\n            Convert Bayer RGGB color to BGR color\r\n            ":"\r\n            将 Bayer RGGB 颜色转换为 BGR 颜色\r\n            \r\n","\r\n            Depth generator present\r\n            ":"\r\n            存在深度发生器\r\n            \r\n","Order of the derivatives":"衍生品的顺序\r\n","the width of the cross":"十字架的宽度\r\n","\r\n            When Tesseract/LSTM is initialized we can choose to instantiate/load/run\r\n            only the Tesseract part, only the Cube part or both along with the combiner.\r\n            The preference of which engine to use is stored in tessedit_ocr_engine_mode.\r\n            ":"\r\n            Tesseract/LSTM初始化时我们可以选择实例化/加载/运行\r\n            仅 Tesseract 部分，仅 Cube 部分或两者以及组合器。\r\n            使用哪个引擎的偏好存储在 tessedit_ocr_engine_mode 中。\r\n            \r\n","K":"钾\r\n","\r\n            Get the NNet packets\r\n            ":"\r\n            获取 NNet 数据包\r\n            \r\n","Projected image scale multiplier":"投影图像比例乘数\r\n","\r\n            Use the Gennert and Negahdaripour illumination model instead of the intensity brightness constraint.\r\n            ":"\r\n            使用 Gennert 和 Negahdaripour 照明模型而不是强度亮度约束。\r\n            \r\n","size of the search window at each pyramid level.":"每个金字塔级别的搜索窗口的大小。\r\n","saturation measure weight":"饱和度量权重\r\n","Value added to the scaled source GpuMat elements":"添加到缩放的源 GpuMat 元素的值\r\n","The CvArray to be converted to GpuMat":"要转换为 GpuMat 的 CvArray\r\n","minimum confidence threshold to select a keypoint":"选择关键点的最小置信度阈值\r\n","The depth of the source image":"源图像的深度\r\n","\r\n            The size of CvPoint3D32f\r\n            ":"\r\n            CvPoint3D32f 的大小\r\n            \r\n","The number of parallel kd-trees to use. Good values are in the range [1..16]":"要使用的并行 kd 树的数量。好的值在 [1..16] 范围内\r\n","\r\n            Release the unmanaged memory associated with this RFFeatureGetter.\r\n            ":"\r\n            释放与此 RFFeatureGetter 关联的非托管内存。\r\n            \r\n","\r\n            Check if this Geodetic coordinate equals ":"\r\n            检查此大地坐标是否等于\r\n","The radius of the search":"搜索半径\r\n","The path of the onnx model used for face recognition":"用于人脸识别的onnx模型的路径\r\n","Detector parameter. Use 10.0 as default":"探测器参数。默认使用 10.0\r\n","An array of Point3D32F":"Point3D32F 数组\r\n","\r\n            Dual TV L1 Optical Flow Algorithm.\r\n            ":"\r\n            双电视 L1 光流算法。\r\n            \r\n","The first mat to be added":"要添加的第一个垫子\r\n","\r\n            Histogram comparison method\r\n            ":"\r\n            直方图比较法\r\n            \r\n","\r\n            The Width\r\n            ":"\r\n            宽度\r\n            \r\n","\r\n            Initialize the OCR engine using the specific dataPath and language name.\r\n            ":"\r\n            使用特定的数据路径和语言名称初始化 OCR 引擎。\r\n            \r\n","branching":"分枝\r\n","Source color type. ":"源颜色类型。\r\n","The k parameter of the algorithm":"算法的k参数\r\n","Image, for which the descriptor is computed":"图像，为其计算描述符\r\n"," Name of the window where selection process will be shown.":" 将显示选择过程的窗口的名称。\r\n","Specify the compression level 0-9 to be used, -1 is the default value and means no compression. The value 0 also means no compression. A value 9 indicating the best compression ration. Note that a higher compression level indicates a higher computational cost. It relies on GNU gzip for compression.":"指定要使用的压缩级别 0-9，-1 是默认值，表示不压缩。值 0 也意味着没有压缩。值 9 表示最佳压缩比。请注意，更高的压缩级别表示更高的计算成本。它依靠 GNU gzip 进行压缩。\r\n","Specify gradient direction feature. Type is CV_32FC2. Values are expected to be normalized: x^2 + y^2 == 1":"指定梯度方向特征。类型是 CV_32FC2。值应该被归一化：x^2 + y^2 == 1\r\n","Size of the pixel neighborhood used to find polynomial expansion in each pixel. The larger values mean that the image will be approximated with smoother surfaces, yielding more robust algorithm and more blurred motion field. Typically, poly n=5 or 7":"用于在每个像素中查找多项式展开的像素邻域的大小。较大的值意味着图像将被更平滑的表面近似，产生更稳健的算法和更模糊的运动场。通常，poly n=5 或 7\r\n","\r\n            Returns the squared sum of matrix elements.\r\n            ":"\r\n            返回矩阵元素的平方和。\r\n            \r\n","\r\n            Automatic exposure/gain ROI offset Y\r\n            ":"\r\n            自动曝光/增益 ROI 偏移 Y\r\n            \r\n","\r\n            The local file name\r\n            ":"\r\n            本地文件名\r\n            \r\n","output image of the same size and type as src":"与 src 相同大小和类型的输出图像\r\n","\r\n            Applies Y Deriche filter to an image.\r\n            ":"\r\n            将 Y Deriche 滤镜应用于图像。\r\n            \r\n","\r\n            Parameter specifying how much the image size is reduced at each image scale\r\n            ":"\r\n            指定图像大小在每个图像比例下缩小多少的参数\r\n            \r\n","\r\n            Create a Gaussian Mixture-based Background/Foreground Segmentation model\r\n            ":"\r\n            创建基于高斯混合的背景/前景分割模型\r\n            \r\n","\r\n            The mask of CV_SEQ_ELTYPE\r\n            ":"\r\n            CV_SEQ_ELTYPE 的掩码\r\n            \r\n","\r\n            Convert RGB to YUV_YV12\r\n            ":"\r\n            将 RGB 转换为 YUV_YV12\r\n            \r\n","\r\n            Use Gini index. This is default option for Real AdaBoost; may be also used for Discrete AdaBoost\r\n            ":"\r\n            使用基尼指数。这是 Real AdaBoost 的默认选项；也可用于离散 AdaBoost\r\n            \r\n","\r\n             Smartek Giganetix GigEVisionSDK\r\n            ":"\r\n             Smartek Giganetix GigEVisionSDK\r\n            \r\n","\r\n            Create an empty standard vector of Byte\r\n            ":"\r\n            创建一个空的 Byte 标准向量\r\n            \r\n","Size of the video frame":"视频帧的大小\r\n","\r\n            Computes power of each matrix element:\r\n              (dst(i,j) = pow(     src(i,j) , power), if src.type() is integer;\r\n              (dst(i,j) = pow(fabs(src(i,j)), power), otherwise.\r\n            supports all, except depth == CV_64F\r\n            ":"计算每个矩阵元素的幂：\r\n              (dst(i,j) = pow( src(i,j) , power)，如果 src.type() 是整数；\r\n              (dst(i,j) = pow(fabs(src(i,j)), power)，否则。\r\n            支持所有，除了深度== CV_64F\r\n            \r\n","\r\n            Type of corner refinement method\r\n            ":"\r\n            角点细化方法的类型\r\n            \r\n","Establish the number of radial bins for the Shape Context Descriptor used in the shape matching pipeline.":"为形状匹配管道中使用的形状上下文描述符建立径向箱数。\r\n","Second rectangle":"第二个矩形\r\n","The collection of points":"积分的收集\r\n","\r\n            A class to find the positions of the ColorCharts in the image.\r\n            ":"\r\n            用于查找图像中 ColorCharts 位置的类。\r\n            \r\n","\r\n            ANNEAL: Update initial temperature.\r\n            ":"\r\n            ANNEAL：更新初始温度。\r\n            \r\n","Blur for descriptor":"模糊描述符\r\n","\r\n            Insert a point to the triangulation. \r\n            ":"\r\n            在三角剖分中插入一个点。\r\n            \r\n","Shift along the horizontal axis":"沿水平轴移动\r\n","\r\n            Create a new dpm detector with the specified files and classes\r\n            ":"\r\n            使用指定的文件和类创建一个新的 dpm 检测器\r\n            \r\n","\r\n            Returns matrix header for the input array that can be matrix - CvMat, image - IplImage or multi-dimensional dense array - CvMatND* (latter case is allowed only if allowND != 0) . In the case of matrix the function simply returns the input pointer. In the case of IplImage* or CvMatND* it initializes header structure with parameters of the current image ROI and returns pointer to this temporary structure. Because COI is not supported by CvMat, it is returned separately. \r\n            ":"\r\n            返回输入数组的矩阵头，可以是矩阵 - CvMat、图像 - IplImage 或多维密集数组 - CvMatND*（后一种情况仅在 allowND != 0 时才允许）。在矩阵的情况下，该函数仅返回输入指针。在 IplImage* 或 CvMatND* 的情况下，它使用当前图像 ROI 的参数初始化标头结构，并返回指向该临时结构的指针。因为CvMat不支持COI，所以单独返回。\r\n            \r\n","\r\n            Calculates per-element bit-wise logical and of two GpuMats:\r\n            dst(I)=src1(I) & src2(I) if mask(I)!=0\r\n            In the case of floating-point GpuMats their bit representations are used for the operation. All the GpuMats must have the same type, except the mask, and the same size\r\n            ":"\r\n            计算每个元素的按位逻辑和两个 GpuMats：\r\n            dst(I)=src1(I) & src2(I) 如果掩码(I)!=0\r\n            在浮点 GpuMats 的情况下，它们的位表示用于操作。所有 GpuMats 必须具有相同的类型（掩码除外）和相同的大小\r\n            \r\n","Handle nest":"拉手窝\r\n","\r\n            Perform k-nearest-neighbours (KNN) search\r\n            ":"\r\n            执行 k 最近邻 (KNN) 搜索\r\n            \r\n","The major version":"主要版本\r\n","\r\n            Rational model\r\n            ":"\r\n            理性模式\r\n            \r\n","\r\n            Initialize the tracker with a know bounding box that surrounding the target.\r\n            ":"\r\n            使用围绕目标的已知边界框初始化跟踪器。\r\n            \r\n","\r\n            gPhoto2 connection\r\n            ":"\r\n            gPhoto2 连接\r\n            \r\n","grid for p":"p 的网格\r\n","Path to the model file.":"模型文件的路径。\r\n","\r\n            Winter\r\n            ":"\r\n            冬天\r\n            \r\n","The Saliency object":"显着性对象\r\n","\r\n            Given the input frame, create input blob, run net and return the output blobs.\r\n            ":"\r\n            给定输入帧，创建输入 blob，运行 net 并返回输出 blob。\r\n            \r\n","The number of cols (":"列数（\r\n","\r\n            Information Flow algorithm implementaton for alphamatting\r\n            This module is dedicated to compute alpha matting of images, given the input image and an input trimap.\r\n            ":"\r\n            alphamatting 的信息流算法实现\r\n            该模块专门用于计算图像的 alpha 抠图，给定输入图像和输入 trimap。\r\n            \r\n","\r\n            Contrast scale factor. HVS response is multiplied by this parameter, thus compressing dynamic range. Values from 0.6 to 0.9 produce best results.\r\n            ":"\r\n            对比度比例因子。 HVS 响应乘以该参数，从而压缩动态范围。 0.6 到 0.9 之间的值会产生最佳结果。\r\n            \r\n"," \r\n            Perform an binary OR operation with some color\r\n            ":" \r\n            对某种颜色进行二元或运算\r\n            \r\n","The InputArray":"输入数组\r\n","\r\n            Returns whether the event loop has been stopped.\r\n            ":"\r\n            返回事件循环是否已停止。\r\n            \r\n","The Pointer to the IplImage":"指向 IplImage 的指针\r\n","\r\n            For PNG, it can be the compression level from 0 to 9. A higher value means a smaller size and longer compression time. Default value is 3.\r\n            ":"\r\n            对于PNG，它可以是从0到9的压缩级别。更高的值意味着更小的尺寸和更长的压缩时间。默认值为 3。\r\n            \r\n","The nvidia optical flow object":"nvidia光流对象\r\n","\r\n            Type of SVM\r\n            ":"\r\n            支持向量机的类型\r\n            \r\n","\r\n            Boost Tree \r\n            ":"\r\n            提升树\r\n            \r\n","\r\n            The user can resize the window (no constraint) / also use to switch a fullscreen window to a normal size\r\n            ":"\r\n            用户可以调整窗口大小（无限制）/也可用于将全屏窗口切换为正常大小\r\n            \r\n","\r\n            Count the non Zero elements for each channel\r\n            ":"\r\n            计算每个通道的非零元素\r\n            \r\n","Criteria when to stop the Levenberg-Marquard iterative algorithm.":"何时停止 Levenberg-Marquard 迭代算法的标准。\r\n","\r\n            Convert the GpuMat to Mat\r\n            ":"\r\n            将 GpuMat 转换为 Mat\r\n            \r\n","\r\n            VP8\r\n            ":"\r\n            VP8\r\n            \r\n","Criteria applied to determine when the window search should be finished. ":"用于确定何时应完成窗口搜索的条件。\r\n","\r\n            Recurs filter\r\n            ":"\r\n            重复过滤器\r\n            \r\n","\r\n            Status of lens control interface. This shall be set to XI_ON before any Lens operations.\r\n            ":"\r\n            镜头控制界面状态。这应在任何镜头操作之前设置为 XI_ON。\r\n            \r\n","\r\n            Pointer to the unmanaged cv::Algorithm\r\n            ":"\r\n            指向非托管 cv::Algorithm 的指针\r\n            \r\n"," Return a flipped copy of the current image":" 返回当前图像的翻转副本\r\n","The data type of the jagged two dimensional":"锯齿状二维的数据类型\r\n","\r\n            regular method using all the point pairs\r\n            ":"\r\n            使用所有点对的常规方法\r\n            \r\n","This call is not thread-safe. Consider calling this function from the main() before any other OpenCV processing functions (and without any other created threads).":"此调用不是线程安全的。考虑在任何其他 OpenCV 处理函数之前从 main() 调用此函数（并且没有任何其他创建的线程）。\r\n","Mock parameter used for CPU/CUDA interfaces similarity, simply add a 0 value.":"Mock 参数用于CPU/CUDA 接口相似性，只需添加一个0 值。\r\n","\r\n            Defines the size of one dimension of a three-dimensional RGB histogram that is used internally by the algorithm. It often makes sense to increase the number of bins for images with higher bit depth (e.g. 256 bins for a 12 bit image).\r\n            ":"\r\n            定义算法内部使用的三维 RGB 直方图的一维大小。对于具有更高位深度的图像，增加 bin 的数量通常是有意义的（例如，对于 12 位图像，增加 256 个 bin）。\r\n            \r\n","\r\n            Release all the unmanaged resource associated with BEBLID\r\n            ":"\r\n            释放与 BEBLID 关联的所有非托管资源\r\n            \r\n","\r\n            Get the rotation angle in radian\r\n            ":"\r\n            获取以弧度为单位的旋转角度\r\n            \r\n","Polygon color":"多边形颜色\r\n","\r\n            Convert Bayer GB to RGBA\r\n            ":"\r\n            将 Bayer GB 转换为 RGBA\r\n            \r\n","\r\n            Create a new 3D visualizer windows\r\n            ":"\r\n            创建一个新的 3D 可视化窗口\r\n            \r\n","\r\n            Compile the program \r\n            ":"\r\n            编译程序\r\n            \r\n","The weight of ":"的重量\r\n","\r\n            Number of iteration\r\n            ":"\r\n            迭代次数\r\n            \r\n","Matches array stored in GPU memory. Internal representation is not defined. Use DescriptorMatcher::matchConvert method to retrieve results in standard representation.":"匹配存储在 GPU 内存中的数组。未定义内部表示。使用 DescriptorMatcher::matchConvert 方法以标准表示形式检索结果。\r\n","Specify cost of gradient direction function (default: 0.43f)":"指定梯度方向函数的成本（默认值：0.43f）\r\n","Current time in milliseconds or other units":"当前时间，以毫秒或其他单位\r\n","\r\n            Draw a ChArUco board\r\n            ":"\r\n            绘制 ChArUco 板\r\n            \r\n","Specify the hdf5 dataset label.":"指定 hdf5 数据集标签。\r\n","\r\n            A 2D cross\r\n            ":"\r\n            二维十字\r\n            \r\n","Image height.":"图像高度。\r\n","The normalization type":"归一化类型\r\n","Matches returned by the LOGOS matching strategy.":"LOGOS 匹配策略返回的匹配项。\r\n","\r\n            Use Triangle algorithm to choose the optimal threshold value\r\n            ":"\r\n            使用三角算法选择最优阈值\r\n            \r\n","Translation vector used to initialize an iterative PnP refinement algorithm, when flag is SOLVEPNP_ITERATIVE and useExtrinsicGuess is set to true.":"当标志为 SOLVEPNP_ITERATIVE 且 useExtrinsicGuess 设置为 true 时，用于初始化迭代 PnP 细化算法的转换向量。\r\n","The written frame.":"书面框架。\r\n","\r\n            This function is similiar to cvCalcBackProjectPatch. It slids through image, compares overlapped patches of size wxh with templ using the specified method and stores the comparison results to result\r\n            ":"\r\n            这个函数类似于 cvCalcBackProjectPatch。它滑过图像，使用指定的方法将大小为 wxh 的重叠块与 templ 进行比较，并将比较结果存储到 result\r\n            \r\n","\r\n            OAST_9_16\r\n            ":"\r\n            OAST_9_16\r\n            \r\n","The optional mask for the operation, use null to ignore":"操作的可选掩码，使用 null 忽略\r\n","\r\n            Fill the convex polygon with the specific color\r\n            ":"\r\n            用特定颜色填充凸多边形\r\n            \r\n","\r\n            This 3D Widget defines a cube.\r\n            ":"\r\n            这个 3D Widget 定义了一个立方体。\r\n            \r\n","\r\n            Get the string representation of the Quaternions\r\n            ":"\r\n            获取四元数的字符串表示\r\n            \r\n","\r\n            Defines source of trigger.\r\n            ":"\r\n            定义触发源。\r\n            \r\n","\r\n            Convert BGR color to Luv color\r\n            ":"\r\n            将 BGR 颜色转换为 Luv 颜色\r\n            \r\n","Specify the offset location over dataset from where read starts.":"指定数据集上读取开始的偏移位置。\r\n","\r\n            Exposure priority (0.5 - exposure 50%, gain 50%).\r\n            ":"\r\n            曝光优先级（0.5 - 曝光 50%，增益 50%）。\r\n            \r\n","Specify cost of non-edge pixels. Type is CV_8UC1. Expected values are {0, 1}.":"指定非边缘像素的成本。类型是 CV_8UC1。预期值为 {0, 1}。\r\n","\r\n            Create a CudaFarnebackOpticalFlow object\r\n            ":"\r\n            创建一个 CudaFarnebackOpticalFlow 对象\r\n            \r\n","\r\n            Converts matches array from internal representation to standard matches vector.\r\n            ":"\r\n            将匹配数组从内部表示转换为标准匹配向量。\r\n            \r\n","Horizontal filter coefficients. Support kernels with size <= 32 .":"水平滤波器系数。支持大小 <​​= 32 的内核。\r\n","Zero-based index of the selected column":"所选列的从零开始的索引\r\n","The disparity filter":"差异过滤器\r\n","\r\n            256 bit descriptor\r\n            ":"\r\n            256 位描述符\r\n            \r\n","\r\n            Convert BGRA color to GRAY color\r\n            ":"\r\n            将 BGRA 颜色转换为 GRAY 颜色\r\n            \r\n","Input/output vector of distortion coefficients (k1,k2,k3,k4) of 4 elements.":"4 个元素的失真系数 (k1,k2,k3,k4) 的输入/输出向量。\r\n","Number of fractional bits in the center coordinates and axes' values":"中心坐标和轴值中的小数位数\r\n","The 3D location of the object points. The first index is the index of image, second index is the index of the point":"对象点的 3D 位置。第一个索引是图像的索引，第二个索引是点的索引\r\n","\r\n            Constructor to a very efficient and robust variant of the iterative closest point (ICP) algorithm.\r\n            ":"\r\n            迭代最近点 (ICP) 算法的一个非常有效和健壮的变体的构造函数。\r\n            \r\n","The arguments to the executable":"可执行文件的参数\r\n","The optional output essential matrix":"可选的输出基本矩阵\r\n"," An other point on the line ":" 线上的另一个点\r\n","Uniformly distributed integer random number from [a,b) range":"来自 [a,b) 范围的均匀分布整数随机数\r\n","\r\n            BayerGB2GRAY_MHT\r\n            ":"\r\n            拜耳GB2GRAY_MHT\r\n            \r\n","\r\n            The tesseract OCR engine\r\n            ":"\r\n            tesseract OCR 引擎\r\n            \r\n","\r\n            Trigger delay\r\n            ":"\r\n            触发延迟\r\n            \r\n","Confidence level, between 0 and 1, for the estimated transformation. Anything between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.":"估计转换的置信水平，介于 0 和 1 之间。介于 0.95 和 0.99 之间的任何值通常就足够了。太接近 1 的值会显着减慢估计速度。低于 0.8-0.9 的值可能导致转换估计不正确。\r\n","\r\n            Stitch mode\r\n            ":"\r\n            针迹模式\r\n            \r\n","\r\n            Convert Bayer RGGB to BGRA \r\n            ":"\r\n            将 Bayer RGGB 转换为 BGRA\r\n            \r\n","InputArray as supported by Sobel. img can be 1-Channel or 3-Channels.":"Sobel 支持的 InputArray。 img 可以是 1 通道或 3 通道。\r\n","\r\n            Calculates seven Hu invariants\r\n            ":"\r\n            计算七个 Hu 不变量\r\n            \r\n","\r\n            Create a new TrackerDaSiamRPN\r\n            ":"创建一个新的 TrackerDaSiamRPN\r\n            \r\n","\r\n            Spatial Moment M03\r\n            ":"\r\n            空间瞬间M03\r\n            \r\n","\r\n            Create a BFMatcher of the specific distance type\r\n            ":"\r\n            创建特定距离类型的 BFMatcher\r\n            \r\n","The Mat to read the file into":"将文件读入的 Mat\r\n","\r\n            Gpu look up table\r\n            ":"\r\n            Gpu查表\r\n            \r\n","Input array of y-coordinates of 2D vectors; it must have the same size and the same type as x.":"输入二维向量的 y 坐标数组；它必须与 x 具有相同的大小和相同的类型。\r\n","\r\n            Automatic page segmentation, but no OSD, or OCR.\r\n            ":"\r\n            自动页面分割，但没有 OSD 或 OCR。\r\n            \r\n","\r\n            This function load the image data from the iplImage pointer\r\n            ":"\r\n            此函数从 iplImage 指针加载图像数据\r\n            \r\n","\r\n            Class implementing two-dimensional phase unwrapping.\r\n            ":"\r\n            实现二维相位展开的类。\r\n            \r\n","\r\n            The node has a name (i.e. it is element of a mapping)\r\n            ":"\r\n            该节点有一个名称（即它是映射的元素）\r\n            \r\n","\r\n            Selects which test pattern generator is controlled by the TestPattern feature.\r\n            ":"\r\n            选择由 TestPattern 功能控制的测试模式生成器。\r\n            \r\n","Calculated mean value":"计算平均值\r\n","\r\n            Convert BGR color to YCrCb color\r\n            ":"\r\n            将 BGR 颜色转换为 YCrCb 颜色\r\n            \r\n","destination image":"目标图像\r\n","The sum for each color channel":"每个颜色通道的总和\r\n","\r\n            4-character code of codec\r\n            ":"\r\n            编解码器的四位字符代码\r\n            \r\n","\r\n            Bad origin\r\n            ":"\r\n            不良来源\r\n            \r\n","The mat to be inverted":"要翻转的垫子\r\n","\r\n            Create a Cuda Convolution object.\r\n            ":"\r\n            创建一个 Cuda 卷积对象。\r\n            \r\n","Translation vector between coordinate systems of the cameras.":"摄像机坐标系之间的平移矢量。\r\n","This parameter may specify Gaussian sigma (standard deviation). If it is zero, it is calculated from the kernel size.":"该参数可以指定高斯西格玛（标准偏差）。如果为零，则根据内核大小计算。\r\n","\r\n            n-class classification with possible imperfect separation. Parameter nu (in the range 0..1, the larger the value, the smoother the decision boundary) is used instead of C\r\n            ":"\r\n            n 类分类，可能存在不完美的分离。使用参数nu（在0..1范围内，值越大，决策边界越平滑）代替C\r\n            \r\n","\r\n            Sets the number of times of exposure in one frame.\r\n            ":"\r\n            设置一帧中的曝光次数。\r\n            \r\n","Can be null if not needed. An n x 1 matrix. If 0, the query descriptor in the corresponding row will be ignored.":"如果不需要，可以为 null。一个 n x 1 矩阵。如果为 0，相应行中的查询描述符将被忽略。\r\n","The computed saliency map.":"计算出的显着图。\r\n","reject levels":"拒绝水平\r\n","New number of rows. newRows = 0 means that the number of rows remains unchanged unless it needs to be changed according to newCn value.":"新的行数。 newRows = 0 表示行数保持不变，除非需要根据newCn值改变。\r\n","\r\n            Release the unmanaged memory associated with this DataLogger\r\n            ":"\r\n            释放与此 DataLogger 关联的非托管内存\r\n            \r\n","The image where the objects are to be detected from":"要从中检测对象的图像\r\n","Camera matrix K=[[fx 0 cx][0 fy cy][0 0 1]]. Note that this function assumes that points1 and points2 are feature points from cameras with the same camera matrix.":"相机矩阵 K=[[fx 0 cx][0 fy cy][0 0 1]]。请注意，此函数假定 points1 和 points2 是来自具有相同相机矩阵的相机的特征点。\r\n","Controls the sharpness of the weight transition from edges to smooth/texture regions, where a bigger value means sharper transition. When the value is negative, it is automatically calculated.":"控制从边缘到平滑/纹理区域的权重过渡的锐度，其中较大的值意味着更锐利的过渡。当值为负时，自动计算。\r\n","True if decoding is successful.":"如果解码成功则为真。\r\n","Output image, 8-bit unsigned 1-channel image.":"输出图像，8 位无符号 1 通道图像。\r\n","\r\n            Solves linear system (src1)*(dst) = (src2)\r\n            ":"\r\n            求解线性系统 (src1)*(dst) = (src2)\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of VectorOfERStat.\r\n            ":"\r\n            VectorOfERStat 的 C++ 标准向量的包装类。\r\n            \r\n","The number of iterations to run GrabCut":"运行 GrabCut 的迭代次数\r\n","\r\n            Flann index\r\n            ":"\r\n            弗兰指数\r\n            \r\n","Output array.":"输出数组。\r\n","\r\n            Video Acceleration Type\r\n            ":"\r\n            视频加速类型\r\n            \r\n","The kernelR1 file":"kernelR1 文件\r\n","\r\n            Given the input frame, create input blob, run net and return top-1 prediction.\r\n            ":"\r\n            给定输入帧，创建输入 blob，运行网络并返回 top-1 预测。\r\n            \r\n","\r\n            Default number of neighbors to use in predict method\r\n            ":"\r\n            预测方法中使用的默认邻居数\r\n            \r\n","\r\n            Hue of the image (only for cameras).\r\n            ":"\r\n            图像的色调（仅适用于相机）。\r\n            \r\n","\r\n            The file name of the opencv_ffmpeg library\r\n            ":"\r\n            opencv_ffmpeg库的文件名\r\n            \r\n","\r\n            Get the data in this storage\r\n            ":"\r\n            获取此存储中的数据\r\n            \r\n","The translation vector between the cameras' coordinate systems":"相机坐标系之间的平移矢量\r\n","Operation mask. Its non-zero elements indicate which matrix elements need to be copied.":"手术面具。它的非零元素表示需要复制哪些矩阵元素。\r\n","\r\n            This class represents high-level API for classification models.\r\n            ":"\r\n            此类代表分类模型的高级 API。\r\n            \r\n","\r\n            Create a GpuMat from the specific pointer\r\n            ":"\r\n            从特定指针创建 GpuMat\r\n            \r\n"," For the multi-scale Hough transform, it is a divisor for the distance resolution theta":" 对于多尺度霍夫变换，它是距离分辨率 theta 的除数\r\n","\r\n            autosize property      (can be WINDOW_NORMAL or WINDOW_AUTOSIZE).\r\n            ":"\r\n            autosize 属性（可以是 WINDOW_NORMAL 或 WINDOW_AUTOSIZE）。\r\n            \r\n","Accumulator of the same number of channels as input image, 32-bit or 64-bit floating-point":"与输入图像相同通道数的累加器，32 位或 64 位浮点数\r\n","\r\n            Create a default KNearest classifier\r\n            ":"\r\n            创建默认的 KNearest 分类器\r\n            \r\n","Flag which indicates that swap first and last channels in 3-channel image is necessary.":"标志，表示需要交换 3 通道图像中的第一个和最后一个通道。\r\n"," to false":" 假的\r\n","Set the inner radius of the shape context descriptor.":"设置形状上下文描述符的内半径。\r\n","Vector of vertices IDs to consider. For all vertices you can pass empty vector.":"要考虑的顶点 ID 向量。对于所有顶点，您可以传递空向量。\r\n","The color of the cross ":"十字架的颜色\r\n","\r\n            Writes the specified Mat to the node with the specific name.\r\n            ":"\r\n            将指定的 Mat 写入具有特定名称的节点。\r\n            \r\n"," \r\n            An array of gray scale images where each element  \r\n            in the array represent a single color channel of the original image \r\n            ":" \r\n            一组灰度图像，其中每个元素\r\n            在数组中表示原始图像的单个颜色通道\r\n            \r\n","Zero-based index of the starting row (inclusive) of the span":"跨度起始行（含）的从零开始的索引\r\n","Output array of the same size as src and CV_8U type.":"与 src 和 CV_8U 类型大小相同的输出数组。\r\n","Weight of the second matrix elements.":"第二个矩阵元素的权重。\r\n","\r\n            polynomial kernel: d(x,y) = (gamma*(xy)+coef0)^degree\r\n            ":"\r\n            多项式内核：d(x,y) = (gamma*(xy)+coef0)^degree\r\n            \r\n","The number of image rotations.":"图像旋转的次数。\r\n","\r\n            initialStepSize of a SVMSGD optimization problem\r\n            ":"\r\n            SVMSGD 优化问题的 initialStepSize\r\n            \r\n","\r\n            These functions try to match the given images and to estimate rotations of each camera.\r\n            ":"\r\n            这些函数尝试匹配给定的图像并估计每个相机的旋转。\r\n            \r\n","b-parameter in the Camera Response Function (CRF).":"相机响应函数 (CRF) 中的 b 参数。\r\n","\r\n            Create an empty standard vector of VectorOfByte\r\n            ":"\r\n            创建一个空的 VectorOfByte 标准向量\r\n            \r\n","\r\n            Calculates the actual amount of superpixels on a given segmentation computed and stored in SuperpixelLSC object\r\n            ":"\r\n            计算给定分割的实际超像素数量，计算并存储在 SuperpixelLSC 对象中\r\n            \r\n","\r\n            8bit signed\r\n            ":"\r\n            8位签名\r\n            \r\n","\r\n            Get the pointer to the Widget3D obj\r\n            ":"\r\n            获取指向 Widget3D obj 的指针\r\n            \r\n","Specify if non-maximum supression should be used.":"指定是否应使用非最大抑制。\r\n","\r\n            Min x value\r\n            ":"\r\n            最小 x 值\r\n            \r\n","\r\n            Instance Number\r\n            ":"\r\n            实例编号\r\n            \r\n","The parent object to keep reference to":"要引用的父对象\r\n","The destination image of the same data type as the source one. The number of channels may be different":"与源图像具有相同数据类型的目标图像。通道数可能不同\r\n","If only a single input vector is passed, the predicted value is returned by the method.":"如果仅传递单个输入向量，则该方法返回预测值。\r\n","\r\n            minimum accuracy during the polygonal approximation process to determine which contours are squares.\r\n            ":"\r\n            在多边形近似过程中确定哪些轮廓是正方形的最小精度。\r\n            \r\n","Array of object points, 1xN/Nx1 3-channel (or vector<Point3f> ), where N is the number of points in the view.":"对象点数组，1xN/Nx1 3 通道（或 vector<Point3f> ），其中 N 是视图中的点数。\r\n","\r\n            Convert the current CudaImage to a regular Image.\r\n            ":"\r\n            将当前 CudaImage 转换为常规图像。\r\n            \r\n","The row to be extracted":"要提取的行\r\n","\r\n            Convert YCrCb color to BGR color\r\n            ":"\r\n            将 YCrCb 颜色转换为 BGR 颜色\r\n            \r\n","\r\n            Bad point\r\n            ":"\r\n            坏点\r\n            \r\n","\r\n            Let this Image object use the specific Image data.\r\n            ":"\r\n            让这个 Image 对象使用特定的 Image 数据。\r\n            \r\n","\r\n            Copy the masked area of this image to destination\r\n            ":"\r\n            将此图像的蒙版区域复制到目标\r\n            \r\n","\r\n            Copy the data in this cv::Mat to an output array\r\n            ":"\r\n            将此 cv::Mat 中的数据复制到输出数组\r\n            \r\n","\r\n            Draws a simple or filled circle with given center and radius. The circle is clipped by ROI rectangle.\r\n            ":"\r\n            使用给定的圆心和半径绘制一个简单的或填充的圆。圆被 ROI 矩形裁剪。\r\n            \r\n","Text only":"纯文本\r\n","\r\n            Dict7X7_1000\r\n            ":"\r\n            词典7X7_1000\r\n            \r\n","The border value":"边界值\r\n","The relative parameter that characterizes intensity of the shuffling performed. The number of iterations (i.e. pairs swapped) is round(iter_factor*rows(mat)*cols(mat)), so iter_factor=0 means that no shuffling is done, iter_factor=1 means that the function swaps rows(mat)*cols(mat) random pairs etc":"表征所执行洗牌强度的相关参数。迭代次数（即pairs swapped）为round(iter_factor*rows(mat)*cols(mat))，所以iter_factor=0表示不做shuffling，iter_factor=1表示函数交换rows(mat)*cols （垫）随机对等\r\n","\r\n            PyrLK optical flow\r\n            ":"\r\n            PyrLK 光流\r\n            \r\n","Input image: 8-bit unsigned 2-channel":"输入图像：8 位无符号 2 通道\r\n","Radius of kernel to be used for filtering. It should be positive integer":"用于过滤的内核半径。应该是正整数\r\n","\r\n            Refine a pose (the translation and the rotation that transform a 3D point expressed in the object coordinate frame to the camera coordinate frame) from a 3D-2D point correspondences and starting from an initial solution\r\n            ":"\r\n            从 3D-2D 点对应并从初始解决方案开始优化姿势（将对象坐标系中表示的 3D 点转换为相机坐标系的平移和旋转）\r\n            \r\n","\r\n            Converts an image from RGB color space to YUV422.\r\n            ":"\r\n            将图像从 RGB 颜色空间转换为 YUV422。\r\n            \r\n","\r\n            Wait for the queue to finish\r\n            ":"\r\n            等待队列完成\r\n            \r\n","Controls the accuracy of registration at each iteration of ICP.":"在 ICP 的每次迭代中控制配准的准确性。\r\n","\r\n            The type of the mixture covariation matrices\r\n            ":"\r\n            混合协方差矩阵的类型\r\n            \r\n"," If thickness is less than 1, the triangle is filled up ":" 如果thickness小于1，三角形被填满\r\n","A two dimension matrix that represent the array":"表示数组的二维矩阵\r\n","\r\n            Reads a network model ONNX.\r\n            ":"\r\n            读取网络模型 ONNX。\r\n            \r\n","\r\n            The 1976 definition was extended to address perceptual non-uniformities.\r\n            ":"\r\n            1976 年的定义被扩展以解决感知上的不均匀性。\r\n            \r\n","\r\n            0 - interleaved color channels, 1 - separate color channels.\r\n            cvCreateImage can only create interleaved images \r\n            ":"\r\n            0 - 交错的颜色通道，1 - 独立的颜色通道。\r\n            cvCreateImage 只能创建交错图像\r\n            \r\n","\r\n            A downwards pointing triangle marker shape\r\n            ":"\r\n            一个向下的三角形标记形状\r\n            \r\n","Resolution of the cylinder.":"圆柱体的分辨率。\r\n","\r\n            MPEG2\r\n            ":"\r\n            MPEG2\r\n            \r\n","The rotation matrix between the 1st and the 2nd cameras' coordinate systems":"第一和第二相机坐标系之间的旋转矩阵\r\n","\r\n            Release the unmanaged memory associated with this TonemapDurand\r\n            ":"\r\n            释放与此 TonemapDurand 关联的非托管内存\r\n            \r\n","A composition of the two rotations":"两个旋转的组合\r\n","\r\n            Detects Barcode in image and returns the rectangle(s) containing the code.\r\n            ":"\r\n            检测图像中的条形码并返回包含代码的矩形。\r\n            \r\n","\r\n            Finds subpixel-accurate positions of the chessboard corners\r\n            ":"\r\n            找到棋盘角的亚像素精确位置\r\n            \r\n","Norm value to normalize to or the lower range boundary in case of the range normalization.":"在范围归一化的情况下要归一化到的标准值或下限范围边界。\r\n","\r\n            Calibrate a camera using Charuco corners.\r\n            ":"\r\n            使用 Charuco 角标定相机。\r\n            \r\n","\r\n            Get or set the pixel data in the current position\r\n            ":"\r\n            获取或设置当前位置的像素数据\r\n            \r\n","\r\n            A custom error handler for OpenCV\r\n            ":"\r\n            OpenCV 的自定义错误处理程序\r\n            \r\n"," image inplace using a 3x3 rectangular structuring element.\r\n            Erosion are applied several (iterations) times\r\n            ":" 使用 3x3 矩形结构元素放置图像。\r\n            侵蚀应用多次（迭代）次\r\n            \r\n","\r\n            calculates matrix of perspective transform such that:\r\n            (t_i x'_i,t_i y'_i,t_i)^T=map_matrix (x_i,y_i,1)^T\r\n            where dst(i)=(x'_i,y'_i), src(i)=(x_i,y_i), i=0..3.\r\n            ":"\r\n            计算透视变换矩阵，使得：\r\n            (t_i x'_i,t_i y'_i,t_i)^T=map_matrix (x_i,y_i,1)^T\r\n            其中 dst(i)=(x'_i,y'_i), src(i)=(x_i,y_i), i=0..3。\r\n            \r\n","Output 3x3 upper-triangular matrix.":"输出 3x3 上三角矩阵。\r\n","\r\n            1 if on the right hand side;\r\n            0 if on the line;\r\n            -1 if on the left hand side;\r\n            ":"\r\n            1 如果在右手边；\r\n            0 如果在线；\r\n            -1 如果在左侧；\r\n            \r\n","\r\n            Control the index (offset) of the coefficient to access in the LUT.\r\n            ":"\r\n            控制要在 LUT 中访问的系数的索引（偏移量）。\r\n            \r\n","\r\n            Get the preview image\r\n            ":"\r\n            获取预览图像\r\n            \r\n","\r\n            Release all unmanaged memory associated with the retina model.\r\n            ":"\r\n            释放与视网膜模型关联的所有非托管内存。\r\n            \r\n","\r\n            Exposure (only for those cameras that support).\r\n            ":"\r\n            曝光（仅适用于支持的相机）。\r\n            \r\n","Byte array that contains the image in the specific image format. If failed to encode, return null":"包含特定图像格式的图像的字节数组。如果编码失败，返回null\r\n","The type of the flipping":"翻转的类型\r\n","Order of derivative x":"导数 x 的阶数\r\n","\r\n            Create an standard vector of KeyLine with the initial values\r\n            ":"\r\n            使用初始值创建 KeyLine 的标准向量\r\n            \r\n","\r\n            Gets a value indicating whether this instance is opened.\r\n            ":"\r\n            获取一个值，该值指示此实例是否已打开。\r\n            \r\n","\r\n            Blender for Image Stitching\r\n            ":"\r\n            图像拼接搅拌机\r\n            \r\n","\r\n            BM3D steps\r\n            ":"\r\n            BM3D步骤\r\n            \r\n","The result of bilateral smooth":"双边平滑的结果\r\n","\r\n            The pointer to the Feature2D object\r\n            ":"\r\n            指向 Feature2D 对象的指针\r\n            \r\n","Output vector of standard deviations estimated for intrinsic parameters. Order of deviations values: (fx,fy,cx,cy,k1,k2,p1,p2,k3,k4,k5,k6,s1,s2,s3,s4,τx,τy) If one of parameters is not estimated, it's deviation is equals to zero.":"为内在参数估计的标准偏差的输出向量。偏差值的顺序：（fx，fy，cx，cy，k1，k2，p1，p2，k3，k4，k5，k6，s1，s2，s3，s4，τx，τy）如果未估计其中一个参数，它的偏差等于零。\r\n","The number of cols":"列数\r\n","The first element of the top-level mapping.":"顶级映射的第一个元素。\r\n","\r\n            Features Matcher for Image Stitching\r\n            ":"\r\n            用于图像拼接的特征匹配器\r\n            \r\n","Value that defines which local binarization algorithm should be used.":"定义应使用哪种局部二值化算法的值。\r\n",", the value of the input ":", 输入值\r\n","\r\n            Create a SeparableLinearFilter\r\n            ":"\r\n            创建一个 SeparableLinearFilter\r\n            \r\n","\r\n            one-class SVM. All the training data are from the same class, SVM builds a boundary that separates the class from the rest of the feature space\r\n            ":"\r\n            一级支持向量机。所有的训练数据都来自同一个类，SVM 构建了一个边界，将类与其余的特征空间分开\r\n            \r\n","\r\n            Convert BayerGB to GRAY\r\n            ":"\r\n            将 BayerGB 转换为 GRAY\r\n            \r\n","\r\n            Rotate this image the specified ":"\r\n            将此图像旋转指定的\r\n","\r\n            computes the rotation matrices for each camera that (virtually) make both camera image planes the same plane. Consequently, that makes all the epipolar lines parallel and thus simplifies the dense stereo correspondence problem. On input the function takes the matrices computed by cvStereoCalibrate and on output it gives 2 rotation matrices and also 2 projection matrices in the new coordinates. The function is normally called after cvStereoCalibrate that computes both camera matrices, the distortion coefficients, R and T\r\n            ":"\r\n            计算每个相机的旋转矩阵（实际上）使两个相机图像平面成为同一平面。因此，这使得所有对极线平行，从而简化了密集立体对应问题。在输入时，该函数采用由 cvStereoCalibrate 计算的矩阵，在输出时它在新坐标中给出 2 个旋转矩阵和 2 个投影矩阵。该函数通常在 cvStereoCalibrate 之后调用，它计算两个相机矩阵、失真系数、R 和 T\r\n            \r\n","\r\n            Convert YUV YV12 to Gray\r\n            ":"\r\n            将 YUV YV12 转换为灰色\r\n            \r\n","Value ranges between 0-2.":"值介于 0-2 之间。\r\n","The matrix to compute dot product with":"计算点积的矩阵\r\n","\r\n            The method of linearization\r\n            ":"\r\n            线性化方法\r\n            \r\n","\r\n            Only for stereo: Same focal length\r\n            ":"\r\n            仅适用于立体声：相同焦距\r\n            \r\n","\r\n            Compares the corresponding elements of two arrays and fills the destination mask array:\r\n            dst(I)=src1(I) op src2(I),\r\n            dst(I) is set to 0xff (all '1'-bits) if the particular relation between the elements is true and 0 otherwise. \r\n            All the arrays must have the same type, except the destination, and the same size (or ROI size)\r\n            ":"\r\n            比较两个数组的相应元素并填充目标掩码数组：\r\n            dst(I)=src1(I) op src2(I),\r\n            如果元素之间的特定关系为真，则 dst(I) 设置为 0xff（全“1”位），否则设置为 0。\r\n            所有数组必须具有相同的类型（目标除外）和相同的大小（或 ROI 大小）\r\n            \r\n","The measured system parameters":"被测系统参数\r\n","Second input array of the same size and type as src1":"与 src1 具有相同大小和类型的第二个输入数组\r\n","\r\n            Convert the standard vector to arrays of arrays of Byte\r\n            ":"\r\n            将标准向量转换为 Byte 数组的数组\r\n            \r\n","\r\n            Create a Tesseract OCR engine.\r\n            ":"\r\n            创建一个 Tesseract OCR 引擎。\r\n            \r\n","The new camera matrix A'=[fx' 0 cx'; 0 fy' cy'; 0 0 1]":"新的相机矩阵A'=[fx' 0 cx'; 0 fy'cy'; 0 0 1]\r\n","\r\n            BayerRG2BGR_MHT\r\n            ":"\r\n            拜耳RG2BGR_MHT\r\n            \r\n","A set of bounding boxes.":"一组边界框。\r\n","Returns matrix header for the input array":"返回输入数组的矩阵头\r\n","The exclusive ending row to be extracted":"要提取的独占结束行\r\n","Thickness of the polyline edges":"多段线边缘的粗细\r\n","\r\n            Define camera signaling LED functionality\r\n            ":"\r\n            定义相机信号 LED 功能\r\n            \r\n","\r\n            Get the UMat from the input array\r\n            ":"\r\n            从输入数组中获取 UMat\r\n            \r\n","Search line radius":"搜索线半径\r\n","Destination histogram with one row, (levels.cols-1) columns, and the CV_32SC1 type.":"包含一行、(levels.cols-1) 列和 CV_32SC1 类型的目标直方图。\r\n","\r\n            This class represents high-level API for segmentation models.\r\n            ":"\r\n            此类代表分段模型的高级 API。\r\n            \r\n","\r\n            Estimate the Gaussian mixture parameters from a samples set. This variation starts with Expectation step. You need to provide initial means of mixture components. Optionally you can pass initial weights and covariance matrices of mixture components.\r\n            ":"\r\n            从样本集中估计高斯混合参数。这种变化从 Expectation 步骤开始。您需要提供混合成分的初始方法。您可以选择传递混合成分的初始权重和协方差矩阵。\r\n            \r\n","\r\n            The value of the EventArgs\r\n            ":"\r\n            EventArgs 的值\r\n            \r\n","\r\n            Pointer to the unmanaged ShapeDistanceExtractor\r\n            ":"\r\n            指向非托管 ShapeDistanceExtractor 的指针\r\n            \r\n","Current time in milliseconds or other units. ":"当前时间，以毫秒或其他单位为单位。\r\n","\r\n            Intelperc Depth Focal Length Vert\r\n            ":"\r\n            Intelperc 深度焦距垂直\r\n            \r\n","The other image to compute absolute different with":"另一个图像计算绝对不同\r\n","\r\n            Generate a random point cloud around the ellipse. \r\n            ":"\r\n            在椭圆周围生成随机点云。\r\n            \r\n","\r\n            Same to cv::VideoCapture >gt; cv::UMat function\r\n            ":"\r\n            与 cv::VideoCapture >gt; 相同cv::UMat 函数\r\n            \r\n"," The maximum number of iterations to use in the k-means clustering stage when building the k-means tree. A value of -1 used here means that the k-means clustering should be iterated until convergence":" 构建 k-means 树时在 k-means 聚类阶段使用的最大迭代次数。这里使用的值 -1 意味着应该迭代 k-means 聚类直到收敛\r\n","The file name where this algorithm will be saved to":"该算法将保存到的文件名\r\n","\r\n            how many corner candidates to consider when segmenting a group of pixels into a quad.\r\n            ":"\r\n            将一组像素分割成四边形时要考虑多少候选角点。\r\n            \r\n","\r\n            Create an empty standard vector of Float\r\n            ":"\r\n            创建一个空的 Float 标准向量\r\n            \r\n","\r\n            DKK ColorChecker\r\n            ":"\r\n            丹麦克朗色卡\r\n            \r\n","\r\n            For each query descriptor, finds the training descriptors not farther than the specified distance (blocking version).\r\n            ":"对于每个查询描述符，找到不超过指定距离的训练描述符（阻塞版本）。\r\n            \r\n","\r\n            Convert sRGB color to Lab color\r\n            ":"\r\n            将 sRGB 颜色转换为 Lab 颜色\r\n            \r\n","\r\n            A class to represent a line.\r\n            ":"\r\n            一个类来表示一条线。\r\n            \r\n","Specifies how to flip the GpuMat.":"指定如何翻转 GpuMat。\r\n","\r\n            Simple blender which mixes images at its borders.\r\n            ":"简单的混合器，在其边界混合图像。\r\n            \r\n","\r\n            A crosshair marker shape\r\n            ":"\r\n            十字准线标记形状\r\n            \r\n","\r\n            OpenNI image generator\r\n            ":"\r\n            OpenNI 图像生成器\r\n            \r\n","Vector of output translation vectors.":"输出翻译向量的向量。\r\n","3x4 projection matrix of the second camera.":"第二台摄像机的 3x4 投影矩阵。\r\n"," Use inpaint to recover the intensity of the pixels which location defined by ":" 使用 inpaint 恢复由定义的位置的像素的强度\r\n","\r\n            Initialize the activation function for each neuron.\r\n            ":"\r\n            为每个神经元初始化激活函数。\r\n            \r\n","Set it to HH to run the full-scale two-pass dynamic programming algorithm. It will consume O(W*H*numDisparities) bytes, which is large for 640x480 stereo and huge for HD-size pictures. By default, it is set to false.":"将其设置为 HH 以运行全面的二次动态规划算法。它将消耗 O(W*H*numDisparities) 字节，这对于 640x480 立体图像来说很大，对于高清尺寸的图片来说很大。默认情况下，它设置为 false。\r\n","An array of Byte":"字节数组\r\n","\r\n            This class contains ocl context information\r\n            ":"\r\n            此类包含 ocl 上下文信息\r\n            \r\n","\r\n            Creates a matrix header for the specified matrix column.\r\n            ":"\r\n            为指定的矩阵列创建矩阵标题。\r\n            \r\n","\r\n            Create a new BOWKmeans trainer\r\n            ":"\r\n            创建一个新的 BOWKmeans 训练器\r\n            \r\n","\r\n            The file info\r\n            ":"\r\n            文件信息\r\n            \r\n","The type of depth":"深度类型\r\n","The lower (inclusive) and upper (exclusive) boundary of the bin":"bin 的下边界（包含）和上边界（不包含）\r\n","\r\n            Computes an image descriptor using the set visual vocabulary.\r\n            ":"\r\n            使用设置的视觉词汇表计算图像描述符。\r\n            \r\n","Time step of the numerical scheme.":"数值方案的时间步长。\r\n","Output convex hull. It is either an integer vector of indices or vector of points. In the first case, the hull elements are 0-based indices of the convex hull points in the original array (since the set of convex hull points is a subset of the original point set). In the second case, hull elements are the convex hull points themselves.":"输出凸包。它是索引的整数向量或点的向量。在第一种情况下，外壳元素是原始数组中凸包点的从 0 开始的索引（因为凸包点集是原始点集的子集）。在第二种情况下，外壳元素是凸包点本身。\r\n","Optional bias added to output":"添加到输出的可选偏差\r\n","The unwrapped phase map used to find correspondences between the two devices.":"展开的相位图用于查找两个设备之间的对应关系。\r\n","It could be a frame index or a driver specific flag":"它可以是帧索引或特定于驱动程序的标志\r\n","\r\n            Boolean flags indicating whether images should be converted to RGB.\r\n            ":"\r\n            指示图像是否应转换为 RGB 的布尔标志。\r\n            \r\n","\r\n            HEVC\r\n            ":"\r\n            HEVC\r\n            \r\n","Indices of length more than 2 is not implemented":"长度超过 2 的索引未实现\r\n","Matching 3D points of the mesh":"匹配网格的 3D 点\r\n","The 2d points obtained by projectPoints":"projectPoints得到的2d点\r\n","\r\n            Depth generator focal length, in pixels.\r\n            ":"\r\n            深度发生器焦距，以像素为单位。\r\n            \r\n","The third vertex":"第三个顶点\r\n","output array of the same size and type as src.":"与 src 大小和类型相同的输出数组。\r\n","\r\n            L1 norm\r\n            ":"\r\n            L1范数\r\n            \r\n","\r\n            Release the unmanaged memory associated with this Tonemap\r\n            ":"\r\n            释放与此色调映射关联的非托管内存\r\n            \r\n"," Resultant size1 x size2 flow matrix":" 生成的 size1 x size2 流矩阵\r\n","Scale Sigma factor":"比例西格玛因子\r\n","Natural logarithm of absolute value of every element of input array":"输入数组每个元素的绝对值的自然对数\r\n","\r\n            Create a default random tree\r\n            ":"\r\n            创建一个默认的随机树\r\n            \r\n","If thickness is less than 1, the rectangle is filled up ":"如果 thickness 小于 1，则矩形被填满\r\n","First signature, a size1 x dims + 1  floating-point matrix. Each row stores the point weight followed by the point coordinates. The matrix is allowed to have a single column (weights only) if the user-defined cost matrix is used.":"第一个签名，一个 size1 x dims + 1 的浮点矩阵。每行存储点权重，然后是点坐标。如果使用用户定义的成本矩阵，则矩阵允许具有单列（仅权重）。\r\n","\r\n            Struct providing information about video file format.\r\n            ":"\r\n            提供有关视频文件格式信息的结构。\r\n            \r\n","Floating-point matrix of input samples, one row per sample":"输入样本的浮点矩阵，每个样本一行\r\n","\r\n            Lines's extremes in original image \r\n            ":"\r\n            原始图像中的线条极端\r\n            \r\n","\r\n            Tonemaps image.\r\n            ":"\r\n            色调映射图像。\r\n            \r\n","\r\n            Convert the standard vector to arrays of arrays of PointF\r\n            ":"\r\n            将标准向量转换为 PointF 数组的数组\r\n            \r\n","\r\n            Base CornernessCriteria class\r\n            ":"\r\n            基础 CornernessCriteria 类\r\n            \r\n","\r\n            Calculates one or more integral images for the source image \r\n            Using these integral images, one may calculate sum, mean, standard deviation over arbitrary up-right or rotated rectangular region of the image in a constant time.\r\n            It makes possible to do a fast blurring or fast block correlation with variable window size etc. In case of multi-channel images sums for each channel are accumulated independently. \r\n            ":"\r\n            计算源图像的一个或多个积分图像\r\n            使用这些积分图像，可以在恒定时间内计算图像的任意直立或旋转矩形区域的总和、均值、标准差。\r\n            它可以通过可变窗口大小等进行快速模糊或快速块相关。在多通道图像的情况下，每个通道的总和是独立累积的。\r\n            \r\n","The coordinate":"坐标\r\n","\r\n            GRAY\r\n            ":"\r\n            灰色的\r\n            \r\n","\r\n            Fatal (critical) error (unrecoverable internal error)\r\n            ":"\r\n            致命（严重）错误（不可恢复的内部错误）\r\n            \r\n","\r\n            Release all unmanaged resources associated with this exposure compensator \r\n            ":"\r\n            释放与此曝光补偿器关联的所有非托管资源\r\n            \r\n","Name of file to be loaded.":"要加载的文件的名称。\r\n","\r\n            OpenNI depth generator\r\n            ":"\r\n            OpenNI 深度生成器\r\n            \r\n","\r\n            Create a video writer using the specific information.\r\n            On windows, it will open a codec selection dialog.\r\n            On linux, it will use the default codec for the specified filename\r\n            ":"\r\n            使用特定信息创建视频编写器。\r\n            在 Windows 上，它将打开编解码器选择对话框。\r\n            在 linux 上，它将使用指定文件名的默认编解码器\r\n            \r\n","Optional output vertex double pointer the input point coincides with":"输入点重合的可选输出顶点双指针\r\n","Histogram with evenly distributed bins. A GpuMat<int> type.":"具有均匀分布的 bin 的直方图。 GpuMat<int> 类型。\r\n","\r\n            Use to download files (e.g. models) from the internet\r\n            ":"\r\n            用于从 Internet 下载文件（例如模型）\r\n            \r\n","maximum per-channel value for any individual pixel; eg 255 for uint8 image":"任何单个像素的最大每通道值；例如 255 用于 uint8 图像\r\n","\r\n            Niblack threshold\r\n            ":"\r\n            黑阈值\r\n            \r\n","Type of filter coefficients. It can be CV_32F or CV_64F .":"滤波器系数的类型。它可以是 CV_32F 或 CV_64F 。\r\n","The second point to be added":"第二点补充\r\n","\r\n            Convert YUV (YV12) to BGR\r\n            ":"\r\n            将 YUV (YV12) 转换成 BGR\r\n            \r\n","\r\n            window size for the corner refinement process (in pixels) (default 5).\r\n            ":"\r\n            角优化过程的窗口大小（以像素为单位）（默认为 5）。\r\n            \r\n","The flipped GMat.":"翻转的GMat。\r\n","\r\n            Polyline\r\n            ":"\r\n            折线\r\n            \r\n","\r\n            Convert the standard vector to an array of RotatedRect\r\n            ":"\r\n            将标准向量转换为 RotatedRect 数组\r\n            \r\n"," image and the parameter image":" 图像和参数图像\r\n","\r\n            Create a simple blob detector\r\n            ":"\r\n            创建一个简单的斑点检测器\r\n            \r\n","If true, will call the release function on the ":"如果为真，将调用 release 函数\r\n","\r\n            Warper that maps an image onto the unit sphere located at the origin.\r\n            ":"\r\n            将图像映射到位于原点的单位球体上的变形器。\r\n            \r\n","\r\n            Reads a Mat from the node\r\n            ":"\r\n            从节点读取 Mat\r\n            \r\n","\r\n            Release all the unmanaged memory assocuated with this VideoWriter\r\n            ":"\r\n            释放与此 VideoWriter 关联的所有非托管内存\r\n            \r\n","\r\n            Resizes the image src down to or up to the specified size\r\n            ":"\r\n            将图像 src 缩小或放大到指定大小\r\n            \r\n","The size of the data in number of bytes":"以字节数表示的数据大小\r\n","\r\n            octave\r\n            ":"\r\n            八度\r\n            \r\n","The point multiplied by the scale":"点乘以刻度\r\n","The number of raws for the convolution kernel":"卷积核的原始数\r\n","\r\n            Creates a Stitcher configured in one of the stitching modes.\r\n            ":"\r\n            创建以其中一种拼接模式配置的拼接器。\r\n            \r\n","The number of solutions":"解数\r\n","\r\n            This class contains ocl device information\r\n            ":"\r\n            此类包含 ocl 设备信息\r\n            \r\n","\r\n            Grayscale polynomial fitting; Need assign a value to deg and dst_whites simultaneously\r\n            ":"\r\n            灰度多项式拟合；需要同时给deg和dst_whites赋值\r\n            \r\n","\r\n            Get a copy of the first element in the storage. If the storage is empty, a default value will be returned\r\n            ":"\r\n            获取存储中第一个元素的副本。如果存储为空，将返回默认值\r\n            \r\n","Specifies maximum number of iterations and/or accuracy (distance the centers move by between the subsequent iterations). Use empty termcrit for default.":"指定最大迭代次数和/或精度（中心在后续迭代之间移动的距离）。默认使用空 termcrit。\r\n","The rectification transformation in object space (3x3 matrix). R1 or R2, computed by cvStereoRectify can be passed here. If the parameter is IntPtr.Zero, the identity matrix is used.":"对象空间（3x3 矩阵）中的整流变换。由 cvStereoRectify 计算的 R1 或 R2 可以传递到这里。如果参数是 IntPtr.Zero，则使用单位矩阵。\r\n","\r\n            Based on all images, graph segmentations and stragies, computes all possible rects and return them.\r\n            ":"\r\n            基于所有图像、图形分割和策略，计算所有可能的矩形并返回它们。\r\n            \r\n","\r\n            Implements CAMSHIFT object tracking algorithm ([Bradski98]). First, it finds an object center using cvMeanShift and, after that, calculates the object size and orientation. \r\n            ":"\r\n            实现 CAMSHIFT 对象跟踪算法 ([Bradski98])。首先，它使用 cvMeanShift 找到一个对象中心，然后计算对象大小和方向。\r\n            \r\n","The border mode, use BORDER_TYPE.CONSTANT for default.":"边框模式，默认使用BORDER_TYPE.CONSTANT。\r\n"," If disposing equals false, the method has been called by the runtime from inside the finalizer and you should not reference other objects. Only unmanaged resources can be disposed. ":" 如果 disposing 等于 false，则运行时已从终结器内部调用该方法，您不应引用其他对象。只能释放非托管资源。\r\n","\r\n            Convert the standard vector to an array of ColorPoint\r\n            ":"\r\n            将标准向量转换为 ColorPoint 数组\r\n            \r\n","\r\n            Check if the GPU module is targeted for the specific PTX version\r\n            ":"\r\n            检查 GPU 模块是否针对特定的 PTX 版本\r\n            \r\n","Kaiser window parameter that affects the sidelobe attenuation of the transform of the window. Kaiser window is used in order to reduce border effects. To prevent usage of the window, set beta to zero.":"影响窗口变换的旁瓣衰减的 Kaiser 窗口参数。使用 Kaiser 窗口是为了减少边界效应。要防止使用窗口，请将 beta 设置为零。\r\n","The center of the kernel. User (-1, -1) for the default kernel center.":"内核的中心。默认内核中心的用户 (-1, -1)。\r\n","\r\n            Create an standard vector of DMatch with the initial values\r\n            ":"\r\n            使用初始值创建 DMatch 的标准向量\r\n            \r\n","\r\n            Inpaint algorithm\r\n            ":"\r\n            修复算法\r\n            \r\n","The value which subtract this image":"减去这个图像的值\r\n","\r\n            Get the program binary\r\n            ":"\r\n            获取程序二进制文件\r\n            \r\n","\r\n            An OpenCL Queue\r\n            ":"\r\n            一个 OpenCL 队列\r\n            \r\n","Type of the orthogonal transform used in collaborative filtering step. Currently only Haar transform is supported.":"协同过滤步骤中使用的正交变换类型。目前仅支持 Haar 变换。\r\n","\r\n            Filter Structure Content Error\r\n            ":"\r\n            过滤器结构内容错误\r\n            \r\n","\r\n            Automatic exposure/gain ROI Width\r\n            ":"\r\n            自动曝光/增益 ROI 宽度\r\n            \r\n","The second GpuMat":"第二个GpuMat\r\n","Mask, 8-bit single channel GpuMat; specifies elements of destination GpuMat to be changed. Use IntPtr.Zero if not needed.":"Mask，8位单通道GpuMat；指定要更改的目标 GpuMat 的元素。如果不需要，请使用 IntPtr.Zero。\r\n","Flag indicating that the image should alias the src UMat. If true, changes to the image or src will be reflected in both objects.":"标志指示图像应该别名 src UMat。如果为 true，则对图像或 src 的更改将反映在两个对象中。\r\n","The value to assign to the diagonal elements.":"分配给对角线元素的值。\r\n","An array which contains result for each channel":"包含每个通道结果的数组\r\n","\r\n            Extracts optimal contour for the given target point on the image\r\n            ":"\r\n            提取图像上给定目标点的最佳轮廓\r\n            \r\n","Template image. The size is not greater than the image size. The type is the same as image .":"模板图像。大小不大于图像大小。类型与 image 相同。\r\n","\r\n            Pointer to the native DisparityFilter\r\n            ":"\r\n            指向本机 DisparityFilter 的指针\r\n            \r\n","\r\n            Create a stereo disparity solver using StereoSGBM algorithm (combination of H. Hirschmuller + K. Konolige approaches) \r\n            ":"\r\n            使用 StereoSGBM 算法（H. Hirschmuller + K. Konolige 方法的组合）创建立体视差求解器\r\n            \r\n","\r\n            48 dimension float\r\n            ":"48维浮点数\r\n            \r\n","Number of color vectors used to model normal background color variation at a given pixel. ":"用于对给定像素处的正常背景颜色变化进行建模的颜色向量的数量。\r\n","The other MCvScalar to compare with":"要与之比较的另一个 MCvScalar\r\n","\r\n            An Chi based cost extraction.\r\n            ":"\r\n            安智基成本提取。\r\n            \r\n","Optional array to returns the indexes of the recovered candidates in the original rejectedCorners array.":"可选数组，用于返回原始 rejectedCorners 数组中已恢复候选人的索引。\r\n","\r\n            Returns true if the node is a text string\r\n            ":"\r\n            如果节点是文本字符串，则返回 true\r\n            \r\n","The number of levels. Use 4 as default":"级别数。默认使用 4\r\n","\r\n            Release the unmanaged memory associated with this MergeMertens object\r\n            ":"\r\n            释放与此 MergeMertens 对象关联的非托管内存\r\n            \r\n","The returned maximum value":"返回的最大值\r\n","\r\n            Get the gradient image\r\n            ":"\r\n            获取渐变图像\r\n            \r\n","Number of samples to maintain at each point of the frame.":"在帧的每个点保持的样本数。\r\n","The capture object to be stabilized. Should not be a camera stream.":"要稳定的捕获对象。不应该是相机流。\r\n","\r\n            Sensor output data bit depth.\r\n            ":"\r\n            传感器输出数据位深度。\r\n            \r\n","Input samples stored by rows. It is a single-precision floating-point matrix of <number_of_samples> * k size.":"按行存储的输入样本。它是 <number_of_samples> * k 大小的单精度浮点矩阵。\r\n","Specify the source hdf5 dataset label.":"指定源 hdf5 数据集标签。\r\n","List of identifiers for each corner in charucoCorners per frame":"每帧 charucoCorners 中每个角的标识符列表\r\n","The output array to put the frame to":"放置框架的输出数组\r\n","\r\n            A Fast Self-tuning Background Subtraction Algorithm.\r\n            ":"\r\n            一种快速自调整背景减法算法。\r\n            \r\n","\r\n            Multiply the point with a scale\r\n            ":"\r\n            将点与比例相乘\r\n            \r\n","The column range. Use MCvSlice.WholeSeq for all columns.":"列范围。对所有列使用 MCvSlice.WholeSeq。\r\n","order of the derivative y.":"导数 y 的阶数。\r\n","Value that defines which thinning algorithm should be used.":"定义应使用哪种细化算法的值。\r\n","Isotropic scale factor.":"各向同性比例因子。\r\n","Reference of the pointer to the array":"数组指针的引用\r\n","\r\n            Creates a CSRT tracker\r\n            ":"\r\n            创建一个 CSRT 跟踪器\r\n            \r\n","\r\n            The function implements simple dct-based denoising, link: http://www.ipol.im/pub/art/2011/ys-dct/.\r\n            ":"\r\n            该函数实现了简单的基于dct的去噪，链接：http://www.ipol.im/pub/art/2011/ys-dct/。\r\n            \r\n","\r\n            Color similarity threshold used by cross-based segmentation. Only used  if supportRegionType is Cross. With the cross-bassed segmentation motion boundaries can be computed more accurately\r\n            ":"\r\n            基于交叉的分割使用的颜色相似度阈值。仅在 supportRegionType 为 Cross 时使用。使用交叉低音分割运动边界可以更准确地计算\r\n            \r\n","\r\n            Calculates per-element bit-wise logical conjunction of two arrays:\r\n            dst(I)=src1(I) & src2(I) if mask(I)!=0\r\n            In the case of floating-point arrays their bit representations are used for the operation. All the arrays must have the same type, except the mask, and the same size\r\n            ":"\r\n            计算两个数组的每个元素的按位逻辑合取：\r\n            dst(I)=src1(I) & src2(I) 如果掩码(I)!=0\r\n            在浮点数组的情况下，它们的位表示用于操作。除掩码外，所有数组必须具有相同的类型和相同的大小\r\n            \r\n","\r\n            Convert radian to degree\r\n            ":"\r\n            将弧度转换为度数\r\n            \r\n","\r\n            Performs Frequency Selective Reconstruction (FSR). Faster inpainting. \r\n            ":"\r\n            执行频率选择性重建 (FSR)。更快的修复。\r\n            \r\n","\r\n            Compute the shape distance between two shapes defined by its contours.\r\n            ":"\r\n            计算由轮廓定义的两个形状之间的形状距离。\r\n            \r\n","\r\n            horizontal\r\n            ":"\r\n            水平的\r\n            \r\n","\r\n            The datapath must be the name of the parent directory of tessdata and\r\n            must end in / . Any name after the last / will be stripped.\r\n            ":"\r\n            数据路径必须是 tessdata 的父目录的名称和\r\n            必须以 / 结尾。最后一个 / 之后的任何名称都将被删除。\r\n            \r\n","\r\n            Erodes ":"\r\n            侵蚀\r\n","A string that represent this oclPlatformInfo object":"表示此 oclPlatformInfo 对象的字符串\r\n","Amount of gradient orientations range division quantity.":"梯度方向量程的划分量。\r\n","\r\n            Check if label exists or not.\r\n            ":"\r\n            检查标签是否存在。\r\n            \r\n","\r\n            Get the resolution of this map as a 2D point\r\n            ":"\r\n            获取此地图的分辨率作为 2D 点\r\n            \r\n","The second threshold.":"第二个门槛。\r\n","The upper level":"上层\r\n","\r\n            Query descriptor index\r\n            ":"\r\n            查询描述符索引\r\n            \r\n","Max median length of displacement difference":"最大位移差中值长度\r\n","\r\n            Finds a triangle of minimum area enclosing a 2D point set and returns its area.\r\n            ":"\r\n            查找包围二维点集的最小面积三角形并返回其面积。\r\n            \r\n","The map between the images":"图像之间的映射\r\n","True if chessboard corners found":"如果找到棋盘角则为真\r\n","radius of Guided Filter.":"引导滤波器的半径。\r\n","\r\n            Convert RGB color to RGBA color\r\n            ":"\r\n            将 RGB 颜色转换为 RGBA 颜色\r\n            \r\n","\r\n            Warper that maps an image onto the x\\*x + z\\*z = 1 cylinder.\r\n            ":"\r\n            将图像映射到 x\\*x + z\\*z = 1 圆柱体上的变形器。\r\n            \r\n","\r\n            width of the margin of pixels on each cell not considered for the determination of the cell bit. Represents the rate respect to the total size of the cell, i.e. perpectiveRemovePixelPerCell (default 0.13)\r\n            ":"\r\n            在确定单元位时不考虑每个单元上像素边距的宽度。表示相对于单元格总大小的速率，即 perpectiveRemovePixelPerCell（默认 0.13）\r\n            \r\n","The model keypoints":"模型关键点\r\n","\r\n            Rgbd method\r\n            ":"\r\n            RGBD方法\r\n            \r\n","Array of pointers to a single polygon":"指向单个多边形的指针数组\r\n","\r\n            DKK color chart with 12 squares and 6 rectangle\r\n            ":"\r\n            12 个正方形和 6 个长方形的 DKK 色卡\r\n            \r\n","\r\n            Create an implementation of the camera parameters refinement algorithm which minimizes sum of the reprojection\r\n            error squares.\r\n            ":"\r\n            创建最小化重投影总和的相机参数细化算法的实现\r\n            误差方块。\r\n            \r\n","The second source array. ":"第二个源数组。\r\n","True if the kernel can be created":"如果可以创建内核则为真\r\n"," The y value for this color ":" 此颜色的 y 值\r\n","The second source image":"第二张源图\r\n","\r\n            Empty structure (sequence or mapping)\r\n            ":"\r\n            空结构（序列或映射）\r\n            \r\n","The average color of the masked area":"遮罩区域的平均颜色\r\n","\r\n             Finds the edges on the input ":"\r\n             查找输入的边缘\r\n","Corners found by findChessboardCorners(SB)":"findChessboardCorners(SB) 找到的角点\r\n","Maximal upper brightness/color difference\r\n            between the currently observed pixel and one of its neighbor belong to the component\r\n            or seed pixel to add the pixel to component.\r\n            In case of 8-bit color images it is packed value.":"最大上亮度/色差\r\n            当前观察到的像素与其相邻像素之一之间属于该组件\r\n            或种子像素以将像素添加到组件。\r\n            对于 8 位彩色图像，它是打包值。\r\n","\r\n            Set the features matcher for this stitcher\r\n            ":"\r\n            为此缝合器设置特征匹配器\r\n            \r\n","spatial and central moments up to the third order":"高达三阶的空间矩和中心矩\r\n","\r\n            Types of Adaptive Threshold\r\n            ":"\r\n            自适应阈值的类型\r\n            \r\n","pageNumber is 0-based but will appear in the output as 1-based.":"pageNumber 从 0 开始，但在输出中将显示为从 1 开始。\r\n","Net object. Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine backend.":"净对象。从英特尔模型优化器导入的网络在英特尔推理引擎后端启动。\r\n"," Compute the element of the new image based on the elements of the four image":" 根据四个图像的元素计算新图像的元素\r\n","The per-element bit-wise logical \"exclusive or\" of a matrix and a scalar.":"矩阵和标量的每个元素按位逻辑“异或”。\r\n","Current time in milliseconds or other units, it is better to store time passed to cvUpdateMotionHistory before and reuse it here, because running cvUpdateMotionHistory and cvCalcMotionGradient on large images may take some time.":"当前时间以毫秒或其他单位为单位，最好存储之前传递给 cvUpdateMotionHistory 的时间并在此处重用，因为在大图像上运行 cvUpdateMotionHistory 和 cvCalcMotionGradient 可能需要一些时间。\r\n","\r\n            Create a sparse matrix\r\n            ":"\r\n            创建稀疏矩阵\r\n            \r\n","\r\n            Return the particular array element\r\n            ":"\r\n            返回特定的数组元素\r\n            \r\n","\r\n            Create an standard vector of UMat with the initial values\r\n            ":"\r\n            使用初始值创建 UMat 的标准向量\r\n            \r\n","\r\n            The minimum object size\r\n            ":"\r\n            最小物体尺寸\r\n            \r\n","\r\n            Saturation enhancement value.\r\n            ":"\r\n            饱和度增强值。\r\n            \r\n","\r\n            Gets the binary data from the specific indices.\r\n            ":"\r\n            从特定索引获取二进制数据。\r\n            \r\n","vector of distortion coefficients (k1,k2,p1,p2[,k3[,k4,k5,k6],[s1,s2,s3,s4]]) of 4, 5, 8 or 12 elements":"4、5、8 或 12 个元素的失真系数向量 (k1,k2,p1,p2[,k3[,k4,k5,k6],[s1,s2,s3,s4]])\r\n","\r\n            Default corners\r\n            ":"\r\n            默认角\r\n            \r\n","Scalar value to subtract from":"要减去的标量值\r\n","Type of the score to use.":"要使用的分数类型。\r\n","\r\n            Canny edge detector using Cuda.\r\n            ":"\r\n            使用 Cuda 的 Canny 边缘检测器。\r\n            \r\n","Lookup table for the B channel":"B通道的查找表\r\n","\r\n            Create a new affine transformation based estimator.\r\n            ":"\r\n            创建一个新的基于仿射变换的估计器。\r\n            \r\n","\r\n            The global memory size\r\n            ":"\r\n            全局内存大小\r\n            \r\n","\r\n            The name of the backend used by this VideoWriter\r\n            ":"\r\n            此 VideoWriter 使用的后端名称\r\n            \r\n","The 2d reprojection difference":"二维重投影差异\r\n","Image to store the Harris detector responces. Should have the same size as image ":"用于存储 Harris 检测器响应的图像。应与图像大小相同\r\n","The Json configuration string":"Json配置字符串\r\n","\r\n            Get the original window size\r\n            ":"\r\n            获取原始窗口大小\r\n            \r\n","wrap around the kernel values":"环绕内核值\r\n","\r\n            Inverses every bit of every array element:\r\n            ":"\r\n            反转每个数组元素的每一位：\r\n            \r\n","The coordinate to be subtracted":"要减去的坐标\r\n","Destination CudaImage, containing position of mapped points. Will have the same size as src and CV 16SC2 type.":"目标 CudaImage，包含映射点的位置。将具有与 src 和 CV 16SC2 类型相同的大小。\r\n","The area this map covers.":"此地图涵盖的区域。\r\n","\r\n            Create a neural network using the specific parameters\r\n            ":"\r\n            使用特定参数创建神经网络\r\n            \r\n","The type of arguments":"参数类型\r\n","determinant of the square matrix mat":"方阵矩阵的行列式\r\n","\r\n            Create an standard vector of Point3D32F of the specific size\r\n            ":"\r\n            创建特定大小的 Point3D32F 标准向量\r\n            \r\n","  \r\n            connected component  \r\n            ":"  \r\n            连通分量\r\n            \r\n","\r\n            Laplacian filter\r\n            ":"\r\n            拉普拉斯滤波器\r\n            \r\n","Number of markers in each frame so that corners and ids can be split":"每帧中的标记数量，以便可以拆分角和 ID\r\n","Specifies output image depth.":"指定输出图像深度。\r\n","\r\n            The host data packet\r\n            ":"\r\n            主机数据包\r\n            \r\n","Descriptors normalization type.":"描述符规范化类型。\r\n","\r\n            The CCM with the shape 3×3 performs linear transformation on color values.\r\n            ":"\r\n            形状为 3×3 的 CCM 对颜色值进行线性变换。\r\n            \r\n","The increment of the k parameter for all graph segmentations":"所有图分割的 k 参数的增量\r\n","The color palette to transform":"要转换的调色板\r\n","\r\n            Finds circles in a grayscale image using the Hough transform\r\n            ":"\r\n            使用 Hough 变换在灰度图像中查找圆\r\n            \r\n","vector of input images":"输入图像的向量\r\n","Image width.":"图像宽度。\r\n","\r\n            The index parameters interface\r\n            ":"\r\n            指标参数接口\r\n            \r\n","\r\n            Creates PCTSignatures algorithm using pre-generated sampling points and clusterization seeds indexes.\r\n            ":"\r\n            使用预先生成的采样点和聚类种子索引创建 PCTSignatures 算法。\r\n            \r\n","The descriptors from the keypoints":"来自关键点的描述符\r\n","\r\n            Calculates the per-element difference between matrix and given scalar.\r\n            ":"\r\n            计算矩阵和给定标量之间的每个元素差异。\r\n            \r\n","Thickness of the lines used to draw a text.":"用于绘制文本的线条粗细。\r\n","Convolution kernel, single-channel floating point matrix (e.g. Emgu.CV.Matrix). If you want to apply different kernels to different channels, split the gpu image into separate color planes and process them individually":"卷积核，单通道浮点矩阵（例如 Emgu.CV.Matrix）。如果要将不同的内核应用于不同的通道，请将 gpu 图像拆分为单独的颜色平面并单独处理\r\n","\r\n            The equivalent MCvScalar value\r\n            ":"\r\n            等效的 MCvScalar 值\r\n            \r\n","\r\n            This type is very similar to InputArray except that it is used for output function parameters. \r\n            ":"\r\n            此类型与 InputArray 非常相似，只是它用于输出函数参数。\r\n            \r\n","\r\n            The size of the elements in this matrix\r\n            ":"\r\n            此矩阵中元素的大小\r\n            \r\n","\r\n            Train descriptor index\r\n            ":"\r\n            列车描述符索引\r\n            \r\n","Output vector that contains indices of inliers in objectPoints and imagePoints .":"包含 objectPoints 和 imagePoints 中的内点索引的输出向量。\r\n","\r\n            chromatic adaptation in [0, 1] range. If 1 channels are treated independently, if 0 adaptation level is the same for each channel.\r\n            ":"\r\n            [0, 1] 范围内的色适应。如果 1 通道被独立处理，如果 0 自适应级别对于每个通道都是相同的。\r\n            \r\n","\r\n            Gets or sets the page seg mode.\r\n            ":"\r\n            获取或设置页段模式。\r\n            \r\n","\r\n            Return true if all files has been downloaded and are valid.\r\n            ":"\r\n            如果所有文件都已下载并且有效，则返回 true。\r\n            \r\n","Detector response threshold to accept point":"检测器响应阈值接受点\r\n","A new mat header that has different shape":"具有不同形状的新垫头\r\n","\r\n            Push multiple values into the standard vector\r\n            ":"\r\n            将多个值推入标准向量\r\n            \r\n","An identity matrix of the specified size and type.":"指定大小和类型的单位矩阵。\r\n","\r\n            Flags for sorting\r\n            ":"\r\n            排序标志\r\n            \r\n","Scale factor for scaled extraction.":"比例提取的比例因子。\r\n","\r\n            Indicates that Mean minus C should be used for adaptive threshold.\r\n            ":"\r\n            指示应将平均值减去 C 用于自适应阈值。\r\n            \r\n","orientation map.":"方向图。\r\n","\r\n            Dictionary/Set of markers. It contains the inner codification.\r\n            ":"\r\n            词典/标记集。它包含内部编码。\r\n            \r\n","\r\n            Get the vertical linesegment of this cross\r\n            ":"\r\n            得到这个十字的垂直线段\r\n            \r\n","\r\n            Train WaldBoost detector.\r\n            ":"\r\n            训练 WaldBoost 检测器。\r\n            \r\n","The optional mask, can be null if not needed":"可选掩码，如果不需要可以为 null\r\n","\r\n            Euclidean\r\n            ":"\r\n            欧几里得\r\n            \r\n","Border mode used to extrapolate pixels outside of the image.":"用于推断图像外部像素的边界模式。\r\n","\r\n            Sets the channel of interest to a given value. Value 0 means that all channels are selected, 1 means that the first channel is selected etc. If ROI is NULL and coi != 0, ROI is allocated.\r\n            ":"\r\n            将感兴趣的频道设置为给定值。值 0 表示选择所有通道，1 表示选择第一个通道等。如果 ROI 为 NULL 且 coi != 0，则分配 ROI。\r\n            \r\n"," \r\n            Defines a Rgb (Red Green Blue) color\r\n            ":" \r\n            定义 Rgb（红绿蓝）颜色\r\n            \r\n","optional number of iterations used for filtering, 3 is quite enough.":"用于过滤的可选迭代次数，3 就足够了。\r\n","\r\n            Calculates integral images for the source image\r\n            ":"\r\n            计算源图像的积分图像\r\n            \r\n","\r\n            Properties of cameras available through OpenNI interfaces, in pixels.\r\n            ":"\r\n            通过 OpenNI 接口可用的相机属性，以像素为单位。\r\n            \r\n","The map":"地图\r\n","\r\n            (median blur) - finding median of param1 x param1 neighborhood (i.e. the neighborhood is square). \r\n            ":"\r\n            （中值模糊）- 找到 param1 x param1 邻域的中值（即邻域是正方形）。\r\n            \r\n","The name of the file that contains the CascadeClassifier":"包含 CascadeClassifier 的文件的名称\r\n","\r\n            Get the vertices of this triangle\r\n            ":"\r\n            获取这个三角形的顶点\r\n            \r\n","\r\n            Interface for realizations of Domain Transform filter.\r\n            ":"\r\n            Domain Transform 过滤器实现的接口。\r\n            \r\n","\r\n            Hint buffer grid size is 4x4.\r\n            ":"\r\n            提示缓冲区网格大小为 4x4。\r\n            \r\n","\r\n            The function emulates the human \"foveal\" vision and can be used for fast scale and rotation-invariant template matching, for object tracking etc.\r\n            ":"\r\n            该函数模拟人类“中央凹”视觉，可用于快速缩放和旋转不变模板匹配、对象跟踪等。\r\n            \r\n","\r\n            This 3D Widget defines a point cloud.\r\n            ":"\r\n            这个 3D Widget 定义了一个点云。\r\n            \r\n","\r\n            Return true if the two color equals\r\n            ":"\r\n            如果两种颜色相等则返回真\r\n            \r\n","\r\n            Class implementing the MSD (Maximal Self-Dissimilarity) keypoint detector, described in \"Federico Tombari and Luigi Di Stefano. Interest points via maximal self-dissimilarities. In Asian Conference on Computer Vision - ACCV 2014, 2014\".\r\n            ":"\r\n            实现 MSD（最大自相异性）关键点检测器的类，在“Federico Tombari 和 Luigi Di Stefano。兴趣点通过最大自相异性。在亚洲计算机视觉会议 - ACCV 2014，2014”中描述。\r\n            \r\n","\r\n            Right to left\r\n            ":"\r\n            右到左\r\n            \r\n","The sobel filtered image":"索贝尔滤波图像\r\n","\r\n            Type for cvSVD\r\n            ":"\r\n            cvSVD 类型\r\n            \r\n","\r\n            Max candidates\r\n            ":"\r\n            最大候选人\r\n            \r\n","\r\n             Calculates the average value M of array elements, independently for each channel:\r\n            N = sumI mask(I)!=0\r\n            Mc = 1/N * sumI,mask(I)!=0 arr(I)c\r\n            If the array is IplImage and COI is set, the function processes the selected channel only and stores the average to the first scalar component (S0).\r\n             ":"\r\n             计算数组元素的平均值 M，独立于每个通道：\r\n            N = sumI mask(I)!=0\r\n            Mc = 1/N * sumI,mask(I)!=0 arr(I)c\r\n            如果数组为 IplImage 且设置了 COI，则该函数仅处理选定的通道并将平均值存储到第一个标量分量 (S0)。\r\n             \r\n","\r\n            Make a copy of this matrix\r\n            ":"\r\n            复制这个矩阵\r\n            \r\n","\r\n            Calculates the image derivative by convolving the image with the appropriate kernel\r\n            The Sobel operators combine Gaussian smoothing and differentiation so the result is more or less robust to the noise. Most often, the function is called with (xorder=1, yorder=0, aperture_size=3) or (xorder=0, yorder=1, aperture_size=3) to calculate first x- or y- image derivative.\r\n            ":"\r\n            通过将图像与适当的内核进行卷积来计算图像导数\r\n            Sobel 算子结合了高斯平滑和微分，因此结果或多或少对噪声具有鲁棒性。大多数情况下，调用函数时使用 (xorder=1, yorder=0, aperture_size=3) 或 (xorder=0, yorder=1, aperture_size=3) 来计算第一个 x- 或 y- 图像导数。\r\n            \r\n","column coordinates in the line bundle":"线束中的列坐标\r\n","\r\n            Open the file for appending\r\n            ":"\r\n            打开要追加的文件\r\n            \r\n","\r\n            Performs a per-element multiplication of two Fourier spectrums and scales the result.\r\n            ":"\r\n            执行两个傅里叶谱的每个元素乘法并缩放结果。\r\n            \r\n","identifier of the marker that will be returned. It has to be a valid id in the specified dictionary.":"将返回的标记的标识符。它必须是指定字典中的有效 ID。\r\n","\r\n            This 3D Widget defines an arrow.\r\n            ":"这个 3D Widget 定义了一个箭头。\r\n            \r\n","\r\n            Rotate 90 degrees clockwise\r\n            ":"\r\n            顺时针旋转90度\r\n            \r\n","The maximum speckle size to consider it a speckle. Larger blobs are not affected by the algorithm":"将其视为散斑的最大散斑大小。较大的斑点不受算法影响\r\n","True id update success":"真实id更新成功\r\n","\r\n            Library to invoke functions that belongs to the shape module\r\n            ":"\r\n            用于调用属于形状模块的函数的库\r\n            \r\n","The background foreground mask where 2 indicates background and 3 indicates foreground":"背景前景蒙版，其中2表示背景，3表示前景\r\n","\r\n            The function allocates a multi-dimensional sparse array. Initially the array contain no elements, that is Get or GetReal returns zero for every index\r\n            ":"\r\n            该函数分配一个多维稀疏数组。最初数组不包含任何元素，即 Get 或 GetReal 为每个索引返回零\r\n            \r\n","Pointer to returned maximum location":"指向返回的最大位置的指针\r\n","\r\n            Flag to specify whether the gamma correction preprocessing is required or not\r\n            ":"\r\n            用于指定是否需要伽玛校正预处理的标志\r\n            \r\n","Image in color space BGR":"色彩空间 BGR 中的图像\r\n","\r\n            Int16\r\n            ":"\r\n            整数16\r\n            \r\n","\r\n            Colors a disparity image.\r\n            ":"\r\n            为视差图像着色。\r\n            \r\n","\r\n            Binary threshold\r\n            ":"\r\n            二进制阈值\r\n            \r\n","\r\n            Get the specific row of the matrix\r\n            ":"\r\n            获取矩阵的特定行\r\n            \r\n","\r\n             value = value > threshold ? value : 0           \r\n            ":"\r\n             价值=价值>阈值？价值：0\r\n            \r\n","\r\n            Release the unmanaged memory associated with this WArrow object\r\n            ":"\r\n            释放与此 WArrow 对象关联的非托管内存\r\n            \r\n","Input 8-bit 1 or 3-channel image.":"输入 8 位 1 或 3 通道图像。\r\n","\r\n            Entry points for the cv::rgb functions\r\n            ":"\r\n            cv::rgb 函数的入口点\r\n            \r\n","\r\n            Resizes an image.\r\n            ":"\r\n            调整图像大小。\r\n            \r\n","Optional scale factor for the computed derivative values; by default, no scaling is applied ":"计算导数值的可选比例因子；默认情况下，不应用缩放\r\n","\r\n            Converts an image from BayerGR color space to RGB. The function converts an input image from BayerGR color space to RGB. The conventional ranges for G, R, and B channel values are 0 to 255.\r\n            ":"将图像从 BayerGR 颜色空间转换为 RGB。该函数将输入图像从 BayerGR 颜色空间转换为 RGB。 G、R 和 B 通道值的常规范围是 0 到 255。\r\n            \r\n","output image":"输出图像\r\n","\r\n            Calculates the absolute L1 norm of a matrix.\r\n            ":"\r\n            计算矩阵的绝对 L1 范数。\r\n            \r\n"," The result of elementwise subtracting color 'val' from the current image":" 当前图像按元素减去颜色'val'的结果\r\n","\r\n            Get the pointer to the widget2D object\r\n            ":"\r\n            获取指向 widget2D 对象的指针\r\n            \r\n","Extracted rectangle":"提取的矩形\r\n","\r\n            Treat the image as a single text line.\r\n            ":"\r\n            将图像视为单个文本行。\r\n            \r\n","\r\n            Get the string representation of this oclDevice\r\n            ":"\r\n            获取此 oclDevice 的字符串表示形式\r\n            \r\n"," The Cb value for this color ":" 此颜色的 Cb 值\r\n","The vector of initial covariance matrices of mixture components. Each of covariance matrices is a one-channel matrix of dims x dims size. If the matrices do not have CV_64F type they will be converted to the inner matrices of such type for the further computing.":"混合分量的初始协方差矩阵的向量。每个协方差矩阵都是 dims x dims 大小的单通道矩阵。如果矩阵没有 CV_64F 类型，它们将被转换为这种类型的内部矩阵以供进一步计算。\r\n","\r\n            Base class for convolution (or cross-correlation) operator.\r\n            ":"\r\n            卷积（或互相关）运算符的基类。\r\n            \r\n","The other mat to compare with":"另一个要比较的垫子\r\n","\r\n            An EMD based cost extraction.\r\n            ":"\r\n            基于 EMD 的成本提取。\r\n            \r\n","Source matrix. 1-, 4-, 8-byte element sizes are supported for now.":"源矩阵。目前支持 1、4、8 字节的元素大小。\r\n","\r\n            First apply Canny Edge Detector on the current image,\r\n            then apply Hough transform to find circles\r\n            ":"\r\n            首先在当前图像上应用 Canny 边缘检测器，\r\n            然后应用霍夫变换来寻找圆圈\r\n            \r\n","Descriptor extractor that is used to compute descriptors for an input image and its key points.":"用于计算输入图像及其关键点的描述符的描述符提取器。\r\n","\r\n            Returns the next random number sampled from the Gaussian distribution.\r\n            ":"\r\n            返回从高斯分布中采样的下一个随机数。\r\n            \r\n","the new number of channles":"新的通道数\r\n","Aperture size used to compute the second-derivative filters.":"用于计算二阶导数滤波器的孔径大小。\r\n","\r\n            This is the proxy class for passing read-only input arrays into OpenCV functions.\r\n            ":"\r\n            这是将只读输入数组传递给 OpenCV 函数的代理类。\r\n            \r\n","This identifier is deprecated, use DISPARITY_16Q_11_4 instead.":"此标识符已弃用，请改用 DISPARITY_16Q_11_4。\r\n","The tile to be written":"要写入的磁贴\r\n","\r\n            Phase-shifting profilometry\r\n            ":"\r\n            相移轮廓测量法\r\n            \r\n"," if have open CL compatible gpu device; otherwise, ":" 如果有开放的 CL 兼容 gpu 设备；否则，\r\n","The number of channels in the dst map.":"dst 地图中的通道数。\r\n","The minimum value":"最小值\r\n","The interpolation index":"插值指数\r\n","\r\n            Flags for SetWindowProperty / GetWindowProperty\r\n            ":"\r\n            SetWindowProperty / GetWindowProperty 的标志\r\n            \r\n","Currently this parameter is ignored and only uniform sampling is applied. ":"目前此参数被忽略，仅应用均匀采样。\r\n","\r\n            Get the OpenCL platform summary as a string\r\n            ":"\r\n            获取字符串形式的 OpenCL 平台摘要\r\n            \r\n","\r\n            Right mesh file\r\n            ":"\r\n            正确的网格文件\r\n            \r\n","\r\n            Point is outside the subdivision reference rectangle\r\n            ":"\r\n            点在细分参考矩形外\r\n            \r\n","\r\n            Project the images to the histogram bins \r\n            ":"\r\n            将图像投影到直方图箱\r\n            \r\n","\r\n            An ORB detector using Cuda\r\n            ":"\r\n            使用 Cuda 的 ORB 检测器\r\n            \r\n","\r\n            Point set\r\n            ":"\r\n            点集\r\n            \r\n","The input 8-bit single-channel image":"输入的8位单通道图像\r\n","Second camera matrix.":"第二个相机矩阵。\r\n","Reading / writing properties involves many layers. Some unexpected result might happens\r\n            along this chain: \"VideoCapture -> API Backend -> Operating System -> Device Driver -> Device Hardware\"\r\n            The returned value might be different from what really used by the device or it could be encoded\r\n            using device dependent rules(eg.steps or percentage). Effective behaviour depends from device\r\n            driver and API Backend\r\n            ":"读/写属性涉及很多层。可能会发生一些意想不到的结果\r\n            沿着这条链：“VideoCapture -> API Backend -> Operating System -> Device Driver -> Device Hardware”\r\n            返回值可能与设备实际使用的值不同，或者可能被编码\r\n            使用设备相关规则（例如步数或百分比）。有效行为取决于设备\r\n            驱动程序和 API 后端\r\n            \r\n","\r\n            Number of output channels from sensor used for data transfer.\r\n            ":"\r\n            用于数据传输的传感器输出通道数。\r\n            \r\n","Destination image. Should have type of float":"目标图像。应该有浮动类型\r\n","\r\n            Enumeration used by cvCheckArr\r\n            ":"\r\n            cvCheckArr 使用的枚举\r\n            \r\n","The scalar":"标量\r\n","Grid Y":"网格 Y\r\n","LSC (Linear Spectral Clustering) produces compact and uniform superpixels with low computational costs. Basically, a normalized cuts formulation of the superpixel segmentation is adopted based on a similarity metric that measures the color similarity and space proximity between image pixels. LSC is of linear computational complexity and high memory efficiency and is able to preserve global properties of images":"LSC（线性光谱聚类）以低计算成本产生紧凑且均匀的超像素。基本上，基于测量图像像素之间的颜色相似性和空间接近度的相似性度量，采用了超像素分割的归一化切割公式。 LSC 具有线性计算复杂度和高存储效率，能够保留图像的全局属性\r\n","Anchor of the kernel that indicates the relative position of a filtered point within the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor is at the kernel center.":"内核的锚点，指示内核中过滤点的相对位置；锚点应该位于内核中；默认值 (-1,-1) 表示锚点位于内核中心。\r\n","\tThe list of rects. The first ones are more relevents than the lasts ones.":"矩形列表。第一个比最后一个更相关。\r\n","The primary use of the function is in multi-camera environments. The method fills the ready state vector, grabs video frame, if camera is ready.\r\n            After this call use VideoCapture::retrieve() to decode and fetch frame data.":"该功能的主要用途是在多相机环境中。如果相机准备就绪，该方法会填充就绪状态向量，抓取视频帧。\r\n            在此调用之后，使用 VideoCapture::retrieve() 解码和获取帧数据。\r\n","Trace back to cut off mser with diversity < min_diversity":"追溯切断 mser 与 diversity < min_diversity\r\n","\r\n            Outer Plexiform Layer (OPL) and Inner Plexiform Layer Parvocellular (IplParvo) parameters \r\n            ":"\r\n            外丛状层 (OPL) 和内丛状层细小细胞 (IplParvo) 参数\r\n            \r\n","\r\n            reject quads containing too few pixels.\r\n            ":"\r\n            拒绝包含太少像素的四边形。\r\n            \r\n","The line segments detected for each of the channels":"为每个通道检测到的线段\r\n","\r\n            White-balance color temperature\r\n            ":"\r\n            白平衡色温\r\n            \r\n","An array of TesseractResult":"TesseractResult 数组\r\n","The model file":"模型文件\r\n","\r\n            Convert Bayer GRBG to BGR (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 Bayer GRBG 转换为 BGR（边缘感知去马赛克）\r\n            \r\n","The destination image; it must be 8-bit color image":"目标图像；它必须是 8 位彩色图像\r\n","Noise strength (standard deviation of the brightness or each color channel). 0 means some automatic value.":"噪声强度（亮度或每个颜色通道的标准偏差）。 0 表示一些自动值。\r\n","\r\n            Get subsamples with the specific rate\r\n            ":"\r\n            获取具有特定速率的子样本\r\n            \r\n","\r\n            Calculates the weighted sum of two matrices\r\n            ":"\r\n            计算两个矩阵的加权和\r\n            \r\n","\r\n            The default morphology value.\r\n            ":"\r\n            默认形态值。\r\n            \r\n","\r\n            Gradient mapper for a projective transformation\r\n            ":"\r\n            用于投影变换的梯度映射器\r\n            \r\n","Number of iterations of algorithm, It should be positive integer":"算法迭代次数，应为正整数\r\n","Optional parameter to select the GPU ID on which the optical flow should be computed. Useful in multi-GPU systems. Defaults to 0.":"用于选择应在其上计算光流的 GPU ID 的可选参数。在多 GPU 系统中很有用。默认为 0。\r\n","input image (8UC1, 8UC3 or 8UC4, must be greater or equal than 3x3)":"输入图像（8UC1、8UC3 或 8UC4，必须大于或等于 3x3）\r\n","\r\n            The pointer to the Descriptor matcher\r\n            ":"\r\n            指向描述符匹配器的指针\r\n            \r\n","The area of the map":"地图面积\r\n","\r\n            Get the minimum and maximum value across all channels of the mat\r\n            ":"\r\n            获取垫子所有通道的最小值和最大值\r\n            \r\n","\r\n            Gets the type of the node.\r\n            ":"\r\n            获取节点的类型。\r\n            \r\n","\r\n            Class implementing the ED (EdgeDrawing)\r\n            ":"\r\n            实现 ED (EdgeDrawing) 的类\r\n            \r\n","The threshold used for edge Linking":"用于边缘链接的阈值\r\n","\r\n            Erode\r\n            ":"\r\n            侵蚀\r\n            \r\n","The output vector of convexity defects. Each convexity defect is represented as 4-element integer vector (a.k.a. cv::Vec4i): (start_index, end_index, farthest_pt_index, fixpt_depth), where indices are 0-based indices in the original contour of the convexity defect beginning, end and the farthest point, and fixpt_depth is fixed-point approximation (with 8 fractional bits) of the distance between the farthest contour point and the hull. That is, to get the floating-point value of the depth will be fixpt_depth/256.0. ":"凸缺陷的输出向量。每个凸性缺陷表示为 4 元素整数向量（又名 cv::Vec4i）：（start_index、end_index、farthest_pt_index、fixpt_depth），其中索引是凸性缺陷原始轮廓中从 0 开始、结束和最远的索引fixpt_depth 是最远轮廓点和船体之间距离的定点近似值（具有 8 个小数位）。也就是说，获取深度的浮点值将是 fixpt_depth/256.0。\r\n","flag, specifying whether the kernel is to be normalized by it's area or not.":"标志，指定内核是否按其面积归一化。\r\n","The number of inner corners per chessboard row and column":"棋盘每行和每列的内角数\r\n","Fundamental matrix. It can be computed using the same set of point pairs points1 and points2 using cvFindFundamentalMat":"基本矩阵。它可以使用同一组点对 points1 和 points2 使用 cvFindFundamentalMat 计算\r\n","\r\n            Create a generic parameter for the Operation class\r\n            ":"\r\n            为 Operation 类创建一个通用参数\r\n            \r\n","\r\n            Wrap\r\n            ":"\r\n            裹\r\n            \r\n","\r\n            Convert BGR to YUV_YV12\r\n            ":"\r\n            将 BGR 转换为 YUV_YV12\r\n            \r\n","\r\n            Retrieve all the contours and reconstructs the full hierarchy of nested contours \r\n            ":"\r\n            检索所有轮廓并重建嵌套轮廓的完整层次结构\r\n            \r\n","\r\n            finds intersection of two convex polygons\r\n            ":"\r\n            找到两个凸多边形的交集\r\n            \r\n","\r\n            Release the unmanaged memory associated with this circle detector.\r\n            ":"释放与此圆形检测器关联的非托管内存。\r\n            \r\n"," A circle ":" 一个圆圈\r\n","\r\n            The preferable target\r\n            ":"\r\n            优选目标\r\n            \r\n","Output buffer resized to fit the compressed image.":"调整输出缓冲区大小以适应压缩图像。\r\n","Factor to be multiplied":"要乘以的系数\r\n","\r\n            Convert Bayer GBRG to GRAY\r\n            ":"\r\n            将拜耳 GBRG 转换为 GRAY\r\n            \r\n","Resolution of the accumulator used to detect centers of the circles. For example, if it is 1, the accumulator will have the same resolution as the input image, if it is 2 - accumulator will have twice smaller width and height, etc":"用于检测圆心的累加器的分辨率。例如，如果它是 1，累加器将具有与输入图像相同的分辨率，如果它是 2 - 累加器将具有两倍小的宽度和高度，等等\r\n","\r\n            Creates TonemapReinhard object.\r\n            ":"\r\n            创建 TonemapReinhard 对象。\r\n            \r\n","The color depth of the source image":"源图像的颜色深度\r\n","The perspective transform matrix":"透视变换矩阵\r\n","\r\n            Probabilistic Hough transform (more efficient in case if picture contains a few long linear segments). It returns line segments rather than the whole lines. Every segment is represented by starting and ending points, and the matrix must be (the created sequence will be) of CV_32SC4 type\r\n            ":"\r\n            概率霍夫变换（如果图片包含一些长线性段则效率更高）。它返回线段而不是整条线。每段由起点和终点表示，矩阵必须是（创建的序列将是）CV_32SC4 类型\r\n            \r\n","The address of the pointer that point to the start of the Bytes taken into consideration ROI":"指向考虑 ROI 的字节开始的指针的地址\r\n","images to project":"要投影的图像\r\n","Optional depth of the output array":"输出数组的可选深度\r\n","The new number of rows":"新的行数\r\n","Spatial window radius.":"空间窗口半径。\r\n","Rotation matrix between the coordinate systems of the first and the second cameras.":"第一和第二相机坐标系之间的旋转矩阵。\r\n","Arrays of arrays of the Point":"Point 的数组数组\r\n","Input vector of 2D points ":"二维点的输入向量\r\n","\r\n            Convert YUV (YVYU) to RGB\r\n            ":"\r\n            将 YUV (YVYU) 转换为 RGB\r\n            \r\n","Gaussian kernel size. ksize.width and ksize.height can differ but they both must be positive and odd. Or, they can be zero's and then they are computed from sigma.":"高斯核大小。 ksize.width 和 ksize.height 可以不同，但​​它们都必须为正数且为奇数。或者，它们可以为零，然后根据 sigma 计算它们。\r\n","mask containing non-zero values for the elements to be retained":"包含要保留的元素的非零值的掩码\r\n","\r\n            Flag that synchronizes the remapping depth map to image map\r\n            by changing depth generator's view point (if the flag is \"on\") or\r\n            sets this view point to its normal one (if the flag is \"off\").\r\n            ":"\r\n            将重映射深度图同步到图像图的标志\r\n            通过改变深度生成器的视点（如果标志为“开”）或\r\n            将此视点设置为其正常视点（如果标志为“关闭”）。\r\n            \r\n","\r\n            Load the Mat from file\r\n            ":"\r\n            从文件加载 Mat\r\n            \r\n","Input vector(s); must have the same dimensionality and the same layout as the input data used at PCA phase":"输入向量；必须与 PCA 阶段使用的输入数据具有相同的维度和相同的布局\r\n","\r\n            The number of angular bins in the shape context descriptor.\r\n            ":"\r\n            形状上下文描述符中的角度箱数。\r\n            \r\n","\r\n            BoxMax filter\r\n            ":"\r\n            BoxMax过滤器\r\n            \r\n","\r\n            depth limit m\r\n            ":"\r\n            深度限制 m\r\n            \r\n"," Create a BGR color using the specific values":" 使用特定值创建 BGR 颜色\r\n","\r\n            Xor\r\n            ":"\r\n            异或\r\n            \r\n","\r\n            The second value\r\n            ":"\r\n            第二个值\r\n            \r\n","\r\n            Performs per-element multiplication of the two CCS-packed or complex matrices that are results of real or complex Fourier transform. \r\n            ":"\r\n            对作为实数或复数傅里叶变换结果的两个 CCS 压缩矩阵或复数矩阵执行逐元素乘法。\r\n            \r\n","\r\n            Create an OclImage2D object from UMat\r\n            ":"\r\n            从 UMat 创建一个 OclImage2D 对象\r\n            \r\n","\r\n            Create an standard vector of CvString of the specific size\r\n            ":"\r\n            创建特定大小的 CvString 标准向量\r\n            \r\n","Prune areas smaller than minArea":"修剪小于 minArea 的区域\r\n","The SVM type":"支持向量机类型\r\n","Number of iterations of joint edge-preserving filtering applied on the source image.":"应用于源图像的联合边缘保留过滤的迭代次数。\r\n","\r\n            Hershey script complex\r\n            ":"\r\n            好时脚本复杂\r\n            \r\n","\r\n            Pointer to the unmanaged WarperCreator object\r\n            ":"\r\n            指向非托管 WarperCreator 对象的指针\r\n            \r\n","Zero-based index of the selected row":"所选行的从零开始的索引\r\n","\r\n            No memory\r\n            ":"\r\n            没有记忆\r\n            \r\n"," is not freed by the disposed function of this class \r\n            ":" 未被此类的释放函数释放\r\n            \r\n","The keypoints in the observed image":"观察图像中的关键点\r\n","\r\n            Simple one-line Adaptive Manifold Filter call.\r\n            ":"简单的一行自适应流形过滤器调用。\r\n            \r\n"," image inplace using a 3x3 rectangular structuring element.\r\n            Dilation are applied several (iterations) times\r\n            ":" 使用 3x3 矩形结构元素放置图像。\r\n            扩张应用了几次（迭代）次\r\n            \r\n"," picked indices.":" 挑选的指数。\r\n","Step of BM3D to be executed. Possible variants are: step 1, step 2, both steps.":"要执行的 BM3D 的步骤。可能的变体是：步骤 1、步骤 2、两个步骤。\r\n","\r\n            Image warper factories base class.\r\n            ":"\r\n            图像变形器工厂基类。\r\n            \r\n","Minimum possible disparity value. Normally, it is zero but sometimes rectification algorithms can shift images, so this parameter needs to be adjusted accordingly.":"最小可能差异值。通常情况下，它为零，但有时校正算法会移动图像，因此需要相应地调整此参数。\r\n","\r\n            Creates 4-dimensional blob from image. Optionally resizes and crops image from center, subtract mean values, scales values by scalefactor, swap Blue and Red channels.\r\n            ":"\r\n            从图像创建 4 维 blob。可选地从中心调整大小和裁剪图像，减去平均值，按比例因子缩放值，交换蓝色和红色通道。\r\n            \r\n","Flags of the window.":"窗口的标志。\r\n","\r\n            Get the pointer to the unmanaged shape transformer\r\n            ":"\r\n            获取指向非托管形状转换器的指针\r\n            \r\n","\r\n            Recognize the image from SetAndThresholdImage, generating Tesseract\r\n            internal structures.\r\n            ":"\r\n            从SetAndThresholdImage中识别图像，生成Tesseract\r\n            内部结构。\r\n            \r\n","\r\n            Normal\r\n            ":"\r\n            普通的\r\n            \r\n","\r\n            NV12\r\n            ":"\r\n            NV12\r\n            \r\n","True if all internal computations were possible":"如果所有内部计算都是可能的，则为真\r\n","\r\n            Detects QR codes in image and returns the vector of the quadrangles containing the codes.\r\n            ":"\r\n            检测图像中的二维码并返回包含二维码的四边形向量。\r\n            \r\n","The thickness of the line segment ":"线段的粗细\r\n","8-bit, single-channel binary source image":"8 位、单通道二进制源图像\r\n","The node from file storage.":"来自文件存储的节点。\r\n","a copy of the data values as an array":"作为数组的数据值的副本\r\n","\r\n            Gives information about what GPU archs this OpenCV GPU module was compiled for\r\n            ":"\r\n            提供有关此 OpenCV GPU 模块编译的 GPU archs 的信息\r\n            \r\n","Anchor position within the kernel. Negative values mean that anchor is positioned at the aperture center.":"内核中的锚点位置。负值表示锚点位于孔径中心。\r\n","\r\n            pairs (number of elements, distance between elements in bytes) for every dimension\r\n            ":"\r\n            每个维度的对（元素数量，元素之间的字节距离）\r\n            \r\n","\r\n             determine minimum perimeter for marker contour to be detected. This is defined as a rate respect to the maximum dimension of the input image (default 0.03).\r\n            ":"\r\n             确定要检测的标记轮廓的最小周长。这被定义为相对于输入图像最大维度的比率（默认 0.03）。\r\n            \r\n","Input images":"输入图像\r\n","\r\n            Find the location of the non-zero pixel\r\n            ":"\r\n            找到非零像素的位置\r\n            \r\n","\r\n            Definition of the transformation occupied in the paper “Principal Warps: Thin-Plate Splines and Decomposition of Deformations”, by F.L. Bookstein (PAMI 1989).\r\n            ":"\r\n            F.L. 在论文“Principal Warps: Thin-Plate Splines and Decomposition of Deformations”中定义的变换。布克斯坦（PAMI 1989）。\r\n            \r\n","\r\n            Convert BayerGR pattern to BGR color using VNG\r\n            ":"\r\n            使用 VNG 将 BayerGR 图案转换为 BGR 颜色\r\n            \r\n","Optional right orthogonal matrix (NxN)":"可选右正交矩阵 (NxN)\r\n","Size of the image used only to initialize the intrinsic camera matrix.":"仅用于初始化内部相机矩阵的图像大小。\r\n","\r\n            Average intensity of output signal AEAG should achieve(in %)\r\n            ":"\r\n            AEAG应达到的输出信号平均强度(%)\r\n            \r\n","Lookup table for the A channel":"A通道的查找表\r\n","\r\n            Creates video writer structure.\r\n            ":"\r\n            创建视频编写器结构。\r\n            \r\n","A flag, indicating whether the angles are measured in radians (which is by default), or in degrees.":"一个标志，指示角度是以弧度（默认情况下）还是以度为单位测量的。\r\n","\r\n            Ask network to make computations on specific target device.\r\n            ":"\r\n            要求网络在特定目标设备上进行计算。\r\n            \r\n","\r\n            Interface to the algorithm class\r\n            ":"\r\n            算法类的接口\r\n            \r\n","\r\n            Returns the up-right bounding rectangle for 2d point set\r\n            ":"\r\n            返回二维点集的右上边界矩形\r\n            \r\n","guided image (or array of images) with up to 3 channels, if it have more then 3 channels then only first 3 channels will be used.":"具有最多 3 个通道的引导图像（或图像阵列），如果它有超过 3 个通道，则仅使用前 3 个通道。\r\n"," Optional scale factor for the output back projection.":" 输出反投影的可选比例因子。\r\n","Possitive value means counter-clock wise rotation":"正值表示逆时针旋转\r\n","Interpolation type.":"插值类型。\r\n","\r\n            AGAST_7_12s\r\n            ":"\r\n            AGAST_7_12 秒\r\n            \r\n","weights":"权重\r\n","Sobel threshold":"索贝尔阈值\r\n","The valid pixel ROI for image1":"image1 的有效像素 ROI\r\n","\r\n            Wrapped class of the C++ standard vector of Rect.\r\n            ":"\r\n            Rect 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            The minimum value of this range\r\n            ":"\r\n            该范围的最小值\r\n            \r\n","\r\n            Allocate the image from the image header. \r\n            ":"\r\n            从图像头分配图像。\r\n            \r\n","\r\n            Bounding box for a detected object\r\n            ":"\r\n            检测到的对象的边界框\r\n            \r\n","\r\n            Class that contains entry points for the XObjdetect module.\r\n            ":"\r\n            包含 XObjdetect 模块入口点的类。\r\n            \r\n"," Input 2D point set, stored in std::vector or Mat.":" 输入 2D 点集，存储在 std::vector 或 Mat 中。\r\n","\r\n            LogitBoost\r\n            ":"\r\n            对数提升\r\n            \r\n","Color of the cube.":"立方体的颜色。\r\n","\r\n            correlate query img and threshold to min class value\r\n            ":"\r\n            将查询 img 和阈值关联到最小类值\r\n            \r\n","\r\n            Output data format\r\n            ":"\r\n            输出数据格式\r\n            \r\n","), if false, this function is equaivalent to Resize(int width, int height)":"), 如果为假，这个函数等价于 Resize(int width, int height)\r\n","path to the .cfg file with text description of the network architecture.":"带有网络架构文本描述的 .cfg 文件的路径。\r\n","\r\n            Warps image to a new coordinate frame. \r\n            ":"\r\n            将图像扭曲到新的坐标系。\r\n            \r\n","The sha256 hash value for the file":"文件的 sha256 哈希值\r\n","The color window radius.":"颜色窗口半径。\r\n","\r\n            A HOG descriptor\r\n            ":"\r\n            HOG 描述符\r\n            \r\n","true if the two color equals":"如果两种颜色相等则为真\r\n","\r\n            Release the unmanaged memory associated with this WCone object\r\n            ":"\r\n            释放与此 WCone 对象关联的非托管内存\r\n            \r\n","3x4 Projection matrices in the new (rectified) coordinate systems":"新（修正）坐标系中的 3x4 投影矩阵\r\n","\r\n            Termination criteria of the training algorithm.\r\n            ":"\r\n            训练算法的终止标准。\r\n            \r\n","\r\n            This class canbe used to initiate TBB. Only usefull if it is compiled with TBB support\r\n            ":"\r\n            此类可用于启动 TBB。只有在使用 TBB 支持编译时才有用\r\n            \r\n","\r\n            Camera Motion compensation mode\r\n            ":"\r\n            相机运动补偿模式\r\n            \r\n","\r\n            sigmoid function is used as a kernel: d(x,y) = tanh(gamma*(xy)+coef0)\r\n            ":"\r\n            sigmoid 函数用作内核：d(x,y) = tanh(gamma*(xy)+coef0)\r\n            \r\n","Angle of rotation in degrees":"以度为单位的旋转角度\r\n","True if the two GpuMat equals":"如果两个 GpuMat 相等则为真\r\n","\r\n            Create an standard vector of Int with the initial values\r\n            ":"\r\n            使用初始值创建 Int 的标准向量\r\n            \r\n","\r\n            Given the EM ":"\r\n            鉴于 EM\r\n","If false, the border is only one pixel wide, otherwise all pixels at the border are masked.":"如果为 false，则边框只有一个像素宽，否则边框处的所有像素都将被屏蔽。\r\n","\r\n            Second blob file config\r\n            ":"\r\n            第二个 blob 文件配置\r\n            \r\n","\r\n            Enable/disable use of OpenVX\r\n            ":"\r\n            启用/禁用 OpenVX\r\n            \r\n","Vector of vectors of the calibration pattern points.":"校准图案点向量的向量。\r\n","Number of points used for image sampling.":"用于图像采样的点数。\r\n","The point cloud":"点云\r\n","\r\n            Create an empty standard vector of ColorPoint\r\n            ":"\r\n            创建 ColorPoint 的空标准向量\r\n            \r\n","\r\n            Bad number of channels\r\n            ":"\r\n            频道数量错误\r\n            \r\n","\r\n            Release the unmanaged memory associated with this WCylinder object\r\n            ":"\r\n            释放与此 WCylinder 对象关联的非托管内存\r\n            \r\n","\r\n            Convert a group of CvArray to Mat and push them into the vector\r\n            ":"\r\n            将一组 CvArray 转换为 Mat 并将它们推入向量\r\n            \r\n","\r\n            Managed Structure equivalent to CvPoint2D64f\r\n            ":"\r\n            等同于 CvPoint2D64f 的托管结构\r\n            \r\n","An n x m matrix of descriptors to be query for nearest neighbors. n is the number of descriptor and m is the size of the descriptor":"要查询最近邻居的 n x m 描述符矩阵。 n是描述符的数量，m是描述符的大小\r\n","Array of arrays of the histogram bin boundaries in each dimension.":"每个维度中直方图 bin 边界数组的数组。\r\n","The image where the channels will be swapped":"通道将被交换的图像\r\n","\r\n            The file name of the cvextern library\r\n            ":"\r\n            cvextern 库的文件名\r\n            \r\n","Floating point array with windowing coefficients to reduce edge effects (optional).":"带有窗口系数的浮点数组以减少边缘效应（可选）。\r\n","\r\n            Blender which uses multi-band blending algorithm\r\n            ":"\r\n            使用多波段混合算法的Blender\r\n            \r\n","\r\n            filename of the face detector model\r\n            ":"面部检测器模型的文件名\r\n            \r\n","\r\n            Release the unmanaged resource\r\n            ":"\r\n            释放非托管资源\r\n            \r\n","\r\n            CV_FM_LMEDS_ONLY | CV_FM_8POINT\r\n            ":"\r\n            CV_FM_LMEDS_ONLY | CV_FM_8POINT\r\n            \r\n","Number of channels of the image.":"图像的通道数。\r\n","Framerate of the created video stream. ":"创建的视频流的帧率。\r\n","Array of 2D Mat containing the images extracted from the blob in floating point precision (CV_32F). They are non normalized neither mean added. The number of returned images equals the first dimension of the blob (batch size). Every image has a number of channels equals to the second dimension of the blob (depth).":"包含以浮点精度从 blob 中提取的图像的 2D Mat 数组 (CV_32F)。它们是非标准化的，也不意味着添加。返回图像的数量等于 blob 的第一个维度（批量大小）。每个图像都有多个通道，等于 blob 的第二个维度（深度）。\r\n","\r\n            The function detects edges in src and draw them to dst. The algorithm underlies this function is much more robust to texture presence, than common approaches, e.g. Sobel\r\n            ":"\r\n            该函数检测 src 中的边缘并将它们绘制到 dst。与常用方法（例如索贝尔\r\n            \r\n","\r\n            Convert YUV (YUNV) to RGB\r\n            ":"\r\n            将 YUV (YUNV) 转换为 RGB\r\n            \r\n","\r\n            Converts an image from RGB color space to YUV color space.\r\n            ":"\r\n            将图像从 RGB 颜色空间转换为 YUV 颜色空间。\r\n            \r\n","Neighbors":"邻居\r\n","The number of components":"组件数量\r\n","\r\n            Detect MSER regions\r\n            ":"\r\n            检测 MSER 区域\r\n            \r\n","The source GpuMat. Supports CV_8UC1, CV_16UC1 and CV_16SC1 types.":"来源 GpuMat。支持 CV_8UC1、CV_16UC1 和 CV_16SC1 类型。\r\n","Checks that image elements lie between values defined by two images of same size and type":"检查图像元素是否位于两个相同大小和类型的图像定义的值之间\r\n","\r\n            Type of the extracted descriptor\r\n            ":"\r\n            提取描述符的类型\r\n            \r\n","A clone of the current Mat":"当前 Mat 的克隆\r\n","True use of OpenVX is possible.":"真正使用 OpenVX 是可能的。\r\n","\r\n            Anti-alias\r\n            ":"\r\n            抗锯齿\r\n            \r\n","\r\n            Creates PCTSignatures algorithm using sample and seed count. It generates its own sets of sampling points and clusterization seed indexes.\r\n            ":"\r\n            使用样本和种子计数创建 PCTSignatures 算法。它生成自己的采样点集和聚类种子索引。\r\n            \r\n","Input/output first camera matrix.If FixIntrinsic is specified, some or all of the matrix components must be initialized.":"输入/输出第一个相机矩阵。如果指定 FixIntrinsic，则必须初始化部分或全部矩阵组件。\r\n","The bounding rectangles of the motion components":"运动组件的边界矩形\r\n","\r\n            Cluster the descriptors and return the cluster centers\r\n            ":"\r\n            对描述符进行聚类并返回聚类中心\r\n            \r\n","\r\n            Set the image for optical character recognition\r\n            ":"\r\n            设置用于光学字符识别的图像\r\n            \r\n","found weights":"找到重量\r\n","Array of the dims arrays of the histogram bin boundaries in each dimension.":"每个维度中直方图 bin 边界的 dims 数组的数组。\r\n","marker side length (normally in meters)":"标记边长（通常以米为单位）\r\n","The preferred DNN backend":"首选的 DNN 后端\r\n","The number of channels in the destination image":"目标图像中的通道数\r\n","Input vector of 2D points":"二维点的输入向量\r\n","\r\n            No prefilter\r\n            ":"\r\n            无前置过滤器\r\n            \r\n","\r\n            Attribute used by ImageBox to generate Operation Menu\r\n            ":"\r\n            ImageBox用于生成操作菜单的属性\r\n            \r\n","\r\n            Device output data packing (or grouping) enabled. Packing could be enabled if output_data_bit_depth > 8 and packing capability is available.\r\n            ":"\r\n            启用设备输出数据打包（或分组）。如果 output_data_bit_depth > 8 并且打包功能可用，则可以启用打包。\r\n            \r\n","\r\n            Predict max vote\r\n            ":"\r\n            预测最大投票\r\n            \r\n","\r\n            rectangle\r\n            ":"\r\n            长方形\r\n            \r\n","\r\n            Height of the Image provided by the device (in pixels).\r\n            ":"\r\n            设备提供的图像的高度（以像素为单位）。\r\n            \r\n","The optional output \"class label\" for each sample(indices of the most probable mixture component for each sample). It has nsamples x 1 size and CV_32SC1 type.":"每个样本的可选输出“类标签”（每个样本最可能的混合物成分的索引）。它有 nsamples x 1 大小和 CV_32SC1 类型。\r\n"," Create a Hls color using the specific values":" 使用特定值创建 Hls 颜色\r\n","\r\n            Create a simple blender which mixes images at its borders\r\n            ":"\r\n            创建一个简单的混合器，在其边界混合图像\r\n            \r\n","\r\n            Class that contains ocl functions.\r\n            ":"\r\n            包含 ocl 函数的类。\r\n            \r\n","The size for each dimension":"每个维度的大小\r\n","\r\n            Synonym or Real\r\n            ":"\r\n            同义词或实数\r\n            \r\n","Right-hand side of a linear system":"线性系统的右侧\r\n","\r\n            Cuda Dense Optical flow\r\n            ":"\r\n            Cuda 密集光流\r\n            \r\n","first threshold for the hysteresis procedure.":"滞后程序的第一个阈值。\r\n","\r\n            Floating point configuration\r\n            ":"\r\n            浮点配置\r\n            \r\n","\r\n            Rotate 180 degrees clockwise\r\n            ":"\r\n            顺时针旋转180度\r\n            \r\n","\r\n            Calculate distance to bb\r\n            ":"\r\n            计算到bb的距离\r\n            \r\n","The output edge image":"输出边缘图像\r\n","\r\n            Set desired model.\r\n            ":"\r\n            设置所需的模型。\r\n            \r\n","Vector of already detected marker corners.":"已检测到的标记角的向量。\r\n","The complement image":"补充图像\r\n","\r\n            FAST(Features from Accelerated Segment Test) keypoint detector. \r\n            See Detects corners using FAST algorithm by E. Rosten (\"Machine learning for high-speed corner\r\n            detection, 2006).\r\n            ":"\r\n            FAST(Features from Accelerated Segment Test) 关键点检测器。\r\n            请参阅 E. Rosten 使用 FAST 算法检测角点（“高速角点的机器学习\r\n            检测，2006 年）。\r\n            \r\n","\r\n            Convert BayerRG to RGB (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 BayerRG 转换为 RGB（边缘感知去马赛克）\r\n            \r\n","Matches, returned from DescriptorMatcher.RadiusMatchAsync.":"匹配项，从 DescriptorMatcher.RadiusMatchAsync 返回。\r\n","\r\n            For PPM, PGM, or PBM, it can be a binary format flag, 0 or 1. Default value is 1.\r\n            ":"\r\n            对于 PPM、PGM 或 PBM，它可以是二进制格式标志，0 或 1。默认值为 1。\r\n            \r\n","\r\n            Given an input bgr or grayscale image and constant gamma, apply power-law transformation, a.k.a. gamma correction to the image on domain [0, 255] and return the resulting image.\r\n            ":"\r\n            给定输入 bgr 或灰度图像和常量伽马，对域 [0, 255] 上的图像应用幂律变换，即伽马校正，并返回结果图像。\r\n            \r\n","Binary file contains trained weights":"二进制文件包含经过训练的权重\r\n","\r\n            Global image smoothing via L0 gradient minimization.\r\n            ":"\r\n            通过 L0 梯度最小化进行全局图像平滑。\r\n            \r\n","Parameter of the similarity function.":"相似度函数的参数。\r\n","\r\n            Min dist between blobs\r\n            ":"\r\n            斑点之间的最小距离\r\n            \r\n","\r\n            Performs per-element division of two matrices.\r\n            ":"\r\n            执行两个矩阵的每个元素除法。\r\n            \r\n","\r\n            Create the PyrLK optical flow solver\r\n            ":"\r\n            创建 PyrLK 光流求解器\r\n            \r\n","\r\n            NU\r\n            ":"\r\n            努\r\n            \r\n","\r\n            Class computing a dense optical flow using the Gunnar Farneback's algorithm.\r\n            ":"\r\n            使用 Gunnar Farneback 算法计算密集光流的类。\r\n            \r\n","\r\n            Enable JPEG features, 0 or 1, default is False.\r\n            ":"\r\n            启用 JPEG 功能，0 或 1，默认为 False。\r\n            \r\n","Set of points which can be of type: CV_32FC3, CV_32FC4, CV_64FC3, CV_64FC4.":"可以是以下类型的点集：CV_32FC3、CV_32FC4、CV_64FC3、CV_64FC4。\r\n","the quality metric":"质量指标\r\n"," Convert the current CudaImage to the specific color and depth ":" 将当前的CudaImage转换为特定的颜色和深度\r\n","The source image location":"源图像位置\r\n","\r\n            C++\r\n            ":"\r\n            C++\r\n            \r\n","\r\n            This class contains functions to call into machine learning library\r\n            ":"\r\n            此类包含调用机器学习库的函数\r\n            \r\n"," \r\n            The Image which contains time stamp which specified what time this image is created \r\n            ":" \r\n            包含指定此图像创建时间的时间戳的图像\r\n            \r\n","Scale factor along the horizontal axis":"沿水平轴的比例因子\r\n","\r\n            Parameter nu of a SVM optimization problem\r\n            ":"\r\n            SVM 优化问题的参数 nu\r\n            \r\n","If true, the function uses the provided rvec and tvec values as initial approximations of the rotation and translation vectors, respectively, and further optimizes them.":"如果为真，则函数使用提供的 rvec 和 tvec 值分别作为旋转和平移向量的初始近似值，并进一步优化它们。\r\n","\r\n            Create text detection algorithm from deep learning network.\r\n            ":"\r\n            从深度学习网络创建文本检测算法。\r\n            \r\n","\r\n            Transforms an image to compensate for fisheye lens distortion. The function is simply a combination of fisheye::initUndistortRectifyMap (with unity R ) and remap (with bilinear interpolation). \r\n            ":"\r\n            变换图像以补偿鱼眼镜头失真。该函数只是 fisheye::initUndistortRectifyMap（具有统一 R ）和重映射（具有双线性插值）的组合。\r\n            \r\n","\r\n            Tracking score\r\n            ":"\r\n            跟踪分数\r\n            \r\n"," image and the specific color\r\n            ":" 图像和特定颜色\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of PointF.\r\n            ":"\r\n            PointF 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Threshold (max grey-level value)\r\n            ":"\r\n            阈值（最大灰度值）\r\n            \r\n","When the comparison result is true, the corresponding element of output array is set to 255. Otherwise it is set to 0 ":"当比较结果为真时，输出数组对应元素设置为255，否则设置为0\r\n","\r\n            The data layout type\r\n            ":"\r\n            数据布局类型\r\n            \r\n","\r\n            Release the unmanaged memory associated with this multi-tracker.\r\n            ":"释放与此多跟踪器关联的非托管内存。\r\n            \r\n","The new number of channels":"新通道数\r\n","guided image (also called as joint image) with unsigned 8-bit or floating-point 32-bit depth and up to 4 channels.":"具有无符号 8 位或浮点 32 位深度和最多 4 个通道的引导图像（也称为联合图像）。\r\n","For color image, the evolution steps":"对于彩色图像，进化步骤\r\n","\r\n            Get or set the display color\r\n            ":"\r\n            获取或设置显示颜色\r\n            \r\n","\r\n             Calculates the derivatives Dx and Dy of mhi and then calculates gradient orientation as:\r\n            orientation(x,y)=arctan(Dy(x,y)/Dx(x,y))\r\n            where both Dx(x,y)' and Dy(x,y)' signs are taken into account (as in cvCartToPolar function). After that mask is filled to indicate where the orientation is valid (see delta1 and delta2 description). \r\n             ":"\r\n             计算 mhi 的导数 Dx 和 Dy，然后计算梯度方向为：\r\n            方向（x，y）=arctan（Dy（x，y）/ Dx（x，y））\r\n            其中同时考虑了 Dx(x,y)' 和 Dy(x,y)' 符号（如在 cvCartToPolar 函数中）。填充该掩码以指示方向有效的位置（参见 delta1 和 delta2 描述）。\r\n             \r\n","The second image to compare with":"第二张图片进行比较\r\n","\r\n            Gets the top-level mapping.\r\n            ":"\r\n            获取顶级映射。\r\n            \r\n","The dimensions":"尺寸\r\n","\r\n            Convert BayerGR to BGR (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 BayerGR 转换为 BGR（边缘感知去马赛克）\r\n            \r\n","\r\n            The X component of the vector: rotation axis * sin(rotation angle / 2)\r\n            ":"\r\n            向量的X分量：旋转轴*sin(旋转角度/2)\r\n            \r\n","\r\n            Create an standard vector of Size of the specific size\r\n            ":"\r\n            创建特定尺寸的标准尺寸向量\r\n            \r\n","\r\n            Create a stereographic warper\r\n            ":"\r\n            创建立体变形器\r\n            \r\n","\r\n            Hershey duplex \r\n            ":"\r\n            好时双工\r\n            \r\n","\r\n            The stitcher statis\r\n            ":"\r\n            缝合器统计\r\n            \r\n","\r\n            iOS device white-balance \r\n            ":"\r\n            iOS 设备白平衡\r\n            \r\n","Include the markers in this dictionary at the beginning (optional)":"在开头包含本词典中的标记（可选）\r\n","\r\n            Assign the new value to the particular element of array\r\n            ":"\r\n            将新值分配给数组的特定元素\r\n            \r\n","\r\n            H264\r\n            ":"\r\n            H264\r\n            \r\n","\r\n            R(x,y)=sumx',y'[T'(x',y') I'(x+x',y+y')]/sqrt[sumx',y'T'(x',y')2 sumx',y'I'(x+x',y+y')2]\r\n            ":"\r\n            R(x,y)=sumx',y'[T'(x',y') I'(x+x',y+y')]/sqrt[sumx',y'T'(x', y')2 sumx',y'I'(x+x',y+y')2]\r\n            \r\n","\r\n            Base class for line segments detector algorithm.\r\n            ":"\r\n            线段检测器算法的基类。\r\n            \r\n","\r\n            readonly, tricky property, returns cpnst char* indeed\r\n            ":"\r\n            只读，棘手的属性，确实返回 cpnst char*\r\n            \r\n","\r\n            Create a default tesseract engine. Needed to Call Init function to load language files in a later stage.\r\n            ":"\r\n            创建一个默认的 tesseract 引擎。后期需要调用Init函数加载语言文件。\r\n            \r\n","Output image of the second step of BM3D with the same size and type as src.":"BM3D第二步输出图像，大小和类型与src相同。\r\n","Array of object points in the object coordinate space, 3xN/Nx3 1-channel or 1xN/Nx1 3-channel, where N is the number of points. VectorOfPoint3D32f can be also passed here.":"对象坐标空间中的对象点数组，3xN/Nx3 1 通道或 1xN/Nx1 3 通道，其中 N 是点数。这里也可以传VectorOfPoint3D32f。\r\n","\r\n            Release the EM model\r\n            ":"\r\n            发布 EM 模型\r\n            \r\n","Select result from either first or second of input matrices by given mask.":"通过给定的掩码从第一个或第二个输入矩阵中选择结果。\r\n","\r\n            Release the decision tree and all the memory associate with it\r\n            ":"\r\n            释放决策树及其关联的所有内存\r\n            \r\n","Robust method used to compute transformation. ":"用于计算转换的稳健方法。\r\n","\r\n            The center of this cross\r\n            ":"\r\n            这个十字架的中心\r\n            \r\n","\r\n            120 dimension float\r\n            ":"\r\n            120维浮点数\r\n            \r\n","\r\n            Out of range\r\n            ":"\r\n            超出范围\r\n            \r\n","\r\n            The size of this matrix\r\n            ":"\r\n            这个矩阵的大小\r\n            \r\n","Output integer vector storing cluster indices for every sample":"输出整数向量存储每个样本的聚类索引\r\n","\r\n            I_2(A,B)=sum_{i=1..7} abs(m^A_i - m^B_i) where m^A_i=sign(h^A_i) log(h^A_i), m^B_i=sign(h^B_i) log(h^B_i), h^A_i, h^B_i - Hu moments of A and B, respectively\r\n            ":"\r\n            I_2(A,B)=sum_{i=1..7} abs(m^A_i - m^B_i) 其中 m^A_i=sign(h^A_i) log(h^A_i), m^B_i=sign( h^B_i) log(h^B_i), h^A_i, h^B_i - 分别为 A 和 B 的 Hu 矩\r\n            \r\n","\r\n            Convert RGB to HSV\r\n            ":"\r\n            将 RGB 转换为 HSV\r\n            \r\n","\r\n            Calculates per-element bit-wise disjunction of two arrays:\r\n            dst(I)=src1(I)|src2(I)\r\n            In the case of floating-point arrays their bit representations are used for the operation. All the arrays must have the same type, except the mask, and the same size\r\n            ":"\r\n            计算两个数组的每个元素的逐位析取：\r\n            dst(I)=src1(I)|src2(I)\r\n            在浮点数组的情况下，它们的位表示用于操作。除掩码外，所有数组必须具有相同的类型和相同的大小\r\n            \r\n","Detected colors of ColorChecker patches; the color type is RGB not BGR, and the color values are in [0, 1];":"ColorChecker 色块的检测颜色；颜色类型是 RGB 而不是 BGR，颜色值在 [0, 1] 中；\r\n","Second input CV_8UC1 matrix to be merged.":"要合并的第二个输入 CV_8UC1 矩阵。\r\n","Resulting image from the convolution filter.":"来自卷积滤波器的结果图像。\r\n","\r\n            Create a LBPH face recognizer\r\n            ":"\r\n            创建 LBPH 人脸识别器\r\n            \r\n","\r\n            String with structure, hyperparameters, backend, target and fusion\r\n            Call method after setInput().\r\n            To see correct backend, target and fusion run after forward().\r\n            ":"\r\n            具有结构、超参数、后端、目标和融合的字符串\r\n            在 setInput() 之后调用方法。\r\n            要查看正确的后端、目标和融合，请在 forward() 之后运行。\r\n            \r\n","The number of non-zero GpuMat elements":"非零 GpuMat 元素的数量\r\n","the array of points":"点数组\r\n","\r\n            Sauvola's technique.\r\n            ":"\r\n            索沃拉的技术。\r\n            \r\n","The pointer to the algorithm object":"指向算法对象的指针\r\n","Grayscale or color (BGR) image containing (or not) QR codes":"包含（或不包含）二维码的灰度或彩色 (BGR) 图像\r\n","Input image channel.":"输入图像通道。\r\n","The second source array":"第二个源数组\r\n","File loading method":"文件加载方式\r\n","\r\n            Converts an image from RGB color space to Lab color space.\r\n            ":"\r\n            将图像从 RGB 颜色空间转换为 Lab 颜色空间。\r\n            \r\n","2d points":"二维点\r\n","The other image to compare with":"要比较的另一张图片\r\n","\r\n            The sparse optical flow .\r\n            ":"\r\n            稀疏光流。\r\n            \r\n","The device feature":"设备特点\r\n","Output disparity map.":"输出视差图。\r\n","\r\n            Sets the specified error mode.\r\n            ":"\r\n            设置指定的错误模式。\r\n            \r\n","\r\n            Computes square of each pixel in an image\r\n            ":"\r\n            计算图像中每个像素的平方\r\n            \r\n","\r\n            minimum error for the stop criteria of the corner refinement process (default: 0.1)\r\n            ":"\r\n            角优化过程停止标准的最小误差（默认值：0.1）\r\n            \r\n","\r\n            Implements sparse iterative version of Lucas-Kanade optical flow in pyramids ([Bouguet00]). It calculates coordinates of the feature points on the current video frame given their coordinates on the previous frame. The function finds the coordinates with sub-pixel accuracy. \r\n            ":"\r\n            在金字塔中实现 Lucas-Kanade 光流的稀疏迭代版本 ([Bouguet00])。它根据前一帧的坐标计算当前视频帧上特征点的坐标。该函数以亚像素精度查找坐标。\r\n            \r\n","Flood fill connectivity":"洪水填充连接\r\n","Detected contours. Each contour is stored as a vector of points.":"检测到的轮廓。每个轮廓都存储为点向量。\r\n","the byte vector":"字节向量\r\n","The number of rows (":"行数（\r\n","Second input matrix to be considered for horizontal concatenation.":"水平串联要考虑的第二个输入矩阵。\r\n","\r\n            Returns the algorithm string identifier.\r\n            This string is used as top level xml/yml node tag when the object is saved to a file or string.\r\n            ":"\r\n            返回算法字符串标识符。\r\n            当对象保存到文件或字符串时，此字符串用作顶级 xml/yml 节点标记。\r\n            \r\n","Input vector of 2D points with depth CV_32S or CV_32F":"深度为 CV_32S 或 CV_32F 的二维点的输入向量\r\n","Destination matrix.":"目的地矩阵。\r\n","\r\n            Internal\r\n            ":"\r\n            内部的\r\n            \r\n","The cropped matrix":"裁剪矩阵\r\n","\r\n            Hershey complex\r\n            ":"\r\n            好时综合体\r\n            \r\n","\r\n            Finishes OpenCL queue.\r\n            ":"\r\n            完成 OpenCL 队列。\r\n            \r\n","The preview image":"预览图\r\n","\tid of first marker in dictionary to use on board.":"在船上使用的字典中第一个标记的 ID。\r\n","Thickness of the circle.":"圆的厚度。\r\n","\r\n            Get the files that will be downloaded by this download manager.\r\n            ":"\r\n            获取将由此下载管理器下载的文件。\r\n            \r\n","\r\n            Vertical binning factor\r\n            ":"\r\n            垂直合并因子\r\n            \r\n","\r\n            Convert Lab color to sBGR color\r\n            ":"\r\n            将 Lab 颜色转换为 sBGR 颜色\r\n            \r\n","\r\n            Performs the per-element comparison of a matrix and a scalar, checking if elements from first matrix are equal to the scalar value.\r\n            ":"\r\n            执行矩阵和标量的每个元素比较，检查第一个矩阵中的元素是否等于标量值。\r\n            \r\n","\r\n            Block of text/image/separator line.\r\n            ":"\r\n            文本/图像/分隔线块。\r\n            \r\n","The type of index parameters":"索引参数的类型\r\n","\r\n            Create a GpuMat from the specific region of ":"\r\n            从特定区域创建一个 GpuMat\r\n"," Make a copy of the image, if ROI is set, only copy the ROI":" 复制图片，如果设置了ROI，只复制ROI\r\n","Various operation flags":"各种操作标志\r\n","\r\n            Converts an image from Bayer pattern to RGB or grayscale.\r\n            ":"\r\n            将图像从拜耳模式转换为 RGB 或灰度。\r\n            \r\n","\r\n            Computes mean value and standard deviation\r\n            ":"\r\n            计算平均值和标准差\r\n            \r\n","The angle of rotation in degrees. Positive means clockwise.":"以度为单位的旋转角度。正表示顺时针。\r\n","\r\n            Constructs a WText.\r\n            ":"\r\n            构造一个 WText。\r\n            \r\n","\r\n            (open, read) Alternative definition to bits-per-sample, but with clear handling of 32F / 32S\r\n            ":"\r\n            (open, read) bits-per-sample 的替代定义，但对 32F / 32S 有清晰的处理\r\n            \r\n","4-dimensional OutputArray with NCHW dimensions order.":"具有 NCHW 维度顺序的 4 维 OutputArray。\r\n","\r\n            Create a default Boost classifier\r\n            ":"\r\n            创建默认的 Boost 分类器\r\n            \r\n","\r\n            Fixed size\r\n            ":"\r\n            固定尺寸\r\n            \r\n"," The size of the Gaussian kernel (":" 高斯核的大小（\r\n","\r\n            A 2D plot\r\n            ":"\r\n            二维图\r\n            \r\n","\r\n            Polygon threshold\r\n            ":"\r\n            多边形阈值\r\n            \r\n","\r\n            Generator present\r\n            ":"\r\n            发电机存在\r\n            \r\n","\r\n            Get the pointer to the widget object\r\n            ":"\r\n            获取指向小部件对象的指针\r\n            \r\n","\r\n            Determine which side of the line the 2D point is at\r\n            ":"\r\n            确定 2D 点位于直线的哪一侧\r\n            \r\n","The window size to compute the normals: can only be 1,3,5 or 7":"计算法线的窗口大小：只能是 1、3、5 或 7\r\n","The number of channels in the src image":"src 图像中的通道数\r\n","The color of the points":"点的颜色\r\n","\r\n            Finds minimum and maximum element values and their positions. The extremums are searched over the whole array, selected ROI (in case of IplImage) or, if mask is not IntPtr.Zero, in the specified array region. If the array has more than one channel, it must be IplImage with COI set. In case if multi-dimensional arrays min_loc->x and max_loc->x will contain raw (linear) positions of the extremums\r\n            ":"\r\n            查找最小和最大元素值及其位置。在整个数组中搜索极值，选择 ROI（在 IplImage 的情况下），或者如果掩码不是 IntPtr.Zero，则在指定的数组区域中搜索。如果阵列有多个通道，则它必须是设置了 COI 的 IplImage。如果多维数组 min_loc->x 和 max_loc->x 将包含极值的原始（线性）位置\r\n            \r\n","The euler angles":"欧拉角\r\n","\r\n            Create an empty standard vector of Int\r\n            ":"\r\n            创建一个空的 Int 标准向量\r\n            \r\n","\r\n            Left\r\n            ":"\r\n            左边\r\n            \r\n","Marker Board layout":"标记板布局\r\n","Optional scale, use 1 for default.":"可选比例，默认使用 1。\r\n","segEgbThresholdI":"segb阈值I\r\n","The shape distance between two shapes defined by its contours.":"由轮廓定义的两个形状之间的形状距离。\r\n","\r\n            Pointer to the ERStat that is the min probability ancestor\r\n            ":"指向作为最小概率祖先的 ERStat 的指针\r\n            \r\n","\r\n            Create a Cuda Harris Corner detector\r\n            ":"\r\n            创建 Cuda Harris Corner 检测器\r\n            \r\n","\r\n            Hamming\r\n            ":"\r\n            海明\r\n            \r\n","\r\n            Create an standard vector of VectorOfPointF of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfPointF 标准向量\r\n            \r\n","\r\n            Get the jpeg representation of the image\r\n            ":"\r\n            获取图像的 jpeg 表示\r\n            \r\n","The output result":"输出结果\r\n","Vector of detected charuco corners per frame":"每帧检测到的 charuco 角向量\r\n","An array of Triangle2DF":"一组 Triangle2DF\r\n","\r\n            If set, always convert image to the single channel grayscale image.\r\n            ":"\r\n            如果设置，始终将图像转换为单通道灰度图像。\r\n            \r\n","Convolution kernel, single-channel floating point matrix. If you want to apply different kernels to different channels, split the image using cvSplit into separate color planes and process them individually":"卷积核，单通道浮点矩阵。如果要将不同的内核应用于不同的通道，请使用 cvSplit 将图像拆分为单独的颜色平面并单独处理它们\r\n","The StatucSaliency object":"StatucSaliency 对象\r\n","\r\n            Makes multi-channel GpuMat out of several single-channel GpuMats\r\n            ":"\r\n            从几个单通道 GpuMat 中创建多通道 GpuMat\r\n            \r\n","The rotation angle in degrees. Positive values mean couter-clockwise rotation (the coordiate origin is assumed at top-left corner).":"以度为单位的旋转角度。正值表示逆时针旋转（坐标原点假定在左上角）。\r\n","\r\n            The device half floating point configuration\r\n            ":"\r\n            设备半浮点配置\r\n            \r\n","\r\n            The topmost (y) coordinate which is the inclusive start of the bounding box in the vertical direction.\r\n            ":"\r\n            最顶层 (y) 坐标，它是边界框在垂直方向上的包含起点。\r\n            \r\n","Optional offset of all points of the contours.":"轮廓所有点的可选偏移量。\r\n","\r\n            The catefory of this function\r\n            ":"\r\n            该函数的类别\r\n            \r\n","\r\n            Get an array of the size of the dimensions. e.g. if the mat is 9x10x11, the array of {9, 10, 11} will be returned.\r\n            ":"\r\n            获取维度大小的数组。例如如果垫子是 9x10x11，则返回 {9, 10, 11} 的数组。\r\n            \r\n","\r\n            SLICO will choose an adaptive compactness factor.\r\n            ":"\r\n            SLICO 将选择一个自适应紧凑因子。\r\n            \r\n","\r\n            Hough detection type\r\n            ":"\r\n            霍夫检测类型\r\n            \r\n","true if success":"如果成功则为真\r\n","The number of inner circle per chessboard row and column":"棋盘每行每列的内圈数\r\n","Weights for first image. Must have tha same size as img1. Supports only CV_32F type.":"第一张图片的权重。必须具有与 img1 相同的大小。仅支持 CV_32F 类型。\r\n","\r\n            Base class for modelling a Map between two images.\r\n            ":"\r\n            用于在两个图像之间建模地图的基类。\r\n            \r\n","\r\n            Allocation usage.\r\n            ":"\r\n            分配使用。\r\n            \r\n","The operation mask":"手术面具\r\n","The results":"结果\r\n","\r\n            The function cvMixChannels is a generalized form of cvSplit and cvMerge and some forms of cvCvtColor. It can be used to change the order of the planes, add/remove alpha channel, extract or insert a single plane or multiple planes etc.\r\n            ":"\r\n            函数 cvMixChannels 是 cvSplit 和 cvMerge 的一般形式以及 cvCvtColor 的某些形式。它可用于更改平面的顺序、添加/删除 alpha 通道、提取或插入单个平面或多个平面等。\r\n            \r\n"," The height of the Gaussian kernel":" 高斯核的高度\r\n","\r\n            Random trees\r\n            ":"\r\n            随机树\r\n            \r\n","For more details about this implementation, please see: Philippe Paillou. Detecting step edges in noisy sar images: a new linear operator. IEEE transactions on geoscience and remote sensing, 35(1):191–196, 1997.":"有关此实现的更多详细信息，请参阅：Philippe Paillou。在嘈杂的 sar 图像中检测阶跃边缘：一种新的线性算子。 IEEE 地球科学与遥感汇刊，35(1):191–196, 1997。\r\n","It has the same type and size as src1.":"它与 src1 具有相同的类型和大小。\r\n","\r\n            Image height\r\n            ":"\r\n            图片高度\r\n            \r\n","Absolute difference between two matrices of the same size and depth":"两个相同大小和深度的矩阵之间的绝对差\r\n","\r\n            Each matrix column is sorted\r\n            independently; this flag and SortEveryRow are\r\n            mutually exclusive.\r\n            ":"\r\n            每个矩阵列都已排序\r\n            独立地；这个标志和 SortEveryRow 是\r\n            互斥的。\r\n            \r\n","input image: 8-bit unsigned 3-channel image.":"输入图像：8 位无符号 3 通道图像。\r\n","\r\n            Convert GRAY color to RGB color\r\n            ":"\r\n            将 GRAY 颜色转换为 RGB 颜色\r\n            \r\n","\r\n            Convert YUV320sp to BGR\r\n            ":"\r\n            将 YUV320sp 转换为 BGR\r\n            \r\n","\r\n            Reads algorithm parameters from a file storage.\r\n            ":"\r\n            从文件存储中读取算法参数。\r\n            \r\n","\r\n            border to ignore\r\n            ":"\r\n            要忽略的边界\r\n            \r\n","The ymap. Supports CV_32FC1 map type.":"地图。支持 CV_32FC1 地图类型。\r\n","The array of corners detected":"检测到的角数组\r\n","\r\n            Subtract one point from the other\r\n            ":"\r\n            从另一点中减去一点\r\n            \r\n","\r\n            Adds product of 2 images or thier selected regions to accumulator acc\r\n            ":"\r\n            将 2 个图像或他们选择的区域的乘积添加到累加器 acc\r\n            \r\n","\r\n            Create an standard vector of VectorOfERStat of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfERStat 标准向量\r\n            \r\n","\r\n            Predicted state (x'(k)): x(k)=A*x(k-1)+B*u(k)\r\n            ":"\r\n            预测状态(x'(k))：x(k)=A*x(k-1)+B*u(k)\r\n            \r\n","Output matrix; if it does not have a proper size or type before the operation, it is reallocated.":"输出矩阵；如果在操作之前它没有合适的大小或类型，则会重新分配。\r\n","\r\n            Return a clone of the Matrix\r\n            ":"\r\n            返回矩阵的克隆\r\n            \r\n","The translational shifts that occur between two images":"两个图像之间发生的平移\r\n","\r\n            Plus\r\n            ":"\r\n            加\r\n            \r\n","\r\n            Treat the image as a single text line, bypassing hacks that are Tesseract-specific.\r\n            ":"\r\n            将图像视为单个文本行，绕过特定于 Tesseract 的黑客攻击。\r\n            \r\n","\r\n            Number of pixels covered by the line\r\n            ":"\r\n            线条覆盖的像素数\r\n            \r\n","Parameter used for motion estimation. It adds a variable allowing for illumination variations Set this parameter to 1. if you have varying illumination.":"用于运动估计的参数。它添加了一个允许照明变化的变量。如果您有不同的照明，请将此参数设置为 1。\r\n","Merge small segments to give the desired number of superpixels. Processing is much faster without merging, but many small segments will be left in the image.":"合并小段以提供所需数量的超像素。不合并的处理速度要快得多，但是图像中会留下许多小片段。\r\n","the disparity search range. For each pixel algorithm will find the best disparity from 0 (default minimum disparity) to ":"视差搜索范围。对于每个像素算法会找到从 0（默认最小视差）到\r\n","\r\n            Get all the methods that belongs to the IImage and Image class with ExposableMethodAttribute set true.\r\n            ":"\r\n            获取属于 IImage 和 Image 类且 ExposableMethodAttribute 设置为 true 的所有方法。\r\n            \r\n","Maximum disparity variation within each connected component. If you do speckle filtering, set the parameter to a positive value, it will be implicitly multiplied by 16. Normally, 1 or 2 is good enough.":"每个连接组件内的最大视差变化。如果你做斑点过滤，将参数设置为正值，它会隐式乘以 16。通常，1 或 2 就足够了。\r\n","\r\n            The base class for camera response calibration algorithms.\r\n            ":"\r\n            相机响应校准算法的基类。\r\n            \r\n","\r\n            Convert RGB color to YCrCb color\r\n            ":"\r\n            将 RGB 颜色转换为 YCrCb 颜色\r\n            \r\n","The lower inclusive boundary of the range":"范围的下边界\r\n","\r\n            16 bit signed: first bit for sign, 11 bits for integer part, 4 bits for fractional part.\r\n            ":"\r\n            16 位有符号：第一位为符号，11 位为整数部分，4 位为小数部分。\r\n            \r\n","This algorithm belongs to the quality-guided phase unwrapping methods. First, it computes a reliability map from second differences between a pixel and its eight neighbours. Reliability values lie between 0 and 16*pi*pi. Then, this reliability map is used to compute the reliabilities of \"edges\". An edge is an entity defined by two pixels that are connected horizontally or vertically. Its reliability is found by adding the reliabilities of the two pixels connected through it. Edges are sorted in a histogram based on their reliability values. This histogram is then used to unwrap pixels, starting from the highest quality pixel. ":"该算法属于质量引导的相位展开方法。首先，它根据像素与其八个相邻像素之间的二次差异计算可靠性图。可靠性值介于 0 和 16*pi*pi 之间。然后，该可靠性图用于计算“边缘”的可靠性。边是由水平或垂直连接的两个像素定义的实体。它的可靠性是通过添加通过它连接的两个像素的可靠性来找到的。边缘根据其可靠性值在直方图中排序。然后使用此直方图从最高质量的像素开始展开像素。\r\n","Minimum distance between the centers of the detected circles. If the parameter is too small, multiple neighbor circles may be falsely detected in addition to a true one. If it is too large, some circles may be missed.":"检测到的圆的中心之间的最小距离。如果参数太小，除了真实的圆圈之外，还可能错误地检测到多个相邻圆圈。如果太大，可能会漏掉一些圆圈。\r\n","The data to be plotted":"要绘制的数据\r\n","\r\n            Standard Deviation.\r\n            ":"\r\n            标准偏差。\r\n            \r\n","Metadata used by side-effect processes, such as reading a box file or formatting as hOCR.":"副作用过程使用的元数据，例如读取 box 文件或格式化为 hOCR。\r\n","If true, the code is run synchronously (blocking)":"如果为真，则代码同步运行（阻塞）\r\n","\r\n            JSON format\r\n            ":"\r\n            JSON 格式\r\n            \r\n","\r\n            Divides given scalar by each element of matrix src and keep the division result in new matrix of the same size and type as src\r\n            ":"\r\n            将给定标量除以矩阵 src 的每个元素，并将除法结果保存在与 src 大小和类型相同的新矩阵中\r\n            \r\n","This identifier is deprecated, use DISPARITY_16Q_10_5 instead.":"此标识符已弃用，请改用 DISPARITY_16Q_10_5。\r\n","\r\n            Convert YUV (Y422) to BGR\r\n            ":"\r\n            将 YUV (Y422) 转换为 BGR\r\n            \r\n","\r\n            Initializes already allocated CvMat structure. It can be used to process raw data with OpenCV matrix functions.\r\n            ":"\r\n            初始化已经分配的 CvMat 结构。它可用于使用 OpenCV 矩阵函数处理原始数据。\r\n            \r\n","\r\n            Draws the line segment between pt1 and pt2 points in the image. The line is clipped by the image or ROI rectangle. For non-antialiased lines with integer coordinates the 8-connected or 4-connected Bresenham algorithm is used. Thick lines are drawn with rounding endings. Antialiased lines are drawn using Gaussian filtering.\r\n            ":"\r\n            绘制图像中 pt1 和 pt2 点之间的线段。该线被图像或 ROI 矩形剪裁。对于具有整数坐标的非抗锯齿线，使用 8 连接或 4 连接 Bresenham 算法。粗线画有圆形末端。使用高斯滤波绘制抗锯齿线。\r\n            \r\n","\r\n            Do not calc average (i.e. mean vector) - use the input vector instead\r\n            (useful for calculating covariance matrix by parts)\r\n            ":"\r\n            不要计算平均值（即平均向量） - 使用输入向量代替\r\n            （用于按部分计算协方差矩阵）\r\n            \r\n","Optional Parameter. Flag to enable passing external hints buffer to calc(). Defaults to false.":"可选参数。启用将外部提示缓冲区传递给 calc() 的标志。默认为假。\r\n","\r\n            Native double\r\n            ":"\r\n            原生双\r\n            \r\n","\r\n            Read the file into a Mat\r\n            ":"\r\n            将文件读入 Mat\r\n            \r\n","Double pointer to the header of the deallocated image":"指向已释放图像标头的双指针\r\n","Output 4x1 translation vector T.":"输出 4x1 平移向量 T。\r\n","\r\n            Create a video frame source\r\n            ":"\r\n            创建视频帧源\r\n            \r\n","The error mode":"错误模式\r\n","Patch size.":"补丁大小。\r\n","\r\n            Class that contains entry points for the XPhoto module.\r\n            ":"\r\n            包含 XPhoto 模块入口点的类。\r\n            \r\n","Number of fractional bits in the center coordinates and radius value":"圆心坐标和半径值的小数位数\r\n","\r\n            Constructs a WCube.\r\n            ":"\r\n            构造一个 WCube。\r\n            \r\n","The depth of the second image":"第二张图的深度\r\n","Input image depth.":"输入图像深度。\r\n","\r\n            Convert Bayer GR color to BGR color\r\n            ":"\r\n            将 Bayer GR 颜色转换为 BGR 颜色\r\n            \r\n","The first parameter of the activation function.":"激活函数的第一个参数。\r\n","\r\n            Gets the bin values.\r\n            ":"\r\n            获取 bin 值。\r\n            \r\n","\r\n            The size for each generic parameter Options\r\n            ":"\r\n            每个通用参数选项的大小\r\n            \r\n","Contour defining first shape":"定义第一个形状的轮廓\r\n","The capture object to be stabalized":"要稳定的捕获对象\r\n","\r\n            Type of Robust Estimation Algorithm\r\n            ":"\r\n            稳健估计算法的类型\r\n            \r\n","\r\n            Get or set the intensity of the y color channel\r\n            ":"\r\n            获取或设置 y 颜色通道的强度\r\n            \r\n","\r\n            Gray-world white balance algorithm.\r\n            This algorithm scales the values of pixels based on a gray-world assumption which states that the average of all channels should result in a gray image.\r\n            It adds a modification which thresholds pixels based on their saturation value and only uses pixels below the provided threshold in finding average pixel values.\r\n            Saturation is calculated using the following for a 3-channel RGB image per pixel I and is in the range [0, 1]:\r\n            Saturation[I]= max(R,G,B)-min(R,G,B) / max(R,G,B)\r\n            A threshold of 1 means that all pixels are used to white-balance, while a threshold of 0 means no pixels are used. Lower thresholds are useful in white-balancing saturated images.\r\n            Currently supports images of type CV_8UC3 and CV_16UC3.\r\n            ":"\r\n            灰色世界白平衡算法。\r\n            该算法基于灰色世界假设缩放像素值，该假设声明所有通道的平均值应产生灰色图像。\r\n            它添加了一个修改，该修改基于像素的饱和度值对像素进行阈值处理，并且仅使用低于提供的阈值的像素来查找平均像素值。\r\n            对于每像素 I 的 3 通道 RGB 图像，使用以下公式计算饱和度，并且在 [0, 1] 范围内：\r\n            饱和度[I]= max(R,G,B)-min(R,G,B) / max(R,G,B)\r\n            阈值 1 表示所有像素都用于白平衡，而阈值 0 表示不使用任何像素。较低的阈值在白平衡饱和图像中很有用。\r\n            目前支持 CV_8UC3 和 CV_16UC3 类型的图像。\r\n            \r\n","The distance between two face features.":"两个面部特征之间的距离。\r\n","Color of the circle":"圆的颜色\r\n","This background subtraction algorithm is inspired to the work of B. Wang and P. Dudek [2] [2] B. Wang and P. Dudek \"A Fast Self-tuning Background Subtraction Algorithm\", in proc of IEEE Workshop on Change Detection, 2014":"这种背景减法算法的灵感来自 B. Wang 和 P. Dudek [2] [2] B. Wang 和 P. Dudek 的“一种快速自调整背景减法算法”，在 IEEE 变化检测研讨会的过程中， 2014\r\n","\r\n            Camera Name\r\n            ":"相机名称\r\n            \r\n","Input/output image. It must have 1 or 3 channels. The number of channels is not altered.":"输入/输出图像。它必须有 1 或 3 个通道。通道数没有改变。\r\n","The url of the file to be downloaded":"要下载的文件的url\r\n","\r\n            The pointer to the unmanaged Tonemap object\r\n            ":"\r\n            指向非托管 Tonemap 对象的指针\r\n            \r\n","Output array of the same size as src .":"与 src 大小相同的输出数组。\r\n","The radius of circular neighborhood of each point inpainted that is considered by the algorithm":"算法考虑的每个修复点的圆形邻域半径\r\n","Specify the number of bytes to copy. If this is -1, the number of bytes equals the number of bytes in the ":"指定要复制的字节数。如果这是 -1，则字节数等于\r\n","region size":"区域大小\r\n","Array with detection confidences":"具有检测置信度的阵列\r\n","\r\n            minimum distance between corners for detected markers relative to its perimeter (default 0.05)\r\n            ":"\r\n            检测到的标记的角之间相对于其周长的最小距离（默认 0.05）\r\n            \r\n","An optional mask to indicate valid values of inputImage.":"一个可选的掩码，用于指示 inputImage 的有效值。\r\n","The tracker follows the object from frame to frame. The detector localizes all appearances that have been observed so far and corrects the tracker if necessary. The learning estimates detector's errors and updates it to avoid these errors in the future.":"跟踪器逐帧跟踪对象。检测器定位到目前为止已观察到的所有外观，并在必要时纠正跟踪器。学习估计检测器的错误并更新它以避免将来出现这些错误。\r\n","\r\n            flag to save the trained model or not\r\n            ":"\r\n            标记是否保存经过训练的模型\r\n            \r\n","\r\n            Release the unmanaged memory associated with this TonemapDrago\r\n            ":"\r\n            释放与此 TonemapDrago 关联的非托管内存\r\n            \r\n","\r\n            ignored by OpenCV \r\n            ":"\r\n            被 OpenCV 忽略\r\n            \r\n","\r\n            Insert the specific channel to the image\r\n            ":"\r\n            将特定通道插入图像\r\n            \r\n","The destination three-channel floating-point array":"目标三通道浮点数组\r\n","Scenario for stitcher operation. This is usually determined by source of images to stitch and their transformation. ":"缝合器操作场景。这通常由要拼接的图像来源及其转换决定。\r\n","Set to precompute gradients for the every pyramid level. If pyramid is constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.":"设置为每个金字塔级别的预计算梯度。如果在没有梯度的情况下构建金字塔，则 calcOpticalFlowPyrLK 将在内部计算它们。\r\n","Anchor position within the structuring element. Negative values mean that the anchor is at the center.":"结构元素中的锚点位置。负值表示锚点位于中心。\r\n","resulting image of log transformations.":"日志转换的结果图像。\r\n","A rect to crop a matrix to":"将矩阵裁剪到的矩形\r\n","Color conversion operation that can be specifed using CV_src_color_space2dst_color_space constants ":"可以使用 CV_src_color_space2dst_color_space 常量指定的颜色转换操作\r\n","\r\n            The ocl device type\r\n            ":"\r\n            ocl 设备类型\r\n            \r\n","\r\n            Implementations of intensity transformation algorithms to adjust image contrast.\r\n            ":"\r\n            实施强度变换算法以调整图像对比度。\r\n            \r\n","\r\n            Create a Gaussian motion filter\r\n            ":"\r\n            创建高斯运动滤波器\r\n            \r\n","1xN array containing the first set of points.":"包含第一组点的 1xN 数组。\r\n","the Mahalanobis distance":"马氏距离\r\n","Input 1- or 3-channel, 8-bit or floating-point image. It is modified by the function unless CV_FLOODFILL_MASK_ONLY flag is set.":"输入 1 或 3 通道、8 位或浮点图像。它由函数修改，除非设置了 CV_FLOODFILL_MASK_ONLY 标志。\r\n","Flow smoothness":"流畅度\r\n","\r\n            Convert BGR color to YUV\r\n            ":"\r\n            将 BGR 颜色转换为 YUV\r\n            \r\n","\r\n            The default type where no optimization is done.\r\n            ":"\r\n            未进行优化的默认类型。\r\n            \r\n","\r\n            Convert YUV (iYUV) to Gray\r\n            ":"\r\n            将 YUV (iYUV) 转换为灰色\r\n            \r\n","The search radius":"搜索半径\r\n","\r\n            This type is very similar to InputArray except that it is used for input/output function parameters.\r\n            ":"\r\n            此类型与 InputArray 非常相似，只是它用于输入/输出函数参数。\r\n            \r\n","The rectangle to be drawn":"要绘制的矩形\r\n","\r\n            Copy the data in this umat to the other mat\r\n            ":"\r\n            将这个umat中的数据复制到另一个mat中\r\n            \r\n","\r\n            QR decomposition\r\n            ":"\r\n            QR分解\r\n            \r\n","\r\n            Release the memory associated with this EM model\r\n            ":"\r\n            释放与此 EM 模型关联的内存\r\n            \r\n","\r\n            The numeric code for error status\r\n            ":"\r\n            错误状态的数字代码\r\n            \r\n","Optional output 3x3 rotation matrix around x-axis.":"围绕 x 轴的可选输出 3x3 旋转矩阵。\r\n","\r\n            ISO SPEED\r\n            ":"\r\n            ISO速度\r\n            \r\n"," is n2 x m, the resulting matrix is (n1+n2) x m.\r\n            ":" 是 n2 x m，得到的矩阵是 (n1+n2) x m。\r\n            \r\n","\r\n            BGM_HARD refers to same BGM but use different type of gradient binning. In the BGM_HARD that use ASSIGN_HARD binning type the gradient is assigned to the nearest orientation bin.\r\n            ":"\r\n            BGM_HARD 指的是相同的 BGM 但使用不同类型的梯度合并。在使用 ASSIGN_HARD binning 类型的 BGM_HARD 中，梯度被分配给最近的方向 bin。\r\n            \r\n","Contrast":"对比\r\n","\r\n            Color Correction Model.\r\n            ":"\r\n            颜色校正模型。\r\n            \r\n","\r\n            Only perform grouping horizontally.\r\n            ":"\r\n            只进行水平分组。\r\n            \r\n","\r\n            Create a blank file node iterator\r\n            ":"\r\n            创建一个空白文件节点迭代器\r\n            \r\n","\r\n            Set every pixel of the image to the specific color, using a mask\r\n            ":"\r\n            使用蒙版将图像的每个像素设置为特定颜色\r\n            \r\n"," If thickness is less than 1, the ellipse is filled up ":" 如果 thickness 小于 1，则椭圆被填满\r\n","\r\n            Un-normalized Haar transform\r\n            ":"\r\n            非标准化 Haar 变换\r\n            \r\n","edge image.":"边缘图像。\r\n","Interpolation method":"插值法\r\n","The roi to be copied":"要复制的投资回报率\r\n","\r\n            1 / (alpha + d(c_i, c_j))\r\n            ":"\r\n            1 / (alpha + d(c_i, c_j))\r\n            \r\n","Size of the output image":"输出图像的大小\r\n","\r\n            Create a MSER detector using the specific parameters\r\n            ":"\r\n            使用特定参数创建 MSER 检测器\r\n            \r\n","\r\n            Readonly, returns (const char *).\r\n            ":"\r\n            只读，返回 (const char *)。\r\n            \r\n","\r\n            Computes absolute value of each pixel in an image\r\n            ":"\r\n            计算图像中每个像素的绝对值\r\n            \r\n","An image frame":"图像框\r\n","The norm of the ":"的规范\r\n","Optional parameter used when some pixels do not hold any phase information in the wrapped phase map.":"当一些像素在包裹的相位图中不包含任何相位信息时使用的可选参数。\r\n","\r\n            Computes disparity map for the input rectified stereo pair.\r\n            ":"\r\n            计算输入校正立体对的视差图。\r\n            \r\n","\r\n            See: \r\n            V. Lepetit T. Trzcinski, M. Christoudias and P. Fua. Boosting Binary Keypoint Descriptors. In Computer Vision and Pattern Recognition, 2013.\r\n            M. Christoudias T. Trzcinski and V. Lepetit. Learning Image Descriptors with Boosting. submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2013.\r\n            ":"\r\n            看：\r\n            V. Lepetit T. Trzcinski、M. Christoudias 和 P. Fua。提升二进制关键点描述符。在计算机视觉和模式识别中，2013 年。\r\n            M. Christoudias T. Trzcinski 和 V. Lepetit。通过提升学习图像描述符。提交给 IEEE 模式分析和机器智能交易 (PAMI)，2013 年。\r\n            \r\n","\r\n            Perform an element wise AND operation on the two images\r\n            ":"\r\n            对两个图像执行元素明智的 AND 操作\r\n            \r\n","\r\n            Performs non maximum suppression given boxes and corresponding scores.\r\n            ":"\r\n            执行给定框和相应分数的非最大抑制。\r\n            \r\n","\r\n            Type used in cvStereoRectify\r\n            ":"\r\n            cvStereoRectify 中使用的类型\r\n            \r\n","True if there are more frames":"如果有更多帧则为真\r\n","\r\n            0 - top-left origin,\r\n            1 - bottom-left origin (Windows bitmaps style)\r\n            ":"\r\n            0 - 左上原点，\r\n            1 - 左下原点（Windows 位图样式）\r\n            \r\n","Initial means of mixture components. It is a one-channel matrix of nclusters x dims size. If the matrix does not have CV_64F type it will be converted to the inner matrix of such type for the further computing.":"混合成分的初始均值。它是一个 nclusters x dims 大小的单通道矩阵。如果矩阵没有 CV_64F 类型，它将被转换为该类型的内部矩阵以供进一步计算。\r\n","\r\n            Openni image generator present\r\n            ":"\r\n            存在 Openni 图像生成器\r\n            \r\n","\r\n            Returns output quality map images that were generated during computation, if supported by the algorithm.\r\n            ":"\r\n            如果算法支持，则返回计算期间生成的输出质量地图图像。\r\n            \r\n","The rectangle area of the sub-image":"子图像的矩形区域\r\n","\r\n            Applies a luminance correction (initially High Dynamic Range (HDR) tone mapping)\r\n            ":"\r\n            应用亮度校正（最初是高动态范围 (HDR) 色调映射）\r\n            \r\n","\r\n            Same as DepthFloat32\r\n            ":"\r\n            与 DepthFloat32 相同\r\n            \r\n","\r\n            Returns the number of logical CPUs available for the process.\r\n            ":"返回进程可用的逻辑 CPU 数。\r\n            \r\n","\r\n            Convert Bayer RG color to RGB color\r\n            ":"\r\n            将 Bayer RG 颜色转换为 RGB 颜色\r\n            \r\n","\r\n            Return true if the two MCvScalar equals\r\n            ":"\r\n            如果两个 MCvScalar 相等则返回真\r\n            \r\n"," and marks them in the output image edges using the Canny algorithm. The smallest of threshold1 and threshold2 is used for edge linking, the largest - to find initial segments of strong edges.\r\n             ":" 并使用 Canny 算法在输出图像边缘标记它们。 threshold1 和 threshold2 中最小的用于边缘链接，最大的用于找到强边缘的初始段。\r\n             \r\n","\r\n            For a (x,y) pixel of a camera returns the corresponding projector pixel. The function decodes each pixel in the pattern images acquired by a camera into their corresponding decimal numbers representing the projector's column and row, providing a mapping between camera's and projector's pixel.\r\n            ":"\r\n            对于相机的 (x,y) 像素，返回相应的投影仪像素。该函数将相机获取的图案图像中的每个像素解码为代表投影仪列和行的相应十进制数，从而提供相机像素和投影仪像素之间的映射。\r\n            \r\n","Vector with results of prediction (regression or classification) for each input sample. It is a single-precision floating-point vector with <number_of_samples> elements.":"包含每个输入样本的预测（回归或分类）结果的向量。它是具有 <number_of_samples> 元素的单精度浮点向量。\r\n","Windows size. Use 21x21 for default":"窗户尺寸。默认使用 21x21\r\n","\r\n            Pointer to native cv::DenseOpticalFlow\r\n            ":"\r\n            指向本机 cv::DenseOpticalFlow 的指针\r\n            \r\n","\r\n            Convert YUV (Y422) to RGBA\r\n            ":"\r\n            将 YUV (Y422) 转换为 RGBA\r\n            \r\n","\r\n            EAN-8\r\n            ":"\r\n            EAN-8\r\n            \r\n","Pointer to array of centers, use IntPtr.Zero if not sure":"指向中心数组的指针，如果不确定，请使用 IntPtr.Zero\r\n"," The result is the colormapped source image. ":" 结果是经过颜色映射的源图像。\r\n","Vector of already detected markers corners. For each marker, its four corners are provided, (e.g std::vector>std::vector>cv::Point2f< < ). For N detected markers, the dimensions of this array should be Nx4. The order of the corners should be clockwise.":"已检测到的标记角的向量。对于每个标记，提供了它的四个角（例如 std::vector>std::vector>cv::Point2f< < ）。对于 N 个检测到的标记，此数组的维度应为 Nx4。角的顺序应该是顺时针的。\r\n","A GpuMat that represent the region of the current matrix.":"表示当前矩阵区域的 GpuMat。\r\n","\r\n            Draw the keypoints found on the image.\r\n            ":"\r\n            绘制在图像上找到的关键点。\r\n            \r\n","\r\n            Create a GOTURN tracker\r\n            ":"\r\n            创建一个 GOTURN 跟踪器\r\n            \r\n","The error status":"错误状态\r\n","The output array of image points, 2xN or Nx2, where N is the total number of points in the view":"图像点的输出数组，2xN 或 Nx2，其中 N 是视图中点的总数\r\n","Pixel extrapolation method. Only BORDER_REFLECT101 and BORDER_REPLICATE are supported for now.":"像素外推法。目前仅支持 BORDER_REFLECT101 和 BORDER_REPLICATE。\r\n","\r\n            Predict mask\r\n            ":"\r\n            预测掩码\r\n            \r\n","The keypoints from the model image":"模型图像的关键点\r\n","The feature set to be checked.":"要检查的功能集。\r\n","Divisor for new focal length.":"新焦距的除数。\r\n","\r\n            The MIL algorithm trains a classifier in an online manner to separate the object from the background.\r\n            Multiple Instance Learning avoids the drift problem for a robust tracking.\r\n            Original code can be found here http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml\r\n            ":"\r\n            MIL 算法以在线方式训练分类器以将对象与背景分开。\r\n            多实例学习避免了鲁棒跟踪的漂移问题。\r\n            原始代码可以在这里找到 http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml\r\n            \r\n","The norm of a matrix":"矩阵的范数\r\n","\r\n            Make a TSV-formatted string from the internal data structures.\r\n            ":"\r\n            从内部数据结构中生成 TSV 格式的字符串。\r\n            \r\n","The directory where the unmanaged modules will be loaded. If it is null, the default location will be used.":"将加载非托管模块的目录。如果为空，将使用默认位置。\r\n","Input vector of matrices to be merged; all the matrices in mv must have the same size and the same depth.":"要合并的矩阵的输入向量； mv 中的所有矩阵必须具有相同的大小和相同的深度。\r\n","The point on the map":"地图上的点\r\n","\r\n            Defines a computation with arbitrary input/output number.\r\n            ":"\r\n            定义具有任意输入/输出数的计算。\r\n            \r\n","\r\n            Create an empty standard vector of VectorOfPoint3D32F\r\n            ":"\r\n            创建一个空的 VectorOfPoint3D32F 标准向量\r\n            \r\n","\r\n            Maximum iteration\r\n            ":"\r\n            最大迭代\r\n            \r\n","The points to be rotated, its value will be modified":"要旋转的点，它的值会被修改\r\n","Standard deviation of the generated random numbers; it can be either a vector (in which case a diagonal standard deviation matrix is assumed) or a square matrix.":"生成的随机数的标准偏差；它可以是一个向量（在这种情况下假定为对角标准差矩阵）或一个方阵。\r\n","\r\n            Gaussian function: f(x)=beta e^{-alpha x*x}\r\n            ":"\r\n            高斯函数：f(x)=beta e^{-alpha x*x}\r\n            \r\n","\r\n            Sets a Euclidean (rigid) transformation as motion model; three parameters are estimated; warpMatrix is 2x3.\r\n            ":"\r\n            将欧几里德（刚性）变换设置为运动模型；估计了三个参数； warpMatrix 是 2x3。\r\n            \r\n","\r\n            YUYV/YUY2 (4:2:2)\r\n            ":"\r\n            YUYV/YUY2 (4:2:2)\r\n            \r\n","Destination GpuMat":"目标 GpuMat\r\n","Set to enable use of upright descriptors (non rotation-invariant).":"设置为启用直立描述符（非旋转不变）的使用。\r\n","The weight type":"重量型\r\n","\r\n            Release all the memory associated with the SVM\r\n            ":"\r\n            释放与 SVM 关联的所有内存\r\n            \r\n","Input matrix":"输入矩阵\r\n","\r\n            Draws a single or multiple polygonal curves\r\n            ":"\r\n            绘制单条或多条多边形曲线\r\n            \r\n","\r\n            Intel MediaSDK\r\n            ":"\r\n            英特尔 MediaSDK\r\n            \r\n","\r\n            A static class that provide extension methods to backgroundSubtractor\r\n            ":"\r\n            为 backgroundSubtractor 提供扩展方法的静态类\r\n            \r\n","The regularization parameter for relaxing the exact interpolation requirements of the TPS algorithm.":"放宽 TPS 算法精确插值要求的正则化参数。\r\n","\r\n            Separate chroma quality level, 0 - 100, default is 0 - don't use.\r\n            ":"\r\n            单独的色度质量级别，0 - 100，默认为 0 - 不使用。\r\n            \r\n","\r\n            Applies a user colormap on a given image.\r\n            ":"\r\n            在给定图像上应用用户颜色图。\r\n            \r\n","orientation image from ComputeOrientation function.":"来自 ComputeOrientation 函数的方向图像。\r\n","Font scale factor that is multiplied by the font-specific base size.":"字体比例因子乘以特定于字体的基本大小。\r\n","\r\n            Represent a bool value in C++\r\n            ":"\r\n            在 C++ 中表示一个 bool 值\r\n            \r\n","\r\n            Splitting criteria, used to choose optimal splits during a weak tree construction\r\n            ":"\r\n            分裂标准，用于在弱树构建过程中选择最佳分裂\r\n            \r\n","Maximal pyramid level number. If 0 , pyramids are not used (single level), if 1 , two levels are used, etc":"最大金字塔层数。如果为 0 ，则不使用金字塔（单层），如果为 1 ，则使用两层，依此类推\r\n","\r\n            The barcode region\r\n            ":"\r\n            条形码区域\r\n            \r\n","\r\n            Initialize the WeChatQRCode. It includes two models, which are packaged with caffe format. Therefore, there are prototxt and caffe models (In total, four paramenters).\r\n            ":"\r\n            初始化微信二维码。它包括两个模型，用caffe格式打包。因此，有prototxt和caffe模型（一共四个参数）。\r\n            \r\n","\r\n            Draw a rectangle in the map\r\n            ":"\r\n            在地图上画一个矩形\r\n            \r\n","Criteria applied to determine when the window search should be finished":"用于确定何时应完成窗口搜索的标准\r\n","New matrix number of channels":"新矩阵通道数\r\n","\r\n            Gets the specified element of the top-level mapping.\r\n            ":"\r\n            获取顶级映射的指定元素。\r\n            \r\n","\r\n            Create a new Cuda Stream\r\n            ":"\r\n            创建一个新的 Cuda 流\r\n            \r\n","The exception to be handled":"要处理的异常\r\n","The source pixel locations of bundle in img as CV_16SC2":"img 中 bundle 的源像素位置为 CV_16SC2\r\n","Pointer to an empty GpuMat":"指向空 GpuMat 的指针\r\n","\r\n            XIMEA Camera API\r\n            ":"\r\n            XIMEA 相机 API\r\n            \r\n","\r\n            The algorithm normalizes brightness and increases contrast of the image\r\n            ":"\r\n            该算法归一化亮度并增加图像的对比度\r\n            \r\n","\r\n            An object that can be interpolated\r\n            ":"\r\n            可以插值的对象\r\n            \r\n","\r\n            Read a file into Mat using native implementations\r\n            ":"\r\n            使用本机实现将文件读入 Mat\r\n            \r\n","The parameters for creating a simple blob detector":"用于创建简单斑点检测器的参数\r\n","The value to be added":"要增加的价值\r\n","\r\n            Create a new stub exposure compensator which does nothing.\r\n            ":"\r\n            创建一个什么都不做的新存根曝光补偿器。\r\n            \r\n","Images to be saved.":"要保存的图像。\r\n","Color space conversion code(see ColorConversionCodes). Histogram will used only first plane":"颜色空间转换代码（参见 ColorConversionCodes）。直方图将仅使用第一平面\r\n","\r\n             Wrapping class for feature detection using the goodFeaturesToTrack() function.\r\n            ":"\r\n             使用 goodFeaturesToTrack() 函数进行特征检测的包装类。\r\n            \r\n","\r\n            Error, camera parameters adjustment failed.\r\n            ":"\r\n            报错，相机参数调整失败。\r\n            \r\n","\r\n            Create a new MACE object\r\n            ":"\r\n            创建一个新的 MACE 对象\r\n            \r\n","Arrays of arrays of the int":"int 数组的数组\r\n","\r\n            Specify gradient magnitude max value threshold. Zero limit value is used to disable gradient magnitude thresholding (default behavior, as described in original article). Otherwize pixels with gradient magnitude greater than threshold have zero cost.\r\n            ":"\r\n            指定梯度幅度最大值阈值。零极限值用于禁用梯度幅度阈值（默认行为，如原始文章中所述）。否则，梯度幅度大于阈值的像素的成本为零。\r\n            \r\n","\r\n            Store to eeprom\r\n            ":"\r\n            存储到eeprom\r\n            \r\n","Vector of identifiers for markers in markersCorners . Optional, if not provided, ids are not painted.":"markersCorners 中标记的标识符向量。可选，如果未提供，则不绘制 ID。\r\n"," The Cr value for this color ":" 此颜色的 Cr 值\r\n","\r\n            NICK's technique.\r\n            ":"\r\n            尼克的技术。\r\n            \r\n","\r\n            On-line Hand-Eye Calibration\r\n            ":"\r\n            在线手眼校准\r\n            \r\n","\r\n            Copies selected elements from input array to output array:\r\n            dst(I)=src(I) if mask(I)!=0. \r\n            If any of the passed arrays is of IplImage type, then its ROI and COI fields are used. Both arrays must have the same type, the same number of dimensions and the same size. The function can also copy sparse arrays (mask is not supported in this case).\r\n            ":"将选定元素从输入数组复制到输出数组：\r\n            dst(I)=src(I) 如果掩码(I)!=0。\r\n            如果任何传递的数组是 IplImage 类型，则使用其 ROI 和 COI 字段。两个数组必须具有相同的类型、相同的维数和相同的大小。该函数还可以复制稀疏数组（在这种情况下不支持掩码）。\r\n            \r\n"," \r\n            Make a copy of the image using a mask, if ROI is set, only copy the ROI \r\n            ":" \r\n            使用遮罩复制图像，如果设置了 ROI，则仅复制 ROI\r\n            \r\n","The value to set to":"要设置的值\r\n","\r\n            Set the variable to the specific value.\r\n            ":"\r\n            将变量设置为特定值。\r\n            \r\n","\r\n            Create a new Camera config\r\n            ":"\r\n            创建一个新的相机配置\r\n            \r\n","Radius of the projected sphere, in pixels. An image spanning the whole sphere will have a width of 2 * scale * PI pixels.":"投影球体的半径，以像素为单位。跨越整个球体的图像的宽度为 2 * scale * PI 像素。\r\n","Thickness of lines used to render the text. ":"用于呈现文本的线条粗细。\r\n","\r\n            Get the item in the specific index\r\n            ":"\r\n            获取特定索引中的项目\r\n            \r\n","\r\n            Convert RGBA to YUV_YV12\r\n            ":"\r\n            将 RGBA 转换为 YUV_YV12\r\n            \r\n","\r\n            Convert RGB colot to HSV color\r\n            ":"\r\n            将 RGB 颜色转换为 HSV 颜色\r\n            \r\n","\r\n            Similar to cvInitUndistortRectifyMap and is opposite to it at the same time. \r\n            The functions are similar in that they both are used to correct lens distortion and to perform the optional perspective (rectification) transformation. \r\n            They are opposite because the function cvInitUndistortRectifyMap does actually perform the reverse transformation in order to initialize the maps properly, while this function does the forward transformation. \r\n            ":"\r\n            类似于cvInitUndistortRectifyMap，同时又与之相反。\r\n            这些函数的相似之处在于它们都用于校正镜头畸变和执行可选的透视（校正）变换。\r\n            它们是相反的，因为函数 cvInitUndistortRectifyMap 实际上执行反向转换以正确初始化映射，而此函数执行正向转换。\r\n            \r\n","\r\n            Release all unmanaged memory associated with the Device.\r\n            ":"\r\n            释放与设备关联的所有非托管内存。\r\n            \r\n","The pixel depth type":"像素深度类型\r\n","\r\n            Release the unmanaged memory associated with this VideoReader\r\n            ":"\r\n            释放与此 VideoReader 关联的非托管内存\r\n            \r\n","\r\n            Tilt\r\n            ":"\r\n            倾斜\r\n            \r\n","\r\n            DGpu\r\n            ":"\r\n            DGpu\r\n            \r\n","\r\n            Create a Random Number Generator using a seed.\r\n            ":"\r\n            使用种子创建随机数生成器。\r\n            \r\n","\r\n            Minkowski\r\n            ":"\r\n            闵可夫斯基\r\n            \r\n","Number of levels in the histogram.":"直方图中的级别数。\r\n","Source 8-bit or floating-point, 1-channel or 3-channel image with the same depth as joint image.":"源 8 位或浮点数、1 通道或 3 通道图像，深度与联合图像相同。\r\n","\r\n            Convert Bayer BGGR pattern to RGB color using VNG\r\n            ":"\r\n            使用 VNG 将拜耳 BGGR 模式转换为 RGB 颜色\r\n            \r\n","The width of the input image":"输入图像的宽度\r\n","The other rotation":"其他旋转\r\n","\r\n            Maximum number of gradient descent iterations in the patch inverse search stage. Higher values may improve quality in some cases.\r\n            ":"\r\n            补丁逆搜索阶段梯度下降迭代的最大次数。在某些情况下，较高的值可能会提高质量。\r\n            \r\n","\r\n            Bad flag\r\n            ":"\r\n            坏标志\r\n            \r\n","Per-element bit-wise inversion of the input matrix":"输入矩阵的按元素逐位求逆\r\n",") columns of the GpuMat. The data is shared with the current GpuMat. \r\n            ":") GpuMat 的列。数据与当前的 GpuMat 共享。\r\n            \r\n","\r\n            Rotation part extracted from the homogeneous matrix that transforms a point expressed in the gripper frame to the robot base frame.\r\n            This is a vector (vector<Mat>) that contains the rotation matrices for all the transformations from gripper frame to robot base frame.\r\n            ":"\r\n            从齐次矩阵中提取的旋转部分，将夹持器框架中表示的点转换为机器人基础框架。\r\n            这是一个向量 (vector<Mat>)，其中包含从夹具框架到机器人基础框架的所有转换的旋转矩阵。\r\n            \r\n","The minimum locations for each channel":"每个通道的最小位置\r\n","\r\n            Voronoi diagram-based seam estimator.\r\n            ":"\r\n            基于 Voronoi 图的接缝估计器。\r\n            \r\n"," The type of depth to convert to":" 要转换为的深度类型\r\n","\r\n            Performs downsampling step of Gaussian pyramid decomposition. First it convolves source image with the specified filter and then downsamples the image by rejecting even rows and columns.\r\n            ":"\r\n            执行高斯金字塔分解的下采样步骤。首先，它使用指定的过滤器对源图像进行卷积，然后通过拒绝偶数行和列来对图像进行下采样。\r\n            \r\n","\r\n            Intel's Inference Engine library\r\n            ":"\r\n            英特尔的推理引擎库\r\n            \r\n","4-dimensional Mat with NCHW dimensions order.":"具有 NCHW 维度顺序的 4 维垫。\r\n","Destination image depth":"目标图像深度\r\n","\r\n            Create an standard vector of Size with the initial values\r\n            ":"\r\n            使用初始值创建 Size 的标准向量\r\n            \r\n","\r\n            Number of elements in this dimension\r\n            ":"\r\n            此维度中的元素数\r\n            \r\n","Destination array; must be either the same type as src or 8-bit. ":"目标数组；必须是与 src 相同的类型或 8 位。\r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are greater compare to elements in second.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否大于第二个矩阵中的元素。\r\n            \r\n","\r\n            OpenNI2 Sync\r\n            ":"\r\n            OpenNI2 同步\r\n            \r\n","DNN Network":"深度神经网络\r\n","The input output array ":"输入输出数组\r\n","\r\n            Return the header, corresponding to a specified column of the input array\r\n            ":"\r\n            返回表头，对应输入数组的指定列\r\n            \r\n","The model image":"模特形象\r\n","\r\n            Read image from a file\r\n            ":"\r\n            从文件中读取图像\r\n            \r\n","\r\n            Central Normalized Moment Nu21\r\n            ":"\r\n            中心归一化矩 Nu21\r\n            \r\n"," The radius of the circle ":" 圆的半径\r\n","In case of non-square Gaussian kernel the parameter may be used to specify a different (from param3) sigma in the vertical direction. Use 0 for default":"在非正方形高斯核的情况下，该参数可用于指定垂直方向上的不同（与 param3）sigma。默认使用 0\r\n","\r\n            L0_5\r\n            ":"\r\n            L0_5\r\n            \r\n"," \r\n            Split current GpuMat into an array of single channel GpuMat where each element \r\n            in the array represent a single channel of the original GpuMat\r\n            ":" \r\n            将当前 GpuMat 拆分为单通道 GpuMat 数组，其中每个元素\r\n            数组中代表原始 GpuMat 的单个通道\r\n            \r\n","Source image of any depth except for CV_64F.":"除 CV_64F 之外的任何深度的源图像。\r\n","\r\n            Get the data as InputArray\r\n            ":"\r\n            获取数据作为 InputArray\r\n            \r\n","\r\n            Find the k-nearest match\r\n            ":"\r\n            找到 k 最近匹配\r\n            \r\n","\r\n            Select counter\r\n            ":"\r\n            选择柜台\r\n            \r\n","The center of the box":"盒子的中心\r\n","\r\n            Convert Bayer BGGR color to RGB color\r\n            ":"\r\n            将 Bayer BGGR 颜色转换为 RGB 颜色\r\n            \r\n","Output computed signature.":"输出计算签名。\r\n","The RotatedRect representation of this ellipse":"此椭圆的 RotatedRect 表示\r\n","\r\n            Cuda compute 3.0\r\n            ":"\r\n            Cuda计算3.0\r\n            \r\n","\r\n            Convert Bayer GRBG pattern to RGB color using VNG\r\n            ":"\r\n            使用 VNG 将 Bayer GRBG 模式转换为 RGB 颜色\r\n            \r\n","\r\n            Perform an element wise AND operation using an images and a color\r\n            ":"\r\n            使用图像和颜色执行元素明智的 AND 操作\r\n            \r\n","Pointer to the CvMat":"指向 CvMat 的指针\r\n","\r\n            Contrast Limited Adaptive Histogram Equalization (CLAHE)\r\n            ":"\r\n            对比度受限自适应直方图均衡化 (CLAHE)\r\n            \r\n","First frame, at time t":"第一帧，时间 t\r\n","A copy of the first element in the storage. If the storage is empty, a default value will be returned":"存储中第一个元素的副本。如果存储为空，将返回默认值\r\n","number of iterations":"迭代次数\r\n","\r\n            Creates PCTSignatures algorithm using pre-generated sampling points and number of clusterization seeds. It uses the provided sampling points and generates its own clusterization seed indexes.\r\n            ":"\r\n            使用预先生成的采样点和聚类种子数创建 PCTSignatures 算法。它使用提供的采样点并生成自己的聚类种子索引。\r\n            \r\n","The minor version":"小版本\r\n","\r\n            The function implements different single-image inpainting algorithms\r\n            ":"\r\n            该函数实现了不同的单图修复算法\r\n            \r\n","\r\n            The method returns the number of array elements (a number of pixels if the array represents an image)\r\n            ":"\r\n            该方法返回数组元素的数量（如果数组表示图像，则返回像素数量）\r\n            \r\n","True of barcode found":"条形码的真实发现\r\n","\r\n            Generates a new customizable marker dictionary.\r\n            ":"\r\n            生成新的可自定义标记字典。\r\n            \r\n","Pointer to returned minimum value":"指向返回最小值的指针\r\n","The height of the projector.":"投影仪的高度。\r\n","If true, crop the source image into a circle.":"如果为真，则将源图像裁剪成圆形。\r\n","True if the two points equals":"如果两点相等则为真\r\n","Descriptor of the updating layer output blob.":"更新层输出 blob 的描述符。\r\n","\r\n            Downloads data from device to host memory. \r\n            ":"\r\n            将数据从设备下载到主机内存。\r\n            \r\n","\r\n            Output vector grid size\r\n            ":"\r\n            输出向量网格大小\r\n            \r\n","\r\n            Indicates if the compiler is available\r\n            ":"\r\n            指示编译器是否可用\r\n            \r\n","Distance resolution of the accumulator in pixels.":"累加器的距离分辨率（以像素为单位）。\r\n","The sum of the two matrix":"两个矩阵的总和\r\n","\r\n            The exponent number of L* component of the reference color in CIE Lab color space\r\n            ":"\r\n            CIE Lab颜色空间中参考颜色的L*分量的指数\r\n            \r\n","\r\n            Returns determinant of the square matrix mat. The direct method is used for small matrices and Gaussian elimination is used for larger matrices. For symmetric positive-determined matrices it is also possible to run SVD with U=V=NULL and then calculate determinant as a product of the diagonal elements of W\r\n            ":"\r\n            返回方阵垫的行列式。直接法用于小矩阵，高斯消去法用于大矩阵。对于对称正定矩阵，也可以使用 U=V=NULL 运行 SVD，然后将行列式计算为 W 的对角线元素的乘积\r\n            \r\n","Input samples stored as the matrix rows or as the matrix columns.":"输入样本存储为矩阵行或矩阵列。\r\n","\r\n            Width of frames in the video stream\r\n            ":"\r\n            视频流中帧的宽度\r\n            \r\n","\r\n            Result intensity in [-8, 8] range. Greater intensity produces brighter results.\r\n            ":"\r\n            结果强度在 [-8, 8] 范围内。更大的强度产生更明亮的结果。\r\n            \r\n","true if input is convex":"如果输入是凸的，则为真\r\n"," \r\n            Get or Set the region of interest for this map. To clear the ROI, set it to System.Drawing.RectangleF.Empty\r\n            ":" \r\n            获取或设置此地图的感兴趣区域。要清除 ROI，请将其设置为 System.Drawing.RectangleF.Empty\r\n            \r\n","\r\n            (Read-only): Size of just encoded video frame. Note that the encoding order may be different from representation order.\r\n            ":"\r\n            （只读）：刚刚编码的视频帧的大小。请注意，编码顺序可能与表示顺序不同。\r\n            \r\n","UTF8-encoded output string or empty string if the code cannot be decoded.":"UTF8 编码的输出字符串或空字符串（如果代码无法解码）。\r\n","\r\n            Create a hough segment detector\r\n            ":"\r\n            创建霍夫段检测器\r\n            \r\n","\r\n            Create a new DP Seam Finder\r\n            ":"\r\n            创建一个新的 DP 接缝查找器\r\n            \r\n","Pixel extrapolation method ":"像素外推法\r\n","\r\n            Vulkan\r\n            ":"\r\n            凡尔康\r\n            \r\n","\r\n            Use global motion prior initialisation. It allows to be more accurate for long-range motion. The computational complexity is slightly increased by enabling the global motion prior initialisation.\r\n            ":"\r\n            在初始化之前使用全局运动。它允许更准确的远程运动。通过启用全局运动先验初始化，计算复杂度略有增加。\r\n            \r\n","\r\n            Hershey simplex\r\n            ":"\r\n            好时单纯形\r\n            \r\n","Set the outer radius of the shape context descriptor.":"设置形状上下文描述符的外半径。\r\n","Search for eps-approximate neighbors ":"搜索 eps 近似邻居\r\n","Optional scale factor.":"可选比例因子。\r\n","\r\n            Used in MinProblemSolver-DownhillSolver, terminal criteria to the algorithm\r\n            ":"\r\n            在 MinProblemSolver-DownhillSolver 中使用，算法的最终标准\r\n            \r\n","\r\n            Get the horizonal linesegment of this cross\r\n            ":"\r\n            得到这个十字的水平线段\r\n            \r\n","\r\n            The types for haar detection\r\n            ":"\r\n            haar检测的类型\r\n            \r\n","The new pose of the widget.":"小部件的新姿势。\r\n","\r\n            The start value of this range\r\n            ":"\r\n            该范围的起始值\r\n            \r\n","\r\n            Distribution type\r\n            ":"\r\n            分布类型\r\n            \r\n","\r\n            Calculates the magnitude and angle of 2D vectors.\r\n            magnitude(I)=sqrt( x(I)^2+y(I)^2 ),\r\n            angle(I)=atan2( y(I)/x(I) ) \r\n            The angles are calculated with accuracy about 0.3 degrees. For the point (0,0), the angle is set to 0.\r\n            ":"\r\n            计算二维向量的大小和角度。\r\n            幅度(I)=sqrt( x(I)^2+y(I)^2 ),\r\n            角度(I)=atan2( y(I)/x(I) )\r\n            角度的计算精度约为 0.3 度。对于点 (0,0)，角度设置为 0。\r\n            \r\n","\r\n            Threshold for the distance between features and SVM classifying plane. Usually it is 0 and should be specfied in the detector coefficients (as the last free coefficient). But if the free coefficient is omitted (which is allowed), you can specify it manually here.\r\n            ":"\r\n            特征与 SVM 分类平面之间距离的阈值。通常它是 0，应该在检测器系数中指定（作为最后一个自由系数）。但如果省略了自由系数（这是允许的），您可以在此处手动指定。\r\n            \r\n","The pointer to the array of integers, which contains the parameter for encoding, use IntPtr.Zero for default":"指向整数数组的指针，其中包含用于编码的参数，默认使用 IntPtr.Zero\r\n","\r\n            Create a HarrisLaplaceFeatureDetector\r\n            ":"\r\n            创建一个 HarrisLaplaceFeatureDetector\r\n            \r\n","\r\n            Copy the source GpuMat to destination GpuMat, using an optional mask.\r\n            ":"使用可选掩码将源 GpuMat 复制到目标 GpuMat。\r\n            \r\n","Number of nearest neighbors to search for":"要搜索的最近邻的数量\r\n","\r\n            Ganglion cells sensitivity. Use 0.7 for default\r\n            ":"\r\n            神经节细胞敏感性。默认使用 0.7\r\n            \r\n","Other types that it must known ahead to deserialize the object":"反序列化对象必须提前知道的其他类型\r\n","The first threshold, used for edge linking":"第一个阈值，用于边缘链接\r\n","Camera matrix ":"相机矩阵\r\n","\r\n            Detect objects on image using WaldBoost detector.\r\n            ":"\r\n            使用 WaldBoost 检测器检测图像上的对象。\r\n            \r\n","detection confidence threshold":"检测置信度阈值\r\n","\r\n            Release the memory associated with this classifier\r\n            ":"\r\n            释放与该分类器关联的内存\r\n            \r\n","\r\n            Create a generic EventArgs with two values\r\n            ":"\r\n            创建具有两个值的通用 EventArgs\r\n            \r\n","\r\n            The device OpenCL version\r\n            ":"\r\n            设备 OpenCL 版本\r\n            \r\n","Motion history image, that is updated by the function (single-channel, 32-bit floating-point) ":"运动历史图像，由函数更新（单通道，32位浮点数）\r\n","\r\n            Converts MSER contours (vector of point) to ERStat regions.\r\n            ":"\r\n            将 MSER 轮廓（点矢量）转换为 ERStat 区域。\r\n            \r\n","Center of the circle.":"圆的中心。\r\n","The score":"分数\r\n","The color of the rectangle ":"矩形的颜色\r\n","\r\n            Draws a rectangle specified by a CvRect structure\r\n            ":"\r\n            绘制由 CvRect 结构指定的矩形\r\n            \r\n","The size of the array":"数组的大小\r\n","Triangle face connectivity":"三角面连通性\r\n","\r\n            Estimates new camera matrix for undistortion or rectification.\r\n            ":"\r\n            估计新的相机矩阵以进行不失真或校正。\r\n            \r\n","Depth of the extracted pixels. By default, they have the same depth as ":"提取像素的深度。默认情况下，它们的深度与\r\n","\r\n            The FacemarkLBF model\r\n            ":"\r\n            FacemarkLBF 模型\r\n            \r\n","\r\n            The maximum object size\r\n            ":"\r\n            最大物体尺寸\r\n            \r\n","\r\n            Create a ORBDetector using the specific values\r\n            ":"\r\n            使用特定值创建 ORBDetector\r\n            \r\n","\r\n            Clears the train descriptor collections.\r\n            ":"\r\n            清除列车描述符集合。\r\n            \r\n","\r\n            Create a VectorOfCvString object from an array of String\r\n            ":"\r\n            从 String 数组创建 VectorOfCvString 对象\r\n            \r\n","Arrays of points":"点数组\r\n","Input size of image1.":"image1 的输入大小。\r\n","Output image, 8-bit unsigned 3-channel image.":"输出图像，8 位无符号 3 通道图像。\r\n","Termination criteria.":"终止标准。\r\n","Max level, use 5 for default.":"最大级别，默认使用 5。\r\n","A cuda platform summary":"一个cuda平台总结\r\n","Array of object points in the object coordinate space, 3x3 1-channel or 1x3/3x1 3-channel. VectorOfPoint3f can be also passed here.":"对象坐标空间中的对象点数组，3x3 1 通道或 1x3/3x1 3 通道。这里也可以传VectorOfPoint3f。\r\n","\r\n            Stride between neighbor patches. Must be less than patch size. Lower values correspond to higher flow quality.\r\n            ":"\r\n            在相邻补丁之间跨步。必须小于补丁大小。较低的值对应于较高的流量质量。\r\n            \r\n","type of the input vector":"输入向量的类型\r\n","Maximum reprojection error in the RANSAC algorithm to consider a point as an inlier.":"将点视为内点的 RANSAC 算法中的最大重投影误差。\r\n","\r\n            A norm based cost extraction.\r\n            ":"\r\n            基于规范的成本提取。\r\n            \r\n","Maximum circle radius.":"最大圆半径。\r\n","\r\n            Method which allows retina to be applied on an input image, after run, encapsulated retina module is ready to deliver its outputs using dedicated acccessors. ":"\r\n            允许将 Retina 应用于输入图像的方法，在运行后，封装的 Retina 模块已准备好使用专用访问器提供其输出。\r\n","v0":"v0\r\n","The image to be written":"要写入的图像\r\n","Objects array in internal representation.":"内部表示中的对象数组。\r\n","\r\n            Given the input frame, create input blob, run net.\r\n            ":"\r\n            给定输入帧，创建输入 blob，运行 net。\r\n            \r\n","Index of the diagonal, with the following values: d=0 is the main diagonal; d < 0 is a diagonal from the lower half. For example, d=-1 means the diagonal is set immediately below the main one; d > 0 is a diagonal from the upper half. For example, d=1 means the diagonal is set immediately above the main one.":"对角线的索引，具有以下值：d=0 是主对角线； d < 0 是下半部分的对角线。例如，d=-1 表示对角线设置在主对角线的正下方； d > 0 是上半部分的对角线。例如，d=1 表示对角线设置在主对角线的正上方。\r\n","\r\n            The Height\r\n            ":"\r\n            高度\r\n            \r\n","\r\n            Get the type of the capture module\r\n            ":"\r\n            获取捕获模块的类型\r\n            \r\n","\r\n            Warps the image using affine transformation\r\n            ":"\r\n            使用仿射变换扭曲图像\r\n            \r\n","Points in grid, use 10 for default.":"网格中的点，默认使用 10。\r\n","\r\n            Returns header, corresponding to a specified rectangle of the input GpuMat. In other words, it allows the user to treat a rectangular part of input array as a stand-alone array.\r\n            ":"\r\n            返回标题，对应于输入 GpuMat 的指定矩形。换句话说，它允许用户将输入数组的矩形部分视为独立数组。\r\n            \r\n","A pointer to the created matrix":"指向创建的矩阵的指针\r\n","\r\n            The default value\r\n            ":"\r\n            默认值\r\n            \r\n","\r\n            The algorithm to use\r\n            ":"\r\n            使用的算法\r\n            \r\n","\r\n            When using a parameters object of this type the index created combines the randomized kd-trees and the hierarchical k-means tree.\r\n            ":"当使用这种类型的参数对象时，创建的索引结合了随机 kd 树和分层 k 均值树。\r\n            \r\n"," * image(x,y) if mask(x,y)!=0\r\n            where ":" * image(x,y) 如果 mask(x,y)!=0\r\n            在哪里\r\n"," The eroded image":" 被侵蚀的形象\r\n","The optional mask that is used to select a subarray. Use null if not needed":"用于选择子数组的可选掩码。如果不需要，则使用 null\r\n","\r\n            Get all the platform info as a vector\r\n            ":"\r\n            获取所有平台信息作为向量\r\n            \r\n","The second image to be subtracted from ":"要从中减去的第二个图像\r\n","\r\n            Pointer to the algorithm object\r\n            ":"\r\n            指向算法对象的指针\r\n            \r\n","Thickness of lines the contours are drawn with. If it is negative the contour interiors are drawn":"绘制等高线的线条粗细。如果为负，则绘制轮廓内部\r\n","\r\n            Best of 2 nearest range matcher\r\n            ":"\r\n            最好的 2 个最近范围匹配器\r\n            \r\n"," image with the specified filter and then downsamples the image \r\n            by rejecting even rows and columns.\r\n            ":" 使用指定过滤器的图像，然后对图像进行下采样\r\n            通过拒绝偶数行和列。\r\n            \r\n","Type of of source image. Only single channel images are supported for now.":"源图像的类型。目前仅支持单通道图像。\r\n","\r\n            Central Moment Mu02\r\n            ":"\r\n            中心矩 Mu02\r\n            \r\n","\r\n            Color Correction Matrix element [0][1]\r\n            ":"\r\n            颜色校正矩阵元素 [0][1]\r\n            \r\n","\tsample patterns using keypoints orientation":"使用关键点方向的样本模式\r\n","\r\n            Type for Norm\r\n            ":"\r\n            范数类型\r\n            \r\n","\r\n            Set the directory to the search path used to locate DLLs for the application\r\n            ":"\r\n            将目录设置为用于查找应用程序 DLL 的搜索路径\r\n            \r\n","\r\n            Create an standard vector of VectorOfInt of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfInt 标准向量\r\n            \r\n","\r\n            Correction of row FPN\r\n            ":"\r\n            行FPN的修正\r\n            \r\n","translation vector of the coordinate system that will be drawn.":"将绘制的坐标系的平移向量。\r\n","\r\n            Central Normalized Moment Nu20\r\n            ":"\r\n            中心归一化力矩 Nu20\r\n            \r\n","\r\n            Create a Bgr color using the System.Drawing.Color\r\n            ":"\r\n            使用 System.Drawing.Color 创建 Bgr 颜色\r\n            \r\n","Second input GMat of the defined binary computation":"定义的二进制计算的第二个输入 GMat\r\n","\r\n            Note that while the algorithm does not need to know the intrinsic parameters of the cameras, it heavily depends on the epipolar geometry. Therefore, if the camera lenses have significant distortion, it would better be corrected before computing the fundamental matrix and calling this function. For example, distortion coefficients can be estimated for each head of stereo camera separately by using cvCalibrateCamera2 and then the images can be corrected using cvUndistort2\r\n            ":"\r\n            请注意，虽然该算法不需要知道相机的内在参数，但它在很大程度上取决于对极几何。因此，如果相机镜头有明显的畸变，最好在计算基本矩阵和调用此函数之前进行校正。例如，可以使用 cvCalibrateCamera2 分别为立体相机的每个头估计畸变系数，然后可以使用 cvUndistort2 校正图像\r\n            \r\n","\r\n            Max Y\r\n            ":"\r\n            最大 Y\r\n            \r\n","\r\n            Scale the image to the specific size \r\n            ":"\r\n            将图像缩放到特定尺寸\r\n            \r\n","\r\n            Create multi-dimension mat using existing data.\r\n            ":"\r\n            使用现有数据创建多维垫。\r\n            \r\n","\r\n            True if the input array is an UMat\r\n            ":"\r\n            如果输入数组是 UMat，则为真\r\n            \r\n","The type of elements in the storage":"存储中元素的类型\r\n","\r\n            Get all channels for the multi channel matrix\r\n            ":"\r\n            获取多通道矩阵的所有通道\r\n            \r\n","\r\n            Extracting face feature from aligned image.\r\n            ":"\r\n            从对齐的图像中提取人脸特征。\r\n            \r\n","Gaussian filter coefficients.":"高斯滤波器系数。\r\n","\r\n            A covariation matrix of each mixture is a scaled identity matrix, ?k*I, so the only parameter to be estimated is ?k. The option may be used in special cases, when the constraint is relevant, or as a first step in the optimization (e.g. in case when the data is preprocessed with PCA). The results of such preliminary estimation may be passed again to the optimization procedure, this time with cov_mat_type=COV_MAT_DIAGONAL\r\n            ":"\r\n            每个混合物的协方差矩阵是一个缩放的单位矩阵，?k*I，所以唯一要估计的参数是?k。该选项可以在特殊情况下使用，当约束相关时，或者作为优化的第一步（例如，在使用 PCA 预处理数据的情况下）。这种初步估计的结果可以再次传递给优化过程，这次使用 cov_mat_type=COV_MAT_DIAGONAL\r\n            \r\n","Output image with ridges.":"带脊的输出图像。\r\n","Orientation of the normal to the parallel stripes of a Gabor function.":"Gabor 函数平行条纹的法线方向。\r\n","\r\n            A pointer to the shared pointer to the unmanaged object\r\n            ":"\r\n            指向非托管对象的共享指针的指针\r\n            \r\n","Line color.":"线条颜色。\r\n","New value of the window property.":"窗口属性的新值。\r\n","\r\n            Outer iterations (number of inner loops) used in the numerical scheme\r\n            ":"\r\n            数值方案中使用的外迭代（内循环数）\r\n            \r\n","The SAD window size. Use 19 for default":"SAD 窗口大小。默认使用 19\r\n","The equivalent depth type":"等效深度型\r\n","\r\n            Return the code to generate the object itself from the specific language\r\n            ":"\r\n            返回代码以从特定语言生成对象本身\r\n            \r\n","\r\n            Pointer to the native BundleAdjusterBase object.\r\n            ":"\r\n            指向本机 BundleAdjusterBase 对象的指针。\r\n            \r\n","Min score of boxes to detect.":"要检测的框的最小分数。\r\n","\r\n            StarDetector\r\n            ":"\r\n            星探测器\r\n            \r\n","If true, it will use meanshift grouping.":"如果为真，它将使用 meanshift 分组。\r\n","The training path":"培养路径\r\n","\r\n            This class set the locale to specific values and revert it back to the old values when the object is disposed.\r\n            ":"\r\n            此类将语言环境设置为特定值，并在处理对象时将其恢复为旧值。\r\n            \r\n","The number of channels in the dest image":"dest图像中的通道数\r\n","\r\n            Type of the file storage node\r\n            ":"\r\n            文件存储节点类型\r\n            \r\n","\r\n            Maximal number of pyramid level used. The large this value is the more likely it is to obtain accurate solutions for long-range motions. The runtime is linear related to this parameter\r\n            ":"\r\n            使用的金字塔级别的最大数量。该值越大，越有可能获得远距离运动的精确解。运行时间与该参数线性相关\r\n            \r\n","Normalize the output Mat to grayscale and convert type to CV_8U":"将输出 Mat 归一化为灰度并将类型转换为 CV_8U\r\n","\r\n            cv::ocl::Image2D\r\n            ":"\r\n            简历:: ocl :: Image2D\r\n            \r\n","Not implemented":"未实现\r\n","\r\n            Color Grad\r\n            ":"\r\n            颜色渐变\r\n            \r\n","\r\n            Calculates distance to closest zero pixel for all non-zero pixels of source image\r\n            ":"\r\n            计算源图像所有非零像素到最近零像素的距离\r\n            \r\n","\r\n            16bit signed\r\n            ":"\r\n            16位签名\r\n            \r\n","System.Drawing.Color":"系统.绘图.颜色\r\n","The optional index":"可选索引\r\n","Limit, specifying minimum possible distance between returned corners; Euclidian distance is used.":"限制，指定返回角之间的最小可能距离；使用欧几里得距离。\r\n","\r\n            Draws the individual chessboard corners detected (as red circles) in case if the board was not found (pattern_was_found=0) or the colored corners connected with lines when the board was found (pattern_was_found != 0). \r\n            ":"\r\n            如果未找到棋盘 (pattern_was_found=0) 或在找到棋盘时绘制与线连接的彩色角（pattern_was_found != 0），则绘制检测到的单个棋盘角（红色圆圈）。\r\n            \r\n","The converter such that accept the IntPtr of a single channel IplImage, and image channel index which returning result of type R":"接受单通道 IplImage 的 IntPtr 和返回 R 类型结果的图像通道索引的转换器\r\n","\r\n            Release the unmanaged resources associated with this object\r\n            ":"\r\n            释放与该对象关联的非托管资源\r\n            \r\n","\r\n            Median of the crossings at three different height levels\r\n            ":"\r\n            三个不同高度水平的交叉路口的中位数\r\n            \r\n","Scale factor along the vertical axis":"沿垂直轴的比例因子\r\n","\r\n            File number.\r\n            ":"\r\n            文件编号。\r\n            \r\n","\r\n            Calculates spatial and central moments up to the third order and writes them to moments. The moments may be used then to calculate gravity center of the shape, its area, main axises and various shape characteristics including 7 Hu invariants.\r\n            ":"\r\n            计算高达三阶的空间和中心矩并将它们写入矩。然后可以使用力矩来计算形状的重心、面积、主轴和各种形状特征，包括 7 Hu 不变量。\r\n            \r\n","Returns image header for the input array":"返回输入数组的图像标题\r\n","The destination array, it should have double type or the same type as the source":"目标数组，它应该是双精度类型或与源相同的类型\r\n","\r\n            A Pinned array of the specific type\r\n            ":"\r\n            特定类型的固定数组\r\n            \r\n","The top label.":"顶部标签。\r\n","the data for this matrix":"该矩阵的数据\r\n","\r\n            Get the url to download the tessdata file for the specific language\r\n            ":"\r\n            获取下载特定语言的tessdata文件的url\r\n            \r\n","\r\n            neighborhood size\r\n            ":"\r\n            邻域大小\r\n            \r\n","\r\n            OpenCV's implementation\r\n            ":"\r\n            OpenCV的实现\r\n            \r\n","\r\n            Debounce polarity (pol = 1 t0 - falling edge, t1 - rising edge)\r\n            ":"\r\n            去抖动极性（pol = 1 t0 - 下降沿，t1 - 上升沿）\r\n            \r\n","The detection result used for indicate face in input image":"用于指示输入图像中人脸的检测结果\r\n","\r\n            Convert RGB color to Lab color\r\n            ":"\r\n            将 RGB 颜色转换为 Lab 颜色\r\n            \r\n","Destination upscaled image":"目标放大图像\r\n","The header, corresponding to a specified column of the input array":"表头，对应输入数组的指定列\r\n","\r\n            The bit to shift for SEQ_ELTYPE\r\n            ":"\r\n            SEQ_ELTYPE 要移位的位\r\n            \r\n","\r\n            Barcode detector\r\n            ":"\r\n            条码检测器\r\n            \r\n","dst(I) is set to 0xff (all '1'-bits) if the particular relation between the elements is true and 0 otherwise.":"如果元素之间的特定关系为真，则 dst(I) 设置为 0xff（全“1”位），否则设置为 0。\r\n","\r\n            BayerGB2RGB_MHT\r\n            ":"\r\n            拜耳GB2RGB_MHT\r\n            \r\n","\r\n            Interface for statistical models in OpenCV ML.\r\n            ":"\r\n            OpenCV ML 中统计模型的接口。\r\n            \r\n","\r\n            Release the unmanaged resources associated with this tracker\r\n            ":"\r\n            释放与此跟踪器关联的非托管资源\r\n            \r\n","\r\n            Routines for correcting image color gamma\r\n            ":"\r\n            校正图像颜色伽玛的例程\r\n            \r\n","\r\n            Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored)\r\n            ":"\r\n            弹出视频/相机滤镜对话框（注：目前仅DSHOW后台支持，忽略属性值）\r\n            \r\n"," The matrix to be subtracted to the current matrix":" 要减去当前矩阵的矩阵\r\n","\r\n            (open-only) Specify stream in multi-language media files, -1 - disable audio processing or microphone. Default value is -1.\r\n            ":"\r\n            (open-only) 在多语言媒体文件中指定流，-1 - 禁用音频处理或麦克风。默认值为 -1。\r\n            \r\n","\r\n            Method to compute a transformation from the source frame to the destination one. Some odometry algorithms do not used some data of frames (eg. ICP does not use images). In such case corresponding arguments can be set as empty Mat. The method returns true if all internal computations were possible (e.g. there were enough correspondences, system of equations has a solution, etc) and resulting transformation satisfies some test if it's provided by the Odometry inheritor implementation (e.g. thresholds for maximum translation and rotation).\r\n            ":"\r\n            计算从源帧到目标帧的转换的方法。一些里程计算法不使用帧的某些数据（例如 ICP 不使用图像）。在这种情况下，相应的参数可以设置为空 Mat。如果所有内部计算都是可能的（例如，有足够的对应关系，方程组有一个解决方案等），则该方法返回 true，并且生成的转换满足某些测试，如果它是由 Odometry 继承者实现提供的（例如，最大平移和旋转的阈值）。\r\n            \r\n","The Mat to be swapped":"要交换的垫子\r\n","RGB setting":"RGB设置\r\n","\r\n            The size of this cross\r\n            ":"\r\n            这个十字架的大小\r\n            \r\n","\r\n            Creates kernel from general functions.\r\n            ":"\r\n            从通用函数创建内核。\r\n            \r\n","spatialWeight":"空间权重\r\n","Border type":"边框类型\r\n","\r\n            Return the main diagonal element of this matrix\r\n            ":"\r\n            返回此矩阵的主对角线元素\r\n            \r\n","\r\n            I_1(A,B)=sum_{i=1..7} abs(1/m^A_i - 1/m^B_i) where m^A_i=sign(h^A_i) log(h^A_i), m^B_i=sign(h^B_i) log(h^B_i), h^A_i, h^B_i - Hu moments of A and B, respectively\r\n            ":"\r\n            I_1(A,B)=sum_{i=1..7} abs(1/m^A_i - 1/m^B_i) 其中 m^A_i=sign(h^A_i) log(h^A_i), m^ B_i=sign(h^B_i) log(h^B_i), h^A_i, h^B_i - 分别为 A 和 B 的 Hu 矩\r\n            \r\n","\r\n            Creates an instance of BackgroundSubtractorGSOC algorithm.\r\n            ":"\r\n            创建 BackgroundSubtractorGSOC 算法的实例。\r\n            \r\n","\r\n            Coefficient of the detection window increase.\r\n            ":"\r\n            检测窗口系数增加。\r\n            \r\n","\r\n            BayerRG2GRAY_MHT\r\n            ":"\r\n            拜耳RG2GRAY_MHT\r\n            \r\n","\r\n            apply one of the flavors of Teh-Chin chain approximation algorithm\r\n            ":"\r\n            应用一种 Teh-Chin 链近似算法\r\n            \r\n","Multiplier for frame values.":"帧值的乘数。\r\n","The comparison mask":"比较面具\r\n","The kernel arg":"内核参数\r\n","When true, the input angles are measured in degrees, otherwise, they are measured in radians.":"当为 true 时，输入角度以度为单位，否则以弧度为单位。\r\n","\r\n            If the number of samples in a node is less than this parameter then the node will not be split\r\n            ":"\r\n            如果节点中的样本数小于此参数，则该节点不会被分裂\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of Byte.\r\n            ":"\r\n            Byte 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Flips a 2D matrix around vertical, horizontal, or both axes.\r\n            ":"\r\n            围绕垂直轴、水平轴或两个轴翻转二维矩阵。\r\n            \r\n","\r\n            Get the pointer to the native ShapeTransformer\r\n            ":"\r\n            获取指向本机 ShapeTransformer 的指针\r\n            \r\n","\r\n            Create a SIFT using the specific values\r\n            ":"\r\n            使用特定值创建 SIFT\r\n            \r\n","The type of color map":"彩色地图的类型\r\n","The frame":"框架\r\n","\r\n            If set, the function does not fill the image (new_val is ignored),\r\n            but the fills mask (that must be non-NULL in this case).\r\n            ":"\r\n            如果设置，该函数不会填充图像（忽略 new_val），\r\n            但是填充掩码（在这种情况下必须是非 NULL）。\r\n            \r\n","\r\n            Returns the segmentation labeling of the image. Each label represents a superpixel, and each pixel is assigned to one superpixel label.\r\n            ":"\r\n            返回图像的分割标签。每个标签代表一个超像素，每个像素都分配给一个超像素标签。\r\n            \r\n","Source 8-bit single channel image.":"源 8 位单通道图像。\r\n","Value of the border pixels if bordertype=CONSTANT":"bordertype=CONSTANT 时边框像素的值\r\n","\r\n            The function applies a separable linear filter to the image. That is, first, every row of src is filtered with the 1D kernel kernelX. Then, every column of the result is filtered with the 1D kernel kernelY. The final result shifted by delta is stored in dst .\r\n            ":"\r\n            该函数对图像应用可分离的线性滤波器。也就是说，首先，src 的每一行都用一维内核 kernelX 进行过滤。然后，结果的每一列都用一维核 kernelY 过滤。 delta 移位的最终结果存储在 dst 中。\r\n            \r\n","\r\n            Returns 1 if camera connected and works properly.\r\n            ":"\r\n            如果相机已连接并正常工作，则返回 1。\r\n            \r\n","\r\n             bit-mask which can be used to separate norm type from norm flags\r\n            ":"\r\n             可用于将规范类型与规范标志分开的位掩码\r\n            \r\n","The result of the AND operation":"AND 运算的结果\r\n","The rotated Affine3 matrix":"旋转后的 Affine3 矩阵\r\n","The samples to be appended to the storage":"要附加到存储的样本\r\n","flag which indicates that swap first and last channels in 3-channel image is necessary.":"指示交换 3 通道图像中的第一个和最后一个通道的标志是必要的。\r\n","\r\n            Get a pointer to the raw data given the specific index\r\n            ":"\r\n            在给定特定索引的情况下获取指向原始数据的指针\r\n            \r\n"," Image to select a ROI.":" 用于选择 ROI 的图像。\r\n","The CvArray to be uploaded to GPU":"要上传到 GPU 的 CvArray\r\n","logarithm to the base 2 of maximal shift in each dimension. Values of 5 and 6 are usually good enough (31 and 63 pixels shift respectively).":"以每个维度中最大位移的底数 2 为对数。 5 和 6 的值通常就足够了（分别移动 31 和 63 像素）。\r\n","\r\n            Convert YUV (i420) to RGB\r\n            ":"将 YUV (i420) 转换为 RGB\r\n            \r\n","\r\n            method for a symmetric positively-defined matrix\r\n            ":"\r\n            对称正定义矩阵的方法\r\n            \r\n","Matrix of responses. If the responses are scalar, they should be stored as a single row or as a single column. The matrix should have type CV_32F or CV_32S (in the former case the responses are considered as ordered by default; in the latter case - as categorical)":"响应矩阵。如果响应是标量的，则应将它们存储为单行或单列。矩阵应具有 CV_32F 或 CV_32S 类型（在前一种情况下，默认情况下将响应视为有序；在后一种情况下 - 作为分类）\r\n","\r\n            Trains a descriptor matcher.\r\n            ":"\r\n            训练描述符匹配器。\r\n            \r\n","Indicates that it is end of stream. The parameter can be ignored.":"表示它是流的结尾。该参数可以忽略。\r\n","The color to be added":"要添加的颜色\r\n","The interface":"界面\r\n"," \r\n            A Uniform Multi-dimensional Dense Histogram \r\n            ":" \r\n            均匀的多维稠密直方图\r\n            \r\n","\r\n            Convert YUV NV21 to Gray\r\n            ":"\r\n            将 YUV NV21 转换为灰色\r\n            \r\n","\r\n            Finds a rotated rectangle of the minimum area enclosing the input 2D point set.\r\n            ":"\r\n            查找包围输入 2D 点集的最小面积的旋转矩形。\r\n            \r\n","Source chessboard view; it must be 8-bit grayscale or color image":"源棋盘视图；它必须是 8 位灰度或彩色图像\r\n","\r\n            Properties of cameras available through OpenNI interfaces\r\n            ":"\r\n            通过 OpenNI 接口可用的相机属性\r\n            \r\n","When true, the image data origin is at the bottom-left corner. Otherwise, it is at the top-left corner.":"为真时，图像数据原点位于左下角。否则，它位于左上角。\r\n","An array of KeyLine":"一组 KeyLine\r\n","The neighbors found":"邻居发现\r\n","\r\n            Initialize the class with the 'Selective search fast' parameters\r\n            ":"\r\n            使用“快速选择性搜索”参数初始化类\r\n            \r\n","All the characters in the image":"图像中的所有字符\r\n","\r\n            Text file contains network configuration. It could be a file with the following extensions:\r\n               *.prototxt(Caffe, http://caffe.berkeleyvision.org/)\r\n               *.pbtxt (TensorFlow, https://www.tensorflow.org/)\r\n               *.cfg (Darknet, https://pjreddie.com/darknet/)\r\n               *.xml (DLDT, https://software.intel.com/openvino-toolkit)\r\n            ":"\r\n            文本文件包含网络配置。它可以是具有以下扩展名的文件：\r\n               *.prototxt（Caffe，http://caffe.berkeleyvision.org/）\r\n               *.pbtxt（TensorFlow，https://www.tensorflow.org/）\r\n               *.cfg（暗网，https://pjreddie.com/darknet/）\r\n               *.xml（DLDT，https://software.intel.com/openvino-toolkit）\r\n            \r\n","The other GpuMat to be compares with":"另一个要与之比较的 GpuMat\r\n","The second convex polygon":"第二个凸多边形\r\n","optional operation mask; it must have the same size as src1 and CV_8UC1 type.":"可选操作面罩；它必须与 src1 和 CV_8UC1 类型具有相同的大小。\r\n","The third source array (shift). Can be IntPtr.Zero, if there is no shift.":"第三源数组（shift）。如果没有移位，可以是 IntPtr.Zero。\r\n","\r\n            Create a retina model\r\n            ":"\r\n            创建视网膜模型\r\n            \r\n","The types that implement the specific interface":"实现特定接口的类型\r\n","\r\n            Color Correction Matrix element [1][3]\r\n            ":"\r\n            颜色校正矩阵元素 [1][3]\r\n            \r\n","\r\n            Produce domain transform filtering operation on source image.\r\n            ":"\r\n            对源图像产生域变换滤波操作。\r\n            \r\n","\r\n            Pointer to the native Estimator object.\r\n            ":"\r\n            指向本机 Estimator 对象的指针。\r\n            \r\n","The destination array; will have the same size and the same type as src":"目标数组；将具有与 src 相同的大小和相同的类型\r\n","\r\n            Creates a window which can be used as a placeholder for images and trackbars. Created windows are reffered by their names. \r\n            If the window with such a name already exists, the function does nothing.\r\n            ":"\r\n            创建一个可用作图像和轨迹栏占位符的窗口。创建的窗口由它们的名称引用。\r\n            如果具有这样名称的窗口已经存在，则该函数不执行任何操作。\r\n            \r\n","\r\n            The device driver version\r\n            ":"\r\n            设备驱动版本\r\n            \r\n","Image signature.":"图片签名。\r\n","\r\n            Perform an generic operation based on the elements of the two images\r\n            ":"\r\n            根据两张图片的元素进行泛型操作\r\n            \r\n","\r\n            Video input or Channel Number (only for those cameras that support)\r\n            ":"\r\n            视频输入或通道号（仅适用于支持的摄像机）\r\n            \r\n","\r\n            Copy a jagged two dimensional array from the unmanaged memory\r\n            ":"\r\n            从非托管内存中复制一个锯齿状的二维数组\r\n            \r\n","\r\n            Updates a FaceRecognizer with given data and associated labels.\r\n            ":"\r\n            使用给定数据和关联标签更新 FaceRecognizer。\r\n            \r\n","\r\n            Rotate the specific point and return the result\r\n            ":"\r\n            旋转特定点并返回结果\r\n            \r\n","\r\n            Cuda fp16\r\n            ":"\r\n            库达fp16\r\n            \r\n","\r\n            Create a Boosting Tracker\r\n            ":"\r\n            创建一个提升追踪器\r\n            \r\n","\r\n            Calculate the map between the images\r\n            ":"\r\n            计算图像之间的映射\r\n            \r\n","\r\n            Number of outer (fixed-point) iterations in the minimization procedure.\r\n            ":"\r\n            最小化过程中的外部（定点）迭代次数。\r\n            \r\n"," \r\n            Defines a Bgra (Blue Green Red Alpha) color\r\n            ":" \r\n            定义 Bgra（蓝绿红 Alpha）颜色\r\n            \r\n","The inpainting mask, 8-bit 1-channel image. Non-zero pixels indicate the area that needs to be inpainted":"修复掩码，8 位 1 通道图像。非零像素表示需要修复的区域\r\n","\r\n            Implements one of the variants of watershed, non-parametric marker-based segmentation algorithm, described in [Meyer92] Before passing the image to the function, user has to outline roughly the desired regions in the image markers with positive (>0) indices, i.e. every region is represented as one or more connected components with the pixel values 1, 2, 3 etc. Those components will be \"seeds\" of the future image regions. All the other pixels in markers, which relation to the outlined regions is not known and should be defined by the algorithm, should be set to 0's. On the output of the function, each pixel in markers is set to one of values of the \"seed\" components, or to -1 at boundaries between the regions.\r\n            ":"\r\n            实现 [Meyer92] 中描述的分水岭、基于非参数标记的分割算法的变体之一 在将图像传递给函数之前，用户必须在具有正（> 0）索引的图像标记中粗略勾勒出所需区域，也就是说，每个区域都表示为一个或多个具有像素值 1、2、3 等的连通分量。这些分量将成为未来图像区域的“种子”。标记中与轮廓区域相关的所有其他像素未知且应由算法定义，应设置为 0。在函数的输出中，标记中的每个像素都设置为“种子”组件的值之一，或者在区域之间的边界处设置为 -1。\r\n            \r\n","Bitwise conjunction of the two matrices (src1 & src2)":"两个矩阵的按位结合 (src1 & src2)\r\n","If true, the result is subsequent scaled by 1/(param1 x param2)":"如果为真，则结果随后按 1/(param1 x param2) 缩放\r\n","Adaptive_method ":"自适应方法\r\n","\r\n            Helper class for training part of [P. Dollar and C. L. Zitnick. Structured Forests for Fast Edge Detection, 2013].\r\n            ":"\r\n            训练部分的辅助类 [P. Dollar 和 C. L. Zitnick。用于快速边缘检测的结构化森林，2013]。\r\n            \r\n","The operation mask. Makes the function consider and normalize only certain array elements":"手术面具。使函数只考虑和规范化某些数组元素\r\n","\r\n            Enable High Dynamic Range feature.\r\n            ":"\r\n            启用高动态范围功能。\r\n            \r\n","\r\n            Number of inflexion points\r\n            ":"\r\n            拐点数\r\n            \r\n","Used to allow the first N1c vectors to adapt over time to changing background.":"用于允许第一个 N1c 向量随着时间的推移适应不断变化的背景。\r\n","Inclusive lower boundary of the generated random numbers.":"生成的随机数的包含下边界。\r\n","\r\n            General case, suits to the case of non-linearly separable sets, allows outliers.\r\n            ":"\r\n            一般情况，适用于非线性可分集的情况，允许异常值。\r\n            \r\n","The item in the specific index":"具体索引中的项目\r\n","\r\n            Returns true if the two points equals.\r\n            ":"\r\n            如果两个点相等，则返回 true。\r\n            \r\n","Point coordinates in the destination plane, 2xN, Nx2, 3xN or Nx3 array (the latter two are for representation in homogeneous coordinates) ":"目标平面中的点坐标，2xN、Nx2、3xN或Nx3数组（后两者用于齐次坐标表示）\r\n","\r\n            Fisheye Camera model\r\n            ":"\r\n            鱼眼相机型号\r\n            \r\n","Output Mat for binary computation":"用于二进制计算的输出矩阵\r\n","\r\n            Features matcher similar to BestOf2NearestMatcher which finds two best matches for each feature and leaves the best one only if the ratio between descriptor distances is greater than the threshold match_conf.\r\n            ":"\r\n            类似于 BestOf2NearestMatcher 的特征匹配器，它为每个特征找到两个最佳匹配，并且仅当描述符距离之间的比率大于阈值 match_conf 时才留下最佳匹配。\r\n            \r\n","\r\n            Same as WU. It is preferable to use the flag with the name of the algorithm (SAUF) rather than the one with the name of the first author (Wu).\r\n            ":"\r\n            和吴一样。最好使用带有算法名称 (SAUF) 的标志，而不是带有第一作者 (Wu) 名称的标志。\r\n            \r\n","range for exclusion bitmap that is constructed to suppress noise around the median value.":"为抑制中值周围的噪声而构造的排除位图的范围。\r\n","frame rate per second":"每秒帧率\r\n","The output tone mapped image":"输出色调映射图像\r\n","\r\n            Entry points for the BgSegm module.\r\n            ":"\r\n            BgSegm 模块的入口点。\r\n            \r\n"," Get or set the intensity of the alpha color channel ":" 获取或设置 alpha 颜色通道的强度\r\n"," Compute the element of the new image based on the elements of the two image":" 根据两个图像的元素计算新图像的元素\r\n","\r\n            For every point in one of the two images of stereo-pair the function cvComputeCorrespondEpilines finds equation of a line that contains the corresponding point (i.e. projection of the same 3D point) in the other image. Each line is encoded by a vector of 3 elements l=[a,b,c]^T, so that: \r\n            l^T*[x, y, 1]^T=0, or\r\n            a*x + b*y + c = 0\r\n            From the fundamental matrix definition (see cvFindFundamentalMatrix discussion), line l2 for a point p1 in the first image (which_image=1) can be computed as: \r\n            l2=F*p1 and the line l1 for a point p2 in the second image (which_image=1) can be computed as: \r\n            l1=F^T*p2Line coefficients are defined up to a scale. They are normalized (a2+b2=1) are stored into correspondent_lines\r\n            ":"\r\n            对于立体对的两个图像之一中的每个点，函数 cvComputeCorrespondEpilines 找到包含另一个图像中对应点（即相同 3D 点的投影）的直线方程。每行由 3 个元素 l=[a,b,c]^T 的向量编码，因此：\r\n            l^T*[x, y, 1]^T=0, 或者\r\n            a*x + b*y + c = 0\r\n            根据基本矩阵定义（参见 cvFindFundamentalMatrix 讨论），第一个图像 (which_image=1) 中点 p1 的行 l2 可以计算为：\r\n            l2=F*p1 和第二幅图像 (which_image=1) 中点 p2 的线 l1 可以计算为：\r\n            l1=F^T*p2Line 系数被定义为一个比例。它们被归一化 (a2+b2=1) 并存储到 correspondent_lines\r\n            \r\n","\r\n            Execute only first step of the algorithm \r\n            ":"\r\n            只执行算法的第一步\r\n            \r\n","The mask for the OR operation":"OR 操作的掩码\r\n","\r\n            Convert BayerGR pattern to RGB color using VNG\r\n            ":"\r\n            使用 VNG 将 BayerGR 模式转换为 RGB 颜色\r\n            \r\n","\r\n            Return true if the two Range equals\r\n            ":"\r\n            如果两个 Range 相等则返回 true\r\n            \r\n","\r\n            Save the GpuMat to a file\r\n            ":"\r\n            将 GpuMat 保存到文件\r\n            \r\n","\r\n            I_3(A,B)=sum_{i=1..7} abs(m^A_i - m^B_i)/abs(m^A_i) where m^A_i=sign(h^A_i) log(h^A_i), m^B_i=sign(h^B_i) log(h^B_i), h^A_i, h^B_i - Hu moments of A and B, respectively\r\n            ":"\r\n            I_3(A,B)=sum_{i=1..7} abs(m^A_i - m^B_i)/abs(m^A_i) 其中 m^A_i=sign(h^A_i) log(h^A_i) , m^B_i=sign(h^B_i) log(h^B_i), h^A_i, h^B_i - 分别为 A 和 B 的 Hu 矩\r\n            \r\n","The horizontally concatenated matrix":"水平连接矩阵\r\n","\r\n            Create a new identity matrix\r\n            ":"\r\n            创建一个新的单位矩阵\r\n            \r\n","\r\n            Depth generator baseline, in mm.\r\n            ":"\r\n            深度发生器基线，以毫米为单位。\r\n            \r\n","The storage.":"存储。\r\n","\r\n            Dump net structure, hyperparameters, backend, target and fusion to dot file\r\n            ":"\r\n            将网络结构、超参数、后端、目标和融合转储到点文件\r\n            \r\n","\r\n            RANSAC-based robust method\r\n            ":"\r\n            基于 RANSAC 的鲁棒方法\r\n            \r\n","\r\n            Check if the GPU module is targeted for the specific BIN version\r\n            ":"\r\n            检查 GPU 模块是否针对特定的 BIN 版本\r\n            \r\n","number of markers in the dictionary":"词典中的标记数\r\n","The baseline of the current object at the given level":"当前对象在给定级别的基线\r\n","\r\n            The 4th distortion coefficient (k4) is fixed (see above)\r\n            ":"\r\n            第 4 个失真系数 (k4) 是固定的（见上文）\r\n            \r\n","\r\n            Create a blank Image of the specified width and height. \r\n            ":"\r\n            创建指定宽度和高度的空白图像。\r\n            \r\n","The number of iterations":"迭代次数\r\n","The image to be subtracted from the current image":"要从当前图像中减去的图像\r\n","The cross product of the two 3D point":"两个3D点的叉积\r\n","array of data":"数据数组\r\n","One of the implemented Hand-Eye calibration method":"实施的手眼校准方法之一\r\n","The vector of distortion coefficients, 4x1 or 1x4 [k1, k2, p1, p2]. If it is IntPtr.Zero, all distortion coefficients are considered 0's.":"失真系数的向量，4x1 或 1x4 [k1, k2, p1, p2]。如果是 IntPtr.Zero，所有失真系数都被认为是 0。\r\n","The supported type includes System.String and System.ValueType":"支持的类型包括 System.String 和 System.ValueType\r\n","\r\n            Read deep learning network represented in one of the supported formats.\r\n            ":"\r\n            阅读以一种受支持的格式表示的深度学习网络。\r\n            \r\n","\r\n            The number of last frames that affect the background model\r\n            ":"\r\n            影响背景模型的最后帧数\r\n            \r\n","The number of columns (width)":"列数（宽度）\r\n","The default value if one is not found in the node.":"如果在节点中找不到，则为默认值。\r\n","\r\n            Same as DisparityFixed_16_11_5\r\n            ":"\r\n            与 DisparityFixed_16_11_5 相同\r\n            \r\n","\r\n            An Unmanaged Object is a disposable object with a Ptr property pointing to the unmanaged object\r\n            ":"\r\n            Unmanaged Object 是一个一次性对象，具有指向非托管对象的 Ptr 属性\r\n            \r\n","The ith row of the CudaImage":"CudaImage 的第 i 行\r\n","\r\n            Create a star detector with the specific parameters\r\n            ":"\r\n            创建具有特定参数的星探测器\r\n            \r\n","\r\n            Returns Gabor filter coefficients.\r\n            ":"\r\n            返回 Gabor 滤波器系数。\r\n            \r\n","Found solution of the system.":"找到系统的解决方案。\r\n","Scale factor for marr wavelet.":"Marr 小波的比例因子。\r\n","The per-element minimum of two matrices of the same size, number of channels and depth":"相同大小、通道数和深度的两个矩阵的每个元素最小值\r\n","The first image to compare with":"要比较的第一张图片\r\n","\r\n            Check if the specific point is in the Cuboid\r\n            ":"\r\n            检查特定点是否在长方体中\r\n            \r\n"," image using a 3x3 rectangular structuring element.\r\n            Dilation are applied several (iterations) times\r\n            ":" 使用 3x3 矩形结构元素的图像。\r\n            扩张应用了几次（迭代）次\r\n            \r\n","The minimum area rectangle that contains both input rectangles inside":"包含两个输入矩形的最小面积矩形\r\n"," \r\n            Create an image of the same size\r\n            ":" \r\n            创建相同大小的图像\r\n            \r\n","Input array (multiple-channel, 8-bit or 32-bit floating point).":"输入数组（多通道、8 位或 32 位浮点数）。\r\n","\r\n            Convert Luv color to BGR color\r\n            ":"\r\n            将 Luv 颜色转换为 BGR 颜色\r\n            \r\n","Output array of x-coordinates of 2D vectors; it has the same size and type as angle.":"二维向量 x 坐标的输出数组；它与角度具有相同的大小和类型。\r\n","\r\n            Converts an image from BGR color space to LUV color space.\r\n            ":"\r\n            将图像从 BGR 色彩空间转换为 LUV 色彩空间。\r\n            \r\n","\r\n            Show Grid\r\n            ":"\r\n            显示网格\r\n            \r\n","\r\n            The chroma format\r\n            ":"\r\n            色度格式\r\n            \r\n","\r\n            Create a new Image Map defined by the Rectangle area. The center (0.0, 0.0) of this map is \r\n            defined by the center of the rectangle.\r\n            ":"\r\n            创建一个由矩形区域定义的新图像映射。这张地图的中心 (0.0, 0.0) 是\r\n            由矩形的中心定义。\r\n            \r\n","\r\n            Create a new HOGDescriptor\r\n            ":"\r\n            创建一个新的 HOGDescriptor\r\n            \r\n","the mask":"面具\r\n","VideoCapture class is NOT implemented in Open CV for Android, iOS or UWP platforms":"VideoCapture 类未在适用于 Android、iOS 或 UWP 平台的 Open CV 中实现\r\n","The maximum number of features to be detected.":"要检测的最大特征数。\r\n","Optional operation mask.":"可选操作面罩。\r\n","First input matrix to be considered for vertical concatenation.":"要考虑垂直串联的第一个输入矩阵。\r\n","\r\n            Create an standard vector of Point3D32F with the initial values\r\n            ":"\r\n            使用初始值创建 Point3D32F 的标准向量\r\n            \r\n","Initial transformation from the source frame to the destination one (optional)":"从源帧到目标帧的初始转换（可选）\r\n","\r\n            Keep aspect ratio\r\n            ":"\r\n            保持长宽比例\r\n            \r\n","The data stride (bytes per row)":"数据跨度（每行字节数）\r\n","The output 3x1 or 1x3 rotation vector (compact representation of a rotation matrix, see cvRodrigues2). ":"输出 3x1 或 1x3 旋转向量（旋转矩阵的紧凑表示，参见 cvRodrigues2）。\r\n","\r\n            Minimum Contours Area Rate\r\n            ":"\r\n            最小轮廓面积率\r\n            \r\n","\r\n            Convert YUV (UYNV) to Gray\r\n            ":"\r\n            将 YUV (UYNV) 转换为灰色\r\n            \r\n"," A Bgr image frame. If no more frames are available, null will be returned.":" Bgr 图像框架。如果没有更多的帧可用，则返回 null。\r\n","\r\n            Returns hardware revision number.\r\n            ":"\r\n            返回硬件修订号。\r\n            \r\n","\r\n            Read write\r\n            ":"\r\n            读写\r\n            \r\n","\r\n            StdVectorVector\r\n            ":"\r\n            StdVector向量\r\n            \r\n","Second input 2D point set containing (x,y).":"第二个输入二维点集包含 (x,y)。\r\n","The resulting GpuMat":"生成的 GpuMat\r\n","Return: CV_8U1 image mask where -1 indicates that the pixel is a superpixel border, and 0 otherwise.":"返回：CV_8U1 图像掩码 其中 -1 表示该像素是超像素边界，否则为 0。\r\n","Background reference image update parameter":"背景参考图像更新参数\r\n","\r\n            Edge-preserving interpolation\r\n            ":"\r\n            保边插值\r\n            \r\n","\r\n            Ip for enable multicast master mode. 0 for disable multicast\r\n            ":"\r\n            Ip 用于启用多播主模式。 0 表示禁用多播\r\n            \r\n","\r\n            Counts non-zero array elements\r\n            ":"\r\n            计算非零数组元素\r\n            \r\n","Filter sigma in the coordinate space. A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough (see sigmaColor ). When d>0 , it specifies the neighborhood size regardless of sigmaSpace. Otherwise, d is proportional to sigmaSpace.":"在坐标空间中过滤 sigma。较大的参数值意味着更远的像素将相互影响，只要它们的颜色足够接近（参见 sigmaColor ）。当 d>0 时，它指定邻域大小而不考虑 sigmaSpace。否则，d 与 sigmaSpace 成正比。\r\n","Number of disparities. Use 64 as default":"差距的数量。默认使用 64\r\n","\r\n            The name of the predefined dictionary\r\n            ":"\r\n            预定义词典的名称\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this simple blob detector parameter.\r\n            ":"\r\n            释放与这个简单的 blob 检测器参数关联的所有非托管内存。\r\n            \r\n","\r\n            Copy data from this Mat to the managed array\r\n            ":"\r\n            将数据从此 Mat 复制到托管数组\r\n            \r\n","The optional pointer to output array of N elements, every element of which is set to 0 for outliers and to 1 for the \"inliers\", i.e. points that comply well with the estimated epipolar geometry. The array is computed only in RANSAC and LMedS methods. For other methods it is set to all 1.":"指向 N 个元素的输出数组的可选指针，其中的每个元素都设置为 0 表示离群值，设置为 1 表示“内点”，即与估计的对极几何相符的点。该数组仅在 RANSAC 和 LMedS 方法中计算。对于其他方法，它设置为全 1。\r\n","\r\n            Get the current Cuda device id\r\n            ":"\r\n            获取当前的 Cuda 设备 ID\r\n            \r\n","Second camera distortion parameters.":"第二个相机畸变参数。\r\n","\r\n            Create a support Vector Machine\r\n            ":"\r\n            创建支持向量机\r\n            \r\n","\r\n            Release the CascadeClassifier Object and all the memory associate with it\r\n            ":"\r\n            释放 CascadeClassifier 对象及其关联的所有内存\r\n            \r\n","\r\n            Get the pointer to cv::_InputOutputArray\r\n            ":"\r\n            获取指向 cv::_InputOutputArray 的指针\r\n            \r\n","Comparison method":"比较法\r\n","The region where the point cloud will be generated. The axes of e corresponds to std of the random point cloud.":"将生成点云的区域。 e 的轴对应于随机点云的标准差。\r\n","If IntPtr.Zero, norm operation is apply to ":"如果 IntPtr.Zero，规范操作适用于\r\n","\r\n            libmfx (Intel MediaSDK/oneVPL)\r\n            ":"\r\n            libmfx（英特尔 MediaSDK/oneVPL）\r\n            \r\n"," Get or set the intensity of the y color channel ":" 获取或设置 y 颜色通道的强度\r\n","\r\n            Start index\r\n            ":"\r\n            起始索引\r\n            \r\n"," \r\n            Defines a Rgba (Red Green Blue Alpha) color\r\n            ":" \r\n            定义 Rgba（红绿蓝 Alpha）颜色\r\n            \r\n","\r\n            Flags used for GEMM function\r\n            ":"\r\n            用于 GEMM 函数的标志\r\n            \r\n","\r\n            create a detection\r\n            ":"\r\n            创建检测\r\n            \r\n","When true, original non-binary descriptors are returned":"为真时，返回原始非二进制描述符\r\n","\r\n            Set the parameters for the kernel\r\n            ":"\r\n            设置内核参数\r\n            \r\n","The type of optical flow algorithm to use":"使用的光流算法类型\r\n","Start point of the arrow.":"箭头的起点。\r\n","Output image with the board. The size of this image will be outSize and the board will be on the center, keeping the board proportions.":"用板子输出图像。此图像的大小将超出尺寸，并且板将位于中心，保持板的比例。\r\n","\r\n            Decode type\r\n            ":"\r\n            解码类型\r\n            \r\n","Size in pixels of the template patch that is used for block-matching. Should be power of 2.":"用于块匹配的模板补丁的大小（以像素为单位）。应该是2的幂。\r\n","\r\n            Collect messages with details.\r\n            ":"\r\n            收集带有详细信息的消息。\r\n            \r\n","An array of KeyPoint":"KeyPoint 数组\r\n","The second mat to AND":"AND 的第二个垫子\r\n","Scale Model Max Area":"比例模型最大面积\r\n","\r\n            Creates an instance of DisparityWLSFilter and sets up all the relevant filter parameters automatically based on the matcher instance. Currently supports only StereoBM and StereoSGBM.\r\n            ":"\r\n            创建 DisparityWLSFilter 的实例并根据匹配器实例自动设置所有相关的过滤器参数。目前仅支持 StereoBM 和 StereoSGBM。\r\n            \r\n","Indicates if the data should be continuous":"指示数据是否应该是连续的\r\n","Output disparity map. It has the same size as the input images. Some algorithms, like StereoBM or StereoSGBM compute 16-bit fixed-point disparity map (where each disparity value has 4 fractional bits), whereas other algorithms output 32-bit floating-point disparity map":"输出视差图。它具有与输入图像相同的大小。一些算法，如 StereoBM 或 StereoSGBM 计算 16 位定点视差图（其中每个视差值有 4 个小数位），而其他算法输出 32 位浮点视差图\r\n","\r\n            Enumeration used by cvFlip\r\n            ":"\r\n            cvFlip 使用的枚举\r\n            \r\n","Scalar value":"标量值\r\n","\r\n            set the correct path from which the algorithm will load the trained model. \r\n            ":"\r\n            设置算法将从中加载训练模型的正确路径。\r\n            \r\n","\r\n            Indicates the origin of the Geodetic Coordinate\r\n            ":"\r\n            指示大地坐标的原点\r\n            \r\n","\r\n            Create an empty standard vector of Double\r\n            ":"\r\n            创建 Double 的空标准向量\r\n            \r\n","\r\n            Create an empty standard vector of Point\r\n            ":"\r\n            创建 Point 的空标准向量\r\n            \r\n","\r\n            The event that will be raised when the unmanaged code send over data\r\n            ":"\r\n            非托管代码发送数据时将引发的事件\r\n            \r\n","\r\n            Convert Bayer GRBG color to BGR color\r\n            ":"\r\n            将 Bayer GRBG 颜色转换为 BGR 颜色\r\n            \r\n","\r\n            Open or create hdf5 file.\r\n            ":"\r\n            打开或创建 hdf5 文件。\r\n            \r\n","The type of Color":"颜色类型\r\n","\r\n            Create an EigenFaceRecognizer\r\n            ":"\r\n            创建一个 EigenFaceRecognizer\r\n            \r\n","\r\n            Encapculates Cuda Stream. Provides interface for async coping.\r\n            Passed to each function that supports async kernel execution.\r\n            Reference counting is enabled\r\n            ":"\r\n            封装 Cuda 流。为异步处理提供接口。\r\n            传递给支持异步内核执行的每个函数。\r\n            启用引用计数\r\n            \r\n","Wavelength of the sinusoidal factor.":"正弦因子的波长。\r\n","The type of GpuMat":"GpuMat 的类型\r\n","\r\n            Get the list of available DNN Backends\r\n            ":"\r\n            获取可用的 DNN 后端列表\r\n            \r\n","\r\n            A class that can be used for writing geotiff\r\n            ":"\r\n            一个可以用来写geotiff的类\r\n            \r\n","An byte array that contains the image as jpeg data":"包含图像作为 jpeg 数据的字节数组\r\n","\r\n            Descriptor matcher\r\n            ":"\r\n            描述符匹配器\r\n            \r\n","The ocl device with the specific index":"具有特定索引的 ocl 设备\r\n","The UMat from which to get image properties and data":"从中获取图像属性和数据的 UMat\r\n","The area of the connected component":"连通分量的面积\r\n","Maximum window size. Use Size.Empty for default, where the parameter will be ignored.":"最大窗口大小。默认使用 Size.Empty，参数将被忽略。\r\n","The operation flags":"操作标志\r\n","\r\n            Norm conv filter\r\n            ":"\r\n            范数转换过滤器\r\n            \r\n","\r\n            A MatND is a wrapper to cvMatND of OpenCV. \r\n            ":"\r\n            MatND 是 OpenCV 的 cvMatND 的包装器。\r\n            \r\n","\r\n            image height in pixels \r\n            ":"\r\n            以像素为单位的图像高度\r\n            \r\n"," The intensity of the gray color":" 灰色的强度\r\n","The second image to perform action on":"第二张要执行操作的图像\r\n","The first GMat contains the X coordinates, the second GMat contains the Y coordinates.":"第一个 GMat 包含 X 坐标，第二个 GMat 包含 Y 坐标。\r\n","\r\n            Indicates that Gaussian minus C should be used for adaptive threshold.\r\n            ":"\r\n            指示应将高斯减去 C 用于自适应阈值。\r\n            \r\n","\r\n            Left FOV in degree\r\n            ":"\r\n            左 FOV 度数\r\n            \r\n"," image ":" 图像\r\n"," \r\n            A line segment \r\n            ":" \r\n            一条线段\r\n            \r\n","The maximum/minimum value of the output array":"输出数组的最大值/最小值\r\n","\r\n            Reads the int from the node.\r\n            ":"\r\n            从节点读取 int。\r\n            \r\n","\r\n            Photoreceptors spatial constant. Use 0.53 for default\r\n            ":"\r\n            光感受器空间常数。默认使用 0.53\r\n            \r\n","Bottom-left/Top-left corner of the text string in the image.":"图像中文本字符串的左下角/左上角。\r\n","\r\n            Updates tone mapping behaviors by adjusting the local luminance computation area\r\n            ":"\r\n            通过调整局部亮度计算区域来更新色调映射行为\r\n            \r\n","\r\n            StdVectorCudaGpuMat\r\n            ":"\r\n            StdVectorCudaGpuMat\r\n            \r\n","Number of angle line":"角线数\r\n","\r\n            Create a new instance of GMSD quality measurement.\r\n            ":"创建 GMSD 质量测量的新实例。\r\n            \r\n","\r\n            Performs mean-shift filtering for each point of the source image. It maps each point of the source\r\n            image into another point, and as the result we have new color and new position of each point.\r\n            ":"\r\n            对源图像的每个点执行均值漂移过滤。它映射源的每个点\r\n            将图像转换成另一个点，结果我们得到了每个点的新颜色和新位置。\r\n            \r\n","A pointer to IplImage ":"指向 IplImage 的指针\r\n","\r\n            Gaussian elimination with optimal pivot element chose\r\n            In case of LU method the function returns src1 determinant (src1 must be square). If it is 0, the matrix is not inverted and src2 is filled with zeros.\r\n            ":"\r\n            选择最佳枢轴元素的高斯消去法\r\n            在 LU 方法的情况下，函数返回 src1 行列式（src1 必须是正方形）。如果为 0，则矩阵不反转并且 src2 填充为零。\r\n            \r\n","\r\n            Ask network to use specific computation backend where it supported.\r\n            ":"\r\n            要求网络在它支持的地方使用特定的计算后端。\r\n            \r\n","The gamma value":"伽马值\r\n","The destination matrix":"目标矩阵\r\n","\r\n            GetImage returns most recent frame\r\n            ":"\r\n            GetImage 返回最近的帧\r\n            \r\n","threshold for the ROI size":"ROI 大小的阈值\r\n","Flags Different flags for the calibration process":"Flags 校准过程的不同标志\r\n","\r\n            Frame rate \r\n            ":"\r\n            帧率\r\n            \r\n","\r\n            Converts an image from I420 color space to BGR color space.\r\n            ":"\r\n            将图像从 I420 色彩空间转换为 BGR 色彩空间。\r\n            \r\n","\r\n            Uses k-Means++ algorithm for initialization\r\n            ":"\r\n            使用k-Means++算法进行初始化\r\n            \r\n"," The result of elementwise adding mat2 to the current matrix":" 将mat2逐元素添加到当前矩阵的结果\r\n","\r\n            Convert YUV (Y422) to RGB\r\n            ":"\r\n            将 YUV (Y422) 转换为 RGB\r\n            \r\n","\r\n            Check that every array element is neither NaN nor +- inf. The functions also check that each value\r\n            is between minVal and maxVal. in the case of multi-channel arrays each channel is processed\r\n            independently. If some values are out of range, position of the first outlier is stored in pos, \r\n            and then the functions either return false (when quiet=true) or throw an exception.\r\n            ":"\r\n            检查每个数组元素既不是 NaN 也不是 +- inf。这些函数还检查每个值\r\n            介于 minVal 和 maxVal 之间。在多通道阵列的情况下，每个通道都被处理\r\n            独立地。如果某些值超出范围，则第一个异常值的位置存储在 pos 中，\r\n            然后函数返回 false（当 quiet=true 时）或抛出异常。\r\n            \r\n","\r\n            Get the width of the mat\r\n            ":"\r\n            获取垫子的宽度\r\n            \r\n","The depth of the src image":"src图像的深度\r\n","This row-vector corresponds to c in the LP problem formulation (see above). It should contain 32- or 64-bit floating point numbers. As a convenience, column-vector may be also submitted, in the latter case it is understood to correspond to c^T.":"此行向量对应于 LP 问题公式中的 c（见上文）。它应包含 32 位或 64 位浮点数。为了方便，也可以提交column-vector，后者理解为对应c^T。\r\n","\r\n            Return the code to generate this MCvScalar from specific language\r\n            ":"\r\n            返回代码以从特定语言生成此 MCvScalar\r\n            \r\n","Source image - 32-bit 3-channel Mat":"源图像 - 32 位 3 通道垫\r\n","\r\n            Applies the joint bilateral filter to an image.\r\n            ":"\r\n            将联合双边过滤器应用于图像。\r\n            \r\n","The color value to be subtracted from the current image":"要从当前图像中减去的颜色值\r\n","\r\n            Create a Input array from an existing unmanaged inputArray pointer\r\n            ":"\r\n            从现有的非托管 inputArray 指针创建输入数组\r\n            \r\n","Desired output matrix type or, rather, the depth since the number of channels are the same as the input has; if rtype is negative, the output matrix will have the same type as the input.":"所需的输出矩阵类型，或者更确切地说，深度，因为通道数与输入相同；如果 rtype 为负，则输出矩阵将具有与输入相同的类型。\r\n","\r\n            XML/YAML file storage class that encapsulates all the information necessary for writing or reading data to/from a file.\r\n            ":"\r\n            XML/YAML 文件存储类，封装了向文件写入数据或从文件读取数据所需的所有信息。\r\n            \r\n","Output rotation vectors (see Rodrigues ) that, together with tvecs , brings points from the model coordinate system to the camera coordinate system. A P3P problem has up to 4 solutions.":"输出旋转矢量（参见 Rodrigues ），与 tvecs 一起将点从模型坐标系带到相机坐标系。一个 P3P 问题最多有 4 个解。\r\n","\r\n            Perform an element wise AND operation on the two mats\r\n            ":"\r\n            在两个垫子上执行元素明智的 AND 操作\r\n            \r\n","Output image with the same size and type as src.":"输出与 src 具有相同大小和类型的图像。\r\n","R-channel multiply factor. Multiplication factor is between .5 to 2.5.":"R 通道乘数。乘数在 0.5 到 2.5 之间。\r\n","\r\n            (open, read) determined from file/codec input. If not specified, then selected audio sample rate is 44100\r\n            ":"\r\n            （打开，读取）由文件/编解码器输入确定。如果没有指定，那么选择的音频采样率为 44100\r\n            \r\n","\r\n            Release the IplImage\r\n            ":"\r\n            释放 IplImage\r\n            \r\n","\r\n            Second blob file\r\n            ":"\r\n            第二个 blob 文件\r\n            \r\n","\r\n            Returns true if the node is an integer\r\n            ":"\r\n            如果节点是整数则返回真\r\n            \r\n","\r\n            Openni generator registration on\r\n            ":"\r\n            Openni 生成器注册\r\n            \r\n","\r\n            The power of the method is fully expressed when inserting objects with complex outlines into a new background\r\n            ":"\r\n            当将具有复杂轮廓的对象插入到新背景中时，该方法的威力得到充分体现\r\n            \r\n","\r\n            Computes Hand-Eye calibration\r\n            ":"\r\n            计算手眼校准\r\n            \r\n","The output min and max values":"输出最小值和最大值\r\n","\r\n            The name of the layer\r\n            ":"\r\n            层的名称\r\n            \r\n","Weights":"重量\r\n","The point to be rotated":"要旋转的点\r\n","\r\n            A DataLogger for unmanaged code to log data back to managed code, using callback.\r\n            ":"\r\n            用于非托管代码的 DataLogger，使用回调将数据记录回托管代码。\r\n            \r\n","\r\n            Android focus distance optimal\r\n            ":"\r\n            Android对焦距离最优\r\n            \r\n","The relative or absolute path to the file containing the pretrained weights of the model in caffe-binary form.":"包含 Caffe 二进制形式的模型预训练权重的文件的相对或绝对路径。\r\n","\r\n            Perform grouping in any orientation.\r\n            ":"\r\n            在任何方向上执行分组。\r\n            \r\n","The aperture size for edge blur":"边缘模糊的光圈大小\r\n","The Matrix to be multiplied":"要相乘的矩阵\r\n","\r\n            Do inverse 1D or 2D transform. The result is not scaled. CV_DXT_FORWARD and CV_DXT_INVERSE are mutually exclusive, of course\r\n            ":"\r\n            进行一维或二维逆变换。结果未缩放。 CV_DXT_FORWARD 和 CV_DXT_INVERSE 当然是互斥的\r\n            \r\n","\r\n            Robot Sensor Calibration: Solving AX = XB on the Euclidean Group\r\n            ":"\r\n            机器人传感器校准：在欧氏群上求解 AX = XB\r\n            \r\n","\r\n            border const, ignored by OpenCV \r\n            ":"\r\n            边界常量，被 OpenCV 忽略\r\n            \r\n","\r\n            The size of CvMat\r\n            ":"\r\n            CvMat 的大小\r\n            \r\n","\r\n            The file storage operation type\r\n            ":"\r\n            文件存储操作类型\r\n            \r\n","Explicit framework name tag to determine a format.":"确定格式的显式框架名称标记。\r\n","\r\n            Get the module format string.\r\n            ":"\r\n            获取模块格式字符串。\r\n            \r\n","\r\n            Jet\r\n            ":"\r\n            喷射\r\n            \r\n","\r\n            Normal distribution\r\n            ":"\r\n            正态分布\r\n            \r\n","\r\n            Thinning technique of Guo-Hall\r\n            ":"\r\n            郭厅的间苗技术\r\n            \r\n","The line segment to be drawn":"要绘制的线段\r\n","The scale to be multiplied":"要乘以的比例\r\n","\r\n            Runs page layout analysis in the mode set by SetPageSegMode. May optionally be called prior to Recognize to get access to just the page layout results. Returns an iterator to the results. Returns NULL on error or an empty page. The returned iterator must be deleted after use. WARNING! This class points to data held within the TessBaseAPI class, and therefore can only be used while the TessBaseAPI class still exists and has not been subjected to a call of Init, SetImage, Recognize, Clear, End DetectOS, or anything else that changes the internal PAGE_RES.\r\n            ":"\r\n            以 SetPageSegMode 设置的模式运行页面布局分析。可以选择在 Recognize 之前调用以仅访问页面布局结果。返回结果的迭代器。错误或空白页返回 NULL。返回的迭代器在使用后必须删除。警告！此类指向 TessBaseAPI 类中保存的数据，因此只能在 TessBaseAPI 类仍然存在且未受到 Init、SetImage、Recognize、Clear、End DetectOS 或任何其他更改内部的调用时使用PAGE_RES。\r\n            \r\n","\r\n            Class implementing the SEEDS (Superpixels Extracted via Energy-Driven Sampling) superpixels algorithm described in Michael Van den Bergh, Xavier Boix, Gemma Roig, Benjamin de Capitani, and Luc Van Gool. Seeds: Superpixels extracted via energy-driven sampling. In Computer Vision-ECCV 2012, pages 13-26. Springer, 2012.\r\n            ":"\r\n            类实现了 Michael Van den Bergh、Xavier Boix、Gemma Roig、Benjamin de Capitani 和 Luc Van Gool 中描述的 SEEDS（通过能量驱动采样提取的超像素）超像素算法。种子：通过能量驱动采样提取的超像素。在 Computer Vision-ECCV 2012，第 13-26 页。施普林格，2012 年。\r\n            \r\n","\r\n            Eig\r\n            ":"\r\n            艾格\r\n            \r\n","if true, the last line segment is defined by the last point of the array and the first point of the array":"如果为真，则最后一条线段由数组的最后一个点和数组的第一个点定义\r\n","\r\n            Col by col\r\n            ":"\r\n            逐列\r\n            \r\n","\r\n            Converts an image from BGR color space to gray-scaled.\r\n            ":"\r\n            将图像从 BGR 颜色空间转换为灰度。\r\n            \r\n"," or its selected region, raised to power 2, to the accumulator sqsum\r\n            ":" 或其选定区域，提高到 2 次方，到累加器 sqsum\r\n            \r\n","The plot grid color":"绘图网格颜色\r\n","\r\n            Gets or sets the data as byte array.\r\n            ":"\r\n            获取或设置字节数组形式的数据。\r\n            \r\n","The max value of this range":"该范围的最大值\r\n","Flags, use 0 if not sure":"标志，如果不确定则使用 0\r\n","\r\n            Performs Principal Component Analysis of the supplied dataset.\r\n            ":"\r\n            对提供的数据集执行主成分分析。\r\n            \r\n","The result of the indices of the k-nearest neighbours":"k-最近邻索引的结果\r\n","\r\n            Get the depth type\r\n            ":"\r\n            获取深度类型\r\n            \r\n","True if the binary map is sucessfully computed":"如果成功计算了二进制映射，则为真\r\n","\r\n            N\r\n            ":"\r\n            否\r\n            \r\n","A buffer consisting of inputImage.Size() / getGridSize() flow vectors in CV_16SC2 format.":"由 CV_16SC2 格式的 inputImage.Size() / getGridSize() 流向量组成的缓冲区。\r\n"," \r\n            The time this image is captured\r\n            ":" \r\n            捕获此图像的时间\r\n            \r\n","\r\n            Estimates transformation between the 2 cameras making a stereo pair. If we have a stereo camera, where the relative position and orientatation of the 2 cameras is fixed, and if we computed poses of an object relative to the first camera and to the second camera, (R1, T1) and (R2, T2), respectively (that can be done with cvFindExtrinsicCameraParams2), obviously, those poses will relate to each other, i.e. given (R1, T1) it should be possible to compute (R2, T2) - we only need to know the position and orientation of the 2nd camera relative to the 1st camera. That's what the described function does. It computes (R, T) such that:\r\n            R2=R*R1,\r\n            T2=R*T1 + T\r\n            ":"\r\n            估计构成立体对的 2 个摄像机之间的转换。如果我们有一个立体相机，其中两个相机的相对位置和方向是固定的，如果我们计算一个物体相对于第一个相机和第二个相机的姿态，(R1, T1) 和 (R2, T2) ，分别（可以用cvFindExtrinsicCameraParams2完成），显然，这些姿势将相互关联，即给定（R1，T1）应该可以计算（R2，T2） - 我们只需要知道位置和方向第二台摄像机相对于第一台摄像机。这就是所描述的函数的作用。它计算 (R, T) 这样：\r\n            R2=R*R1,\r\n            T2=R*T1 + T\r\n            \r\n","\r\n            number of landmark points\r\n            ":"\r\n            地标点数\r\n            \r\n","Aperture parameter for Sobel operator ":"Sobel 算子的孔径参数\r\n","Number of times erosion and dilation are applied":"应用腐蚀和膨胀的次数\r\n","The transformed image.":"转换后的图像。\r\n","activate the resize feature to improve the processing speed":"激活调整大小功能以提高处理速度\r\n","\r\n            This class contains the information about the detected checkers,i.e, their type, the corners of the chart, the color profile, the cost, centers chart, etc.\r\n            ":"\r\n            此类包含有关检测到的棋子的信息，即它们的类型、图表的角、颜色配置文件、成本、中心图表等。\r\n            \r\n","The type of depth of the cvArray":"cvArray 的深度类型\r\n","Nms radius":"Nms 半径\r\n","Line color ":"线条颜色\r\n","If true, a more accurate L2 norm should be used to calculate the image gradient magnitude.":"如果为真，则应使用更准确的 L2 范数来计算图像梯度大小。\r\n"," <= 0 stands for disable this prune.":" <= 0 代表禁用此修剪。\r\n","Enable orientation normalization":"启用方向规范化\r\n","\r\n            Predict options\r\n            ":"\r\n            预测选项\r\n            \r\n","\r\n            Return true if the detector is empty\r\n            ":"\r\n            如果检测器为空则返回真\r\n            \r\n","\r\n            Return the header, corresponding to a specified col span of the input array\r\n            ":"\r\n            返回标题，对应于输入数组的指定列范围\r\n            \r\n","The blender":"搅拌机\r\n","\r\n            Read specific keypoint dataset from hdf5 file into VectorOfKeyPoint object.\r\n            ":"\r\n            从 hdf5 文件中读取特定关键点数据集到 VectorOfKeyPoint 对象中。\r\n            \r\n","\r\n            Computes magnitude of each (x(i), y(i)) vector\r\n            ":"\r\n            计算每个 (x(i), y(i)) 向量的大小\r\n            \r\n","\r\n            Entry points to the Open CV Surface Matching module\r\n            ":"\r\n            Open CV 表面匹配模块的入口点\r\n            \r\n","Line thickness.":"线的粗细。\r\n","\r\n            The class implements a standard Kalman filter. However, you can modify transitionMatrix, controlMatrix, and measurementMatrix to get\r\n            an extended Kalman filter functionality.\r\n            ":"\r\n            该类实现了标准的卡尔曼滤波器。但是，您可以修改 transitionMatrix、controlMatrix 和 measurementMatrix 以获得\r\n            扩展的卡尔曼滤波器功能。\r\n            \r\n","\r\n            Clear the tracker state\r\n            ":"\r\n            清除跟踪器状态\r\n            \r\n","\r\n            Convert YUV (UYVY) to RGBA\r\n            ":"\r\n            将 YUV (UYVY) 转换为 RGBA\r\n            \r\n","Second input matrix of the same size and channel number as src1":"与 src1 具有相同大小和通道号的第二个输入矩阵\r\n","Bitwise logical disjunction of a matrix and a scalar":"矩阵和标量的按位逻辑或\r\n","true if the two boxes equals":"如果两个框相等则为真\r\n","\r\n            Convert Bayer GR color to RGB color\r\n            ":"\r\n            将 Bayer GR 颜色转换为 RGB 颜色\r\n            \r\n","All the methods that belongs to the IImage and Image class with ExposableMethodAttribute set true":"属于 IImage 和 Image 类且 ExposableMethodAttribute 设置为 true 的所有方法\r\n","\r\n            Pointer to the unmanaged TessResultRendered\r\n            ":"\r\n            指向非托管 TessResultRendered 的指针\r\n            \r\n","\r\n            Convert Bayer GRBG pattern to BGR color using VNG\r\n            ":"\r\n            使用 VNG 将 Bayer GRBG 图案转换为 BGR 颜色\r\n            \r\n","\r\n            Image editing tasks concern either global changes (color/intensity corrections, filters, deformations) or local changes concerned to a selection. Here we are interested in achieving local changes, ones that are restricted to a region manually selected (ROI), in a seamless and effortless manner. The extent of the changes ranges from slight distortions to complete replacement by novel content \r\n            ":"\r\n            图像编辑任务涉及全局变化（颜色/强度校正、滤镜、变形）或与选择相关的局部变化。在这里，我们有兴趣以无缝和轻松的方式实现局部变化，这些变化仅限于手动选择的区域 (ROI)。变化的程度从轻微扭曲到完全被新内容替代\r\n            \r\n","\r\n            Represent a int value in C++\r\n            ":"\r\n            在 C++ 中表示一个 int 值\r\n            \r\n","The line to be draw":"要画的线\r\n","The left single-channel, 8-bit image":"左侧单通道，8 位图像\r\n","\r\n            Creates kernel from basic functions.\r\n            ":"\r\n            从基本函数创建内核。\r\n            \r\n","\r\n            Blurs an image using the box filter.\r\n            ":"\r\n            使用盒式过滤器模糊图像。\r\n            \r\n","\r\n            Add a new object to be tracked. The defaultAlgorithm will be used the newly added tracker.\r\n            ":"\r\n            添加要跟踪的新对象。 defaultAlgorithm 将用于新添加的跟踪器。\r\n            \r\n","\r\n            Calculates per-element minimum of two arrays:\r\n            dst(I)=min(src1(I),src2(I))\r\n            All the arrays must have a single channel, the same data type and the same size (or ROI size).\r\n            ":"\r\n            计算两个数组的每个元素的最小值：\r\n            dst(I)=min(src1(I),src2(I))\r\n            所有数组必须具有单个通道、相同的数据类型和相同的大小（或 ROI 大小）。\r\n            \r\n","Translation between mesh and camera. Input values are used as an initial solution.":"网格和相机之间的转换。输入值用作初始解决方案。\r\n"," Compute the element of the new image based on the elements of the three image":" 根据三个图像的元素计算新图像的元素\r\n","\r\n            An error handler which will ignore any error and continue\r\n            ":"\r\n            一个错误处理程序，它将忽略任何错误并继续\r\n            \r\n","\r\n            Enables modification of matrix src1 during the operation. It speeds up the processing. \r\n            ":"\r\n            在操作期间启用矩阵 src1 的修改。它加快了处理速度。\r\n            \r\n","The destination CudaImage, should have 2x smaller width and height than the source.":"目标 CudaImage 的宽度和高度应比源图像小 2 倍。\r\n","\r\n            Converts an image from RGB color space to gray-scaled.\r\n            ":"\r\n            将图像从 RGB 颜色空间转换为灰度。\r\n            \r\n","The source image color type":"源图像颜色类型\r\n","Output array of the same type as src.  The size is the same with ROTATE_180, and the rows and cols are switched for ROTATE_90 and ROTATE_270.":"与 src 相同类型的输出数组。大小与ROTATE_180相同，ROTATE_90和ROTATE_270的行列互换。\r\n","Rotation between mesh and camera. Input values are used as an initial solution.":"网格和相机之间的旋转。输入值用作初始解决方案。\r\n","\r\n            Returns coefficients of the classifier trained for people detection (for default window size).\r\n            ":"\r\n            返回为人员检测训练的分类器的系数（对于默认窗口大小）。\r\n            \r\n","\r\n            Bad Offset\r\n            ":"\r\n            不良偏移\r\n            \r\n","Parameter specifying how the IplImage COI (when set) is handled. If coiMode=0 and COI is set, the function reports an error. If coiMode=1 , the function never reports an error. Instead, it returns the header to the whole original image and you will have to check and process COI manually. ":"指定如何处理 IplImage COI（设置时）的参数。如果 coiMode=0 并且设置了 COI，函数会报错。如果 coiMode=1 ，函数从不报告错误。相反，它将标题返回到整个原始图像，您将不得不手动检查和处理 COI。\r\n","This method calculates saliency based on center-surround differences. High resolution saliency maps are generated in real time by using integral images.":"该方法根据中心-环绕差异计算显着性。高分辨率显着图是通过使用积分图像实时生成的。\r\n","\r\n            Calculates the sum of a scaled array and another array.\r\n            ":"\r\n            计算缩放数组和另一个数组的总和。\r\n            \r\n","\r\n            Retrieve only the extreme outer contours \r\n            ":"\r\n            只检索最外层的轮廓\r\n            \r\n","\r\n            Convert GRAY color to BGR color\r\n            ":"\r\n            将 GRAY 颜色转换为 BGR 颜色\r\n            \r\n","\r\n            Specify this mode when calling init_*(),\r\n            to indicate that any of the above modes\r\n            should be automatically inferred from the\r\n            variables in the language-specific config,\r\n            command-line configs, or if not specified\r\n            in any of the above should be set to the\r\n            default OEM_TESSERACT_ONLY.\r\n            ":"\r\n            调用init_*()时指定该模式，\r\n            表示上述任何一种模式\r\n            应该自动从\r\n            语言特定配置中的变量，\r\n            命令行配置，或者如果未指定\r\n            在以上任何一项中都应设置为\r\n            默认 OEM_TESSERACT_ONLY。\r\n            \r\n","\r\n            Output callback\r\n            ":"\r\n            输出回调\r\n            \r\n","\r\n            norm = ||arr1-arr2||_L1/||arr2||_L1\r\n            ":"\r\n            范数 = ||arr1-arr2||_L1/||arr2||_L1\r\n            \r\n","\r\n            Convert YUV (YUY2) to Gray\r\n            ":"\r\n            将 YUV (YUY2) 转换为灰色\r\n            \r\n","Gradient constancy importance":"梯度恒常重要性\r\n","The shape transformer":"形状变换器\r\n","The data type of the vector":"向量的数据类型\r\n","The minimum enclosing rectangle for this Box":"此 Box 的最小外接矩形\r\n","Name of the input video file.":"输入视频文件的名称。\r\n","Layout of the board that will be drawn. The board should be planar, z coordinate is ignored":"将绘制的板的布局。电路板应该是平面的，忽略 z 坐标\r\n","Input image, 1- or 3-channel, 8-bit or 32-bit floating point (each channel of multi-channel image is processed independently). ":"输入图像，1 或 3 通道，8 位或 32 位浮点数（多通道图像的每个通道独立处理）。\r\n","Aspect ratio":"纵横比\r\n","\r\n            Add the descriptors to the trainer\r\n            ":"\r\n            将描述符添加到培训师\r\n            \r\n","number of frames with same pixel color to consider stable":"考虑稳定的具有相同像素颜色的帧数\r\n","Oriented area flag. If it is true, the function returns a signed area value, depending on the contour orientation (clockwise or counter-clockwise).\r\n            Using this feature you can determine orientation of a contour by taking the sign of an area. \r\n            By default, the parameter is false, which means that the absolute value is returned.":"定向区域标志。如果为真，则函数返回带符号的面积值，具体取决于轮廓方向（顺时针或逆时针）。\r\n            使用此功能，您可以通过获取区域的符号来确定轮廓的方向。\r\n            默认情况下，该参数为false，即返回绝对值。\r\n","The locale category":"语言环境类别\r\n","\r\n            Point falls into some facet\r\n            ":"\r\n            点落入某个面\r\n            \r\n","If true sample pixel locations are chosen at random, otherwise the form a rectangular grid.":"如果真正的样本像素位置是随机选择的，否则形成一个矩形网格。\r\n","images will get resized to this (should be an even number)":"图像将调整为此大小（应该是偶数）\r\n","Source image for filtering with unsigned 8-bit or signed 16-bit or floating-point depth.":"用于使用无符号 8 位或有符号 16 位或浮点深度进行过滤的源图像。\r\n","\r\n            gpuMatReshape the src GpuMat  \r\n            ":"\r\n            gpuMatReshape the src GpuMat\r\n            \r\n","Output 8-bit 1-channel image":"输出 8 位 1 通道图像\r\n","\r\n            Predict the label of the image\r\n            ":"\r\n            预测图像的标签\r\n            \r\n","\r\n            Non-maximum suppression threshold\r\n            ":"\r\n            非最大抑制阈值\r\n            \r\n","\r\n            The match distance type\r\n            ":"\r\n            匹配距离类型\r\n            \r\n","pixel extrapolation method":"像素外推法\r\n","\r\n            Capture only preview from liveview mode.\r\n            ":"\r\n            仅从实时取景模式捕获预览。\r\n            \r\n","The file node, The file may contain a new cascade classifier only.":"文件节点，文件可能只包含一个新的级联分类器。\r\n","The transpose of this matrix":"这个矩阵的转置\r\n","\r\n            Create a clone of this CudaImage\r\n            ":"\r\n            创建此 CudaImage 的克隆\r\n            \r\n","Input image: 8-bit unsigned 3-channel.":"输入图像：8 位无符号 3 通道。\r\n","\r\n            Release all the unmanaged memory associated with this framesource\r\n            ":"\r\n            释放与此 framesource 关联的所有非托管内存\r\n            \r\n","Output vector of rotation vectors (see Rodrigues ) estimated for each board view (e.g. std::vector<cv::Mat>). That is, each k-th rotation vector together with the corresponding k-th translation vector (see the next output parameter description) brings the board pattern from the model coordinate space (in which object points are specified) to the world coordinate space, that is, a real position of the board pattern in the k-th pattern view (k=0.. M -1).":"为每个板视图（例如 std::vector<cv::Mat>）估计的旋转向量的输出向量（参见 Rodrigues）。也就是说，每个第k个旋转向量连同对应的第k个平移向量（见下一个输出参数说明）将板图从模型坐标空间（其中指定了对象点）带到世界坐标空间，即是第k个图案视图（k=0.. M -1）中棋盘图案的真实位置。\r\n","Number of kernel channels.":"内核通道数。\r\n","\r\n            Random Number Generator.\r\n            ":"\r\n            随机数生成器。\r\n            \r\n","edge image from DetectEdges function.":"来自 DetectEdges 函数的边缘图像。\r\n"," Get or set the intensity of the blue color channel ":" 获取或设置蓝色通道的强度\r\n","\r\n            Initialize the TBB task scheduler\r\n            ":"\r\n            初始化 TBB 任务调度器\r\n            \r\n","\r\n            Draw the polyline defined by the array of 2D points\r\n            ":"\r\n            绘制由二维点数组定义的折线\r\n            \r\n","\r\n            Camera exposure program.\r\n            ":"\r\n            相机曝光程序。\r\n            \r\n","The global size":"全球规模\r\n","\r\n            StdBoolVector\r\n            ":"\r\n            标准布尔向量\r\n            \r\n","\r\n            For each scale factor used the function will downscale the image rather than \"zoom\" the feature coordinates in the classifier cascade. Currently, the option can only be used alone, i.e. the flag can not be set together with the others\r\n            ":"\r\n            对于使用的每个比例因子，函数将缩小图像而不是“缩放”分类器级联中的特征坐标。目前该选项只能单独使用，即flag不能和其他一起设置\r\n            \r\n","Destination image of the same size and type as src.":"与 src 具有相同大小和类型的目标图像。\r\n","The GpuMat. Supports only CV_8UC1 type":"GpuMat。仅支持 CV_8UC1 类型\r\n","Color of the circle.":"圆圈的颜色。\r\n","The second image for the XOR operation":"异或运算的第二张图片\r\n","image serving as guide for filtering. It should have 8-bit depth and either 1 or 3 channels.":"用作过滤指南的图像。它应该有 8 位深度和 1 或 3 个通道。\r\n","The image such that: dst(x,y) = max_value, if src(x,y)>threshold; 0, otherwise ":"图像满足：dst(x,y) = max_value，如果 src(x,y)>threshold； 0，否则\r\n","list of 4 ids for each ArUco marker in the ChArUco marker.":"ChArUco 标记中每个 ArUco 标记的 4 个 ID 列表。\r\n","\r\n            Create an average hash object.\r\n            ":"\r\n            创建一个平均哈希对象。\r\n            \r\n","Knn":"克恩\r\n","\r\n            OT\r\n            ":"\r\n            加时赛\r\n            \r\n","\r\n            Edge fill color\r\n            ":"\r\n            边缘填充颜色\r\n            \r\n","\r\n            Create a CudaImage of the specific size\r\n            ":"\r\n            创建特定大小的 CudaImage\r\n            \r\n","\r\n            Pointer to the unmanaged cv::DenseOpticalFlow\r\n            ":"\r\n            指向非托管 cv::DenseOpticalFlow 的指针\r\n            \r\n","The image to compute descriptors from":"从中计算描述符的图像\r\n","\r\n            Light adaptation in [0, 1] range. If 1 adaptation is based only on pixel value, if 0 it is global, otherwise it is a weighted mean of this two cases.\r\n            ":"\r\n            [0, 1] 范围内的光照适应。如果 1 自适应仅基于像素值，如果为 0 则它是全局的，否则它是这两种情况的加权平均值。\r\n            \r\n","\r\n            Finds line segments in a binary image using the probabilistic Hough transform.\r\n            ":"\r\n            使用概率霍夫变换在二值图像中查找线段。\r\n            \r\n","A value used to fill outliers":"用于填充异常值的值\r\n","Rotation between mesh and camera":"网格和相机之间的旋转\r\n","\r\n            Draws contour outlines in the image if thickness>=0 or fills area bounded by the contours if thickness<0\r\n            ":"\r\n            如果 thickness>=0，则在图像中绘制轮廓轮廓；如果 thickness<0，则填充由轮廓包围的区域\r\n            \r\n","The minimal circumscribed circle for 2D point set":"二维点集的最小外接圆\r\n","\r\n            Create a Ridge detection filter.\r\n            ":"\r\n            创建脊检测过滤器。\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this detector\r\n            ":"\r\n            释放与此检测器关联的所有非托管内存\r\n            \r\n","4 or 8 way connectivity":"4 或 8 路连接\r\n","Determines maximal radius of signature in the output image.":"确定输出图像中签名的最大半径。\r\n","\r\n            Convert YUV420i to RGB\r\n            ":"\r\n            将 YUV420i 转换为 RGB\r\n            \r\n","The power image":"电源图像\r\n","The value to convert to":"要转换为的值\r\n","The seam finder":"接缝查找器\r\n","\r\n            Get the reliability map computed from the wrapped phase map.\r\n            ":"\r\n            获取从包装相位图计算的可靠性图。\r\n            \r\n","Output image with the same size and type as src .":"输出与 src 具有相同大小和类型的图像。\r\n","The steps":"步骤\r\n","Assigned scalar value.":"分配的标量值。\r\n","\r\n            Horizontal Binning - number of horizontal photo-sensitive cells to combine together.\r\n            ":"\r\n            Horizo​​ntal Binning - 要组合在一起的水平光敏单元的数量。\r\n            \r\n","\r\n            Probability that the ER belongs to the class we are looking for\r\n            ":"\r\n            ER 属于我们正在寻找的类别的概率\r\n            \r\n","The optional output disparity-to-depth mapping matrix, 4x4, see cvReprojectImageTo3D. ":"可选的输出视差到深度映射矩阵，4x4，参见 cvReprojectImageTo3D。\r\n","\r\n            Boost Type\r\n            ":"\r\n            升压类型\r\n            \r\n","Name of the window.":"窗口的名称。\r\n","gamma value for gamma correction. ":"伽玛校正的伽玛值。\r\n","\r\n            FrameWidth\r\n            ":"\r\n            帧宽\r\n            \r\n","Back projection of object histogram":"对象直方图的反投影\r\n","input image(s) to use as the source for comparison":"用作比较源的输入图像\r\n"," The Y value for this color ":" 此颜色的 Y 值\r\n","\r\n            Create an empty cv::Mat\r\n            ":"\r\n            创建一个空的 cv::Mat\r\n            \r\n","\r\n            Text string in UTF-8 encoding\r\n            ":"\r\n            UTF-8 编码的文本字符串\r\n            \r\n","Number of histogram bins.":"直方图 bin 的数量。\r\n","\r\n            Parameter gamma of a kernel function\r\n            ":"\r\n            核函数的参数 gamma\r\n            \r\n","\r\n              |-1 -2 -1|\r\n              | 0  0  0|\r\n              | 1  2  1|":"\r\n              |-1 -2 -1|\r\n              | 0 0 0|\r\n              | 1 2 1|\r\n","\r\n            Entry points to the Open CV bioinspired module\r\n            ":"\r\n            Open CV bioinspired 模块的入口点\r\n            \r\n","The value of the specific property":"具体财产的价值\r\n","\r\n            Convert BGR555 color to GRAY color\r\n            ":"\r\n            将 BGR555 颜色转换为 GRAY 颜色\r\n            \r\n","\r\n            Counter clockwise\r\n            ":"\r\n            逆时针\r\n            \r\n","The ocl image":"ocl图像\r\n","\r\n            Sets the specified property of video capture\r\n            ":"\r\n            设置视频采集的指定属性\r\n            \r\n","The output array where the image will be read into.":"图像将被读入的输出数组。\r\n","\r\n            Returns a GpuMat corresponding to the ith row of the GpuMat. The data is shared with the current GpuMat. \r\n            ":"\r\n            返回对应于 GpuMat 的第 i 行的 GpuMat。数据与当前的 GpuMat 共享。\r\n            \r\n","\r\n            Get the number of pattern images needed for the graycode pattern\r\n            ":"\r\n            获取灰码图案所需的图案图像数量\r\n            \r\n","radius for gathering positive instances during init":"在 init 期间收集正例的半径\r\n","Approximation method (for all the modes, except CV_RETR_RUNS, which uses built-in approximation). ":"近似方法（对于所有模式，CV_RETR_RUNS 除外，它使用内置近似）。\r\n","\r\n            Sequence constants\r\n            ":"\r\n            序列常量\r\n            \r\n","\r\n            Create an empty standard vector of ERStat\r\n            ":"\r\n            创建 ERStat 的空标准向量\r\n            \r\n","The input samples, floating-point matrix.":"输入样本，浮点矩阵。\r\n","It should be either 1 or 3 channel matrix of 1x256":"它应该是 1x256 的 1 或 3 通道矩阵\r\n","Distance resolution of the accumulator in pixels":"累加器的距离分辨率（以像素为单位）\r\n","\r\n            ChiSquare\r\n            ":"\r\n            卡方\r\n            \r\n"," Threshold the image inplace such that: dst(x,y) = max_value, if src(x,y)>threshold; 0, otherwise ":" 对图像进行阈值处理，使得：dst(x,y) = max_value，如果 src(x,y)>threshold； 0，否则\r\n","Per-element sum of two matrices.":"两个矩阵的每个元素之和。\r\n","\r\n            Swap channels.\r\n            ":"\r\n            交换频道。\r\n            \r\n","\r\n            Reads the string from the node\r\n            ":"\r\n            从节点读取字符串\r\n            \r\n","\r\n            z-coordinate\r\n            ":"\r\n            z坐标\r\n            \r\n","\r\n            Entry points for the DepthAI module.\r\n            ":"\r\n            DepthAI 模块的入口点。\r\n            \r\n","Mode of operation":"操作模式\r\n","\r\n            Cuda compute 2.1\r\n            ":"\r\n            Cuda 计算 2.1\r\n            \r\n","Source image. Supports 1, 3 or 4 channels images with Byte, UInt16 or float depth":"源图像。支持具有字节、UInt16 或浮点深度的 1、3 或 4 通道图像\r\n","\r\n            4-connected\r\n            ":"\r\n            4-连接\r\n            \r\n","floating-point 2×3 or 3×3 mapping matrix (warp).":"浮点 2×3 或 3×3 映射矩阵（扭曲）。\r\n","The final enhanced correlation coefficient, that is the correlation coefficient between the template image and the final warped input image.":"最终增强相关系数，即模板图像与最终变形输入图像之间的相关系数。\r\n","The destination image, result of transformation.":"目标图像，转换结果。\r\n","The first zero-based component of the element index":"元素索引的第一个从零开始的组件\r\n","Array of double numbers containing difference between patches around the original and moved points":"包含原始点和移动点周围补丁之间差异的双精度数组\r\n","The other MatND to compares to":"另一个 MatND 比较\r\n","Distance resolution in pixel-related units.":"像素相关单位的距离分辨率。\r\n","The String value":"字符串值\r\n","the shift factor to apply during conversion (defaults to 0.0 -- no shifting)":"转换期间应用的移位因子（默认为 0.0——无移位）\r\n","\r\n            Maps the specified executable module into the address space of the calling process.\r\n            ":"\r\n            将指定的可执行模块映射到调用进程的地址空间。\r\n            \r\n","\r\n            The pixels from the top and bottom rows, the left-most and right-most columns are replicated to fill the border\r\n            ":"\r\n            复制顶部和底部行、最左侧和最右侧列的像素以填充边框\r\n            \r\n","\r\n            Input array type\r\n            ":"\r\n            输入数组类型\r\n            \r\n","Optional output array with a sharpness value for calculated edge responses":"可选的输出数组，带有用于计算边缘响应的锐度值\r\n","Switch to disable interpolation for speed improvement at minor quality loss":"切换为禁用插值以在轻微质量损失下提高速度\r\n","Range blur parameter for texture blurring. Larger value makes result to be more blurred. When the value is negative, it is automatically calculated as described in the paper.":"用于纹理模糊的范围模糊参数。较大的值使结果更加模糊。当该值为负数时，会按照论文中的描述自动计算。\r\n","\r\n            The response, by which the strongest keylines have been selected.\r\n            It's represented by the ratio between line's length and maximum between\r\n            image's width and height \r\n            ":"\r\n            选择最强关键线的响应。\r\n            它由线的长度与最大值之间的比率表示\r\n            图像的宽度和高度\r\n            \r\n"," The x value for this color ":" 这种颜色的 x 值\r\n","The pointer to the StatModel object":"指向 StatModel 对象的指针\r\n","\r\n            Decimation pattern type.\r\n            ":"\r\n            抽取模式类型。\r\n            \r\n","\r\n            Return the dot product of two 3D point\r\n            ":"\r\n            返回两个 3D 点的点积\r\n            \r\n","\r\n            Get the number of bytes of a row of data in a tile. \r\n            ":"\r\n            获取瓦片中一行数据的字节数。\r\n            \r\n","\r\n            Spatial Moment M20\r\n            ":"\r\n            时空M20\r\n            \r\n","Leaf Size":"叶片大小\r\n","Destination array (should have 8u depth). ":"目标数组（应该有 8u 深度）。\r\n","\r\n            (open-only) Hardware device index (select GPU if multiple available)\r\n            ":"\r\n            （只打开）硬件设备索引（如果有多个可用，请选择 GPU）\r\n            \r\n","\r\n            Pointer to native IBoard\r\n            ":"\r\n            指向本机 IBoard 的指针\r\n            \r\n","Get the sum for each color channel ":"获取每个颜色通道的总和\r\n","The output background image":"输出背景图片\r\n","\r\n            Create a MCvPoint3D64f structure with the specific x and y coordinates\r\n            ":"\r\n            创建具有特定 x 和 y 坐标的 MCvPoint3D64f 结构\r\n            \r\n","\r\n            Get the normalized point\r\n            ":"\r\n            获取归一化点\r\n            \r\n","param2 passed to setRpropDWMin for ANN_MLP::RPROP and to setBackpropMomentumScale for ANN_MLP::BACKPROP and to finalT for ANN_MLP::ANNEAL.":"param2 传递给 ANN_MLP::RPROP 的 setRpropDWMin 和 ANN_MLP::BACKPROP 的 setBackpropMomentumScale 以及 ANN_MLP::ANNEAL 的 finalT。\r\n","\r\n            Release the memory associated with this PCA Flow algorithm\r\n            ":"\r\n            释放与此 PCA 流算法关联的内存\r\n            \r\n","Optional scale. Use 1.0 for default":"可选规模。默认使用 1.0\r\n","\r\n            Open the file for reading\r\n            ":"\r\n            打开文件进行读取\r\n            \r\n","\r\n            Draw a line segment in the map\r\n            ":"\r\n            在地图中绘制线段\r\n            \r\n","\r\n            Compare the hash value between inOne and inTwo\r\n            ":"比较 inOne 和 inTwo 的哈希值\r\n            \r\n","\r\n            Convert YUV420i to BGRA\r\n            ":"\r\n            将 YUV420i 转换为 BGRA\r\n            \r\n","\r\n            Release the unmanaged memory associated with this detector.\r\n            ":"\r\n            释放与此检测器关联的非托管内存。\r\n            \r\n","Output 3x3 external rotation matrix R.":"输出3x3外旋矩阵R。\r\n","Vector for tick timings for all layers.":"所有层的刻度时间向量。\r\n","\r\n            Auto focus\r\n            ":"\r\n            自动对焦\r\n            \r\n","\r\n            Infinitesimal Plane-Based Pose Estimation. This is a special case suitable for marker pose estimation.\r\n             4 coplanar object points must be defined in the following order:\r\n              - point 0: [-squareLength / 2,  squareLength / 2, 0]\r\n              - point 1: [ squareLength / 2,  squareLength / 2, 0]\r\n              - point 2: [ squareLength / 2, -squareLength / 2, 0]\r\n              - point 3: [-squareLength / 2, -squareLength / 2, 0]\r\n            ":"\r\n            基于无穷小平面的姿态估计。这是适用于标记姿态估计的特例。\r\n             必须按以下顺序定义 4 个共面对象点：\r\n              - 点 0：[-squareLength / 2, squareLength / 2, 0]\r\n              - 第 1 点：[ squareLength / 2, squareLength / 2, 0]\r\n              - 第 2 点：[ squareLength / 2, -squareLength / 2, 0]\r\n              - 第 3 点：[-squareLength / 2, -squareLength / 2, 0]\r\n            \r\n","Size of the image used only to initialize intrinsic camera matrix.":"仅用于初始化内部相机矩阵的图像大小。\r\n","The first GpuMat":"第一个 GpuMat\r\n","The decision threshold":"决策门槛\r\n","\r\n            Gamma correction; Need assign a value to gamma simultaneously\r\n            ":"\r\n            伽玛校正；需要同时给gamma赋值\r\n            \r\n","The index of the parameter":"参数索引\r\n","\r\n            Creates a generalized Deriv operator.\r\n            ":"\r\n            创建广义 Deriv 运算符。\r\n            \r\n","The image to be elementwise multiplied to the current image":"要与当前图像逐元素相乘的图像\r\n"," Find the elementwise maximum value ":" 找到元素最大值\r\n","\r\n            The IplImage structure\r\n            ":"\r\n            IplImage 结构\r\n            \r\n","The 3x3 homography matrix if found. Null if not found.":"3x3 单应矩阵（如果找到）。如果找不到则为空。\r\n","\r\n            Given the input frame, create input blob, run net\r\n            ":"\r\n            给定输入帧，创建输入 blob，运行网络\r\n            \r\n","\r\n            Get the pointer to cv::_InputArray\r\n            ":"\r\n            获取指向 cv::_InputArray 的指针\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of OclPlatformInfo.\r\n            ":"\r\n            OclPlatformInfo 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Leptonica Pix image structure\r\n            ":"\r\n            Leptonica Pix图像结构\r\n            \r\n","\r\n            Create an standard vector of Double with the initial values\r\n            ":"\r\n            使用初始值创建 Double 的标准向量\r\n            \r\n"," Elementwise multiply the current image with ":" 按元素将当前图像乘以\r\n","\r\n            Dict4X4_50\r\n            ":"\r\n            词典4X4_50\r\n            \r\n","\r\n            Release all the unmanaged memory associate with this ERFilter\r\n            ":"\r\n            释放与此 ERFilter 关联的所有非托管内存\r\n            \r\n","\r\n            Singular value decomposition (SVD) method\r\n            In case of SVD methods the function returns the inversed condition number of src1 (ratio of the smallest singular value to the largest singular value) and 0 if src1 is all zeros. The SVD methods calculate a pseudo-inverse matrix if src1 is singular\r\n            ":"\r\n            奇异值分解（SVD）方法\r\n            在 SVD 方法的情况下，该函数返回 src1 的逆条件数（最小奇异值与最大奇异值的比率），如果 src1 全为零，则返回 0。如果 src1 是奇异的，则 SVD 方法计算伪逆矩阵\r\n            \r\n","\r\n            Projects vector(s) to the principal component subspace.\r\n            ":"\r\n            将向量投影到主成分子空间。\r\n            \r\n","\r\n            Create an standard vector of VectorOfInt with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfInt 的标准向量\r\n            \r\n","Access type":"接入类型\r\n","\r\n            Create an standard vector of Byte with the initial values\r\n            ":"\r\n            使用初始值创建 Byte 的标准向量\r\n            \r\n","\r\n            Calculates absolute difference between two matrices of the same size and depth\r\n            ":"\r\n            计算两个相同大小和深度的矩阵之间的绝对差\r\n            \r\n","The action to be applied to each element of the image":"要应用于图像的每个元素的操作\r\n","\r\n            Pointer to the unmanaged object\r\n            ":"\r\n            指向非托管对象的指针\r\n            \r\n","Bounding boxes coordinates output vector":"边界框坐标输出向量\r\n","Descriptor matcher that is used to find the nearest word of the trained vocabulary for each key point descriptor of the image.":"描述符匹配器，用于为图像的每个关键点描述符找到训练词汇表中最近的单词。\r\n","\r\n            The function edgenms in edge image and suppress edges where edge is stronger in orthogonal direction.\r\n            ":"\r\n            边缘图像中的函数 edgenms 和抑制边缘在正交方向上更强的边缘。\r\n            \r\n","Array of dimension sizes":"维度大小数组\r\n","\r\n            Symmetric grid\r\n            ":"\r\n            对称网格\r\n            \r\n","\r\n            CV Capture property identifier\r\n            ":"\r\n            CV 捕获属性标识符\r\n            \r\n","\r\n            Hsv\r\n            ":"\r\n            HSV\r\n            \r\n","The caller is responsible for allocating and freeing the block of memory specified by the scan0 parameter, however, the memory should not be released until the related Image is released. ":"调用者负责分配和释放由 scan0 参数指定的内存块，但是，在释放相关 Image 之前不应释放内存。\r\n","\r\n            Release all the unmanaged memory associated with this OclProgram\r\n            ":"\r\n            释放与此 OclProgram 关联的所有非托管内存\r\n            \r\n","\r\n            The type of line for drawing\r\n            ":"\r\n            绘图线的类型\r\n            \r\n","A line is returned by the function if the corresponding accumulator value is greater than threshold":"如果相应的累加器值大于阈值，则函数返回一行\r\n","\r\n            Same as CAP_V4L\r\n            ":"\r\n            与 CAP_V4L 相同\r\n            \r\n","If true, the algorithm will detect shadows and mark them. It decreases the speed a bit, so if you do not need this feature, set the parameter to false.":"如果为真，该算法将检测阴影并标记它们。它会稍微降低速度，所以如果您不需要此功能，请将参数设置为 false。\r\n","\r\n            Get the number of Cuda enabled devices\r\n            ":"\r\n            获取支持 Cuda 的设备数量\r\n            \r\n","The region of interest of the triangulation":"三角测量的感兴趣区域\r\n","\r\n            Returns the current error status - the value set with the last cvSetErrStatus call. Note, that in Leaf mode the program terminates immediately after error occurred, so to always get control after the function call, one should call cvSetErrMode and set Parent or Silent error mode.\r\n            ":"\r\n            返回当前错误状态 - 上次调用 cvSetErrStatus 时设置的值。请注意，在叶模式下，程序在错误发生后立即终止，因此要始终在函数调用后获得控制权，应该调用 cvSetErrMode 并设置 Parent 或 Silent 错误模式。\r\n            \r\n","\r\n            Returns true if the node is a floating-point number\r\n            ":"\r\n            如果节点是浮点数则返回真\r\n            \r\n","\r\n            XML format\r\n            ":"\r\n            格式\r\n            \r\n","The matrix to initialize (not necessarily square).":"要初始化的矩阵（不一定是正方形）。\r\n","The value to be divided":"要分割的值\r\n","\r\n            Hierarchical Feature Selection for Efficient Image Segmentation\r\n            ":"\r\n            高效图像分割的分层特征选择\r\n            \r\n","disparity/depth map for the specified stereo-pair":"指定立体对的视差/深度图\r\n","\r\n            Inverse and scale\r\n            ":"\r\n            逆和比例\r\n            \r\n","Projection map for the x axis":"x 轴的投影图\r\n","\r\n            size of aligned image row in bytes \r\n            ":"\r\n            对齐图像行的大小（以字节为单位）\r\n            \r\n","\r\n            Android white balance lock\r\n            ":"\r\n            安卓白平衡锁\r\n            \r\n","Marker board layout.":"标记板布局。\r\n","\r\n            Create a Flann based matcher.\r\n            ":"\r\n            创建一个基于 Flann 的匹配器。\r\n            \r\n","Image to upscale":"图像到高档\r\n","A row by row matrix of descriptors":"描述符的逐行矩阵\r\n","Path to directory with cropped positive samples":"包含裁剪正样本的目录路径\r\n","\r\n            Adds one array to another one:\r\n            dst(I)=src1(I)+src2(I) if mask(I)!=0All the arrays must have the same type, except the mask, and the same size (or ROI size)\r\n            ":"\r\n            将一个数组添加到另一个数组：\r\n            dst(I)=src1(I)+src2(I) if mask(I)!=0 所有数组必须具有相同的类型，除了掩码，以及相同的大小（或 ROI 大小）\r\n            \r\n","\r\n            Remove keypoints within borderPixels of an image edge.\r\n            ":"\r\n            删除图像边缘 borderPixels 内的关键点。\r\n            \r\n","th column (x direction)\r\n            ":"第 列（x 方向）\r\n            \r\n","Input image. Supported formats: CV_8U, CV_16U, CV_32F. Image size & number of channels must match with the initialized image size & channels with the function createSuperpixelSEEDS(). It should be in HSV or Lab color space. Lab is a bit better, but also slower.":"输入图像。支持的格式：CV_8U、CV_16U、CV_32F。图像大小和通道数必须与使用函数 createSuperpixelSEEDS() 初始化的图像大小和通道相匹配。它应该在 HSV 或 Lab 颜色空间中。实验室好一点，但也慢一些。\r\n","Range width":"范围宽度\r\n","\r\n            A deformable parts model detector\r\n            ":"\r\n            一种可变形零件模型检测器\r\n            \r\n","\r\n            Given the input frame, prepare network input, run network inference, post-process network output and return result detections.\r\n            ":"\r\n            给定输入帧，准备网络输入，运行网络推理，后处理网络输出和返回结果检测。\r\n            \r\n","\r\n            Microsoft Media Foundation (via videoInput)\r\n            ":"\r\n            微软媒体基金会（通过 videoInput）\r\n            \r\n","An array of String":"字符串数组\r\n","Step of BM3D to be executed. Allowed are only BM3D_STEP1 and BM3D_STEPALL. BM3D_STEP2 is not allowed as it requires basic estimate to be present.":"要执行的 BM3D 的步骤。仅允许 BM3D_STEP1 和 BM3D_STEPALL。 BM3D_STEP2 是不允许的，因为它需要基本估计存在。\r\n","Border value in case of a constant border, use Constant for default":"常量边框情况下的边框值，默认使用Constant\r\n","\r\n            The type of SVM parameters\r\n            ":"\r\n            SVM参数的类型\r\n            \r\n","\r\n            Size of used camera FFS.\r\n            ":"\r\n            使用的相机 FFS 的大小。\r\n            \r\n","The input/output Int32 depth single-channel image (map) of markers. ":"标记的输入/输出 Int32 深度单通道图像（地图）。\r\n","\r\n            Performs mean-shift procedure and stores information about processed points (i.e. their colors\r\n            and positions) into two images.\r\n            ":"\r\n            执行均值漂移程序并存储有关处理点的信息（即它们的颜色\r\n            和位置）分成两个图像。\r\n            \r\n"," \r\n            Capture images from either camera or video file. \r\n            ":" \r\n            从相机或视频文件中捕获图像。\r\n            \r\n","\r\n            Cuda video reader\r\n            ":"\r\n            Cuda视频阅读器\r\n            \r\n","The algorithm":"算法\r\n","The GpuMat where the result will be stored in":"结果将存储在的 GpuMat\r\n","\r\n            Computes features by input image.\r\n            ":"\r\n            通过输入图像计算特征。\r\n            \r\n","The second method-specific parameter. In case of CV_HOUGH_GRADIENT it is accumulator threshold at the center detection stage. The smaller it is, the more false circles may be detected. Circles, corresponding to the larger accumulator values, will be returned first":"第二个特定于方法的参数。在 CV_HOUGH_GRADIENT 的情况下，它是中心检测阶段的累加器阈值。它越小，可能检测到的错误圆圈就越多。与较大的累加器值相对应的圆圈将首先返回\r\n","\r\n            Returns the triangles subdivision of the current planar subdivision. \r\n            ":"\r\n            返回当前平面细分的三角形细分。\r\n            \r\n","Border type.":"边框类型。\r\n","\r\n            Maximal window size of the support region. If supportRegionType is Fixed this gives the exact support region size. The speed of the RLOF is related to the applied win sizes. The smaller the window size the lower is the runtime, but the more sensitive to noise is the method.\r\n            ":"\r\n            支持区域的最大窗口大小。如果 supportRegionType 是固定的，这给出了准确的支持区域大小。 RLOF 的速度与应用的获胜大小有关。窗口尺寸越小，运行时间越短，但方法对噪声越敏感。\r\n            \r\n","Resulting image of contrast stretching.":"对比度拉伸的结果图像。\r\n","\r\n            (|I1-I2|^2+sigma^2)^-1\r\n            ":"\r\n            (|I1-I2|^2+西格玛^2)^-1\r\n            \r\n","the saliency map obtained through one of the specialized algorithms":"通过一种专门算法获得的显着图\r\n","\r\n            Create an empty standard vector of KeyPoint\r\n            ":"\r\n            创建 KeyPoint 的空标准向量\r\n            \r\n","\r\n            Dict5X5_50\r\n            ":"\r\n            字典5X5_50\r\n            \r\n","\r\n            Set the optimal parameters for the given model type\r\n            ":"\r\n            为给定的模型类型设置最佳参数\r\n            \r\n","Neighborhood size ":"街区大小\r\n","destination image (grayscale, float, in [0;1]) where edges are drawn":"绘制边缘的目标图像（灰度，浮点数，在 [0;1] 中）\r\n","\r\n            Parameter used when the mask (or masks) is not empty. If compactResult is\r\n            false, the matches vector has the same size as queryDescriptors rows.If compactResult is true,\r\n            the matches vector does not contain matches for fully masked-out query descriptors.\r\n            ":"\r\n            当掩码（或掩码）不为空时使用的参数。如果 compactResult 是\r\n            false，匹配向量与 queryDescriptors 行的大小相同。如果 compactResult 为 true，\r\n            matches 向量不包含完全屏蔽的查询描述符的匹配项。\r\n            \r\n","  \r\n            freeman code: 0..7 \r\n            ":"  \r\n            自由人代码：0..7\r\n            \r\n","\r\n            This 2D Widget represents text overlay.\r\n            ":"\r\n            这个 2D Widget 表示文本叠加。\r\n            \r\n","The value for the XOR operation":"XOR 运算的值\r\n","\r\n            Page orientation\r\n            ":"\r\n            页面方向\r\n            \r\n"," image":" 图像\r\n","\r\n            Returns a CudaImage corresponding to the [":"\r\n            返回对应于 [\r\n","\r\n            Fills the destination array with values from the look-up table. Indices of the entries are taken from the source array. That is, the function processes each element of src as following:\r\n            dst(I)=lut[src(I)+DELTA]\r\n            where DELTA=0 if src has depth CV_8U, and DELTA=128 if src has depth CV_8S\r\n            ":"\r\n            用查找表中的值填充目标数组。条目的索引取自源数组。也就是说，该函数对 src 的每个元素进行如下处理：\r\n            dst(I)=lut[src(I)+DELTA]\r\n            其中，如果 src 的深度为 CV_8U，则 DELTA=0，如果 src 的深度为 CV_8S，则 DELTA=128\r\n            \r\n","The number of bits to shift to check for neighboring buckets (0 is regular LSH, 2 is recommended).":"为检查相邻桶而移动的位数（0 是常规 LSH，建议使用 2）。\r\n","size of Sobel kernel. It must be 3.":"Sobel 内核的大小。它必须是 3。\r\n","\r\n            Applies arbitrary linear filter to the image. In-place operation is supported. When the aperture is partially outside the image, the function interpolates outlier pixel values from the nearest pixels that is inside the image\r\n            ":"对图像应用任意线性过滤器。支持就地操作。当孔径部分位于图像外部时，该函数会从图像内部最近的像素中插入异常像素值\r\n            \r\n","\r\n            Dilates ":"\r\n            膨胀\r\n","if true cuts images, otherwise fills the new regions with zeros.":"如果为 true 则剪切图像，否则用零填充新区域。\r\n","\r\n            Create a GScalar from a double value\r\n            ":"\r\n            从双精度值创建一个 GScalar\r\n            \r\n","\r\n            The value of the inner radius.\r\n            ":"\r\n            内半径的值。\r\n            \r\n","The vector of distortion coefficients, 4x1, 1x4, 5x1 or 1x5":"失真系数的向量，4x1、1x4、5x1 或 1x5\r\n","\r\n            Surface format\r\n            ":"\r\n            表面格式\r\n            \r\n","\r\n            Delete all data in the existing storage, if there is any.\r\n            ":"\r\n            删除现有存储中的所有数据（如果有）。\r\n            \r\n","\r\n            Sparse Optical flow\r\n            ":"\r\n            稀疏光流\r\n            \r\n","Minimum segment size. Smaller segements will be merged.":"最小段大小。较小的段将被合并。\r\n","\r\n            Calculates sum S of array elements, independently for each channel\r\n            Sc = sumI arr(I)c\r\n            If the array is IplImage and COI is set, the function processes the selected channel only and stores the sum to the first scalar component (S0).\r\n            ":"\r\n            为每个通道独立计算数组元素的总和 S\r\n            Sc = sumI arr(I)c\r\n            如果数组为 IplImage 且设置了 COI，则该函数仅处理选定的通道并将总和存储到第一个标量分量 (S0)。\r\n            \r\n","The current Cuda device id":"当前的 Cuda 设备 ID\r\n","\r\n            Type used for cvCmp function\r\n            ":"\r\n            用于 cvCmp 函数的类型\r\n            \r\n","The color for highlighting the keypoints":"突出显示关键点的颜色\r\n","\r\n            WaldBoost detector.\r\n            ":"\r\n            WaldBoost 检测器。\r\n            \r\n","The interpolation type":"插值类型\r\n","The grouping methods":"分组方法\r\n","White balancing result":"白平衡结果\r\n","\r\n            The unmanaged pointer to the input/output array\r\n            ":"\r\n            指向输入/输出数组的非托管指针\r\n            \r\n","\r\n            Subtracts one matrix from another (c = a - b).\r\n            ":"\r\n            从一个矩阵中减去另一个矩阵 (c = a - b)。\r\n            \r\n","Number of octaves inside pyramid":"金字塔内的八度数\r\n","\r\n            Get an empty output array\r\n            ":"\r\n            得到一个空的输出数组\r\n            \r\n","First input matrix to be considered for horizontal concatenation.":"水平串联时要考虑的第一个输入矩阵。\r\n","\r\n            Top hat\r\n            ":"\r\n            礼帽\r\n            \r\n","The second image to be added":"要添加的第二张图片\r\n","\r\n             value = value > threshold ? 0 : max_value       \r\n            ":"\r\n             价值=价值>阈值？ 0：最大值\r\n            \r\n","The output corners":"输出角\r\n","\r\n            Create a umat of the specific type.\r\n            ":"\r\n            创建特定类型的 umat。\r\n            \r\n"," \r\n            Defines a Bgr (Blue Green Red) color\r\n            ":" \r\n            定义 Bgr（蓝绿红）颜色\r\n            \r\n","The image, where the lines will be drawn. Should be bigger or equal to the image, where the lines were found.":"将在其中绘制线条的图像。应该大于或等于找到线条的图像。\r\n","Specify Mat data array to be written.":"指定要写入的 Mat 数据数组。\r\n","\r\n            (open, read) Enables audio synchronization.\r\n            ":"\r\n            (open, read) 启用音频同步。\r\n            \r\n","\r\n            BayerBG2BGR_MHT\r\n            ":"\r\n            拜耳BG2BGR_MHT\r\n            \r\n","The id of the layer":"层的id\r\n","The essential mat":"必不可少的垫子\r\n"," Pixel extrapolation method.":" 像素外推法。\r\n","\r\n            Finds an object pose from 3D-2D point correspondences using the RANSAC scheme.\r\n            ":"\r\n            使用 RANSAC 方案从 3D-2D 点对应中找到对象姿势。\r\n            \r\n","detect threshold, use 0 for default":"检测阈值，默认使用0\r\n","Termination criteria, use count = 20 and eps = 0.3 for default":"终止条件，默认使用 count = 20 和 eps = 0.3\r\n","\r\n            Indicates if the device is available\r\n            ":"\r\n            指示设备是否可用\r\n            \r\n","The radius":"半径\r\n"," \r\n             Capture a Bgr image frame that is half width and half height. \r\n             Mainly used by WCF when sending image to remote locations in a bandwidth conservative scenario \r\n            ":" \r\n             捕获一半宽度和一半高度的 Bgr 图像帧。\r\n             主要由 WCF 在带宽保守的情况下将图像发送到远程位置时使用\r\n            \r\n","\r\n            Map an image point to a Map point\r\n            ":"\r\n            将图像点映射到地图点\r\n            \r\n","The data will be used as the Matrix data storage. You need to make sure that the data object live as long as this Matrix object":"该数据将用作 Matrix 数据存储。您需要确保数据对象与此 Matrix 对象一样长\r\n","The result of the shift":"转变的结果\r\n","In second. Any change happens between a time interval smaller than this will not be considered.":"在第二。将不考虑小于此时间间隔之间发生的任何更改。\r\n","Granularity of the optical flow vectors returned by calc() function.":"calc() 函数返回的光流向量的粒度。\r\n","String containing one of the desired models: \"edsr\", \"espcn\", \"fsrcnn\", \"lapsrn\"":"包含所需模型之一的字符串：“edsr”、“espcn”、“fsrcnn”、“lapsrn”\r\n","\r\n            Create an standard vector of RotatedRect of the specific size\r\n            ":"\r\n            创建特定大小的 RotatedRect 标准向量\r\n            \r\n","Chooses the algorithm variant to use":"选择要使用的算法变体\r\n","Coefficients for filtering each column.":"过滤每列的系数。\r\n","\r\n            Edge preserving filter flag\r\n            ":"\r\n            边缘保留过滤器标志\r\n            \r\n","The color for the AND operation":"AND 操作的颜色\r\n","\r\n            The maximum number of objects\r\n            ":"\r\n            最大对象数\r\n            \r\n","\r\n            Read\r\n            ":"\r\n            读\r\n            \r\n","The default people detector":"默认人员检测器\r\n","\r\n            Brighten the edges of the image\r\n            ":"\r\n            使图像的边缘变亮\r\n            \r\n","\r\n            Set the plot text color\r\n            ":"\r\n            设置绘图文本颜色\r\n            \r\n","Depth type of the first output map that can be CV_32FC1 or CV_16SC2 .":"第一个输出图的深度类型，可以是 CV_32FC1 或 CV_16SC2 。\r\n","\r\n            Filter by convexity\r\n            ":"\r\n            按凸性过滤\r\n            \r\n","Samples from which the Gaussian mixture model will be estimated. It should be a one-channel matrix, each row of which is a sample. If the matrix does not have CV_64F type it will be converted to the inner matrix of such type for the further computing.":"将从中估计高斯混合模型的样本。它应该是一个单通道矩阵，每一行都是一个样本。如果矩阵没有 CV_64F 类型，它将被转换为该类型的内部矩阵以供进一步计算。\r\n","Accumulator of the same number of channels as input images, 32-bit or 64-bit floating-point":"与输入图像相同通道数的累加器，32 位或 64 位浮点数\r\n","\r\n            Queue of field/frame buffers\r\n            ":"\r\n            场/帧缓冲区队列\r\n            \r\n","Source CudaImage. Only CV 8UC4 images are supported for now.":"来源 CudaImage。目前仅支持 CV 8UC4 图像。\r\n","All the input contours. Each contour is stored as a point vector.":"所有输入轮廓。每个轮廓都存储为一个点向量。\r\n","\r\n            Get the managed image from an unmanaged IplImagePointer\r\n            ":"\r\n            从非托管 IplImagePointer 获取托管图像\r\n            \r\n","\r\n            filename where the trained model will be saved\r\n            ":"\r\n            保存训练模型的文件名\r\n            \r\n","\r\n            Create an standard vector of VectorOfRect with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfRect 的标准向量\r\n            \r\n","the row of the element":"元素的行\r\n","\r\n            Converts points from Euclidean to homogeneous space.\r\n            ":"\r\n            将点从欧氏空间转换为齐次空间。\r\n            \r\n","Output array of image points, 2xN/Nx2 1-channel or 1xN/Nx1 2-channel, or vector<Point2f>.":"输出图像点数组，2xN/Nx2 1 通道或 1xN/Nx1 2 通道，或 vector<Point2f>。\r\n","\r\n            The Affine3 matrix, double precision. \r\n            ":"\r\n            Affine3 矩阵，双精度。\r\n            \r\n","enum to specified output kind: depth or disparity and corresponding type":"枚举到指定的输出类型：深度或视差以及相应的类型\r\n","\r\n            Create an empty standard vector of VideoCapture\r\n            ":"\r\n            创建 VideoCapture 的空标准向量\r\n            \r\n","\r\n            Divides one array by another:\r\n            dst(I)=scale * src1(I)/src2(I), if src1!=IntPtr.Zero;\r\n            dst(I)=scale/src2(I),      if src1==IntPtr.Zero;\r\n            All the arrays must have the same type, and the same size (or ROI size)\r\n            ":"\r\n            将一个数组除以另一个数组：\r\n            dst(I)=scale * src1(I)/src2(I), if src1!=IntPtr.Zero;\r\n            dst(I)=scale/src2(I)，如果 src1==IntPtr.Zero；\r\n            所有数组必须具有相同的类型和相同的大小（或 ROI 大小）\r\n            \r\n","Draw an Rectangle of the specific color and thickness ":"绘制特定颜色和厚度的矩形\r\n","\r\n            Minimum Average Correlation Energy Filter useful for authentication with (cancellable) biometrical features. (does not need many positives to train (10-50), and no negatives at all, also robust to noise/salting)\r\n            ":"\r\n            最小平均相关能量滤波器可用于使用（可取消的）生物特征进行身份验证。 （不需要很多积极因素来训练（10-50），根本不需要消极因素，对噪音/加盐也很稳健）\r\n            \r\n","\r\n            An elliptic element.\r\n            ":"\r\n            一个椭圆元素。\r\n            \r\n","A pointer to the raw data given the specific index":"给定特定索引的指向原始数据的指针\r\n","The input image to process RGB or gray levels":"要处理 RGB 或灰度级的输入图像\r\n","\r\n            The pointer to the native AlignExposures object\r\n            ":"\r\n            指向本机 AlignExposures 对象的指针\r\n            \r\n","\r\n            Create a SparsePyrLKOpticalFlow object\r\n            ":"\r\n            创建一个 SparsePyrLKOpticalFlow 对象\r\n            \r\n","\r\n            Smartek Giganetix Ethernet Vision: frame sens height\r\n            ":"\r\n            Smartek Giganetix Ethernet Vision：框架感应高度\r\n            \r\n","\r\n            Resampling using pixel area relation. It is the preferred method for image decimation that gives moire-free results. In case of zooming it is similar to CV_INTER_NN method\r\n            ":"\r\n            使用像素面积关系重采样。它是提供无波纹结果的图像抽取的首选方法。在缩放的情况下，它类似于 CV_INTER_NN 方法\r\n            \r\n","Size of the kernel":"内核大小\r\n","\r\n            Max Convexity\r\n            ":"\r\n            最大凸度\r\n            \r\n","The maximum value of the pixel on the result":"结果上像素的最大值\r\n","\r\n            ParasolCells_tau. Use 0.0 for default\r\n            ":"\r\n            ParasolCells_tau。默认使用 0.0\r\n            \r\n","\r\n            Mask\r\n            ":"\r\n            面具\r\n            \r\n","\r\n            AdaptiveThreshold minimum window size\r\n            ":"\r\n            AdaptiveThreshold 最小窗口大小\r\n            \r\n","\r\n            A reference to the Parent object\r\n            ":"\r\n            对父对象的引用\r\n            \r\n","\r\n            Creates blob from .pb file.\r\n            ":"\r\n            从 .pb 文件创建 blob。\r\n            \r\n","\r\n            Create a new bundle adjuster\r\n            ":"\r\n            创建一个新的包调整器\r\n            \r\n","If the parameter is greater than zero, then all the point pairs that do not comply the epipolar geometry well enough (that is, the points for which fabs(points2[i]T*F*points1[i])>threshold) are rejected prior to computing the homographies":"如果参数大于零，则拒绝所有不符合对极几何的点对（即 fabs(points2[i]T*F*points1[i])>threshold 的点）在计算单应性之前\r\n","resulting image of gamma corrections.":"伽玛校正的结果图像。\r\n","\r\n            Maximum limit of exposure in AEAG procedure\r\n            ":"\r\n            AEAG 程序中的最大暴露限值\r\n            \r\n","The transformation center, where the output precision is maximal":"输出精度最大的变换中心\r\n","\r\n            The type for CopyMakeBorder function\r\n            ":"\r\n            CopyMakeBorder 函数的类型\r\n            \r\n","Translation between mesh and camera":"网格和相机之间的转换\r\n","\r\n            parameter of the shrinked Hampel norm\r\n            ":"收缩的 Hampel 范数的参数\r\n            \r\n","\r\n            Convert RGB color to BGR555 color\r\n            ":"\r\n            将 RGB 颜色转换为 BGR555 颜色\r\n            \r\n","The VectorOfMat that is passed to the second parameter of DetectAndDecode":"传递给 DetectAndDecode 的第二个参数的 VectorOfMat\r\n","\r\n            Returns a CudaImage corresponding to the ith column of the CudaImage. The data is shared with the current Image. \r\n            ":"\r\n            返回对应于 CudaImage 的第 i 列的 CudaImage。数据与当前图像共享。\r\n            \r\n","The normal of the points":"点的法线\r\n","\r\n            Convert BGR color to HLS color\r\n            ":"将 BGR 颜色转换为 HLS 颜色\r\n            \r\n","\r\n            Camera setting\r\n            ":"\r\n            相机设置\r\n            \r\n","\r\n            Retrieves contours from the binary image and returns the number of retrieved contours. The pointer firstContour is filled by the function. It will contain pointer to the first most outer contour or IntPtr.Zero if no contours is detected (if the image is completely black). Other contours may be reached from firstContour using h_next and v_next links. The sample in cvDrawContours discussion shows how to use contours for connected component detection. Contours can be also used for shape analysis and object recognition - see squares.c in OpenCV sample directory\r\n            The function modifies the source image content\r\n            ":"\r\n            从二值图像中检索轮廓并返回检索到的轮廓数。函数填充指针 firstContour。如果没有检测到轮廓（如果图像是全黑的），它将包含指向第一个最外层轮廓或 IntPtr.Zero 的指针。可以使用 h_next 和 v_next 链接从 firstContour 到达其他轮廓。 cvDrawContours 讨论中的示例显示了如何使用轮廓进行连通分量检测。轮廓也可用于形状分析和对象识别 - 请参阅 OpenCV 示例目录中的 squares.c\r\n            函数修改源图片内容\r\n            \r\n","a-parameter in the Camera Response Function (CRF).":"相机响应函数 (CRF) 中的 a 参数。\r\n","marker detection parameters":"标记检测参数\r\n","The list of Voronoi Facets":"Voronoi 面列表\r\n","\r\n            Constructs a WCloud.\r\n            ":"\r\n            构建一个 WCloud。\r\n            \r\n","The image to be added to history":"要添加到历史记录的图像\r\n","Aperture size of derivative operators used by the function: CV_SCHARR, 1, 3, 5 or 7 (see cvSobel). ":"函数使用的导数运算符的孔径大小：CV_SCHARR、1、3、5 或 7（参见 cvSobel）。\r\n","The image used for segmentation":"用于分割的图像\r\n","Indices of the nearest neighbors found":"找到最近邻居的索引\r\n","The exponent image":"指数图像\r\n","The header, corresponding to a specified row span of the input array":"表头，对应于输入数组的指定行跨度\r\n","Caffe model file path for the detector":"检测器的 Caffe 模型文件路径\r\n"," The type of color to be converted to ":" 要转换成的颜色类型\r\n","\r\n            Create a new features matcher\r\n            ":"\r\n            创建一个新的特征匹配器\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this estimator\r\n            ":"\r\n            释放与此估算器关联的所有非托管内存\r\n            \r\n","Framerate of the created video stream.":"创建的视频流的帧率。\r\n","\r\n            A New Technique for Fully Autonomous and Efficient 3D Robotics Hand/Eye Calibration\r\n            ":"\r\n            一种用于完全自主和高效 3D 机器人手/眼校准的新技术\r\n            \r\n","Specify cost of gradient magnitude function: Type is CV_32FC1. Values should be in range [0, 1].":"指定梯度幅度函数的成本：类型为 CV_32FC1。值应在 [0, 1] 范围内。\r\n","The rotated point":"旋转点\r\n","The file to be downloaded":"要下载的文件\r\n","The contour hierarchy":"轮廓层次\r\n","\r\n            Implementation for the minimum eigen value of a 2x2 derivative covariation matrix (the cornerness criteria).\r\n            ":"\r\n            2x2 导数协方差矩阵（拐点准则）的最小特征值的实现。\r\n            \r\n","\r\n            Convert BGR color to BGRA color\r\n            ":"\r\n            将 BGR 颜色转换为 BGRA 颜色\r\n            \r\n","\r\n            Parameter epsilon of a SVM optimization problem\r\n            ":"\r\n            SVM 优化问题的参数 epsilon\r\n            \r\n","The depth type":"深度型\r\n","Window property to retrieve.":"要检索的窗口属性。\r\n","New matrix element depth type.":"新的矩阵元素深度类型。\r\n","\r\n            Creates TonemapDurand object.\r\n            ":"\r\n            创建 TonemapDurand 对象。\r\n            \r\n","\r\n            Get the Mat from the input array\r\n            ":"\r\n            从输入数组中获取 Mat\r\n            \r\n","\r\n            Create an standard vector of VectorOfERStat with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfERStat 的标准向量\r\n            \r\n","Pointer to CvMat structure used as a temporary buffer":"指向用作临时缓冲区的 CvMat 结构的指针\r\n","\r\n            Clear the vector\r\n            ":"\r\n            清除矢量\r\n            \r\n","\r\n            The principal point is not changed during the global optimization, it stays at the center and at the other location specified (when CV_CALIB_FIX_FOCAL_LENGTH - Both fx and fy are fixed.\r\n            CV_CALIB_USE_INTRINSIC_GUESS is set as well)\r\n            ":"主点在全局优化期间没有改变，它停留在中心和指定的其他位置（当 CV_CALIB_FIX_FOCAL_LENGTH - fx 和 fy 都是固定的。\r\n            CV_CALIB_USE_INTRINSIC_GUESS 也已设置）\r\n            \r\n","the height of the cross":"十字架的高度\r\n","Query set of descriptors.":"查询描述符集。\r\n","\r\n            Create an standard vector of Mat of the specific size\r\n            ":"\r\n            创建特定大小的 Mat 标准向量\r\n            \r\n","Whether or not the descriptor should compensate for orientation changes.":"描述符是否应该补偿方向变化。\r\n","dictionary of markers indicating the type of markers. The first markersX*markersY markers in the dictionary are used.":"指示标记类型的标记字典。使用字典中的第一个 markersX*markersY 标记。\r\n","vector of identifiers of the detected markers. The identifier is of type int (e.g. VectorOfInt). For N detected markers, the size of ids is also N. The identifiers have the same order than the markers in the imgPoints array.":"检测到的标记的标识符向量。标识符是 int 类型（例如 VectorOfInt）。对于 N 个检测到的标记，ids 的大小也是 N。标识符与 imgPoints 数组中的标记具有相同的顺序。\r\n","Confidence values for bounding boxes output vector":"边界框输出向量的置信度值\r\n","\r\n            Extension methods for ISparseOpticalFlow\r\n            ":"\r\n            ISparseOpticalFlow 的扩展方法\r\n            \r\n","\r\n            Get the tesseract version as String\r\n            ":"\r\n            获取 tesseract 版本作为字符串\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this OclContext\r\n            ":"\r\n            释放与此 OclContext 关联的所有非托管内存\r\n            \r\n","\r\n            The function vertically concatenates two or more matrices\r\n            ":"\r\n            该函数垂直连接两个或多个矩阵\r\n            \r\n","Coordinates of 3 triangle vertices in the source image. If the array contains more than 3 points, only the first 3 will be used":"源图像中 3 个三角形顶点的坐标。如果数组包含超过 3 个点，则只使用前 3 个\r\n","Output vector indicating which points are inliers.":"指示哪些点是内点的输出向量。\r\n","The optional output matrix that contains posterior probabilities of each Gaussian mixture component given the each sample. It has nsamples x nclusters size and CV_64FC1 type.":"可选输出矩阵，包含给定每个样本的每个高斯混合分量的后验概率。它有 nsamples x nclusters 大小和 CV_64FC1 类型。\r\n","Size in pixels of the window that is used to compute weighted average for given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater denoising time.":"用于计算给定像素的加权平均值的窗口大小（以像素为单位）。应该是奇数。线性影响性能：更大的 searchWindowsSize - 更长的去噪时间。\r\n","\r\n            Create an empty standard vector of GpuMat\r\n            ":"\r\n            创建一个空的 GpuMat 标准向量\r\n            \r\n","\r\n            Structured Light Pattern interface\r\n            ":"\r\n            结构光模式界面\r\n            \r\n","\r\n            The name of the backend\r\n            ":"\r\n            后台名称\r\n            \r\n","\r\n            Returns a GpuMat corresponding to a specified rectangle of the current GpuMat. The data is shared with the current matrix. In other words, it allows the user to treat a rectangular part of input array as a stand-alone array.\r\n            ":"\r\n            返回与当前 GpuMat 的指定矩形对应的 GpuMat。数据与当前矩阵共享。换句话说，它允许用户将输入数组的矩形部分视为独立数组。\r\n            \r\n","number of markers in Y direction":"Y方向标记数\r\n","\r\n            The maximum value of M\r\n            ":"\r\n            M的最大值\r\n            \r\n","\r\n            Sets a homography as a motion model; eight parameters are estimated; warpMatrix is 3x3.\r\n            ":"\r\n            将单应性设置为运动模型；估计了八个参数； warpMatrix 是 3x3。\r\n            \r\n","\r\n            Predict sum\r\n            ":"\r\n            预测总和\r\n            \r\n","found scales":"发现鳞片\r\n","\r\n            Release the video writer and all the memory associate with it\r\n            ":"释放视频编写器和与之关联的所有内存\r\n            \r\n","\r\n            Set the value of the quaternions using euler angle\r\n            ":"\r\n            使用欧拉角设置四元数的值\r\n            \r\n","\r\n            GStreamer\r\n            ":"\r\n            流媒体\r\n            \r\n","Gaussian kernel standard deviation in X direction.":"X 方向的高斯核标准偏差。\r\n","\r\n            Check if the GPU module is targeted for equal or greater device version\r\n            ":"\r\n            检查 GPU 模块是否针对相同或更高的设备版本\r\n            \r\n","\r\n            Point distributions supported by random point generator.\r\n             ":"\r\n            随机点生成器支持的点分布。\r\n             \r\n","The destination points":"目的地点\r\n","\r\n            The storage is open for reading\r\n            ":"\r\n            存储已打开以供读取\r\n            \r\n","Array of object points, 1xN/Nx1 2-channel (or vector<Point2f> ), where N is the number of points in the view.":"对象点数组，1xN/Nx1 2 通道（或 vector<Point2f> ），其中 N 是视图中的点数。\r\n"," and the interpolation ":" 和插值\r\n","Establish the number of angular bins for the Shape Context Descriptor used in the shape matching pipeline.":"为形状匹配管道中使用的形状上下文描述符建立角度箱的数量。\r\n","The input floating-point M x N matrix.":"输入浮点 M x N 矩阵。\r\n","Type of the first output map that can be CV_32FC1 or CV_16SC2 . See convertMaps() for details.":"第一个输出映射的类型，可以是 CV_32FC1 或 CV_16SC2 。有关详细信息，请参阅 convertMaps()。\r\n"," The convex polygon to be drawn":" 要绘制的凸多边形\r\n","\r\n            Convert YUV (UYVY) to RGB\r\n            ":"\r\n            将 YUV (UYVY) 转换为 RGB\r\n            \r\n","\r\n            Creates MergeDebevec object.\r\n            ":"\r\n            创建 MergeDebevec 对象。\r\n            \r\n","\r\n            Kind of regularization to be applied\r\n            ":"\r\n            要应用的正则化类型\r\n            \r\n","\r\n            Central Normalized Moment Nu11\r\n            ":"\r\n            中心标准化矩 Nu11\r\n            \r\n","The integral image for squared pixel values, W+1xH+1, double precision floating-point (64f). ":"平方像素值的积分图像，W+1xH+1，双精度浮点数 (64f)。\r\n","The structuring element":"结构元素\r\n","\r\n            Returns the number of coefficients required for the classification.\r\n            ":"\r\n            返回分类所需的系数数。\r\n            \r\n","\r\n            R(x,y)=sumx',y'[T(x',y')-I(x+x',y+y')]2/sqrt[sumx',y'T(x',y')2 sumx',y'I(x+x',y+y')2]\r\n            ":"\r\n            R(x,y)=sumx',y'[T(x',y')-I(x+x',y+y')]2/sqrt[sumx',y'T(x',y ')2 sumx',y'I(x+x',y+y')2]\r\n            \r\n","\r\n            XSobel\r\n            ":"\r\n            X索贝尔\r\n            \r\n","LSBP descriptor radius.":"LSBP 描述符半径。\r\n","Arrays of arrays of the MCvPoint3D32f":"MCvPoint3D32f 的数组数组\r\n","\r\n            Create a new instance of MSE quality measurement.\r\n            ":"\r\n            创建 MSE 质量测量的新实例。\r\n            \r\n","\r\n            Transforms an image to compensate for fisheye lens distortion.\r\n            ":"\r\n            变换图像以补偿鱼眼镜头失真。\r\n            \r\n","\r\n            Convert Bayer BGGR color to BGR color\r\n            ":"\r\n            将 Bayer BGGR 颜色转换为 BGR 颜色\r\n            \r\n","True if the two RangeF equals":"如果两个 RangeF 相等则为真\r\n","\r\n            The size for the network input, which overwrites the input size of creating model.\r\n            ":"\r\n            网络输入的大小，它会覆盖创建模型的输入大小。\r\n            \r\n","The new size":"新尺寸\r\n","The result of the element-wise absolute difference.":"逐元素绝对差的结果。\r\n","\r\n            YUV420\r\n            ":"\r\n            YUV420\r\n            \r\n","True if two coordinates equals":"如果两个坐标相等则为真\r\n","\r\n            The degree of linearization polynomial\r\n            ":"\r\n            线性化多项式的次数\r\n            \r\n","\r\n            The equivalent of cv::GMat\r\n            ":"\r\n            相当于 cv::GMat\r\n            \r\n","\r\n            Execute an unary computation (with compilation on the fly)\r\n            ":"\r\n            执行一元计算（即时编译）\r\n            \r\n","\r\n            Get or Set the raw image data\r\n            ":"\r\n            获取或设置原始图像数据\r\n            \r\n","\r\n            EAN-13\r\n            ":"\r\n            EAN-13\r\n            \r\n","\r\n            (open-only) Specify video stream, 0-based index. Use -1 to disable video stream from file or IP cameras. Default value is 0.\r\n            ":"\r\n            (open-only) 指定视频流，从 0 开始的索引。使用 -1 禁用来自文件或 IP 摄像机的视频流。默认值为 0。\r\n            \r\n","\r\n            Seamless clone method\r\n            ":"\r\n            无缝克隆法\r\n            \r\n","\r\n            Get the currently observed element\r\n            ":"\r\n            获取当前观察到的元素\r\n            \r\n","\r\n            Input image range maximum value\r\n            ":"\r\n            输入图像范围最大值\r\n            \r\n","Pointer to the matrix header to be initialized.":"指向要初始化的矩阵头的指针。\r\n","\r\n            Computes dense optical flow using Gunnar Farneback's algorithm\r\n            ":"\r\n            使用 Gunnar Farneback 算法计算密集光流\r\n            \r\n","\r\n            Dilates the source image using the specified structuring element that determines the shape of a pixel neighborhood over which the maximum is taken\r\n            The function supports the in-place mode. Dilation can be applied several (iterations) times. In case of color image each channel is processed independently\r\n            ":"\r\n            使用确定取最大值的像素邻域形状的指定结构元素扩大源图像\r\n            该函数支持就地模式。扩张可以应用多次（迭代）次。在彩色图像的情况下，每个通道都是独立处理的\r\n            \r\n","\r\n            Discrete AdaBoost\r\n            ":"\r\n            离散 AdaBoost\r\n            \r\n","The source color type. Must be a type inherited from IColor":"源颜色类型。必须是继承自 IColor 的类型\r\n","radian":"弧度\r\n","The higher, the less matches.":"越高，匹配越少。\r\n","First output is a matrix of magnitudes of the same size and depth as input x. Second output is a matrix of angles that has the same size and depth as x; the angles are measured in radians (from 0 to 2*Pi) or in degrees (0 to 360 degrees).":"第一个输出是一个大小和深度与输入 x 相同的矩阵。第二个输出是与 x 具有相同大小和深度的角度矩阵；角度以弧度（从 0 到 2*Pi）或以度（0 到 360 度）为单位测量。\r\n","Array of CV_32FC1 y-coordinates.":"CV_32FC1 y 坐标数组。\r\n","\r\n            Create a (2x3) 2D rotation matrix\r\n            ":"\r\n            创建一个 (2x3) 二维旋转矩阵\r\n            \r\n","\r\n            The interface for cv::reg::Map\r\n            ":"\r\n            cv::reg::Map 的接口\r\n            \r\n","the tracking result, represent a list of ROIs of the tracked objects.":"跟踪结果，表示被跟踪对象的 ROI 列表。\r\n","\r\n            Leaky ReLU function:\r\n            for x>0, $f(x)=x;\r\n            and x<=0, f(x)=alpha x \r\n            ":"\r\n            泄漏 ReLU 函数：\r\n            对于 x>0，$f(x)=x；\r\n            且 x<=0，f(x)=alpha x\r\n            \r\n","\r\n            Get a copy of the map in the specific area\r\n            ":"\r\n            获取特定区域的地图副本\r\n            \r\n","Index of the image (1 or 2) that contains the points":"包含点的图像索引（1 或 2）\r\n","\r\n            Depth\r\n            ":"\r\n            深度\r\n            \r\n","\r\n            Min Max\r\n            ":"\r\n            最小最大值\r\n            \r\n","\r\n            Create a BoxMin filter.\r\n            ":"\r\n            创建一个 BoxMin 过滤器。\r\n            \r\n","\r\n            Find bounding boxes of text words given an input image.\r\n            ":"\r\n            在给定输入图像的情况下查找文本单词的边界框。\r\n            \r\n","\r\n            The square distance\r\n            ":"\r\n            平方距离\r\n            \r\n","\r\n            Dynamic parallelism\r\n            ":"\r\n            动态并行\r\n            \r\n","\r\n            The bounding box\r\n            ":"\r\n            边界框\r\n            \r\n",". The data is shared between the two CudaImage\r\n            ":".数据在两个 CudaImage 之间共享\r\n            \r\n","\r\n            Create a flann index for 3D points\r\n            ":"\r\n            为 3D 点创建一个 flann 索引\r\n            \r\n","\r\n            Create a FisherFaceRecognizer\r\n            ":"\r\n            创建 FisherFaceRecognizer\r\n            \r\n","Maximum size":"最大尺寸\r\n"," The circle to be drawn":" 要绘制的圆\r\n","\r\n            The event to be called when an image is grabbed\r\n            ":"\r\n            抓取图像时调用的事件\r\n            \r\n","\r\n            Current format of pixels on transport layer.\r\n            ":"\r\n            传输层上像素的当前格式。\r\n            \r\n","List of detected marker corners of the board.":"检测到的电路板标记角列表。\r\n","distribution type":"分配类型\r\n","\r\n            Returns a GpuMat corresponding to the [":"\r\n            返回对应于 [\r\n","\r\n            Left mesh file\r\n            ":"\r\n            左网格文件\r\n            \r\n","The other image to concate":"要连接的另一个图像\r\n","Vector of vectors of the projections of the calibration pattern points, observed by the first camera.":"由第一个相机观察到的校准图案点的投影向量的向量。\r\n","\r\n            Measurement matrix (H)\r\n            ":"\r\n            测量矩阵 (H)\r\n            \r\n","The cost function":"代价函数\r\n","\r\n            Selects Region in Multiple ROI which parameters are set by width, height, ... ,region mode\r\n            ":"\r\n            在多个 ROI 中选择区域，其参数由宽度、高度、...、区域模式设置\r\n            \r\n","\r\n            V4L/V4L2 capturing support\r\n            ":"\r\n            V4L/V4L2 捕获支持\r\n            \r\n","\r\n            Defines how time stamp reset engine will be armed\r\n            ":"\r\n            定义时间戳重置引擎将如何武装\r\n            \r\n","\r\n            Joining multiple index ascending IInterpolatables together as a single index ascending IInterpolatable. \r\n            ":"\r\n            将多个索引升序 IInterpolatables 连接在一起作为单个索引升序 IInterpolatable。\r\n            \r\n","\r\n            Type of sinusoidal pattern profilometry methods.\r\n            ":"\r\n            正弦图形轮廓测量方法的类型。\r\n            \r\n","Scale factor.":"比例因子。\r\n","Number of warpings per scale. Represents the number of times that I1(x+u0) and grad( I1(x+u0) ) are computed per scale. This is a parameter that assures the stability of the method. It also affects the running time, so it is a compromise between speed and accuracy.":"每个尺度的翘曲数。表示每个尺度计算 I1(x+u0) 和 grad( I1(x+u0) ) 的次数。这是确保方法稳定性的参数。它还会影响运行时间，因此它是速度和准确性之间的折衷。\r\n","\r\n            Constructor used to deserialize runtime serialized object\r\n            ":"\r\n            用于反序列化运行时序列化对象的构造函数\r\n            \r\n","Vector of input images":"输入图像的向量\r\n","Matches. If a query descriptor is masked out in mask , no match is added for this descriptor. So, matches size may be smaller than the query descriptors count.":"火柴。如果在 mask 中屏蔽了查询描述符，则不会为该描述符添加任何匹配项。因此，匹配大小可能小于查询描述符计数。\r\n","\r\n            If True, methods raise exceptions if not successful instead of returning an error code\r\n            ":"\r\n            如果为 True，则方法在不成功时引发异常而不是返回错误代码\r\n            \r\n","Enable 3x3 shape smoothing term if >0. A larger value leads to smoother shapes. prior must be in the range [0, 5].":"如果 >0，则启用 3x3 形状平滑项。较大的值会导致更平滑的形状。 prior 必须在 [0, 5] 范围内。\r\n","The size of the descriptor - can be 64, 32, 16, 8, 4, 2 or 1":"描述符的大小 - 可以是 64、32、16、8、4、2 或 1\r\n","grid for gamma":"伽玛网格\r\n","\r\n            Create the termination Criteria using only the constrain of epsilon\r\n            ":"\r\n            仅使用 epsilon 的约束创建终止条件\r\n            \r\n"," The result of the AND operation":" AND 运算的结果\r\n","The methods to use":"使用方法\r\n","\r\n            Depth type\r\n            ":"\r\n            深度型\r\n            \r\n","\r\n            HDDL\r\n            ":"\r\n            高密度脂蛋白\r\n            \r\n","The local subfolder name to download the model to.":"要将模型下载到的本地子文件夹名称。\r\n","\r\n            The range use to setup the histogram\r\n            ":"\r\n            用于设置直方图的范围\r\n            \r\n","The joint matrix of corresponding image points in the views from the 2nd camera, 2xN or Nx2, where N is the total number of points in all views":"第 2 个摄像机的视图中相应图像点的联合矩阵，2xN 或 Nx2，其中 N 是所有视图中点的总数\r\n","\r\n            Threshold that is used to determine saturated pixels, i.e. pixels where at least one of the channels exceeds saturation_threshold x range_max_val are ignored.\r\n            ":"\r\n            用于确定饱和像素的阈值，即忽略至少一个通道超过 saturation_threshold x range_max_val 的像素。\r\n            \r\n","\r\n            Release any images associated with this object\r\n            ":"\r\n            释放与此对象关联的任何图像\r\n            \r\n"," Get or set the intensity of the satuation color channel ":" 获取或设置饱和度颜色通道的强度\r\n","Sum of all matrix elements, independently for each channel.":"所有矩阵元素的总和，独立于每个通道。\r\n","Scalar(average sharpness, average min brightness, average max brightness,0)":"标量（平均锐度，平均最小亮度，平均最大亮度，0）\r\n","\r\n            Tesseract page segmentation mode\r\n            ":"\r\n            Tesseract 页面分割模式\r\n            \r\n","\r\n            Primal-dual algorithm is an algorithm for solving special types of variational problems (that is, finding a function to minimize some functional).\r\n            As the image denoising, in particular, may be seen as the variational problem, primal-dual algorithm then can be used to perform \r\n            denoising and this is exactly what is implemented.\r\n            ":"\r\n            Primal-dual algorithm 是一种求解特殊类型变分问题的算法（即寻找一个函数使某些泛函最小化）。\r\n            由于图像去噪，特别是可以看作是变分问题，因此可以使用原始对偶算法来执行\r\n            去噪，这正是实现的。\r\n            \r\n","\r\n            Calculates the per-element minimum of two matrices of the same size, number of channels and depth\r\n            ":"\r\n            计算相同大小、通道数和深度的两个矩阵的每个元素最小值\r\n            \r\n","Array of 2D points containing calculated new positions of input features in the second image":"二维点数组，包含计算出的第二幅图像中输入特征的新位置\r\n","The second point":"第二点\r\n","The point cloud file name":"点云文件名\r\n","Border value.":"边界值。\r\n","\r\n            If a foreground pixel keeps semi-constant value for about backgroundRatio * history frames, it's considered background and added to the model as a center of a new component. It corresponds to TB parameter in the paper.\r\n            ":"\r\n            如果前景像素在大约 backgroundRatio * 历史帧中保持半恒定值，则它被视为背景并作为新组件的中心添加到模型中。对应论文中的TB参数。\r\n            \r\n","\r\n            An EMD-L1 based cost extraction.\r\n            ":"\r\n            基于 EMD-L1 的成本提取。\r\n            \r\n","\r\n            Creates simple linear mapper with gamma correction.\r\n            ":"\r\n            使用伽马校正创建简单的线性映射器。\r\n            \r\n","\r\n            StdVectorUMat\r\n            ":"\r\n            标准矢量UMat\r\n            \r\n","\r\n            Spatial Moment M10\r\n            ":"\r\n            时空M10\r\n            \r\n","Specify the HDF5 filename.":"指定 HDF5 文件名。\r\n","\r\n            Height\r\n            ":"\r\n            高度\r\n            \r\n","The path to the config file for compability, which is not requested for ONNX models":"用于兼容性的配置文件的路径，ONNX 模型不需要此路径\r\n","Attribute name":"属性名称\r\n"," The edges found by the Canny edge detector":" Canny 边缘检测器发现的边缘\r\n","\r\n            Stub bundle adjuster that does nothing.\r\n            ":"\r\n            什么都不做的存根束调节器。\r\n            \r\n","\r\n            Class implementing EdgeBoxes algorithm from C. Lawrence Zitnick and Piotr Dollár. Edge boxes: Locating object proposals from edges. In ECCV, 2014.\r\n            ":"\r\n            实现 EdgeBoxes 算法的类，来自 C. Lawrence Zitnick 和 Piotr Dollár。边缘框：从边缘定位对象建议。在 ECCV，2014 年。\r\n            \r\n","\r\n            Board of markers\r\n            ":"\r\n            标记板\r\n            \r\n","\r\n            Create an ellipse from the specific RotatedRect\r\n            ":"\r\n            从特定的 RotatedRect 创建一个椭圆\r\n            \r\n","\r\n            Exposure compensator which tries to remove exposure related artifacts by adjusting image block on each channel.\r\n            ":"\r\n            曝光补偿器，它试图通过调整每个通道上的图像块来消除与曝光相关的伪影。\r\n            \r\n","\r\n            Create a new GMat\r\n            ":"\r\n            创建一个新的 GMat\r\n            \r\n","\r\n            Get or Set the compositing resolution\r\n            ":"\r\n            获取或设置合成分辨率\r\n            \r\n","name of the file where the model is stored":"存储模型的文件的名称\r\n","stereo matcher instance that will be used with the filter":"将与过滤器一起使用的立体匹配器实例\r\n","\r\n            Release just the header\r\n            ":"\r\n            只释放标题\r\n            \r\n","The translated Affine3 matrix":"翻译后的 Affine3 矩阵\r\n","\r\n            Add a new image in the list of images to process.\r\n            ":"\r\n            在要处理的图像列表中添加一个新图像。\r\n            \r\n","Output 8-bit unsigned 3-channel image":"输出 8 位无符号 3 通道图像\r\n","Type of morphological operation":"形态运算的类型\r\n","\r\n            Get the display color for each channel\r\n            ":"\r\n            获取每个通道的显示颜色\r\n            \r\n","Lookup table for the G channel":"G通道的查找表\r\n","\r\n            Instantiate NVIDIA Optical Flow\r\n            ":"\r\n            实例化 NVIDIA 光流\r\n            \r\n","\r\n            Spaghetti algorithm for 8-way connectivity, Spaghetti4C algorithm for 4-way connectivity.\r\n            ":"\r\n            8 路连接的 Spaghetti 算法，4 路连接的 Spaghetti4C 算法。\r\n            \r\n","The algorithm as an yml string":"算法作为 yml 字符串\r\n","The frameSource":"框架来源\r\n","\r\n            Create the standard vector of VectorOfERStat \r\n            ":"\r\n            创建 VectorOfERStat 的标准向量\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of VectorOfMat.\r\n            ":"\r\n            VectorOfMat 的 C++ 标准向量的包装类。\r\n            \r\n","dataDir is the location of the TESSDATA. We need it because we load a custom PDF font from this location.":"dataDir 是 TESSDATA 的位置。我们需要它，因为我们从该位置加载自定义 PDF 字体。\r\n","Rhe norm used to compute the Hausdorff value between two shapes. It can be L1 or L2 norm.":"Rhe 范数用于计算两个形状之间的 Hausdorff 值。它可以是 L1 或 L2 范数。\r\n","\r\n            Create an standard vector of Point of the specific size\r\n            ":"\r\n            创建特定大小的 Point 的标准向量\r\n            \r\n","\r\n            Create an image hash based on Radon transform\r\n            ":"\r\n            基于 Radon 变换创建图像哈希\r\n            \r\n","The descriptors to be added to the trainer":"要添加到培训师的描述符\r\n","\r\n            Computes an optimal affine transformation between two 3D point sets.\r\n            ":"\r\n            计算两个 3D 点集之间的最佳仿射变换。\r\n            \r\n","\r\n            Hand-Eye Calibration Using Dual Quaternions\r\n            ":"\r\n            使用双四元数进行手眼校准\r\n            \r\n","\r\n            Finds the positions of internal corners of the chessboard using a sector based approach.\r\n            ":"\r\n            使用基于扇区的方法查找棋盘内角的位置。\r\n            \r\n","\r\n            Create a Panini warper\r\n            ":"\r\n            创建帕尼尼整经机\r\n            \r\n","parameter defining the amount of regularization":"定义正则化量的参数\r\n","Filter sigma in the coordinate space. Larger value of the parameter means that farther pixels will influence each other (as long as their colors are close enough; see sigmaColor). Then d>0, it specifies the neighborhood size regardless of sigmaSpace, otherwise d is proportional to sigmaSpace.":"在坐标空间中过滤 sigma。较大的参数值意味着更远的像素将相互影响（只要它们的颜色足够接近；参见 sigmaColor）。则d>0，则指定邻域大小而不考虑sigmaSpace，否则d与sigmaSpace成正比。\r\n","Image depth ":"图像深度\r\n","\r\n            Create a locale guard to set the locale to specific value. Will revert locale back to previous value when the object is disposed.\r\n            ":"\r\n            创建一个语言环境守卫以将语言环境设置为特定值。当对象被释放时，会将语言环境恢复到以前的值。\r\n            \r\n","Input/output 8-bit single-channel mask. The mask is initialized by the function\r\n             when mode is set to GC_INIT_WITH_RECT. Its elements may have one of following values:\r\n             0 (GC_BGD) defines an obvious background pixels.\r\n             1 (GC_FGD) defines an obvious foreground (object) pixel.\r\n             2 (GC_PR_BGR) defines a possible background pixel.\r\n             3 (GC_PR_FGD) defines a possible foreground pixel.\r\n            ":"输入/输出 8 位单通道掩码。掩码由函数初始化\r\n             当模式设置为 GC_INIT_WITH_RECT 时。它的元素可能具有以下值之一：\r\n             0 (GC_BGD) 定义了一个明显的背景像素。\r\n             1 (GC_FGD) 定义了一个明显的前景（对象）像素。\r\n             2 (GC_PR_BGR) 定义了一个可能的背景像素。\r\n             3 (GC_PR_FGD) 定义了一个可能的前景像素。\r\n            \r\n","After detection some objects could be covered by many rectangles. This coefficient regulates similarity threshold. 0 means don't perform grouping. Should be an integer if not using meanshift grouping. ":"检测后，一些对象可能被许多矩形覆盖。该系数调节相似性阈值。 0 表示不执行分组。如果不使用 meanshift 分组，则应为整数。\r\n","\r\n            Extended Image Processing\r\n            ":"\r\n            扩展图像处理\r\n            \r\n","Multiplier for conservative suppression.":"保守抑制的乘数。\r\n","The result of the rotation, should be the same size as ":"旋转的结果，应该是相同的大小\r\n","\r\n            The label\r\n            ":"\r\n            标签\r\n            \r\n","\r\n            LocalAdaptintegration_k. Use 7.0 for default\r\n            ":"\r\n            LocalAdaptintegration_k。默认使用 7.0\r\n            \r\n","\r\n             value = value > threshold ? 0 : value           \r\n            ":"\r\n             价值=价值>阈值？ 0：价值\r\n            \r\n","\r\n            Converts a rotation vector to rotation matrix or vice versa. Rotation vector is a compact representation of rotation matrix. Direction of the rotation vector is the rotation axis and the length of the vector is the rotation angle around the axis. \r\n            ":"\r\n            将旋转向量转换为旋转矩阵，反之亦然。旋转向量是旋转矩阵的紧凑表示。旋转矢量的方向是旋转轴，矢量的长度是绕轴的旋转角度。\r\n            \r\n","\r\n            Create a transformation that consists on a projective transformation\r\n            ":"\r\n            创建一个包含投影变换的变换\r\n            \r\n","Input camera matrix":"输入相机矩阵\r\n","The text regions found.":"找到的文本区域。\r\n","\r\n            No callback\r\n            ":"\r\n            无回调\r\n            \r\n","The time when the image is captured":"拍摄图像的时间\r\n","second threshold for the hysteresis procedure.":"滞后程序的第二个阈值。\r\n","\r\n            the ratio of the image is respected\r\n            ":"\r\n            尊重图像的比例\r\n            \r\n","\r\n            Release the unmanaged memory associated with this Optical flow algorithm.\r\n            ":"\r\n            释放与此光流算法关联的非托管内存。\r\n            \r\n","Only useful if param useRetinaLogSampling=true, specifies the strength of the log scale that is applied":"仅在参数 useRetinaLogSampling=true 时有用，指定所应用的对数刻度的强度\r\n","The output placeholder for the decoded matrix.":"解码矩阵的输出占位符。\r\n","\r\n            Draw a set of detected ChArUco Diamond markers\r\n            ":"\r\n            绘制一组检测到的 ChArUco Diamond 标记\r\n            \r\n","The keypoints in the model image":"模型图像中的关键点\r\n","\r\n            Clear all retina buffers (equivalent to opening the eyes after a long period of eye close.\r\n            ":"\r\n            清除所有视网膜缓冲区（相当于长时间闭眼后睁开眼睛。\r\n            \r\n","The name of the dll":"dll的名称\r\n","\r\n            The kaze\r\n            ":"\r\n            风\r\n            \r\n","\r\n            Loss\r\n            ":"\r\n            损失\r\n            \r\n","The value to be multiplied":"要乘以的值\r\n","The color conversion code":"颜色转换代码\r\n","\r\n            Create a Morphology filter.\r\n            ":"\r\n            创建形态过滤器。\r\n            \r\n","\r\n            Create an InputArray from a double value\r\n            ":"\r\n            从双精度值创建 InputArray\r\n            \r\n","Value > 100":"值 > 100\r\n","The index, in case if this is an VectorOfUMat":"索引，如果这是一个 VectorOfUMat\r\n","The pointer to the Facemark object":"指向 Facemark 对象的指针\r\n","Border size in pixel":"以像素为单位的边框大小\r\n","\r\n            The equivalent of cv::GComputation\r\n            ":"\r\n            相当于 cv::GComputation\r\n            \r\n","The length of the marker axis [default = 20 pixels]":"标记轴的长度 [默认 = 20 像素]\r\n","The text recognition result":"文字识别结果\r\n","\r\n            Generates the structured light pattern to project.\r\n            ":"\r\n            生成要投射的结构光图案。\r\n            \r\n","Output vector of vector of vertices of the minimum-area quadrangle containing the codes.":"包含代码的最小面积四边形的顶点向量的输出向量。\r\n","If 0.0, the result is the same as this quaternions. If 1.0 the result is the same as ":"如果为 0.0，则结果与此四元数相同。如果 1.0 结果与\r\n","\r\n            Minimum InterChecker Distance\r\n            ":"\r\n            最小 InterChecker 距离\r\n            \r\n","\r\n            Save this image to the specific file. \r\n            ":"\r\n            将此图像保存到特定文件。\r\n            \r\n","\r\n            Allocates, initializes, and returns the structure IplImage.\r\n            ":"\r\n            分配、初始化并返回结构 IplImage。\r\n            \r\n","Scale coefficient for threshold values.":"阈值的比例系数。\r\n","A copy of the boxed region of the image":"图像盒装区域的副本\r\n","An array of Double":"Double 数组\r\n","Optional scale factor for the computed derivative values. By default, no scaling is applied. ":"计算导数值的可选比例因子。默认情况下，不应用缩放。\r\n"," The top-level mapping":" 顶层映射\r\n","\r\n            Bilinear interpolation\r\n            ":"\r\n            双线性插值\r\n            \r\n","\r\n            Destroys all of the HighGUI windows.\r\n            ":"\r\n            销毁所有 HighGUI 窗口。\r\n            \r\n","The number of Cuda enabled devices":"支持 Cuda 的设备数量\r\n","Pointer to the prelocated memory of the resulting sub-array header":"指向结果子数组头的预置内存的指针\r\n","\r\n            A Constant-Space Belief Propagation Algorithm for Stereo Matching\r\n            ":"\r\n            立体匹配的恒定空间置信度传播算法\r\n            \r\n","The name of the file to be loaded":"要加载的文件的名称\r\n","This is both input and output. This matrix indicates which row is valid for the matches.":"这既是输入也是输出。该矩阵指示哪一行对匹配有效。\r\n","True if the exception has been handled, or false if the exception should be rethrown and the application terminated.":"如果异常已被处理，则为 True；如果应重新抛出异常并终止应用程序，则为 false。\r\n","\r\n            Longitude (lambda) in radian\r\n            ":"\r\n            以弧度表示的经度 (lambda)\r\n            \r\n","\r\n            Ot\r\n            ":"\r\n            其他\r\n            \r\n","The camera matrix A=[fx 0 cx; 0 fy cy; 0 0 1]":"相机矩阵A=[fx 0 cx; 0 个周期； 0 0 1]\r\n","The maximum allowed number of mixture components. Actual number is determined dynamically per pixel.":"混合成分的最大允许数量。实际数量是按像素动态确定的。\r\n","\r\n            Returns true if the node is a sequence\r\n            ":"\r\n            如果节点是一个序列，则返回 true\r\n            \r\n","The panoramic image":"全景影像\r\n","Chooses the enforcement of superpixel smoothness factor of superpixel":"选择超像素的超像素平滑因子的强制执行\r\n","\r\n            result = val - this\r\n            ":"\r\n            结果 = val - 这个\r\n            \r\n","The number of channels of the image that will be used in the template matching":"将在模板匹配中使用的图像通道数\r\n","The image such that: dst(x,y) = threshold, if src(x,y)>threshold; src(x,y), otherwise":"图像满足：dst(x,y) = threshold，如果 src(x,y)>threshold； src(x,y)，否则\r\n","\r\n            Distance Type\r\n            ":"\r\n            距离类型\r\n            \r\n","The drawing type":"图纸类型\r\n","\r\n            16bit unsigned\r\n            ":"\r\n            16 位无符号\r\n            \r\n","\r\n            Applies vertical concatenation to given matrices.\r\n            ":"\r\n            将垂直串联应用于给定矩阵。\r\n            \r\n","\r\n            A function to load the trained model before the fitting process.\r\n            ":"\r\n            在拟合过程之前加载训练模型的函数。\r\n            \r\n","\r\n            This algorithm converts images to median threshold bitmaps (1 for pixels brighter than median luminance and 0 otherwise) and than aligns the resulting bitmaps using bit operations.\r\n            ":"\r\n            该算法将图像转换为中值阈值位图（1 表示比中值亮度更亮的像素，否则为 0），然后使用位操作对齐生成的位图。\r\n            \r\n","Pointer to the old error handler":"指向旧错误处理程序的指针\r\n","\r\n            src1(I) \"less than\" src2(I)\r\n            ":"\r\n            src1(I) \"小于\" src2(I)\r\n            \r\n","\r\n            Return the pointer to the algorithm object\r\n            ":"\r\n            返回指向算法对象的指针\r\n            \r\n","\r\n            The type of KNearest search\r\n            ":"\r\n            KNearest搜索的类型\r\n            \r\n","\r\n            Turn a single image into symbolic text.\r\n            ":"\r\n            将单个图像转换为符号文本。\r\n            \r\n","\r\n            Get a list of the available parallel backends.\r\n            ":"\r\n            获取可用并行后端的列表。\r\n            \r\n","The capture object that will be converted to a FrameSource":"将转换为 FrameSource 的捕获对象\r\n","\r\n            The propagation parameters\r\n            ":"\r\n            传播参数\r\n            \r\n","Center of the rotation in the source image. ":"源图像中的旋转中心。\r\n","Optional parameter. Refer https://developer.nvidia.com/opticalflow-sdk for details about presets.":"可选参数。有关预设的详细信息，请参阅 https://developer.nvidia.com/opticalflow-sdk。\r\n","\r\n            Returns the block histogram size.\r\n            ":"\r\n            返回块直方图大小。\r\n            \r\n","\r\n            Obtains the list of Voronoi Facets \r\n            ":"\r\n            获取 Voronoi Facets 列表\r\n            \r\n","\r\n            Convert RGB color to BGR565 color\r\n            ":"\r\n            将 RGB 颜色转换为 BGR565 颜色\r\n            \r\n","\r\n            Release all the unmanaged resource associated with this object\r\n            ":"\r\n            释放与该对象关联的所有非托管资源\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of VectorOfInt.\r\n            ":"\r\n            VectorOfInt 的 C++ 标准向量的包装类。\r\n            \r\n","The sizes of each dimension":"每个维度的大小\r\n","\r\n            Camera sensor temperature\r\n            ":"相机传感器温度\r\n            \r\n","\r\n            minimum mean distance beetween two marker corners to be considered similar, so that the smaller one is removed. The rate is relative to the smaller perimeter of the two markers (default 0.05).\r\n            ":"\r\n            两个标记角之间的最小平均距离被认为是相似的，因此较小的角被移除。该速率相对于两个标记的较小周长（默认 0.05）。\r\n            \r\n","The Z component of the vector: rotation axis * sin(rotation angle / 2)":"矢量的Z分量：旋转轴*sin(旋转角度/2)\r\n","A threshold used to filter boxes by confidences.":"用于按置信度过滤框的阈值。\r\n","\r\n            Dict4X4_250\r\n            ":"\r\n            词典4X4_250\r\n            \r\n","The output image depth (-1 to use src.depth()).":"输出图像深度（-1 使用 src.depth()）。\r\n","Projected image minimum bounding box":"投影图像最小边界框\r\n","Size of the input video frames.":"输入视频帧的大小。\r\n","The signature to measure distance of other signatures from.":"测量其他签名距离的签名。\r\n","source image (RGB, float, in [0;1]) to detect edges":"用于检测边缘的源图像（RGB，浮点数，在 [0;1] 中）\r\n","\r\n            Agast feature type\r\n            ":"\r\n            反对特征类型\r\n            \r\n","\r\n            Transverse mercator warper\r\n            ":"\r\n            横向墨卡托整经机\r\n            \r\n","True for forward gamma correction or false for inverse gamma correction.":"正向伽马校正为真，反向伽马校正为假。\r\n","The DataLogger":"数据记录器\r\n","\r\n            Converts an image from LUV color space to BGR color space.\r\n            ":"\r\n            将图像从 LUV 色彩空间转换为 BGR 色彩空间。\r\n            \r\n","\r\n            Check whether a given attribute exits or not in the root group.\r\n            ":"\r\n            检查给定属性是否存在于根组中。\r\n            \r\n","\r\n            If set, always convert image to the 3 channel BGR color image.\r\n            ":"\r\n            如果设置，始终将图像转换为 3 通道 BGR 彩色图像。\r\n            \r\n","Output scalar for binary computation":"二进制计算的输出标量\r\n","\r\n            Slower than average hash, but tolerant of minor modifications\r\n            ":"\r\n            比平均散列慢，但可以容忍较小的修改\r\n            \r\n","\r\n            Feature vectors are stored as rows\r\n            ":"\r\n            特征向量存储为行\r\n            \r\n","\r\n            Intelperc Depth Low Confidence Value\r\n            ":"\r\n            Intelperc 深度低置信值\r\n            \r\n","Mat container where data reads will be returned.":"将返回数据读取的 Mat 容器。\r\n","\r\n            Create a new sinusoidal patterns\r\n            ":"\r\n            创建新的正弦曲线模式\r\n            \r\n","\r\n            Specifies the kind of training method used.\r\n            ":"\r\n            指定使用的训练方法的种类。\r\n            \r\n","\r\n            The termination criteria that specifies when the training algorithm stops\r\n            ":"\r\n            指定训练算法何时停止的终止条件\r\n            \r\n","Number of Gaussian mixtures.":"高斯混合数。\r\n","Specifying whether the kernel is normalized by its area or not.":"指定内核是否按其面积归一化。\r\n","The parent GpuMat should never be released before the returned GpuMat that represent the subregion":"在代表子区域的返回 GpuMat 之前，不应释放父 GpuMat\r\n","\r\n            Bad image size\r\n            ":"\r\n            图像尺寸错误\r\n            \r\n","Scale factor for the first array":"第一个数组的比例因子\r\n","Arrays of arrays of the Byte":"字节数组的数组\r\n","Output image with the same size and type as dst.":"输出与 dst 具有相同大小和类型的图像。\r\n","\r\n            Create a new RgbdNormals object that can compute the normals in an image.\r\n            ":"\r\n            创建一个可以计算图像法线的新 RgbdNormals 对象。\r\n            \r\n","\r\n            The function tests whether the input contour is convex or not. The contour must be simple, that is, without self-intersections. Otherwise, the function output is undefined.\r\n            ":"\r\n            该函数测试输入轮廓是否是凸的。轮廓必须简单，即没有自相交。否则，函数输出未定义。\r\n            \r\n","\r\n            Create an standard vector of TesseractResult with the initial values\r\n            ":"\r\n            使用初始值创建 TesseractResult 的标准向量\r\n            \r\n","\r\n            Implements \"Optimal local searching for fast and robust textureless 3D object tracking in highly cluttered backgrounds\"\r\n            ":"\r\n            实现“在高度杂乱的背景中快速和稳健的无纹理 3D 对象跟踪的最佳局部搜索”\r\n            \r\n","Edge image.":"边缘图像。\r\n","Number of initial clusterization seeds. Must be lower or equal to initSampleCount":"初始聚类种子数。必须小于或等于 initSampleCount\r\n","Optional scale factor":"可选比例因子\r\n","buffer containing the content of the pbtxt file":"包含 pbtxt 文件内容的缓冲区\r\n","\r\n            Release the unmanaged memory associated with this BasicFaceRecognizer\r\n            ":"\r\n            释放与此 BasicFaceRecognizer 关联的非托管内存\r\n            \r\n","vector of aligned images":"对齐图像的矢量\r\n","Cross-validation parameter. The training set is divided into k_fold subsets, one subset being used to train the model, the others forming the test set. So, the SVM algorithm is executed k_fold times":"交叉验证参数。训练集分为k_fold子集，一个子集用于训练模型，其他子集组成测试集。所以，SVM算法执行了k_fold次\r\n","\r\n            Wrapped class of the C++ standard vector of UMat.\r\n            ":"\r\n            UMat 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Gaussian filter\r\n            ":"\r\n            高斯滤波器\r\n            \r\n","The (degree + 1)-length array of equation coefficients (CV_32FC1 or CV_64FC1)":"等式系数的 (degree + 1) 长度数组（CV_32FC1 或 CV_64FC1）\r\n","\r\n            Class implementing Signature Quadratic Form Distance (SQFD).\r\n            ":"\r\n            实现签名二次形式距离 (SQFD) 的类。\r\n            \r\n","Parameters of the detection system":"检测系统参数\r\n","If true, will try to use gpu.":"如果为真，将尝试使用 gpu。\r\n","The file name of the storage":"存储的文件名\r\n","Pixel extrapolation method in the vertical direction. ":"垂直方向的像素外推法。\r\n","\r\n            BGM is the base descriptor where each binary dimension is computed as the output of a single weak learner.\r\n            ":"\r\n            BGM 是基本描述符，其中每个二进制维度都被计算为单个弱学习器的输出。\r\n            \r\n","\r\n            Adds one matrix to another (c = a + b).\r\n            ":"\r\n            将一个矩阵加到另一个矩阵 (c = a + b)。\r\n            \r\n","\r\n            Create a rotation matrix for rotating an image\r\n            ":"\r\n            创建用于旋转图像的旋转矩阵\r\n            \r\n","\r\n            Ctype\r\n            ":"\r\n            C型\r\n            \r\n","\r\n            Renders tesseract output into searchable PDF\r\n            ":"\r\n            将 tesseract 输出呈现为可搜索的 PDF\r\n            \r\n","The color of the text":"文本的颜色\r\n","Array of the second image points of the same size and format as points1":"与 points1 具有相同大小和格式的第二个图像点的数组\r\n","\r\n            Turbo\r\n            ":"\r\n            涡轮\r\n            \r\n","A two dimension matrix that represent the points":"表示点的二维矩阵\r\n","The output 3x1 or 1x3 translation vector":"输出 3x1 或 1x3 平移向量\r\n","channel of interest of the image (it returns 0 if all the channels are selected)":"图像的感兴趣通道（如果选择了所有通道，则返回 0）\r\n","\r\n            Returns array containing proposal boxes.\r\n            ":"\r\n            返回包含提案框的数组。\r\n            \r\n","\r\n            Spatial Moment M30\r\n            ":"\r\n            时空M30\r\n            \r\n","\r\n            C#\r\n            ":"\r\n            C＃\r\n            \r\n","\r\n            Maximal number of generated clusters. If the number is exceeded, the clusters are sorted by their weights and the smallest clusters are cropped.\r\n            ":"\r\n            生成的簇的最大数量。如果超过该数量，则簇按其权重排序并裁剪掉最小的簇。\r\n            \r\n","the size of half of the mini-patches size. For example, if we would like to compare triplets of patches of size 7x7x\r\n            then the half_ssd_size should be (7-1)/2 = 3.":"小补丁大小的一半大小。例如，如果我们想比较大小为 7x7x 的补丁的三元组\r\n            那么 half_ssd_size 应该是 (7-1)/2 = 3。\r\n","\r\n            Log level\r\n            ":"\r\n            日志级别\r\n            \r\n","\r\n            Warp shuffle functions\r\n            ":"\r\n            扭曲洗牌功能\r\n            \r\n","The minimum area (% of image size) allowed for retreived ER’s.":"允许检索 ER 的最小区域（图像大小的百分比）。\r\n","\r\n            Bad Order\r\n            ":"\r\n            坏订单\r\n            \r\n","\r\n            Scale the image to the specific size\r\n            ":"\r\n            将图像缩放到特定尺寸\r\n            \r\n","\r\n            Set the seam finder for this stitcher\r\n            ":"\r\n            为这个订书机设置接缝探测器\r\n            \r\n","\r\n            Get the available NNet and data packets\r\n            ":"\r\n            获取可用的 NNet 和数据包\r\n            \r\n","The number of points in the search radius":"搜索半径内的点数\r\n","\r\n            Pointer to the native Tracker object\r\n            ":"\r\n            指向本机 Tracker 对象的指针\r\n            \r\n","\r\n            Convert RGB to YUV_IYUV\r\n            ":"\r\n            RGB转YUV_IYUV\r\n            \r\n","\r\n            Release the unmanaged memory associated with this AlignMTB object\r\n            ":"\r\n            释放与此 AlignMTB 对象关联的非托管内存\r\n            \r\n"," image using a 3x3 rectangular structuring element.\r\n            Erosion are applied several (iterations) times\r\n            ":" 使用 3x3 矩形结构元素的图像。\r\n            侵蚀应用多次（迭代）次\r\n            \r\n","\r\n            Create a new instance of OLS tracker\r\n            ":"\r\n            创建一个新的 OLS 跟踪器实例\r\n            \r\n","The element on the specific ":"具体的元素\r\n","8-bit single-channel right image of CV_8UC1 type.":"CV_8UC1 类型的 8 位单通道右图像。\r\n","\r\n            Create a one pass stabilizer\r\n            ":"\r\n            创建单程稳定器\r\n            \r\n","The equivalent opencv depth type":"等效opencv深度类型\r\n","\r\n            Background/Foreground Segmentation Algorithm.\r\n            ":"\r\n            背景/前景分割算法。\r\n            \r\n"," First input 3D point set.":" 首先输入 3D 点集。\r\n","Maximum size of the 3D group for collaborative filtering.":"用于协同过滤的 3D 组的最大大小。\r\n","\r\n            The VideoWriter property\r\n            ":"\r\n            VideoWriter 属性\r\n            \r\n","Pointer to returned maximum value":"指向返回最大值的指针\r\n","\r\n            Create an empty (2x3) 2D rotation matrix\r\n            ":"\r\n            创建一个空的 (2x3) 二维旋转矩阵\r\n            \r\n","The second image for the OR operation":"OR 操作的第二个图像\r\n","\r\n            Calibration file\r\n            ":"\r\n            校准文件\r\n            \r\n","\r\n            Bundle adjuster that expects affine transformation with 4 DOF represented in homogeneous coordinates in R for each camera param. Implements camera parameters refinement algorithm which minimizes sum of the reprojection error squares.\r\n            ":"\r\n            Bundle adjuster 期望具有 4 个 DOF 的仿射变换，每个相机参数在 R 中以齐次坐标表示。实现相机参数细化算法，使重投影误差平方和最小化。\r\n            \r\n","\r\n            Bad mask\r\n            ":"\r\n            坏面具\r\n            \r\n","\r\n            Do forward 1D or 2D transform. The result is not scaled\r\n            ":"\r\n            进行正向 1D 或 2D 变换。结果未缩放\r\n            \r\n","\r\n            Implicit operator for IntPtr\r\n            ":"\r\n            IntPtr 的隐式运算符\r\n            \r\n"," The inclusive lower limit of color value":" 色值下限（含）\r\n","\r\n            Release the page iterator\r\n            ":"\r\n            释放页面迭代器\r\n            \r\n","\r\n            The number that the barcode represents\r\n            ":"\r\n            条形码代表的数字\r\n            \r\n"," Draw a line segment using the specific color and thickness ":" 使用特定颜色和粗细绘制线段\r\n","\r\n            80 dimension float\r\n            ":"\r\n            80维浮点数\r\n            \r\n","\r\n            (read only) Contains the time difference between the start of the audio stream and the video stream in nanoseconds. Positive value means that audio is started after the first video frame. Negative value means that audio is started before the first video frame.\r\n            ":"\r\n            （只读）包含音频流和视频流开始之间的时间差，以纳秒为单位。正值表示音频在第一个视频帧之后开始。负值表示音频在第一个视频帧之前开始。\r\n            \r\n","\r\n            Sparse PyrLK optical flow\r\n            ":"\r\n            稀疏 PyrLK 光流\r\n            \r\n","\r\n            This represent a character that is detected by the OCR engine\r\n            ":"\r\n            这表示 OCR 引擎检测到的字符\r\n            \r\n","\r\n            Write the whole image as tile tiff\r\n            ":"\r\n            将整个图像写为平铺 tiff\r\n            \r\n","Size of the extended Sobel kernel":"扩展 Sobel 内核的大小\r\n","Output image size; if it equals zero, it is computed as: dsize=Size(round(fx*src.cols), round(fy * src.rows)). Either dsize or both fx and fy must be non-zero.":"输出图像大小；如果它等于零，则计算为：dsize=Size(round(fx*src.cols), round(fy * src.rows))。 dsize 或 fx 和 fy 都必须非零。\r\n","\r\n            Convert GRAY color to BGR555 color\r\n            ":"\r\n            将 GRAY 颜色转换为 BGR555 颜色\r\n            \r\n","Use false for default":"默认使用 false\r\n","Created array type":"创建的数组类型\r\n"," Compute the element of the new image based on element of this image":" 根据该图像的元素计算新图像的元素\r\n","Minimum margins (in pixels) of the board in the output image":"输出图像中电路板的最小边距（以像素为单位）\r\n","Vector of DMatch objects.":"DMatch 对象的向量。\r\n","\r\n            The dimension is chosen automatically by analysing the dst size\r\n            ":"\r\n            通过分析 dst 大小自动选择维度\r\n            \r\n","Array of points for which the flow needs to be found. ":"需要找到流的点数组。\r\n"," \r\n            Decodes and returns the grabbed video frame.\r\n            ":" \r\n            解码并返回抓取的视频帧。\r\n            \r\n","\r\n            Scales the map by a given factor as if the coordinates system is expanded/compressed by that factor.\r\n            ":"\r\n            按给定因子缩放地图，就好像坐标系按该因子扩展/压缩一样。\r\n            \r\n","The border value, use new MCvScalar() for default.":"边界值，默认使用 new MCvScalar()。\r\n","The tile size in pixels":"以像素为单位的图块大小\r\n","\r\n            The device extensions\r\n            ":"\r\n            设备扩展\r\n            \r\n","All the support vector as floating-point matrix, where support vectors are stored as matrix rows.":"所有支持向量作为浮点矩阵，其中支持向量存储为矩阵行。\r\n","\r\n            Switch edge feature extractor to use Canny edge detector.\r\n            ":"\r\n            将边缘特征提取器切换为使用 Canny 边缘检测器。\r\n            \r\n","\r\n            Returns image header for the input array that can be matrix - CvMat*, or image - IplImage*.\r\n            ":"\r\n            返回输入数组的图像标题，可以是矩阵 - CvMat* 或图像 - IplImage*。\r\n            \r\n","\r\n            Create a Sobel filter.\r\n            ":"\r\n            创建 Sobel 过滤器。\r\n            \r\n","The array of object points":"对象点数组\r\n","\r\n            Automatic exposure/gain\r\n            ":"\r\n            自动曝光/增益\r\n            \r\n"," The ellipse to be draw":" 要画的椭圆\r\n","aperture linear size; it must be odd and greater than 1, for example: 3, 5, 7 ...":"孔径线性尺寸；它必须是奇数且大于 1，例如：3, 5, 7 ...\r\n","\r\n            Draw the matched keypoints between the model image and the observered image.\r\n            ":"\r\n            在模型图像和观察图像之间绘制匹配的关键点。\r\n            \r\n","\r\n            Create an EMD based cost extraction.\r\n            ":"\r\n            创建基于 EMD 的成本提取。\r\n            \r\n","\r\n            src1(I) \"greater than\" src2(I)\r\n            ":"\r\n            src1(I) \"大于\" src2(I)\r\n            \r\n","Line bundle image with size ctl2d.rows() x (2 * len + 1) and the same type as img":"大小为 ctl2d.rows() x (2 * len + 1) 且类型与 img 相同的线束图像\r\n"," <= this[i,j] <= ":" <=这个[我，j] <=\r\n","Strength of the noise removal for background points.":"背景点的噪声去除强度。\r\n","Starting angle of the elliptic arc":"椭圆弧的起始角\r\n"," Input 2D point set":" 输入二维点集\r\n","A single Color for the whole cloud.":"整个云的单一颜色。\r\n","\r\n            Create an standard vector of VectorOfByte with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfByte 的标准向量\r\n            \r\n","The jpeg quality":"jpeg 质量\r\n","\r\n            OpenCV's DMatch structure\r\n            ":"\r\n            OpenCV的DMatch结构\r\n            \r\n","The generated all-white CV_8U image, at projector's resolution.":"以投影仪的分辨率生成的全白 CV_8U 图像。\r\n","\r\n            Get or Set the color in the ":"获取或设置颜色\r\n","\r\n            The dimension of color\r\n            ":"\r\n            颜色的维度\r\n            \r\n","First rectangle":"第一个矩形\r\n","\r\n            Library to invoke Tesseract OCR functions\r\n            ":"\r\n            调用 Tesseract OCR 函数的库\r\n            \r\n","\r\n            Detection of quads can be done on a lower-resolution image, improving speed at a\r\n            cost of pose accuracy and a slight decrease in detection rate.Decoding the binary payload is still\r\n            done at full resolution.\r\n            ":"可以在较低分辨率的图像上检测四边形，提高速度\r\n            姿势精度的成本和检测率的轻微下降。解码二进制有效载荷仍然是\r\n            以全分辨率完成。\r\n            \r\n","\r\n            Sets an affine motion model (DEFAULT); six parameters are estimated; warpMatrix is 2x3.\r\n            ":"\r\n            设置仿射运动模型（默认）；估计了六个参数； warpMatrix 是 2x3。\r\n            \r\n","Position of the text.":"文本的位置。\r\n","\r\n            When passing an object of this type the index created is automatically tuned to offer the best performance, by choosing the optimal index type (randomized kd-trees, hierarchical kmeans, linear) and parameters for the dataset provided.\r\n            ":"\r\n            当传递这种类型的对象时，通过为提供的数据集选择最佳索引类型（随机 kd 树、分层 kmeans、线性）和参数，自动调整创建的索引以提供最佳性能。\r\n            \r\n","The Pinned/Unmanaged data, the data must not be release before the Matrix is Disposed":"Pinned/Unmanaged 数据，在 Matrix 被处置前不得释放数据\r\n","\r\n            Converts an array to half precision floating number.\r\n            ":"\r\n            将数组转换为半精度浮点数。\r\n            \r\n","Gaussian kernel size. ksize.width and ksize.height can differ but they both must be positive and odd. Or, they can be zero’s and then they are computed from sigma* .":"高斯核大小。 ksize.width 和 ksize.height 可以不同，但​​它们都必须为正数且为奇数。或者，它们可以为零，然后根据 sigma* 计算得出。\r\n","\r\n            Creates an instance of the TextDetectorCNN class using the provided parameters.\r\n            ":"\r\n            使用提供的参数创建 TextDetectorCNN 类的实例。\r\n            \r\n","The class id":"班级编号\r\n","\r\n            Push an array of value into the standard vector\r\n            ":"\r\n            将值数组推入标准向量\r\n            \r\n"," Perform an binary AND operation with some color":" 对某种颜色执行二元与运算\r\n","\r\n            The device minor version number\r\n            ":"\r\n            设备次版本号\r\n            \r\n","output list of detected diamond corners (4 corners per diamond). The order is the same than in marker corners: top left, top right, bottom right and bottom left. Similar format than the corners returned by detectMarkers(e.g VectorOfVectorOfPointF ).":"检测到的钻石角的输出列表（每个钻石 4 个角）。顺序与标记角中的顺序相同：左上角、右上角、右下角和左下角。与 detectMarkers 返回的角的格式相似（例如 VectorOfVectorOfPointF ）。\r\n","\r\n            Creates the header and allocates data. \r\n            ":"\r\n            创建标头并分配数据。\r\n            \r\n","The depth type to convert the image to.":"将图像转换为的深度类型。\r\n","\r\n            The max compute unit\r\n            ":"\r\n            最大计算单元\r\n            \r\n","Input camera matrix.":"输入相机矩阵。\r\n","spatial bandwidth (proportional to target)":"空间带宽（与目标成比例）\r\n","output array of the same size and the same depth as mv[0]; The number of channels will be the total number of channels in the matrix array.":"与 mv[0] 相同大小和相同深度的输出数组；通道数将是矩阵数组中的通道总数。\r\n","\r\n            Calculates area of the whole contour or contour section. \r\n            ":"\r\n            计算整个轮廓或轮廓部分的面积。\r\n            \r\n","\r\n            Allows access to lens feature value currently selected by XI_PRM_LENS_FEATURE_SELECTOR.\r\n            ":"\r\n            允许访问当前由 XI_PRM_LENS_FEATURE_SELECTOR 选择的镜头特征值。\r\n            \r\n","Pointer to the standard deviation":"指向标准偏差的指针\r\n","The exclusive ending column to be extracted":"要提取的独占结束列\r\n","3x4 input projection matrix P.":"3x4 输入投影矩阵 P。\r\n","\r\n            State transition matrix (A)\r\n            ":"\r\n            状态转移矩阵（A）\r\n            \r\n","\r\n            True if the data is continues\r\n            ":"\r\n            如果数据继续，则为真\r\n            \r\n","\r\n            Wolf's technique.\r\n            ":"\r\n            狼的技术。\r\n            \r\n","\r\n            The default\r\n            ":"\r\n            默认的\r\n            \r\n","\r\n            Create text detection algorithm from deep learning network\r\n            ":"\r\n            从深度学习网络创建文本检测算法\r\n            \r\n"," Create a RGBA color using the specific values":" 使用特定值创建 RGBA 颜色\r\n","The string that represent the text in the FileStorage":"代表 FileStorage 中文本的字符串\r\n","\r\n            should the thresholded image be deglitched? Only useful for very noisy images\r\n            ":"\r\n            阈值图像应该去毛刺吗？仅对非常嘈杂的图像有用\r\n            \r\n","To calculate the largest eigenvector/-value set lowindex = highindex = 1. For legacy reasons this function always returns a square matrix the same size as the source matrix with eigenvectors and a vector the length of the source matrix with eigenvalues. The selected eigenvectors/-values are always in the first highindex - lowindex + 1 rows.":"要计算最大的特征向量/-值，请设置 lowindex = highindex = 1。由于遗留原因，此函数始终返回一个方阵，其大小与具有特征向量的源矩阵相同，以及一个与具有特征值的源矩阵的长度相同的向量。选定的特征向量/-值始终位于第一个 highindex - lowindex + 1 行中。\r\n","The strucutred light pattern":"结构光模式\r\n","The sum GpuMat, supports only CV_32S source type, but will contain unsigned int values":"GpuMat 的总和，仅支持 CV_32S 源类型，但将包含无符号整数值\r\n","Neighborhood size.":"街区大小。\r\n","input image; the image can have any number of channels, which are processed independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.":"输入图像；图像可以有任意数量的通道，独立处理，但深度应为 CV_8U、CV_16U、CV_16S、CV_32F 或 CV_64F。\r\n","A map of comparison results; single-channel 32-bit floating-point. If image is WxH and templ is wxh then result must be W-w+1xH-h+1.":"比较结果图；单通道 32 位浮点数。如果图像是 WxH 而模板是 wxh 那么结果必须是 W-w+1xH-h+1。\r\n","\r\n            Release all the unmanaged memory associated with this object\r\n            ":"\r\n            释放与该对象关联的所有非托管内存\r\n            \r\n","The computed flow image; will have the same size as prevImg and type CV 32FC2":"计算出的流图；大小与 prevImg 相同，类型为 CV 32FC2\r\n"," \r\n            Defines a CIE Luv color \r\n            ":" \r\n            定义 CIE Luv 颜色\r\n            \r\n","\r\n            The Kmeans center initiation types\r\n            ":"\r\n            Kmeans 中心启动类型\r\n            \r\n","The color at the specific location":"特定位置的颜色\r\n","\r\n            Maximum size of the features. The following\r\n            values of the parameter are supported:\r\n            4, 6, 8, 11, 12, 16, 22, 23, 32, 45, 46, 64, 90, 128":"\r\n            特征的最大尺寸。下列\r\n            支持参数值：\r\n            4, 6, 8, 11, 12, 16, 22, 23, 32, 45, 46, 64, 90, 128\r\n","The learning rate, use -1.0f for default value.":"学习率，默认使用-1.0f。\r\n","\r\n            Convex sequence\r\n            ":"\r\n            凸序列\r\n            \r\n","\r\n            VideoCapture API backends identifier.\r\n            ":"\r\n            VideoCapture API 后端标识符。\r\n            \r\n","The name of the executable":"可执行文件的名称\r\n","\r\n            Implementation of the Shape Context descriptor and matching algorithm proposed by Belongie et al. in “Shape Matching and Object Recognition Using Shape Contexts” (PAMI 2002). \r\n            ":"\r\n            Belongie等人提出的Shape Context描述符和匹配算法的实现。在“使用形状上下文的形状匹配和对象识别”（PAMI 2002）中。\r\n            \r\n","\r\n            EPnP: Efficient Perspective-n-Point Camera Pose Estimation\r\n            F.Moreno-Noguer, V.Lepetit and P.Fua \"EPnP: Efficient Perspective-n-Point Camera Pose Estimation\"\r\n            ":"\r\n            EPnP：高效的透视 n 点相机姿态估计\r\n            F.Moreno-Noguer、V.Lepetit 和 P.Fua“EPnP：高效透视 n 点相机姿态估计”\r\n            \r\n","The canny edges":"精明的边缘\r\n","\r\n            Extremal Region Filter for the 2nd stage classifier of N&M algorithm\r\n            ":"\r\n            N&M算法第二阶段分类器的极值区域滤波器\r\n            \r\n","The color by with which the squares of the checker will be drawn":"绘制方格的颜色\r\n","Image to store the edges found by the function":"存储函数找到的边缘的图像\r\n","\r\n            Check if the two MatND are equal\r\n            ":"\r\n            检查两个MatND是否相等\r\n            \r\n","output image depth; the following combinations of src.depth() and ddepth are supported:\r\n             ":"输出图像深度；支持以下 src.depth() 和 ddepth 的组合：\r\n             \r\n","The Matrix to be divided":"要划分的矩阵\r\n","Type of the matrix":"矩阵类型\r\n","Input 8-bit 3-channel image.":"输入 8 位 3 通道图像。\r\n","\r\n            A Voronoi Facet\r\n            ":"\r\n            一个 Voronoi 面\r\n            \r\n","the value which subtract this image":"减去此图像的值\r\n","Absolute value of area of intersecting polygon.":"相交多边形面积的绝对值。\r\n","The second GpuMat to be element-wise multiplied.":"要按元素相乘的第二个 GpuMat。\r\n","The number of iterations made":"进行的迭代次数\r\n","\r\n            Sets the index of a point which coordinates will be printed on the top left corner of the plot (if ShowText flag is true)\r\n            ":"\r\n            设置坐标将打印在绘图左上角的点的索引（如果 ShowText 标志为真）\r\n            \r\n","\r\n            Pointer to the shared pointer to the unmanaged object\r\n            ":"\r\n            指向非托管对象的共享指针\r\n            \r\n","The array of output arrays":"输出数组的数组\r\n","In second, the duration of motion history you wants to keep":"第二，你想保留的运动历史的持续时间\r\n","pointer to video file writer structure":"指向视频文件编写器结构的指针\r\n","Pixel extrapolation method in the vertical direction. For details, see borderInterpolate.":"垂直方向的像素外推法。有关详细信息，请参阅 borderInterpolate。\r\n","\r\n            Copy this Input array to another.\r\n            ":"\r\n            将此输入数组复制到另一个。\r\n            \r\n","\r\n            If it is not zero, the encoder will expect and encode color frames, otherwise it will work with grayscale frames.\r\n            ":"\r\n            如果它不为零，编码器将期望并编码彩色帧，否则它将使用灰度帧。\r\n            \r\n","Vector containing lines for which descriptors must be computed":"包含必须为其计算描述符的行的向量\r\n","Output image channel. Only single channel type is supported for now.":"输出图像通道。目前仅支持单通道类型。\r\n","\r\n            Returns the sum of absolute values for matrix elements.\r\n            ":"\r\n            返回矩阵元素的绝对值之和。\r\n            \r\n","the textual description for the specified error status code.":"指定错误状态代码的文本描述。\r\n"," The result of elementwise subtracting ":" 元素相减的结果\r\n","Size of the extended Sobel kernel; it must be odd.":"扩展 Sobel 内核的大小；这一定很奇怪。\r\n","The inpainting mask. Non-zero pixels indicate the area that needs to be inpainted":"修复面具。非零像素表示需要修复的区域\r\n"," Threshold the image inplace such that: dst(x,y) = threshold, if src(x,y)>threshold; src(x,y), otherwise ":"阈值图像就地使得： dst(x,y) = threshold, if src(x,y)>threshold; src(x,y)，否则\r\n"," The z value for this color ":" 此颜色的 z 值\r\n","\r\n            Load all the assemblies.\r\n            ":"\r\n            加载所有程序集。\r\n            \r\n","\r\n            Finds lines in a binary image using the standard Hough transform.\r\n            ":"\r\n            使用标准 Hough 变换在二值图像中查找线条。\r\n            \r\n","The url where the file can be downloaded from":"可以从中下载文件的 url\r\n","\r\n            The default exception to be thrown when error is encountered in Open CV \r\n            ":"\r\n            Open CV 遇到错误时默认抛出的异常\r\n            \r\n","Decrease step for T-values.":"减少 T 值的步长。\r\n","\r\n            For each query descriptor, finds the training descriptors not farther than the specified distance (asynchronous version).\r\n            ":"\r\n            对于每个查询描述符，找到不超过指定距离的训练描述符（异步版本）。\r\n            \r\n","\r\n            Create instance of DTFilter and produce initialization routines.\r\n            ":"\r\n            创建 DTFilter 实例并生成初始化例程。\r\n            \r\n","Coordinates of the bottom-left corner of the first letter":"第一个字母左下角的坐标\r\n","The file node":"文件节点\r\n","Color sigma":"颜色西格玛\r\n","\r\n            Show Text\r\n            ":"\r\n            显示文字\r\n            \r\n","\r\n            Bad Size\r\n            ":"\r\n            大小不合适\r\n            \r\n","\r\n            Create a binary File Storage with the specific data\r\n            ":"\r\n            使用特定数据创建二进制文件存储\r\n            \r\n","\r\n            Data move policy\r\n            ":"\r\n            数据移动策略\r\n            \r\n","\r\n            Raises every element of input array to p:\r\n            dst(I)=src(I)p, if p is integer\r\n            dst(I)=abs(src(I))p, otherwise\r\n            That is, for non-integer power exponent the absolute values of input array elements are used. However, it is possible to get true values for negative values using some extra operations, as the following sample, computing cube root of array elements, shows:\r\n            CvSize size = cvGetSize(src);\r\n            CvMat* mask = cvCreateMat( size.height, size.width, CV_8UC1 );\r\n            cvCmpS( src, 0, mask, CV_CMP_LT ); /* find negative elements */\r\n            cvPow( src, dst, 1./3 );\r\n            cvSubRS( dst, cvScalarAll(0), dst, mask ); /* negate the results of negative inputs */\r\n            cvReleaseMat( &mask );\r\n            For some values of power, such as integer values, 0.5 and -0.5, specialized faster algorithms are used.\r\n            ":"\r\n            将输入数组的每个元素增加到 p：\r\n            dst(I)=src(I)p，如果p是整数\r\n            dst(I)=abs(src(I))p，否则\r\n            也就是说，对于非整数幂指数，使用输入数组元素的绝对值。但是，使用一些额外的操作可以获得负值的真值，如以下示例所示，计算数组元素的立方根：\r\n            CvSize 大小 = cvGetSize(src);\r\n            CvMat* mask = cvCreateMat( size.height, size.width, CV_8UC1 );\r\n            cvCmpS( 源码, 0, 掩码, CV_CMP_LT ); /* 寻找负元素 */\r\n            cvPow( src, dst, 1./3 );\r\n            cvSubRS(dst, cvScalarAll(0), dst, mask ); /* 否定负输入的结果 */\r\n            cvReleaseMat( &mask );\r\n            对于某些幂值，例如整数值 0.5 和 -0.5，使用专门的更快算法。\r\n            \r\n","The output disparity map, should have the same size as the input disparity map":"输出视差图应与输入视差图具有相同的大小\r\n","Output vector of found circles. Each vector is encoded as a 3-element floating-point vector.":"找到的圆的输出向量。每个向量都被编码为一个 3 元素浮点向量。\r\n","\r\n            Median Flow tracker implementation.\r\n            The tracker is suitable for very smooth and predictable movements when object is visible throughout\r\n            the whole sequence.It's quite and accurate for this type of problems (in particular, it was shown\r\n            by authors to outperform MIL). During the implementation period the code at\r\n            http://www.aonsquared.co.uk/node/5, the courtesy of the author Arthur Amarra, was used for the\r\n            reference purpose.\r\n            ":"\r\n            中值流跟踪器实施。\r\n            当目标始终可见时，跟踪器适用于非常平滑和可预测的运动\r\n            整个序列。对于这类问题非常准确（特别是，它被证明\r\n            由作者胜过 MIL）。在实施期间，代码位于\r\n            http://www.aonsquared.co.uk/node/5，由作者 Arthur Amarra 友情提供，用于\r\n            参考目的。\r\n            \r\n","\r\n            Get the average value on this image, using the specific mask\r\n            ":"\r\n            使用特定掩码获取此图像的平均值\r\n            \r\n","\r\n            If the image contains Byte and width is not a multiple of 4. The second dimension of the array might be larger than the Width of this image.  \r\n            This is necessary since the length of a row need to be 4 align for OpenCV optimization. \r\n            The Set function always make a copy of the specific value. If the image contains Byte and width is not a multiple of 4. The second dimension of the array created might be larger than the Width of this image.  \r\n            ":"\r\n            如果图像包含字节且宽度不是 4 的倍数。数组的第二个维度可能大于此图像的宽度。\r\n            这是必要的，因为对于 OpenCV 优化，行的长度需要为 4 对齐。\r\n            Set 函数总是复制特定值。如果图像包含字节且宽度不是 4 的倍数。创建的数组的第二个维度可能大于此图像的宽度。\r\n            \r\n","Parameter in the original article, it's similar to the sigma in the color space into bilateralFilter.":"原文中的参数，类似于颜色空间中的sigma进入bilateralFilter。\r\n","\r\n            Interface for all widget2D\r\n            ":"\r\n            所有 widget2D 的接口\r\n            \r\n","The norm type. Supports NORM_INF, NORM_L1, NORM_L2.":"规范类型。支持 NORM_INF、NORM_L1、NORM_L2。\r\n","The sigma parameter for the graph segmentation":"图分割的 sigma 参数\r\n","Try to create Bitmap that shares the data with the image":"尝试创建与图像共享数据的位图\r\n","\r\n            Create a Cuda cascade classifier using the specific file storage\r\n            ":"\r\n            使用特定文件存储创建 Cuda 级联分类器\r\n            \r\n","\r\n            Returns list of available backends which works via cv::VideoWriter()\r\n            ":"\r\n            返回通过 cv::VideoWriter() 工作的可用后端列表\r\n            \r\n","\r\n            Class that contains entry points for the WeChatQRCode module.\r\n            ":"\r\n            包含 WeChatQRCode 模块入口点的类。\r\n            \r\n","The source image. Input image must be of a complex type.":"源图像。输入图像必须是复杂类型。\r\n","\r\n            Convert BGR color to RGBA color\r\n            ":"\r\n            将 BGR 颜色转换为 RGBA 颜色\r\n            \r\n","true if at least one chart is detected, otherwise false":"如果至少检测到一个图表，则为 true，否则为 false\r\n","\r\n            The end value of this range\r\n            ":"\r\n            这个范围的结束值\r\n            \r\n","\r\n            Various camera calibration flags\r\n            ":"\r\n            各种相机校准标志\r\n            \r\n","Output image depth。":"输出图像深度。\r\n","The integral for the image rotated by 45 degrees, W+1xH+1, the same data type as sum.":"图像旋转45度的积分，W+1xH+1，数据类型与sum相同。\r\n","\r\n            The RotatedRect representation of this ellipse\r\n            ":"\r\n            此椭圆的 RotatedRect 表示\r\n            \r\n"," Defines a Gray color ":" 定义灰色\r\n","Optional 3x3 rotation matrix around z-axis.":"围绕 z 轴的可选 3x3 旋转矩阵。\r\n","A vector holding the x and y coordinates of each detected keypoint":"包含每个检测到的关键点的 x 和 y 坐标的向量\r\n","\r\n            This class contains ocl platform information\r\n            ":"\r\n            此类包含 ocl 平台信息\r\n            \r\n","An optional scaling":"可选缩放\r\n","\r\n            Creates a matrix header for the specified matrix row.\r\n            ":"\r\n            为指定的矩阵行创建矩阵标题。\r\n            \r\n","Threshold for the forward backward confidence check. Use 1.0f for default":"前向后向置信度检查的阈值。默认使用 1.0f\r\n","\r\n            Create an InputArray from MCvScalar\r\n            ":"\r\n            从 MCvScalar 创建一个 InputArray\r\n            \r\n","\r\n            L5\r\n            ":"\r\n            L5\r\n            \r\n","sz":"尺寸\r\n","\r\n            Wrapped AKAZE detector\r\n            ":"\r\n            包裹式 AKAZE 探测器\r\n            \r\n","\r\n            The function cvAvgSdv calculates the average value and standard deviation of array elements, independently for each channel\r\n            ":"\r\n            函数 cvAvgSdv 计算数组元素的平均值和标准偏差，独立于每个通道\r\n            \r\n","\r\n            Estimated translation part extracted from the homogeneous matrix that transforms a point expressed in the camera frame to the gripper frame.\r\n            ":"\r\n            从齐次矩阵中提取的估计翻译部分，将相机框架中表示的点转换为夹持器框架。\r\n            \r\n","\r\n            Pointer to the native FeaturesMatcher object.\r\n            ":"\r\n            指向本机 FeaturesMatcher 对象的指针。\r\n            \r\n","The number of rows of the depth image normals will be computed on":"将计算深度图像法线的行数\r\n","The threshold to suppress bounding boxes of IoU bigger than the given value":"抑制大于给定值的 IoU 边界框的阈值\r\n","Output vector of measured distances.":"测量距离的输出向量。\r\n","\r\n            Compute a wrapped phase map from sinusoidal patterns.\r\n            ":"\r\n            从正弦模式计算包裹相位图。\r\n            \r\n","\r\n            Set the RGB charts\r\n            ":"\r\n            设置 RGB 图表\r\n            \r\n","Optional Opencl queue":"可选的 Opencl 队列\r\n","grid for nu":"网格为 nu\r\n","Motion history image":"运动历史图像\r\n","The facemark object":"面标对象\r\n","true if streamReady is not empty":"如果 streamReady 不为空则为真\r\n","Size of the input image in pixels for which these flow vectors were generated.":"生成这些流矢量的输入图像的大小（以像素为单位）。\r\n","Optional output mask set by a robust method ( CV_RANSAC or CV_LMEDS ). Note that the input mask values are ignored.":"由可靠方法（ CV_RANSAC 或 CV_LMEDS ）设置的可选输出掩码。请注意，输入掩码值将被忽略。\r\n"," \r\n            Create a line segment with the specific starting point and end point \r\n            ":" \r\n            创建具有特定起点和终点的线段\r\n            \r\n","\r\n            Dnn Backend and Target pair\r\n            ":"Dnn 后端和目标对\r\n            \r\n","Size of the extended Sobel kernel, must be 1, 3, 5 or 7. ":"扩展 Sobel 内核的大小，必须是 1、3、5 或 7。\r\n","True if the classifier can be imported.":"如果可以导入分类器，则为真。\r\n","Norm type. NORM_L1 , NORM_L2 , and NORM_INF are supported for now.":"规范类型。目前支持 NORM_L1 、 NORM_L2 和 NORM_INF 。\r\n","\r\n            The size of MCvMat\r\n            ":"\r\n            MCvMat 的大小\r\n            \r\n","The matrix to be multiplied":"要相乘的矩阵\r\n","\r\n            LBPH face recognizer\r\n            ":"\r\n            LBPH人脸识别器\r\n            \r\n","\r\n            Set flag swapRB for frame.\r\n            ":"\r\n            为帧设置标志 swapRB。\r\n            \r\n","input image; it can have any number of channels, which are processed independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.":"输入图像；它可以有任意数量的通道，独立处理，但深度应为 CV_8U、CV_16U、CV_16S、CV_32F 或 CV_64F。\r\n","\r\n            Performs mean-shift segmentation of the source image and eleminates small segments.\r\n            ":"\r\n            对源图像执行均值偏移分割并删除小片段。\r\n            \r\n","True if an image with the specified filename can be encoded by OpenCV.":"如果具有指定文件名的图像可以由 OpenCV 编码，则为真。\r\n","Start angle of the transform in degrees.":"转换的起始角度（以度为单位）。\r\n","Threshold":"临界点\r\n","The depth type of img4":"img4的深度类型\r\n","\r\n            A writer for writing GeoTiff\r\n            ":"\r\n            编写 GeoTiff 的作家\r\n            \r\n","\r\n            Flip horizontally\r\n            ":"\r\n            水平翻转\r\n            \r\n","specifying the termination criteria of the ECC algorithm; criteria.epsilon defines the threshold of the increment in the correlation coefficient between two iterations (a negative criteria.epsilon makes criteria.maxcount the only termination criterion). Default values can use 50 iteration and 0.001 eps.":"指定 ECC 算法的终止标准； criteria.epsilon 定义两次迭代之间相关系数增量的阈值（负 criteria.epsilon 使 criteria.maxcount 成为唯一的终止标准）。默认值可以使用 50 次迭代和 0.001 eps。\r\n","\r\n            Get the number of channels for this matrix\r\n            ":"\r\n            获取此矩阵的通道数\r\n            \r\n","Border thickness of the visualized signature.":"可视化签名的边框厚度。\r\n","\r\n            Currently unsupported.\r\n            ":"\r\n            目前不受支持。\r\n            \r\n","\r\n            Extracts pixels from src:\r\n            dst(x, y) = src(x + center.x - (width(dst)-1)*0.5, y + center.y - (height(dst)-1)*0.5)\r\n            where the values of pixels at non-integer coordinates are retrieved using bilinear interpolation. Every channel of multiple-channel images is processed independently. Whereas the rectangle center must be inside the image, the whole rectangle may be partially occluded. In this case, the replication border mode is used to get pixel values beyond the image boundaries.\r\n            ":"\r\n            从 src 中提取像素：\r\n            dst(x, y) = src(x + center.x - (width(dst)-1)*0.5, y + center.y - (height(dst)-1)*0.5)\r\n            使用双线性插值检索非整数坐标处的像素值。多通道图像的每个通道都是独立处理的。虽然矩形中心必须在图像内部，但整个矩形可能会被部分遮挡。在这种情况下，复制边界模式用于获取超出图像边界的像素值。\r\n            \r\n","Dnn network":"网络\r\n","\r\n            Max x value\r\n            ":"\r\n            最大 x 值\r\n            \r\n","the particular element of single-channel array":"单通道数组的特定元素\r\n","The sum of absolute values for matrix elements.":"矩阵元素的绝对值之和。\r\n","\r\n            Finds the best match for each descriptor from a query set. Train descriptors collection that was set by the Add function is used.\r\n            ":"\r\n            从查询集中找到每个描述符的最佳匹配。使用由 Add 函数设置的列车描述符集合。\r\n            \r\n","\r\n            Reflect 101\r\n            ":"\r\n            反映101\r\n            \r\n","The detection result":"检测结果\r\n","\r\n            Main process of the algorithm. This method computes the sparse seeds and then densifies them.\r\n            Initially input images are converted to gray-scale and then the sparseMatching method is called to obtain the sparse stereo. Finally quasiDenseMatching is called to densify the corresponding points.\r\n            ":"\r\n            算法的主要过程。该方法计算稀疏种子，然后将它们加密。\r\n            最初将输入图像转换为灰度，然后调用 sparseMatching 方法以获得稀疏立体。最后调用quasiDenseMatching对对应点进行加密。\r\n            \r\n","\r\n            DigitalSG with 140 squares\r\n            ":"\r\n            DigitalSG 140 方块\r\n            \r\n","Percentage of variance that PCA should retain. Using this parameter will let the PCA decided how many components to retain but it will always keep at least 2.":"PCA 应保留的方差百分比。使用此参数将让 PCA 决定保留多少个组件，但它始终至少保留 2 个。\r\n","Thickness of the circle outline if positive, otherwise indicates that a filled circle has to be drawn":"圆轮廓的厚度如果为正，否则表示必须绘制实心圆\r\n","The point cloud file":"点云文件\r\n","\r\n            Create 2D plot for data\r\n            ":"\r\n            为数据创建二维图\r\n            \r\n","An array of Rect":"矩形数组\r\n","\r\n            Compute the descriptors on the image from the given keypoint locations.\r\n            ":"\r\n            从给定的关键点位置计算图像上的描述符。\r\n            \r\n","\r\n            Shift the box by the specific amount\r\n            ":"\r\n            按特定数量移动框\r\n            \r\n","\r\n            The pointer to the first element on the vector. In case of an empty vector, IntPtr.Zero will be returned.\r\n            ":"\r\n            指向向量上第一个元素的指针。如果是空向量，将返回 IntPtr.Zero。\r\n            \r\n","\r\n            Background subtraction based on counting.\r\n            ":"\r\n            基于计数的背景扣除。\r\n            \r\n","where each row should be 4-align":"每行应为 4 对齐\r\n","\r\n            Get a sequence of motion component\r\n            ":"\r\n            获取一系列运动组件\r\n            \r\n","\r\n            Create model from deep learning network.\r\n            ":"\r\n            从深度学习网络创建模型。\r\n            \r\n","Input vector of distortion coefficients of 4, 5, 8 or 12 elements. If the vector is null/empty, the zero distortion coefficients are assumed.":"4、5、8 或 12 个元素的失真系数的输入向量。如果矢量为零/空，则假定零失真系数。\r\n","Norm used to calculate distance between blocks. L2 is slower than L1 but yields more accurate results.":"范数用于计算块之间的距离。 L2 比 L1 慢，但产生更准确的结果。\r\n","A diagonal from a matrix":"来自矩阵的对角线\r\n"," The area of the circle ":" 圆的面积\r\n"," If true center of selection will match initial mouse position. In opposite case a corner of selection rectangle will correspont to the initial mouse position.":" 如果为真，选择中心将匹配初始鼠标位置。在相反的情况下，选择矩形的一个角将对应于初始鼠标位置。\r\n","Minimum width of a line":"线的最小宽度\r\n","Pointer to the deallocated header.":"指向已释放标头的指针。\r\n","Scale coefficient for threshold.":"阈值的比例系数。\r\n","\r\n            True if the connection is USB3\r\n            ":"\r\n            如果连接是 USB3，则为真\r\n            \r\n","The size (width & height) of the window":"窗口的大小（宽度和高度）\r\n","\r\n            Re-allocate data for the array\r\n            ":"\r\n            为数组重新分配数据\r\n            \r\n","\r\n            Convert YUV (420p) to BGRA\r\n            ":"\r\n            将 YUV (420p) 转换为 BGRA\r\n            \r\n","\r\n            Release the unmanaged resources associated with the HistogramPhaseUnwrapping\r\n            ":"\r\n            释放与 HistogramPhaseUnwrapping 关联的非托管资源\r\n            \r\n","The input point cloud for the scene. It is assumed that the model is registered on the scene. Scene remains static. Expected to have the normals (Nx6). Currently, CV_32F is the only supported data type.":"场景的输入点云。假定模型已在现场注册。场景保持静止。预期具有法线 (Nx6)。目前，CV_32F 是唯一支持的数据类型。\r\n","\r\n            Selects general purpose input\r\n            ":"\r\n            选择通用输入\r\n            \r\n","The number of interpolated corners.":"内插角的数量。\r\n","The depth type of the destination image":"目标图像的深度类型\r\n","\r\n            Hint vector grid size\r\n            ":"\r\n            提示向量网格大小\r\n            \r\n","\r\n            Hcells temporal constant. Use 1.0 for default\r\n            ":"\r\n            Hcells 时间常数。默认使用 1.0\r\n            \r\n","Input source depth. Only 8U and 32F are supported for now.":"输入源深度。目前仅支持 8U 和 32F。\r\n","Derivative order in respect of x.":"关于 x 的导数阶数。\r\n","connected components algorithm type ":"连通分量算法类型\r\n","Input image, 1- or 3-channel, 8-bit or 32-bit floating point. (each channel of multi-channel image is processed independently). ":"输入图像，1 或 3 通道，8 位或 32 位浮点数。 （多通道图像的每个通道都是独立处理的）。\r\n","Image.":"图像。\r\n","\r\n            Convert arrays of data to matrix\r\n            ":"\r\n            将数据数组转换为矩阵\r\n            \r\n","\r\n            Gaussian smoothing window parameter\r\n            ":"\r\n            高斯平滑窗口参数\r\n            \r\n","Pointer to the EM model":"指向 EM 模型的指针\r\n","Pointer to the prelocated memory of resulting sub-array header":"指向结果子数组头的预置内存的指针\r\n"," Threshold the image such that: dst(x,y) = src(x,y), if src(x,y)>threshold;  0, otherwise ":" 对图像进行阈值处理：dst(x,y) = src(x,y)，如果 src(x,y)>threshold； 0，否则\r\n","contains a path to the BRISQUE range data. If empty, attempts to load from ${OPENCV_DIR}/testdata/contrib/quality/brisque_range_live.yml":"包含 BRISQUE 范围数据的路径。如果为空，则尝试从 ${OPENCV_DIR}/testdata/contrib/quality/brisque_range_live.yml 加载\r\n","optional 3x3 floating-point camera matrix":"可选的 3x3 浮点相机矩阵\r\n","chromatic adaptation in [0, 1] range. If 1 channels are treated independently, if 0 adaptation level is the same for each channel.":"[0, 1] 范围内的色适应。如果 1 通道被独立处理，如果 0 自适应级别对于每个通道都是相同的。\r\n","First image. Supports only CV_8U and CV_32F depth.":"第一张图片。仅支持 CV_8U 和 CV_32F 深度。\r\n","The unwrapped phase map.":"展开的相图。\r\n","\r\n            The pointer to the frame source\r\n            ":"\r\n            指向帧源的指针\r\n            \r\n","\r\n            Perform a search within the given radius\r\n            ":"\r\n            在给定半径内执行搜索\r\n            \r\n","\r\n            Y,U,V (4:2:0)\r\n            ":"\r\n            Y,U,V (4:2:0)\r\n            \r\n","Image where the reliability map is stored.":"存储可靠性图的图像。\r\n","\r\n            Shift one of the image in horizontal or vertical direction (depending on the orientation of epipolar lines) in order to maximise the useful image area\r\n            ":"\r\n            在水平或垂直方向（取决于对极线的方向）移动图像之一，以最大化有用的图像区域\r\n            \r\n","\r\n            Release the GpuMat\r\n            ":"\r\n            发布 GpuMat\r\n            \r\n","Model Tie Point, an array of size 6":"模型连接点，大小为 6 的数组\r\n","\r\n            Convert YUV (UYNY) to RGB\r\n            ":"\r\n            将 YUV (UYNY) 转换为 RGB\r\n            \r\n","The second image for the Min operation":"Min 操作的第二个图像\r\n","\r\n            The function cvConvexHull2 finds convex hull of 2D point set using Sklansky's algorithm. \r\n            ":"\r\n            函数 cvConvexHull2 使用 Sklansky 算法找到二维点集的凸包。\r\n            \r\n","Output reverse affine transformation.":"输出反向仿射变换。\r\n","\r\n            True if the output array is needed\r\n            ":"\r\n            如果需要输出数组则为真\r\n            \r\n"," Draw a convex polygon of the specific color and thickness ":" 绘制特定颜色和粗细的凸多边形\r\n","Exclusive upper boundary of the generated random numbers.":"生成的随机数的唯一上边界。\r\n","Source images, all are of the same size and type":"源图像，所有图像的大小和类型都相同\r\n","\r\n            Creates MergeRobertson object.\r\n            ":"\r\n            创建 MergeRobertson 对象。\r\n            \r\n","\r\n            The feature 2D base class\r\n            ":"\r\n            特征二维基类\r\n            \r\n","The k parameter for the first graph segmentation":"第一个图分割的 k 参数\r\n","The constant to be added":"要添加的常量\r\n","\r\n            Release memory associated with this stitcher\r\n            ":"\r\n            释放与此拼接器关联的内存\r\n            \r\n","\r\n            Convert YUV (YUYV) to BGR \r\n            ":"\r\n            将 YUV (YUYV) 转换成 BGR\r\n            \r\n","\r\n            Return the particular element of single-channel array. If the array has multiple channels, runtime error is raised. Note that cvGet*D function can be used safely for both single-channel and multiple-channel arrays though they are a bit slower.\r\n            ":"\r\n            返回单通道数组的特定元素。如果数组有多个通道，则会引发运行时错误。请注意，cvGet*D 函数可以安全地用于单通道和多通道数组，尽管它们有点慢。\r\n            \r\n","\r\n            R(x,y)=sumx',y'[T(x',y') I(x+x',y+y')]/sqrt[sumx',y'T(x',y')2 sumx',y'I(x+x',y+y')2]\r\n            ":"\r\n            R(x,y)=sumx',y'[T(x',y') I(x+x',y+y')]/sqrt[sumx',y'T(x',y') 2 sumx',y'I(x+x',y+y')2]\r\n            \r\n","\r\n            Checks whether the Cuda module can be run on the given device\r\n            ":"\r\n            检查 Cuda 模块是否可以在给定设备上运行\r\n            \r\n","Weight of input image":"输入图像的权重\r\n"," \r\n            Defines a CIE Lab color \r\n            ":" \r\n            定义 CIE Lab 颜色\r\n            \r\n","Depth of this image (either Byte, SByte, Single, double, UInt16, Int16 or Int32)":"此图像的深度（Byte、SByte、Single、double、UInt16、Int16 或 Int32）\r\n","\r\n            Scale the covariance matrix coefficients by number of the vectors\r\n            ":"\r\n            按向量数量缩放协方差矩阵系数\r\n            \r\n","\r\n            Given an input bgr or grayscale image and constant c, apply log transformation to the image on domain [0, 255] and return the resulting image.\r\n            ":"\r\n            给定输入 bgr 或灰度图像和常量 c，对域 [0, 255] 上的图像应用对数变换并返回结果图像。\r\n            \r\n","The other iterator to compares with.":"要与之比较的另一个迭代器。\r\n","\r\n            Adds a directory to the search path used to locate DLLs for the application\r\n            ":"\r\n            将目录添加到用于查找应用程序 DLL 的搜索路径\r\n            \r\n","\r\n            Release the unmanaged memory associated with this WCube object\r\n            ":"\r\n            释放与此 WCube 对象关联的非托管内存\r\n            \r\n","\r\n            In case of the DECOMP_LU method, the function returns non-zero value if the inverse has been successfully calculated and 0 if src is singular.\r\n            In case of the DECOMP_SVD method, the function returns the inverse condition number of src (the ratio of the smallest singular value to the largest singular value) and 0 if src is singular. The SVD method calculates a pseudo-inverse matrix if src is singular.\r\n            Similarly to DECOMP_LU, the method DECOMP_CHOLESKY works only with non-singular square matrices that should also be symmetrical and positively defined. In this case, the function stores the inverted matrix in dst and returns non-zero. Otherwise, it returns 0.\r\n            ":"\r\n            在 DECOMP_LU 方法的情况下，如果已成功计算逆函数，则函数返回非零值；如果 src 为奇异值，则函数返回 0。\r\n            在 DECOMP_SVD 方法的情况下，该函数返回 src 的逆条件数（最小奇异值与最大奇异值的比率），如果 src 是奇异值，则返回 0。如果 src 是奇异的，则 SVD 方法计算伪逆矩阵。\r\n            与 DECOMP_LU 类似，方法 DECOMP_CHOLESKY 仅适用于非奇异方阵，这些方阵也应该是对称的和正定义的。在这种情况下，该函数将倒置矩阵存储在 dst 中并返回非零值。否则，它返回 0。\r\n            \r\n","this * alpha + img2 * beta + gamma":"这 * alpha + img2 * beta + 伽玛\r\n","\r\n            Defines which source will be used for timestamp reset. Writing this parameter will trigger settings of engine (arming)\r\n            ":"\r\n            定义哪个源将用于时间戳重置。写入此参数将触发引擎设置（武装）\r\n            \r\n","\r\n            Min y value\r\n            ":"\r\n            最小值\r\n            \r\n","\r\n            Swap left and right cameras\r\n            ":"\r\n            交换左右摄像头\r\n            \r\n","\r\n            Convert the standard vector to an array of Double\r\n            ":"\r\n            将标准向量转换为 Double 数组\r\n            \r\n","\r\n            Get the ranges of this histogram\r\n            ":"\r\n            获取此直方图的范围\r\n            \r\n","note, that this tracker works with grayscale images, if passed bgr ones, they will get converted internally.":"请注意，此跟踪器适用于灰度图像，如果通过 bgr 图像，它们将在内部进行转换。\r\n","\r\n            Finding median of ":"\r\n            寻找中位数\r\n","N, the total number of labels [0, N-1] where 0 represents the background label.":"N，标签总数 [0, N-1] 其中 0 表示背景标签。\r\n","The other point to compare with":"另一个要比较的点\r\n","The triangles might contains virtual points that do not belongs to the inserted points, if you do not want those points, set ":"三角形可能包含不属于插入点的虚拟点，如果您不想要这些点，请设置\r\n","The SVM detector":"SVM检测器\r\n","\r\n            Creates instance of SparseRLOFOpticalFlow\r\n            ":"\r\n            创建 SparseRLOFOpticalFlow 的实例\r\n            \r\n","\r\n            Central Moment Mu03\r\n            ":"\r\n            中心矩 Mu03\r\n            \r\n","The header, corresponding to a specified col span of the input array":"header，对应输入数组的指定col span\r\n","True if the feature is supported":"如果支持该功能，则为真\r\n","\r\n            Convert the standard vector to an array of ERStat\r\n            ":"\r\n            将标准向量转换为 ERStat 数组\r\n            \r\n","\r\n            Warning message\r\n            ":"\r\n            警告信息\r\n            \r\n","\r\n            Squared Euclidean distance\r\n            ":"\r\n            平方欧氏距离\r\n            \r\n","\r\n            The x value of the 3d location\r\n            ":"\r\n            3d位置的x值\r\n            \r\n","The element-wise quotient of the two GpuMat":"两个 GpuMat 的元素商\r\n","Input matrix (CV_8UC1).":"输入矩阵 (CV_8UC1)。\r\n","Searched template; must be not greater than the source image and the same data type as the image":"搜索模板；必须不大于源图像和与图像相同的数据类型\r\n","The color type of the image":"图片的颜色类型\r\n","\r\n            The setlocale function installs the specified system locale or its portion as the new C locale. The modifications remain in effect and influences the execution of all locale-sensitive C library functions until the next call to setlocale. If locale is a null pointer, setlocale queries the current C locale without modifying it.\r\n            ":"\r\n            setlocale 函数安装指定的系统语言环境或其部分作为新的 C 语言环境。在下一次调用 setlocale 之前，修改仍然有效并影响所有区域设置敏感的 C 库函数的执行。如果 locale 是空指针，则 setlocale 查询当前 C 语言环境而不修改它。\r\n            \r\n","\r\n            Get the size of the vector\r\n            ":"\r\n            获取向量的大小\r\n            \r\n","\r\n            Central Moment Mu12\r\n            ":"\r\n            中心矩 Mu12\r\n            \r\n","\r\n            Measurement noise covariance matrix (R)\r\n            ":"\r\n            测量噪声协方差矩阵 (R)\r\n            \r\n","\r\n            The Z component of the vector: rotation axis * sin(rotation angle / 2)\r\n            ":"\r\n            矢量的Z分量：旋转轴*sin(旋转角度/2)\r\n            \r\n"," Create a BGRA color using the specific values":" 使用特定值创建 BGRA 颜色\r\n","The recognized text":"识别的文本\r\n","Weight of the second array elements.":"第二个数组元素的权重。\r\n","The optional mask, use IntPtr.Zero if not needed.":"可选掩码，如果不需要，请使用 IntPtr.Zero。\r\n","XML configuration file with network's topology.":"带有网络拓扑结构的 XML 配置文件。\r\n","\r\n            Returns names of layers with unconnected outputs.\r\n            ":"\r\n            返回具有未连接输出的层的名称。\r\n            \r\n","Gain for the B channel":"B通道的增益\r\n","The convolution kernel":"卷积核\r\n"," The complement image":" 补充图像\r\n","\r\n            Apply a transformation, given a pre-estimated transformation parameters.\r\n            ":"\r\n            给定一个预先估计的转换参数，应用一个转换。\r\n            \r\n","\r\n            Android focus distance far\r\n            ":"\r\n            Android对焦距离远\r\n            \r\n"," The result of the XOR operation":" 异或运算的结果\r\n"," Minimum circle radius.":" 最小圆半径。\r\n","The averaging window size; The larger values increase the algorithm robustness to image noise and give more chances for fast motion detection, but yield more blurred motion field":"平均窗口大小；较大的值会增加算法对图像噪声的鲁棒性，并为快速运动检测提供更多机会，但会产生更模糊的运动场\r\n","\r\n            Multiplies matrix by scalar.\r\n            ":"\r\n            将矩阵乘以标量。\r\n            \r\n","\r\n            Computes HOG descriptors of given image.\r\n            ":"\r\n            计算给定图像的 HOG 描述符。\r\n            \r\n","\r\n            Write a Mat into a file using native implementations\r\n            ":"\r\n            使用本机实现将 Mat 写入文件\r\n            \r\n","Input floating-point array.":"输入浮点数组。\r\n","Scalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true.":"具有从通道中减去的平均值的标量。如果图像具有 BGR 排序且 swapRB 为真，则值旨在按（mean-R、mean-G、mean-B）顺序排列。\r\n","The number of multiprocessors on device":"设备上的多处理器数量\r\n","\r\n            Farneback optical flow\r\n            ":"\r\n            法尼巴克光流\r\n            \r\n","\r\n            Abstract base class for shape distance algorithms.\r\n            ":"\r\n            形状距离算法的抽象基类。\r\n            \r\n","\r\n            Update the current tracking status. The result will be saved in the internal storage.\r\n            ":"\r\n            更新当前跟踪状态。结果将保存在内部存储器中。\r\n            \r\n","\r\n            LocalBinarizationMethods type\r\n            ":"\r\n            LocalBinarizationMethods 类型\r\n            \r\n","\r\n            Create an empty Affine3, double precision matrix\r\n            ":"\r\n            创建一个空的 Affine3，双精度矩阵\r\n            \r\n","\r\n            Create an \"Improved adaptive Gaussian mixture model for background subtraction\".\r\n            ":"\r\n            创建一个“用于背景减法的改进自适应高斯混合模型”。\r\n            \r\n","\r\n            Calculates the general motion direction in the selected region and returns the angle between 0 and 360. At first the function builds the orientation histogram and finds the basic orientation as a coordinate of the histogram maximum. After that the function calculates the shift relative to the basic orientation as a weighted sum of all orientation vectors: the more recent is the motion, the greater is the weight. The resultant angle is a circular sum of the basic orientation and the shift. \r\n            ":"\r\n            计算所选区域的一般运动方向并返回 0 到 360 之间的角度。首先，该函数构建方向直方图并找到基本方向作为直方图最大值的坐标。之后，该函数计算相对于基本方向的偏移作为所有方向向量的加权和：运动越近，权重越大。合成角度是基本方向和位移的圆周和。\r\n            \r\n","When the comparison result is true, the corresponding element of output array is set to 255. Otherwise it is set to 0.":"当比较结果为真时，输出数组对应元素设置为255，否则设置为0。\r\n"," Obtain the Y value from the X value using first degree interpolation":" 使用一次插值从 X 值获取 Y 值\r\n","\r\n            Calculates the integral of an image.\r\n            ":"\r\n            计算图像的积分。\r\n            \r\n","output array of detected centers.":"检测中心的输出数组。\r\n","\r\n            Retrieve all the contours and puts them in the list \r\n            ":"\r\n            检索所有轮廓并将它们放入列表中\r\n            \r\n","Output vector of distortion coefficients (k1,k2,k3,k4).":"失真系数的输出向量 (k1,k2,k3,k4)。\r\n","\r\n            Rotate the points in ":"\r\n            旋转点\r\n","\tThe image":"图片\r\n","\r\n            Applies the bilateral filter to an image. BilateralFilter can reduce unwanted noise very well while keeping edges fairly sharp. However, it is very slow compared to most filters.\r\n            ":"\r\n            将双边过滤器应用于图像。 BilateralFilter 可以很好地减少不需要的噪声，同时保持边缘相当锐利。但是，与大多数过滤器相比，它非常慢。\r\n            \r\n","The output array of real roots. Should have 3 elements. Padded with zeros if there is only one root":"实根的输出数组。应该有3个元素。如果只有一个根，则用零填充\r\n","The logLevel. The Log function only logs when the ":"日志级别。日志功能仅在\r\n","\r\n            One of the three neighborhoods as defined in the paper\r\n            ":"\r\n            论文中定义的三个社区之一\r\n            \r\n","The pointer to the unmanaged object":"指向非托管对象的指针\r\n","The result of the XOR operation":"异或运算的结果\r\n","Probability of propagating to neighbors.":"传播到邻居的概率。\r\n","\r\n            Read and write\r\n            ":"\r\n            读和写\r\n            \r\n","Output rotation vector ":"输出旋转矢量\r\n"," this .* img2 * scale ":" 这 .* img2 * 规模\r\n","\r\n            Type for cvCalcOpticalFlowPyrLK\r\n            ":"\r\n            cvCalcOpticalFlowPyrLK 的类型\r\n            \r\n","Aperture size for the Sobel operator.":"Sobel 算子的孔径大小。\r\n","Source matrix":"源矩阵\r\n","\r\n            Append the samples to the end of the storage\r\n            ":"\r\n            将样本附加到存储的末尾\r\n            \r\n","\r\n            Normalization type\r\n            ":"\r\n            归一化类型\r\n            \r\n","\r\n            Convert BayerBG pattern to RGB color using VNG\r\n            ":"\r\n            使用 VNG 将 BayerBG 模式转换为 RGB 颜色\r\n            \r\n","\r\n            Create a GpuMat from the unmanaged pointer\r\n            ":"\r\n            从非托管指针创建 GpuMat\r\n            \r\n","\r\n            Color Correction Matrix element [2][1]\r\n            ":"\r\n            颜色校正矩阵元素 [2][1]\r\n            \r\n","\r\n            Read only\r\n            ":"\r\n            只读\r\n            \r\n","\r\n            Finds perspective transformation H=||h_ij|| between the source and the destination planes\r\n            ":"\r\n            找到透视变换 H=||h_ij||在源平面和目标平面之间\r\n            \r\n","\r\n            If set, the function does not raises an error if an element is invalid or out of range\r\n            ":"\r\n            如果设置，则该函数不会在元素无效或超出范围时引发错误\r\n            \r\n","Computed epilines, 3xN or Nx3 array ":"计算外线，3xN 或 Nx3 阵列\r\n","Multiplier for the maxmin eigenvalue; specifies minimal accepted quality of image corners.":"最大最小特征值的乘数；指定图像角点的最低可接受质量。\r\n","The images plus the value":"图片加上价值\r\n","Buffer of type CV_32FC2, containing flow vectors in floating point representation, each flow vector for 1 pixel per gridSize, in the pitch-linear layout.":"CV_32FC2 类型的缓冲区，包含浮点表示形式的流向量，每个流向量为每个 gridSize 1 个像素，在间距线性布局中。\r\n","\r\n            Hint buffer grid size is 8x8.\r\n            ":"\r\n            提示缓冲区网格大小为 8x8。\r\n            \r\n","\r\n            Write the Mat into the file\r\n            ":"\r\n            将Mat写入文件\r\n            \r\n","\r\n            Indicates if this is an AMD device\r\n            ":"\r\n            指示这是否是 AMD 设备\r\n            \r\n","If true, incremental merging of segments will be performed ":"如果为真，将执行段的增量合并\r\n","\r\n            If set, always convert image to the single channel grayscale image and the image size reduced 1/4.\r\n            ":"\r\n            如果设置，总是将图像转换为单通道灰度图像，图像尺寸缩小 1/4。\r\n            \r\n","If true, we will change the locale to \"C\" before initializing the tesseract engine and reverting it back once the tesseract initialiation is completer. If false, it will be the user's responsibility to set the locale to \"C\", otherwise an exception will be thrown. See https://github.com/tesseract-ocr/tesseract/issues/1670 ":"如果为真，我们将在初始化 tesseract 引擎之前将语言环境更改为“C”，并在 tesseract 初始化完成后将其还原。如果为 false，则用户有责任将语言环境设置为“C”，否则将抛出异常。请参阅 https://github.com/tesseract-ocr/tesseract/issues/1670\r\n","\r\n            The method write the specified image to video file. The image must have the same size and the same surface format as has been specified when opening the video writer.\r\n            ":"\r\n            该方法将指定图像写入视频文件。图像必须与打开视频编写器时指定的大小和表面格式相同。\r\n            \r\n","\r\n            Amacrin cells temporal cut frequency. Use 1.2 for default\r\n            ":"\r\n            无长突细胞时间截止频率。默认使用 1.2\r\n            \r\n","\r\n            Accumulate ":"积累\r\n","A list of sizes for multi-scale detection. The values[(300,300),(700,500),(700,300),(700,700),(1600,1600)] are recommended to achieve the best quality.":"用于多尺度检测的尺寸列表。建议使用值 [(300,300),(700,500),(700,300),(700,700),(1600,1600)] 以获得最佳质量。\r\n","\r\n            The retina color sampling method.\r\n            ":"\r\n            视网膜颜色采样方法。\r\n            \r\n","Locale category identifier":"语言环境类别标识符\r\n","The mask for find the average value":"求平均值的掩码\r\n","\r\n            A neighbor point\r\n            ":"\r\n            相邻点\r\n            \r\n","\r\n            src1(I) \"equal to\" src2(I)\r\n            ":"\r\n            src1(I) “等于” src2(I)\r\n            \r\n","\r\n            An interface for the convex polygon\r\n            ":"\r\n            凸多边形的接口\r\n            \r\n","Diffusivity type":"扩散型\r\n","\r\n            Convert the standard vector to an array of Point3D32F\r\n            ":"\r\n            将标准向量转换为 Point3D32F 数组\r\n            \r\n","\r\n            A covariation matrix of each mixture may be arbitrary diagonal matrix with positive diagonal elements, that is, non-diagonal elements are forced to be 0's, so the number of free parameters is d  for each matrix. This is most commonly used option yielding good estimation results\r\n            ":"\r\n            每个混合的协变矩阵可以是任意对角元素为正的对角矩阵，即非对角元素强制为0，因此每个矩阵的自由参数个数为d。这是产生良好估计结果的最常用选项\r\n            \r\n","\r\n            Write the geo information into the tiff file\r\n            ":"\r\n            将地理信息写入tiff文件\r\n            \r\n","Number of columns in a 2D array.":"二维数组中的列数。\r\n","A unique id for the widget.":"小部件的唯一 ID。\r\n","\r\n            Create a new HOGDescriptor using the specific parameters.\r\n            ":"\r\n            使用特定参数创建一个新的 HOGDescriptor。\r\n            \r\n","the location of the pixel ":"像素的位置\r\n","Optional input/output parameter: lower boundary of a distance between the two signatures that is a distance between mass centers. The lower boundary may not be calculated if the user-defined cost matrix is used, the total weights of point configurations are not equal, or if the signatures consist of weights only (the signature matrices have a single column). ":"可选的输入/输出参数：两个签名之间的距离的下边界，即质心之间的距离。如果使用用户定义的成本矩阵，点配置的总权重不相等，或者签名仅由权重组成（签名矩阵只有一列），则可能无法计算下边界。\r\n","\r\n            K-nearest neighbors - based Background/Foreground Segmentation Algorithm.\r\n            ":"\r\n            基于 K 最近邻的背景/前景分割算法。\r\n            \r\n","degree":"程度\r\n","\r\n            Applies a separable linear filter to a matrix(image).\r\n            ":"\r\n            将可分离的线性滤波器应用于矩阵（图像）。\r\n            \r\n","The input points. 2xN, Nx2, 3xN or Nx3 array (where N number of points). Multi-channel 1xN or Nx1 array is also acceptable.":"输入点。 2xN、Nx2、3xN 或 Nx3 数组（其中 N 个点）。多通道 1xN 或 Nx1 阵列也是可以接受的。\r\n","The fourth image":"第四个图像\r\n","The number of BP iterations on each level. Use 8 as default.":"每个级别上的 BP 迭代次数。使用 8 作为默认值。\r\n","The initial frame":"初始框架\r\n","\r\n            Initializes a new instance of the FastLineDetector object.\r\n            ":"\r\n            初始化 FastLineDetector 对象的新实例。\r\n            \r\n","constant in c*r^gamma where r is pixel value.":"c*r^gamma 中的常量，其中 r 是像素值。\r\n","\r\n            Perform image denoising using Non-local Means Denoising algorithm: \r\n            http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/ \r\n            with several computational optimizations. Noise expected to be a Gaussian white noise.\r\n            ":"\r\n            使用非局部均值去噪算法执行图像去噪：\r\n            http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/\r\n            有几个计算优化。噪声预计为高斯白噪声。\r\n            \r\n","\r\n            Read an attribute from the root group.\r\n            ":"\r\n            从根组中读取一个属性。\r\n            \r\n","\r\n            The tesseract page iterator\r\n            ":"\r\n            tesseract 页面迭代器\r\n            \r\n","\r\n            Resets the camera to default state.\r\n            ":"\r\n            将相机重置为默认状态。\r\n            \r\n","\r\n            Down\r\n            ":"\r\n            向下\r\n            \r\n","\r\n            Exponential Chi2 kernel, similar to the RBF kernel\r\n            ":"\r\n            Exponential Chi2 kernel，类似于RBF kernel\r\n            \r\n","The result of the sobel edge detector":"sobel边缘检测器的结果\r\n","New number of channels. new_cn = 0 means that number of channels remains unchanged":"新的频道数量。 new_cn = 0表示通道数不变\r\n","The search radius. The bundle will have 2*len + 1 columns.":"搜索半径。捆绑包将有 2*len + 1 列。\r\n","\r\n            Confidence level \r\n            ":"\r\n            置信水平\r\n            \r\n","Optional mask to select a sub-matrix.":"用于选择子矩阵的可选掩码。\r\n","First spectrum.":"第一谱。\r\n","\r\n            Applying bilateral 3x3 filtering\r\n            ":"\r\n            应用双边 3x3 过滤\r\n            \r\n","Original affine transformation":"原始仿射变换\r\n","\r\n            Interface for all widget3D\r\n            ":"\r\n            所有 widget3D 的接口\r\n            \r\n","\r\n            The ColorPalette of Grayscale for Bitmap Format8bppIndexed\r\n            ":"\r\n            Bitmap Format8bppIndexed 的灰度调色板\r\n            \r\n","output image of the same size and the same number of channels as src.":"与 src 大小和通道数相同的输出图像。\r\n","The input frame size":"输入帧大小\r\n","If true, any exception during insert will be ignored":"如果为真，插入期间的任何异常都将被忽略\r\n","\r\n            TLD is a novel tracking framework that explicitly decomposes the long-term tracking task into tracking, learning and detection.\r\n            ":"\r\n            TLD 是一种新颖的跟踪框架，可将长期跟踪任务明确分解为跟踪、学习和检测。\r\n            \r\n","Per-element division of two matrices.":"两个矩阵的按元素划分。\r\n","True if it is a umat":"如果它是 umat 则为真\r\n","\r\n            Horizontally concatenate two images\r\n            ":"\r\n            水平连接两个图像\r\n            \r\n","\r\n            Sequence element type\r\n            ":"\r\n            序列元素类型\r\n            \r\n","[i,j], 0 otherwise":"[i,j], 0 否则\r\n","The up-right bounding rectangle for 2d point set":"二维点集的右上边界矩形\r\n","\r\n            Create an standard vector of KeyPoint with the initial values\r\n            ":"\r\n            使用初始值创建 KeyPoint 的标准向量\r\n            \r\n"," will be changed.\r\n            ":" 将被改变。\r\n            \r\n","The destination image; should have the same size and the same type as src":"目标图像；应该与 src 具有相同的大小和相同的类型\r\n","Floating point coordinates of the extracted rectangle center within the source image. The center must be inside the image.":"源图像中提取的矩形中心的浮点坐标。中心必须在图像内部。\r\n","\r\n            The number of single multi processors\r\n            ":"\r\n            单多处理器数量\r\n            \r\n","The Built-in color card":"内置色卡\r\n","\r\n            Return device model id\r\n            ":"\r\n            返回设备型号 ID\r\n            \r\n","\r\n            Intelperc Depth Focal Length Horz\r\n            ":"\r\n            Intelperc 景深焦距 Horz\r\n            \r\n","\r\n            Output vector of vector of vertices of the minimum-area rotated rectangle containing the codes.\r\n            For N detected barcodes, the dimensions of this array should be [N][4].\r\n            Order of four points in VectorOfPointF is bottomLeft, topLeft, topRight, bottomRight.\r\n            ":"\r\n            包含代码的最小面积旋转矩形的顶点向量的输出向量。\r\n            对于 N 个检测到的条形码，此数组的维度应为 [N][4]。\r\n            VectorOfPointF 中四个点的顺序是 bottomLeft、topLeft、topRight、bottomRight。\r\n            \r\n","Enables/disables parallel computing.":"启用/禁用并行计算。\r\n","\r\n            Constructor providing explicit values\r\n            ":"\r\n            提供显式值的构造函数\r\n            \r\n","\r\n            Draws a arrow segment pointing from the first point to the second one.\r\n            ":"\r\n            绘制从第一个点指向第二个点的箭头段。\r\n            \r\n","\r\n            Release the unmanaged memory associated with this Affine3 model\r\n            ":"\r\n            释放与此 Affine3 模型关联的非托管内存\r\n            \r\n","Binary file contains trained weights.":"二进制文件包含经过训练的权重。\r\n","The enumerables, each should be stored in index ascending order":"枚举，每个都应按索引升序存储\r\n","\r\n            If true then pruned branches are physically removed from the tree\r\n            ":"\r\n            如果为真，则修剪的分支将从树中物理移除\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of GMat.\r\n            ":"\r\n            GMat 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            intrinsic_matrix contains valid initial values of fx, fy, cx, cy that are optimized further. Otherwise, (cx, cy) is initially set to the image center (image_size is used here), and focal distances are computed in some least-squares fashion\r\n            ":"\r\n            intrinsic_matrix 包含进一步优化的 fx、fy、cx、cy 的有效初始值。否则，(cx, cy) 最初设置为图像中心（此处使用 image_size），并以某种最小二乘方式计算焦距\r\n            \r\n","Source array, real 1D or 2D array":"源数组，真正的一维或二维数组\r\n","result CV_32FC image with same number of channel than _op.":"结果 CV_32FC 图像，通道数与 _op 相同。\r\n","Anchor position within the kernel. The value (-1,-1) means that the anchor is at the kernel center.":"内核中的锚点位置。值 (-1,-1) 表示锚点位于内核中心。\r\n","Rotation around y-axis (pitch) in radian":"以弧度为单位绕 y 轴旋转（俯仰）\r\n","\r\n            Create Dual TV L1 Optical Flow.\r\n            ":"\r\n            创建双电视 L1 光流。\r\n            \r\n","\r\n            Barcode type\r\n            ":"\r\n            条码类型\r\n            \r\n","\r\n            Horizontal resolution\r\n            ":"\r\n            水平分辨率\r\n            \r\n","path to the .pb file with binary protobuf description of the network architecture":"带有网络架构的二进制 protobuf 描述的 .pb 文件的路径\r\n","The input GpuMat":"输入的 GpuMat\r\n","Miscellaneous flags":"杂旗\r\n","\r\n            Write a tile into the tile tiff\r\n            ":"\r\n            将瓦片写入瓦片 tiff\r\n            \r\n","\r\n            Convert RGBA color to RGB color\r\n            ":"\r\n            将 RGBA 颜色转换为 RGB 颜色\r\n            \r\n","Proposal boxes.":"提案箱。\r\n","\r\n            Enable/ disable auto white-balance\r\n            ":"\r\n            启用/禁用自动白平衡\r\n            \r\n","\r\n            True if the camera is opened\r\n            ":"\r\n            如果相机打开则为真\r\n            \r\n","output integer array of the same size as src.":"输出与 src 大小相同的整数数组。\r\n","The device":"装置\r\n","\r\n            Convert YUV420sp to RGB\r\n            ":"\r\n            将 YUV420sp 转换为 RGB\r\n            \r\n","vector of detected charuco corners":"检测到的 charuco 角向量\r\n","Anchor point; default value Point(-1,-1) means that the anchor is at the kernel center.":"锚点；默认值 Point(-1,-1) 表示锚点位于内核中心。\r\n","the points that defines the poly line":"定义折线的点\r\n","The first mat to apply bitwise OR operation":"应用按位或运算的第一个垫\r\n","\r\n            For single channel image, apply converter directly.\r\n            For multiple channel image, set the COI for the specific channel before appling the convertor\r\n            ":"\r\n            对于单通道图像，直接应用转换器。\r\n            对于多通道图像，在应用转换器之前设置特定通道的 COI\r\n            \r\n","\r\n            The platform version\r\n            ":"\r\n            平台版本\r\n            \r\n","The image where detection took place":"检测发生的图像\r\n","\r\n            Set the plot grid color\r\n            ":"\r\n            设置绘图网格颜色\r\n            \r\n","put ROI of input image into the pyramid if possible. You can pass false to force data copying.":"如果可能，将输入图像的 ROI 放入金字塔中。您可以传递 false 以强制复制数据。\r\n","The file name to be saved to":"要保存到的文件名\r\n","True if all the modules has been loaded successfully":"如果所有模块都已成功加载，则为真\r\n","The MCvScalar to be converted to InputArray":"要转换为 InputArray 的 MCvScalar\r\n","Pointer to the mean value":"指向平均值的指针\r\n","Scale step":"缩放步长\r\n","Destination array channels.":"目标阵列通道。\r\n","vector of vectors of calibration pattern points in the calibration pattern coordinate space.":"校准图案坐标空间中校准图案点的向量向量。\r\n","\r\n            Creates training data from in-memory arrays.\r\n            ":"\r\n            从内存数组创建训练数据。\r\n            \r\n","The video frame":"视频帧\r\n","\r\n            Calibrate a camera using aruco markers.\r\n            ":"\r\n            使用 aruco 标记校准相机。\r\n            \r\n","The type of managed data array":"托管数据数组的类型\r\n","\r\n            Create a video writer using the specific information\r\n            ":"\r\n            使用特定信息创建视频编写器\r\n            \r\n","The Mat to be written":"要写的垫子\r\n","\r\n            x-coordinate\r\n            ":"\r\n            x坐标\r\n            \r\n","The image pyramid":"图像金字塔\r\n","\r\n            Reconstructs vectors from their PC projections.\r\n            ":"\r\n            从它们的 PC 投影重建向量。\r\n            \r\n","\r\n            Detect the features in the image\r\n            ":"\r\n            检测图像中的特征\r\n            \r\n","\r\n            Returns the centroid of this triangle\r\n            ":"\r\n            返回这个三角形的质心\r\n            \r\n","\r\n            Release the unmanaged memory associated with this HOGDescriptor\r\n            ":"\r\n            释放与此 HOGDescriptor 关联的非托管内存\r\n            \r\n","\r\n            An option parent object to keep reference to\r\n            ":"\r\n            保留引用的选项父对象\r\n            \r\n","Destination image of the same size and type as src .":"与 src 具有相同大小和类型的目标图像。\r\n","\r\n            Find the loaded assembly with the specific assembly name\r\n            ":"\r\n            查找具有特定程序集名称的已加载程序集\r\n            \r\n","\r\n            Managed structure equivalent to CvScalar \r\n            ":"\r\n            等效于 CvScalar 的托管结构\r\n            \r\n","Destination vector. Its size and type is defined by dim and dtype parameters":"目标向量。它的大小和类型由 dim 和 dtype 参数定义\r\n","If the flag is true, all the zero pixel values are treated as zeroes, all the others are treated as 1's":"如果该标志为真，则所有零像素值都被视为零，所有其他像素值都被视为 1\r\n","The array where NaN needs to be converted":"需要转换NaN的数组\r\n","Matrix of samples. It should have CV_32F type.":"样本矩阵。它应该有 CV_32F 类型。\r\n","\r\n            Width of the Image provided by the device (in pixels).\r\n            ":"\r\n            设备提供的图像的宽度（以像素为单位）。\r\n            \r\n","\r\n            Computes PSNR image/video quality metric\r\n            ":"\r\n            计算 PSNR 图像/视频质量指标\r\n            \r\n","\r\n            use minimum eigen values as an error measure (see minEigThreshold description); if the flag is not set, then L1 distance between patches around the original and a moved point, divided by number of pixels in a window, is used as a error measure.\r\n            ":"\r\n            使用最小特征值作为误差度量（参见 minEigThreshold 描述）；如果未设置标志，则原始点和移动点周围的块之间的 L1 距离除以窗口中的像素数，用作误差度量。\r\n            \r\n","\r\n            Create a N-dimensional matrix \r\n            ":"\r\n            创建一个 N 维矩阵\r\n            \r\n","Increase/Decrease step for threshold values.":"增加/减少阈值的步骤。\r\n","\r\n            Convert YUV NV12 to Gray\r\n            ":"\r\n            将 YUV NV12 转换为灰色\r\n            \r\n"," Create a capture using the specific camera":" 使用特定相机创建捕获\r\n","\r\n            Main interface for all quality filters.\r\n            ":"\r\n            所有质量过滤器的主界面。\r\n            \r\n","Optional depth of the output image. dDepth can be set to Default, which will be equivalent to src.depth().":"输出图像的可选深度。 dDepth 可以设置为 Default，相当于 src.depth()。\r\n","Pointer to an array of PointF, Coordinates of the 3 corresponding triangle vertices in the destination image":"指向 PointF 数组的指针，目标图像中 3 个对应三角形顶点的坐标\r\n","Number of octaves covered by the detected keypoints.":"检测到的关键点覆盖的八度音程数。\r\n","\r\n            Update the motion history with the specific image and the specific timestamp\r\n            ":"\r\n            使用特定图像和特定时间戳更新运动历史\r\n            \r\n","\r\n            Create an standard vector of UMat of the specific size\r\n            ":"\r\n            创建特定大小的 UMat 标准向量\r\n            \r\n","\r\n            List of learned parameters must be stored here to allow read them by using Net::getParam().\r\n            ":"\r\n            学习参数列表必须存储在这里，以允许使用 Net::getParam() 读取它们。\r\n            \r\n","Output 3x3 floating-point camera matrix. ":"输出 3x3 浮点相机矩阵。\r\n","Destination array, image or matrix":"目标数组、图像或矩阵\r\n","Minimum distance between centers of the detected circles. If the parameter is too small, multiple neighbor circles may be falsely detected in addition to a true one. If it is too large, some circles may be missed":"检测到的圆的中心之间的最小距离。如果参数太小，除了真实的圆圈之外，还可能错误地检测到多个相邻圆圈。如果太大，可能会漏掉一些圆圈\r\n","\r\n            Return the Mat representation of the UMat\r\n            ":"\r\n            返回 UMat 的 Mat 表示\r\n            \r\n","\r\n            Color Correction Matrix element [3][3]\r\n            ":"\r\n            颜色校正矩阵元素 [3][3]\r\n            \r\n","The color to fill the polygon with":"填充多边形的颜色\r\n","\r\n            Error, need more images.\r\n            ":"\r\n            错误，需要更多图像。\r\n            \r\n","The CvArry to be converted to GpuMat":"要转换为 GpuMat 的 CvArry\r\n","If true, this will be a blocking function call":"如果为真，这将是一个阻塞函数调用\r\n","The factor by which the search window is scaled between the subsequent scans, for example, 1.1 means increasing window by 10%":"搜索窗口在后续扫描之间缩放的因子，例如，1.1 表示将窗口增加 10%\r\n","\r\n            Size of an image patch for matching (in pixels). Normally, default 8x8 patches work well enough in most cases.\r\n            ":"\r\n            用于匹配的图像块的大小（以像素为单位）。通常，默认的 8x8 补丁在大多数情况下都能很好地工作。\r\n            \r\n","True if the training is successful.":"如果培训成功，则为真。\r\n","The build options":"构建选项\r\n","\r\n            Returns filter coefficients for computing spatial image derivatives.\r\n            ":"\r\n            返回用于计算空间图像导数的滤波器系数。\r\n            \r\n","\r\n            The type of optical flow algorithms used for super resolution\r\n            ":"\r\n            用于超分辨率的光流算法类型\r\n            \r\n","The string value to insert.":"要插入的字符串值。\r\n","\r\n            Defines an affine transformation\r\n            ":"\r\n            定义仿射变换\r\n            \r\n","\r\n            If compiled with OpenCL AND an available OpenCL\r\n            device is deemed faster than serial code, then\r\n            \"device\" is populated with the cl_device_id\r\n            and returns sizeof(cl_device_id)\r\n            otherwise *device=nullptr and returns 0.\r\n            ":"\r\n            如果使用 OpenCL 和可用的 OpenCL 编译\r\n            设备被认为比串行代码更快，然后\r\n            “设备”填充了 cl_device_id\r\n            并返回 sizeof(cl_device_id)\r\n            否则 *device=nullptr 并返回 0。\r\n            \r\n","The depth type of the destination GpuMat":"目标 GpuMat 的深度类型\r\n","\r\n            Interface to provide access to the cuda::SparseOpticalFlow class.\r\n            ":"\r\n            提供对 cuda::SparseOpticalFlow 类的访问的接口。\r\n            \r\n","The base mapper":"基础映射器\r\n","\r\n            number of array dimensions\r\n            ":"数组维数\r\n            \r\n"," The direction of the line, the norm of which is 1 ":" 线的方向，范数为 1\r\n","The Mat":"垫子\r\n","Size of the structuring element.":"结构元素的大小。\r\n","A subimage which image data is shared with the current image":"与当前图像共享图像数据的子图像\r\n","\r\n            Filter Offset Error\r\n            ":"\r\n            滤波器偏移误差\r\n            \r\n","Usb device":"USB 设备\r\n","output array. It has the same number of rows and depth as the src, and the sum of cols of the src. same depth.":"输出数组。它具有与 src 相同的行数和深度，以及 src 的列的总和。同样的深度。\r\n","True if the two Mats are equal":"如果两个 Mats 相等则为真\r\n","\r\n            Rotation-only model image warper interface.\r\n            ":"\r\n            仅旋转模型图像变形界面。\r\n            \r\n","\r\n            File Storage Node class.\r\n            The node is used to store each and every element of the file storage opened for reading. When\r\n            XML/YAML file is read, it is first parsed and stored in the memory as a hierarchical collection of\r\n            nodes. Each node can be a \"leaf\" that is contain a single number or a string, or be a collection of\r\n            other nodes. There can be named collections (mappings) where each element has a name and it is\r\n            accessed by a name, and ordered collections (sequences) where elements do not have names but rather\r\n            accessed by index. Type of the file node can be determined using FileNode::type method.\r\n            Note that file nodes are only used for navigating file storages opened for reading. When a file\r\n            storage is opened for writing, no data is stored in memory after it is written.\r\n            ":"\r\n            文件存储节点类。\r\n            该节点用于存储打开以供读取的文件存储的每个元素。什么时候\r\n            XML/YAML文件被读取，首先被解析并存储在内存中作为一个分层集合\r\n            节点。每个节点可以是包含单个数字或字符串的“叶子”，或者是一组\r\n            其他节点。可以有命名集合（映射），其中每个元素都有一个名称，并且它是\r\n            通过名称访问，以及有序的集合（序列），其中元素没有名称，而是\r\n            通过索引访问。可以使用 FileNode::type 方法确定文件节点的类型。\r\n            请注意，文件节点仅用于导航打开以供读取的文件存储。当一个文件\r\n            storage 被打开用于写入，写入后没有数据存储在内存中。\r\n            \r\n","The output rotation matrix (3x3) or rotation vector (3x1 or 1x3), respectively":"分别输出旋转矩阵（3x3）或旋转向量（3x1或1x3）\r\n","\r\n            Create a multi-channel image from multiple gray scale images\r\n            ":"\r\n            从多个灰度图像创建多通道图像\r\n            \r\n","Pose of the widget.":"小部件的姿势。\r\n","\r\n            Get the dictionary that hold the Open CV build flags. The key is a String and the value is type double. If it is a flag, 0 means false and 1 means true \r\n            ":"\r\n            获取包含 Open CV 构建标志的字典。键是字符串，值是双精度类型。如果是flag，0表示false，1表示true\r\n            \r\n","\r\n            The file name of the storage\r\n            ":"\r\n            存储的文件名\r\n            \r\n","\r\n            Converts image transformation maps from one representation to another.\r\n            ":"\r\n            将图像变换图从一种表示形式转换为另一种表示形式。\r\n            \r\n","\r\n            Integer array describing how channel values are permutated. The n-th entry\r\n            of the array contains the number of the channel that is stored in the n-th channel of\r\n            the output image. E.g. Given an RGBA image, aDstOrder = [3,2,1,0] converts this to ABGR\r\n            channel order.\r\n            ":"\r\n            描述通道值如何排列的整数数组。第 n 个条目\r\n            数组的第 n 个通道中存储的通道编号\r\n            输出图像。例如。给定一个 RGBA 图像，aDstOrder = [3,2,1,0] 将其转换为 ABGR\r\n            渠道订单。\r\n            \r\n","\r\n            Recovers inverse camera response.\r\n            ":"\r\n            恢复逆相机响应。\r\n            \r\n","The minimum probability for accepting a group.":"接受一组的最小概率。\r\n","\r\n            Get the 3x3 matrix's value as a double vector (of size 9)\r\n            ":"\r\n            获取 3x3 矩阵的值作为双向量（大小为 9）\r\n            \r\n","\r\n            Write rawdata in Base64 by default. (consider using WriteBase64)\r\n            ":"\r\n            默认情况下以 Base64 写入原始数据。 （考虑使用 WriteBase64）\r\n            \r\n","\r\n            Defines an unary (one input – one output) computation.\r\n            ":"\r\n            定义一元（一个输入 - 一个输出）计算。\r\n            \r\n","\r\n            Least-Median robust method\r\n            ":"\r\n            最小中值鲁棒法\r\n            \r\n","\r\n            DigitalSG ColorChecker with 140 squares\r\n            ":"\r\n            DigitalSG ColorChecker 140 个方块\r\n            \r\n","\r\n            Max inertia ratio\r\n            ":"\r\n            最大惯量比\r\n            \r\n","True if iterator needs to be set after the last element of the node":"如果需要在节点的最后一个元素之后设置迭代器，则为真\r\n","Stopping criterion iterations number used in the numerical scheme.":"数值方案中使用的停止标准迭代次数。\r\n","\r\n            Cuda Host Mem\r\n            ":"\r\n            Cuda 主机内存\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this matcher\r\n            ":"\r\n            释放与此匹配器关联的所有非托管内存\r\n            \r\n","\r\n            Verbose (trace) messages. Requires verbosity level. Disabled in the \"Release\" build.\r\n            ":"\r\n            详细（跟踪）消息。需要详细级别。在“发布”版本中禁用。\r\n            \r\n","Number of processing threads for parallelisation. Setting -1 uses the maximum number of threads. In practice, four threads is enough for smaller images and eight threads for larger ones.":"用于并行化的处理线程数。设置 -1 使用最大线程数。实际上，对于较小的图像，四个线程就足够了，对于较大的图像，八个线程就足够了。\r\n","\r\n            Creates a uniform 1-D histogram of the specified size\r\n            ":"\r\n            创建指定大小的统一一维直方图\r\n            \r\n","The images used in the training. This can be a VectorOfMat":"训练中使用的图像。这可以是一个 VectorOfMat\r\n","\r\n            Finds lines in the input image.\r\n            ":"\r\n            在输入图像中查找线条。\r\n            \r\n","\r\n            Finest level of the Gaussian pyramid on which the flow is computed (zero level corresponds to the original image resolution). The final flow is obtained by bilinear upscaling.\r\n            ":"\r\n            计算流量的高斯金字塔的最佳级别（零级别对应于原始图像分辨率）。通过双线性放大获得最终流量。\r\n            \r\n","\r\n            Create LATCH descriptor extractor\r\n            ":"\r\n            创建 LATCH 描述符提取器\r\n            \r\n","It has a type of CV_8UC(n) or CV_32FC(n), where n is a positive integer.":"它的类型为 CV_8UC(n) 或 CV_32FC(n)，其中 n 为正整数。\r\n","The minimum/maximum value of the output array or the norm of output array":"输出数组的最小值/最大值或输出数组的范数\r\n",") * acc(x,y) + ":") * acc(x,y) +\r\n","The value which subtract this matrix":"减去这个矩阵的值\r\n","Border value in case of constant border type":"常量边框类型情况下的边框值\r\n","The compressed bytes":"压缩字节\r\n","Radius of the descriptor at the initial scale.":"描述符在初始比例下的半径。\r\n","Silhouette mask that has non-zero pixels where the motion occurs. ":"在运动发生的位置具有非零像素的轮廓蒙版。\r\n","The maximum number of iterations":"最大迭代次数\r\n","\r\n            Creates a vertical 1D box filter.\r\n            ":"\r\n            创建垂直一维盒式过滤器。\r\n            \r\n","\r\n            The number of iterations\r\n            ":"\r\n            迭代次数\r\n            \r\n","Output vector of translation vectors estimated for each pattern view.":"为每个模式视图估计的平移向量的输出向量。\r\n","\r\n            This is a real-time object tracking based on a novel on-line version of the AdaBoost algorithm. \r\n            The classifier uses the surrounding background as negative examples in update step to avoid the drifting problem.\r\n            ":"\r\n            这是基于 AdaBoost 算法的新颖在线版本的实时对象跟踪。\r\n            分类器在更新步骤中使用周围背景作为反例以避免漂移问题。\r\n            \r\n","The mapper":"映射器\r\n","Filter sigma in the coordinate space. A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough (see sigmaColor ). When d>0 , it specifies the neighborhood size regardless of sigmaSpace . Otherwise, d is proportional to sigmaSpace .":"在坐标空间中过滤 sigma。较大的参数值意味着更远的像素将相互影响，只要它们的颜色足够接近（参见 sigmaColor ）。当 d>0 时，它指定邻域大小而不考虑 sigmaSpace 。否则，d 与 sigmaSpace 成正比。\r\n","Text color.":"文字颜色。\r\n","Pointer to the image header":"指向图像标题的指针\r\n","\r\n            Creates an instance of this class with given parameters.\r\n            ":"\r\n            使用给定参数创建此类的实例。\r\n            \r\n","A clone of the GPU Mat":"GPU 垫的克隆\r\n","A reshaped matrix which also share the same data with the current matrix":"与当前矩阵共享相同数据的重塑矩阵\r\n","The confident of the classification.":"分类的置信度。\r\n","\r\n             returns the current position in the image\r\n            ":"\r\n             返回图像中的当前位置\r\n            \r\n","\r\n            round to nearest\r\n            ":"\r\n            四舍五入到最近\r\n            \r\n","\r\n            Converts an image from YUV color space to BGR color space.\r\n            ":"\r\n            将图像从 YUV 颜色空间转换为 BGR 颜色空间。\r\n            \r\n","The line segments to be rotated":"要旋转的线段\r\n","\r\n            Histograms are normalized independently for L2 norm equal to 1.0\r\n            ":"\r\n            对于等于 1.0 的 L2 范数，直方图独立归一化\r\n            \r\n","\r\n            For stereo rectification: use LU instead of SVD decomposition for solving. much faster but potentially less precise\r\n            ":"\r\n            对于立体校正：使用 LU 代替 SVD 分解来求解。快得多但可能不太精确\r\n            \r\n","  \r\n            =6 \r\n            ":"  \r\n            =6\r\n            \r\n","Output array of y-coordinates of 2D vectors; it has the same size and type as angle.":"二维向量的 y 坐标输出数组；它与角度具有相同的大小和类型。\r\n"," Perform an elementwise OR operation with another image and return the result":" 与另一个图像执行元素或操作并返回结果\r\n","\r\n            Decrements the matrix data reference counter and releases matrix header\r\n            ":"\r\n            递减矩阵数据引用计数器并释放矩阵头\r\n            \r\n","\r\n            The 6th distortion coefficient (k6) is fixed to 0 or to the initial passed value if CV_CALIB_USE_INTRINSIC_GUESS is passed\r\n            ":"\r\n            第 6 个失真系数 (k6) 固定为 0 或如果传递 CV_CALIB_USE_INTRINSIC_GUESS 则固定为初始传递值\r\n            \r\n","Input image (with 1- or 3-channels).":"输入图像（1 或 3 通道）。\r\n","The absolute infinite norm of a matrix.":"矩阵的绝对无限范数。\r\n","light adaptation in [0, 1] range. If 1 adaptation is based only on pixel value, if 0 it's global, otherwise it's a weighted mean of this two cases.":"[0, 1] 范围内的光照适应。如果 1 自适应仅基于像素值，如果为 0 则它是全局的，否则它是这两种情况的加权平均值。\r\n","Type of the line.":"线的类型。\r\n","the color used for drawing":"用于绘图的颜色\r\n","\r\n            Return the specific diagonal elements of this matrix\r\n            ":"\r\n            返回此矩阵的特定对角线元素\r\n            \r\n","\r\n            Bicubic interpolation\r\n            ":"\r\n            双三次插值\r\n            \r\n","Kernel for descriptor construction, where 1=3x3, 2=5x5, 3=7x7 and so forth":"描述符构造的内核，其中 1=3x3、2=5x5、3=7x7 等等\r\n","\r\n            Create a new QR code detector\r\n            ":"\r\n            创建一个新的二维码检测器\r\n            \r\n","\r\n            Octave (pyramid layer), from which the keyline has been extracted \r\n            ":"\r\n            八度（金字塔层），从中提取了关键线\r\n            \r\n","The first threshold":"第一个门槛\r\n","\r\n            Selective search segmentation algorithm\r\n            ":"\r\n            选择性搜索分割算法\r\n            \r\n","The strings to be placed in this VectorOfCvString":"要放置在此 VectorOfCvString 中的字符串\r\n","\r\n            Create a Color Moment Hash object\r\n            ":"\r\n            创建一个 Color Moment Hash 对象\r\n            \r\n","\r\n            Create an standard vector of ColorPoint of the specific size\r\n            ":"\r\n            创建特定大小的 ColorPoint 标准向量\r\n            \r\n","\r\n            This parameter multiplied by the index of iteration gives lower limit for cluster size. Clusters containing fewer points than specified by the limit have their centroid dismissed and points are reassigned.\r\n            ":"\r\n            此参数乘以迭代索引给出了簇大小的下限。包含的点少于限制指定的点的集群将取消其质心并重新分配点。\r\n            \r\n","Probability of replacing the old sample - how fast the model will update itself.":"替换旧样本的概率——模型自我更新的速度。\r\n","Output status vector. Each element of the vector is set to 1 if the flow for the corresponding features has been found. Otherwise, it is set to 0.":"输出状态向量。如果已找到相应特征的流，则向量的每个元素都设置为 1。否则，它被设置为 0。\r\n","The output single-row/single-column vector that accumulates somehow all the matrix rows/columns":"以某种方式累积所有矩阵行/列的输出单行/单列向量\r\n","The mean value of matrix elements, independently for each channel, and return it. ":"矩阵元素的平均值，独立于每个通道，并返回它。\r\n","Masks for each input image specifying where to look for keypoints (optional).":"每个输入图像的掩码指定在哪里寻找关键点（可选）。\r\n","Border extrapolation mode":"边界外推模式\r\n","The 3 letter language identifier":"3 个字母的语言标识符\r\n","Array header.":"数组头。\r\n","\r\n            Type used by cvMatchShapes\r\n            ":"\r\n            cvMatchShapes 使用的类型\r\n            \r\n","The xmap. Supports CV_32FC1 map type.":"x地图。支持 CV_32FC1 地图类型。\r\n","The absolute L2 norm of a matrix.":"矩阵的绝对 L2 范数。\r\n","\r\n            Load the FaceRecognizer from the file\r\n            ":"\r\n            从文件中加载 FaceRecognizer\r\n            \r\n","\r\n            Rainbow\r\n            ":"\r\n            彩虹\r\n            \r\n","\r\n            Do not look outside of ROI\r\n            ":"\r\n            不要在投资回报率之外看\r\n            \r\n","The type of objects that will be joined":"将要连接的对象类型\r\n","\r\n            Get the type of the GpuMat\r\n            ":"\r\n            获取 GpuMat 的类型\r\n            \r\n","FileStorage for output":"用于输出的文件存储\r\n","Input single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit floating-point disparity image. If 16-bit signed format is used, the values are assumed to have no fractional bits.":"输入单通道8位无符号、16位有符号、32位有符号或32位浮点视差图像。如果使用 16 位有符号格式，则假定值没有小数位。\r\n","\r\n            The support region type\r\n            ":"\r\n            支持区域类型\r\n            \r\n"," Get or set the intensity of the x color channel ":" 获取或设置 x 颜色通道的强度\r\n","A 0-based row index.":"从 0 开始的行索引。\r\n","\r\n            Convert BGR to YUV_I420\r\n            ":"\r\n            将 BGR 转换为 YUV_I420\r\n            \r\n","\r\n            Out Premul\r\n            ":"\r\n            出前乳\r\n            \r\n","\r\n            Computes the integral image and integral for the squared image\r\n            ":"\r\n            计算积分图像和平方图像的积分\r\n            \r\n","\r\n            Convert Bayer GBRG to BGRA \r\n            ":"\r\n            拜耳 GBRG 转换为 BGRA\r\n            \r\n","\r\n            Obtain the capture property\r\n            ":"\r\n            获取捕获属性\r\n            \r\n","Read flags":"读取标志\r\n","\r\n            number of bits of the marker border, i.e. marker border width (default 1).\r\n            ":"\r\n            标记边框的位数，即标记边框宽度（默认为 1）。\r\n            \r\n","Optional delta value that is added to the results prior to storing them in dst .":"在将结果存储在 dst 之前添加到结果中的可选增量值。\r\n","\r\n            Create an empty Image of the specified width and height\r\n            ":"\r\n            创建指定宽高的空图像\r\n            \r\n","\r\n            Set the SVM detector \r\n            ":"\r\n            设置 SVM 检测器\r\n            \r\n","The unmanaged pointer to the GpuMat":"指向 GpuMat 的非托管指针\r\n","\r\n            Color Correction Matrix element [0][0]\r\n            ":"\r\n            颜色校正矩阵元素 [0][0]\r\n            \r\n","Latitude in radian":"纬度弧度\r\n","Result image":"结果图片\r\n","\r\n            maximum number of iterations for stop criteria of the corner refinement process (default 30).\r\n            ":"\r\n            角优化过程停止标准的最大迭代次数（默认 30）。\r\n            \r\n","\r\n            Cuda compute 5.0\r\n            ":"\r\n            Cuda计算5.0\r\n            \r\n","The output foreground mask":"输出前景掩码\r\n","Zero-based index of the stream. In most cases there is only one stream in the file.\r\n            However, YAML supports multiple streams and so there can be several.":"流的从零开始的索引。在大多数情况下，文件中只有一个流。\r\n            但是，YAML 支持多个流，因此可以有多个。\r\n","The center of the cross":"十字架的中心\r\n","Image to segment":"要分割的图像\r\n","\r\n            Fits an ellipse around a set of 2D points.\r\n            ":"\r\n            在一组 2D 点周围拟合一个椭圆。\r\n            \r\n","A clone of this CudaImage":"这个 CudaImage 的克隆\r\n","output image with first-order derivative in y.":"在 y 中具有一阶导数的输出图像。\r\n","\r\n            Apply a adaptive support region obtained by cross-based segmentation\r\n            ":"\r\n            应用通过基于交叉的分割获得的自适应支持区域\r\n            \r\n","\r\n            Get the pointer to the ImgHashBase object\r\n            ":"\r\n            获取指向 ImgHashBase 对象的指针\r\n            \r\n"," The red value for this color ":" 这种颜色的红色值\r\n","\r\n            True if the input array is a Matx\r\n            ":"\r\n            如果输入数组是 Matx，则为真\r\n            \r\n","\r\n            Pointer to the native cv::Algorithm\r\n            ":"\r\n            指向本机 cv::Algorithm 的指针\r\n            \r\n","The point to be compared":"要比较的点\r\n","The first convex polygon":"第一个凸多边形\r\n","If it is true, the network provided using the setNet() is used for preliminary search for regions where chart\r\n            could be present, inside the regionsOfInterest provided.":"如果为真，使用 setNet() 提供的网络用于初步搜索图表所在的区域\r\n            可能存在于所提供的 regionsOfInterest 中。\r\n","Size of the search window of each pyramid level.":"每个金字塔级别的搜索窗口的大小。\r\n","\r\n            BayerRG2RGB_MHT\r\n            ":"\r\n            拜耳RG2RGB_MHT\r\n            \r\n","\r\n            position of first kneepoint(in % of XI_PRM_EXPOSURE)\r\n            ":"\r\n            第一个拐点的位置（以 XI_PRM_EXPOSURE 的百分比表示）\r\n            \r\n","\r\n            Grid Lines Number\r\n            ":"\r\n            网格线数\r\n            \r\n","The depth type of img3":"img3的深度类型\r\n","\r\n            It true, will perform non-maximum suppression across classes\r\n            ":"\r\n            是的，会跨类进行非极大值抑制\r\n            \r\n","Input 1-nearest neighbor matches.":"输入 1-最近邻匹配。\r\n","Spatial size for output image":"输出图像的空间大小\r\n","\r\n            Fills the area bounded by one or more polygons.\r\n            ":"\r\n            填充由一个或多个多边形界定的区域。\r\n            \r\n","img2 in: res = this * alpha + img2 * beta + gamma ":"img2 in: res = this * alpha + img2 * beta + gamma\r\n","\r\n            Opengl buffer\r\n            ":"\r\n            缓冲区\r\n            \r\n"," Perform an elementwise OR operation with some color":" 对某种颜色执行逐元素或运算\r\n","input single-channel array.":"输入单通道阵列。\r\n","\r\n            Clears (sets to zero) the particular element of dense array or deletes the element of sparse array. If the element does not exists, the function does nothing\r\n            ":"\r\n            清除（设置为零）密集数组的特定元素或删除稀疏数组的元素。如果元素不存在，则该函数不执行任何操作\r\n            \r\n","Size of the kernerl used for the filtering. Uses a (windowSize x windowSize) filter.":"用于过滤的内核大小。使用 (windowSize x windowSize) 过滤器。\r\n","Number of split points from bezier-curve to line":"从贝塞尔曲线到直线的分割点数\r\n","\r\n            Filter by area\r\n            ":"\r\n            按地区过滤\r\n            \r\n","\r\n            pairs (number of elements, distance between elements in bytes)\r\n            ":"\r\n            对（元素数量，元素之间的距离，以字节为单位）\r\n            \r\n","\r\n            Termination criteria for regression trees\r\n            ":"\r\n            回归树的终止标准\r\n            \r\n","Comparison image(s), or image(s) to evaluate for no-reference quality algorithms":"比较图像或用于评估无参考质量算法的图像\r\n","\r\n            Get the pointer to the widget object.\r\n            ":"\r\n            获取指向小部件对象的指针。\r\n            \r\n","\r\n            Copy a generic vector to the unmanaged memory\r\n            ":"\r\n            将通用向量复制到非托管内存\r\n            \r\n","The depth type of the source image":"源图像的深度类型\r\n","\r\n            BoxMin filter\r\n            ":"\r\n            BoxMin过滤器\r\n            \r\n","The re-projection 4x4 matrix, can be arbitrary, e.g. the one, computed by cvStereoRectify":"重投影 4x4 矩阵可以是任意的，例如一个，由 cvStereoRectify 计算\r\n","\r\n            Blob file\r\n            ":"\r\n            文件\r\n            \r\n","\r\n            Clear the algorithm\r\n            ":"\r\n            清除算法\r\n            \r\n","\r\n            Normalise output. Use true for default\r\n            ":"\r\n            规范化输出。默认使用 true\r\n            \r\n","\r\n            Convert MCvScalar to InputArray\r\n            ":"\r\n            将 MCvScalar 转换为 InputArray\r\n            \r\n","Second spectrum with the same size and type.":"具有相同大小和类型的第二个光谱。\r\n","Scale factor used in pyramids generation":"金字塔生成中使用的比例因子\r\n","Threshold value, above which it is marked foreground, else background.":"阈值，超过它标记为前景，否则为背景。\r\n","\r\n            Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.\r\n            ":"\r\n            构造可以传递给 calcOpticalFlowPyrLK 的图像金字塔。\r\n            \r\n","filtering image with unsigned 8-bit or floating-point 32-bit depth and up to 4 channels.":"具有无符号 8 位或浮点 32 位深度和最多 4 个通道的过滤图像。\r\n","\r\n            The work scale\r\n            ":"\r\n            工作规模\r\n            \r\n","\r\n            Get the default parameter grid for the specific SVM type\r\n            ":"\r\n            获取特定 SVM 类型的默认参数网格\r\n            \r\n","Indicates whether the complete board was found (!=0) or not (=0). One may just pass the return value cvFindChessboardCorners here. ":"指示是否找到完整的电路板 (!=0) 或未找到 (=0)。可以在这里传递返回值 cvFindChessboardCorners。\r\n","val - this, with mask":"val - 这个，带面具\r\n","the area of the map to be retrieve":"要检索的地图区域\r\n","\r\n            BBDT algorithm for 8-way connectivity, SAUF algorithm for 4-way connectivity. The parallel implementation is available for both BBDT and SAUF.\r\n            ":"\r\n            8路连接的BBDT算法，4路连接的SAUF算法。并行实现可用于 BBDT 和 SAUF。\r\n            \r\n","\r\n            Get the device name\r\n            ":"\r\n            获取设备名称\r\n            \r\n","The ith column of the GpuMat":"GpuMat的第i列\r\n","The normalized output array":"规范化输出数组\r\n","The unmanaged pointer for this DataLogger":"此 DataLogger 的非托管指针\r\n","aperture size for the Sobel operator.":"Sobel 算子的孔径大小。\r\n","Another cross-product operand.":"另一个叉积操作数。\r\n"," is greater or equals to the DataLogger's logLevel":" 大于或等于 DataLogger 的 logLevel\r\n"," Output vector indicating which points are inliers.":" 指示哪些点是内点的输出向量。\r\n","Flag indicating whether the fixed-point maps are used for the nearest-neighbor or for a more complex interpolation.":"指示定点映射是用于最近邻还是用于更复杂的插值的标志。\r\n","Allocation Usage":"分配使用\r\n","Binary file with trained weights.":"具有训练权重的二进制文件。\r\n","64-bit value used to initialize the RNG":"用于初始化 RNG 的 64 位值\r\n","optional 3x3 homography matrix used to warp the grid of daisy but sampling keypoints remains unwarped on image":"可选的 3x3 单应矩阵用于扭曲菊花的网格，但采样关键点在图像上保持未扭曲\r\n","\r\n            KullbackLeibler\r\n            ":"\r\n            库尔巴克莱布勒\r\n            \r\n","The number of channels of the source image":"源图像的通道数\r\n","\r\n            Get the tesseract version\r\n            ":"\r\n            获取 tesseract 版本\r\n            \r\n","\r\n            string marshaling type\r\n            ":"\r\n            字符串编组类型\r\n            \r\n","\r\n            If it is set, the function uses Canny edge detector to reject some image regions that contain too few or too much edges and thus can not contain the searched object. The particular threshold values are tuned for face detection and in this case the pruning speeds up the processing\r\n            ":"\r\n            如果设置，该函数使用 Canny 边缘检测器拒绝一些包含太少或太多边缘的图像区域，从而不能包含搜索到的对象。特定的阈值针对人脸检测进行了调整，在这种情况下，修剪加快了处理速度\r\n            \r\n","The type of the depth of the ":"深度类型\r\n","\r\n            Sets all or some of the array elements to the specified value.\r\n            ":"将所有或部分数组元素设置为指定值。\r\n            \r\n","Buffer containing the content of the .cfg file with text description of the network architecture.":"包含带有网络架构文本描述的 .cfg 文件内容的缓冲区。\r\n","A path to binary network.":"通往二进制网络的路径。\r\n","\r\n            Kalman gain matrix (K(k)): K(k)=P'(k)*Ht*inv(H*P'(k)*Ht+R)\r\n            ":"\r\n            卡尔曼增益矩阵(K(k))：K(k)=P'(k)*Ht*inv(H*P'(k)*Ht+R)\r\n            \r\n","Cloning method":"克隆方法\r\n","A rows x cols x 3 matrix":"行 x 列 x 3 矩阵\r\n","positions of diamond corners in the same format returned by detectCharucoDiamond(). (e.g VectorOfVectorOfPointF ). For N detected markers, the dimensions of this array should be Nx4. The order of the corners should be clockwise.":"与 detectCharucoDiamond() 返回的格式相同的菱形角位置。 （例如 VectorOfVectorOfPointF ）。对于 N 个检测到的标记，此数组的维度应为 Nx4。角的顺序应该是顺时针的。\r\n","\r\n            Write detector to FileStorage.\r\n            ":"\r\n            将检测器写入 FileStorage。\r\n            \r\n","\r\n            The unmanaged pointer the frameSource\r\n            ":"\r\n            frameSource 的非托管指针\r\n            \r\n","\r\n            Create a Mercator Warper\r\n            ":"\r\n            创建墨卡托变形器\r\n            \r\n","\r\n            Create the termination criteria using the constrain of maximum iteration as well as epsilon\r\n            ":"\r\n            使用最大迭代约束和 epsilon 创建终止条件\r\n            \r\n","Source matrix. Any matrices except 64F are supported.":"源矩阵。支持除 64F 之外的任何矩阵。\r\n"," If true, the approximated curve is closed (its first and last vertices are connected). Otherwise, it is not closed.":" 如果为真，则近似曲线是闭合的（它的第一个和最后一个顶点相连）。否则，它不会关闭。\r\n","\r\n            Convert YUV (YUY2) to RGB\r\n            ":"\r\n            将 YUV (YUY2) 转换为 RGB\r\n            \r\n","\r\n            Value at entry LUTIndex of the LUT\r\n            ":"\r\n            LUT 的入口 LUTIndex 处的值\r\n            \r\n","Match confident":"比赛自信\r\n","\r\n            Buffer size\r\n            ":"\r\n            缓冲区大小\r\n            \r\n","Pixel extrapolation method":"像素外推法\r\n","\r\n            Convert YUV (420p) to BGR\r\n            ":"\r\n            将 YUV (420p) 转换为 BGR\r\n            \r\n","Pixel extrapolation method in the horizontal direction.":"水平方向的像素外推法。\r\n","The file to create the classifier from":"从中创建分类器的文件\r\n","\r\n            Object that can compute the normals in an image. It is an object as it can cache data for speed efficiency\r\n            ":"\r\n            可以计算图像中法线的对象。它是一个对象，因为它可以缓存数据以提高速度效率\r\n            \r\n","Block size in cells. Use (16, 16) for default.":"单元格中的块大小。默认使用 (16, 16)。\r\n"," if the object is associated with the current file; otherwise, ":" 如果对象与当前文件关联；否则，\r\n","Edge min magnitude. Increase to trade off accuracy for speed.":"边缘最小幅度。增加以牺牲速度的准确性。\r\n","Size of grid for histogram equalization. Input image will be divided into equally sized rectangular tiles. This parameter defines the number of tiles in row and column. Use (8, 8) for default":"直方图均衡化的网格大小。输入图像将被分成大小相等的矩形块。此参数定义行和列中的图块数。默认使用 (8, 8)\r\n","\r\n            1bit unsigned\r\n            ":"\r\n            1位无符号\r\n            \r\n","The sum of the two images":"两个图像的总和\r\n","\r\n            Get or Set the vocabulary for recognition.\r\n            ":"\r\n            获取或设置识别词汇。\r\n            \r\n","The value to be added to the current matrix":"要添加到当前矩阵的值\r\n","\r\n            (read-only) Video bitrate in kbits/s\r\n            ":"\r\n            （只读）以 kbits/s 为单位的视频比特率\r\n            \r\n","\r\n            Hand-eye Calibration\r\n            ":"\r\n            手眼标定\r\n            \r\n","A point placed from a hypothesis line segment farther than this will be regarded as an outlier.":"距假设线段更远的点将被视为异常值。\r\n","vector of reference images, converted to internal type":"参考图像矢量，转换为内部类型\r\n","\r\n            The ERStat structure represents a class-specific Extremal Region (ER).\r\n            An ER is a 4-connected set of pixels with all its grey-level values smaller than the values in its outer boundary. \r\n            A class-specific ER is selected (using a classifier) from all the ER’s in the component tree of the image.\r\n            ":"\r\n            ERStat 结构表示类特定的极值区域 (ER)。\r\n            ER 是一组 4 连通的像素，其所有灰度值都小于其外边界中的值。\r\n            从图像组件树中的所有 ER 中选择（使用分类器）特定类别的 ER。\r\n            \r\n","A matrix of the same size with all elements equals 0":"所有元素都为0的相同大小的矩阵\r\n","output image with the marker. The size of this image will be 3*squareLength + 2*marginSize.":"带有标记的输出图像。此图像的大小将为 3*squareLength + 2*marginSize。\r\n","For more details about this implementation, please see: Qi Zhang, Li Xu, and Jiaya Jia. 100+ times faster weighted median filter (wmf). In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2830–2837. IEEE, 2014.":"有关此实现的更多详细信息，请参阅：Qi Zhang、Li Xu 和 Jiaya Jia。加权中值滤波器 (wmf) 快 100 倍以上。在计算机视觉和模式识别 (CVPR) 中，2014 年 IEEE 会议，第 2830–2837 页。 IEEE，2014 年。\r\n"," The epsilon value":" epsilon 值\r\n","\r\n            Runs forward pass to compute outputs of layers listed in outBlobNames.\r\n            ":"\r\n            运行前向传递以计算 outBlobNames 中列出的层的输出。\r\n            \r\n","\r\n            Check if the GPU module is targeted for equal or greater PTX version\r\n            ":"\r\n            检查 GPU 模块是否针对相同或更高的 PTX 版本\r\n            \r\n","\r\n            Matx\r\n            ":"\r\n            矩阵\r\n            \r\n","\r\n            Camera housing temperature\r\n            ":"\r\n            摄像机外壳温度\r\n            \r\n","\r\n            Collect corresponding 2d and 3d points based on correspondencies and mask\r\n            ":"\r\n            根据对应关系和mask收集对应的2d和3d点\r\n            \r\n","Array of polygons where each polygon is represented as an array of points.":"多边形数组，其中每个多边形表示为点数组。\r\n","The type of depth of the matrix":"矩阵的深度类型\r\n","\r\n            The size of CvSize2D32f\r\n            ":"\r\n            CvSize2D32f 的大小\r\n            \r\n","\r\n            Release the memory associated with this segmentation model.\r\n            ":"\r\n            释放与此分段模型关联的内存。\r\n            \r\n","\r\n            Execute all steps of the algorithm \r\n            ":"\r\n            执行算法的所有步骤\r\n            \r\n","\r\n            Set mean value for frame.\r\n            ":"\r\n            设置帧的平均值。\r\n            \r\n","\r\n            Convert the standard vector to an array of PointF\r\n            ":"\r\n            将标准向量转换为 PointF 数组\r\n            \r\n"," The color of the convex polygon ":" 凸多边形的颜色\r\n","\r\n            Implementation of bio-inspired features (BIF) from the paper: Guo, Guodong, et al. \"Human age estimation using bio-inspired features.\" Computer Vision and Pattern Recognition, 2009. CVPR 2009.\r\n            ":"\r\n            论文中仿生特征 (BIF) 的实现：Guo、Guodong 等。 “使用仿生特征估计人类年龄。”计算机视觉和模式识别，2009。CVPR 2009。\r\n            \r\n","The vector of distortion coefficients, 4x1 or 1x4 [k1, k2, p1, p2].":"失真系数的向量，4x1 或 1x4 [k1, k2, p1, p2]。\r\n","DFT flags":"DFT 标志\r\n","\r\n            Dispose the unmanaged memory associated with this DPM\r\n            ":"\r\n            处置与此 DPM 关联的非托管内存\r\n            \r\n","\r\n            Up\r\n            ":"\r\n            向上\r\n            \r\n","Normal of the plane in which the circle lies.":"圆所在平面的法线。\r\n","True if backend is set":"如果设置了后端则为真\r\n","The border mode for gradients.":"渐变的边框模式。\r\n","\r\n            Returns the mask of the superpixel segmentation stored in SuperpixelSEEDS object.\r\n            ":"返回存储在 SuperpixelSEEDS 对象中的超像素分割的掩码。\r\n            \r\n","The id of the widget whose pose will be set.":"将设置姿势的小部件的 ID。\r\n","L2-Hys normalization method shrinkage.":"L2-Hys归一化方法收缩。\r\n","\r\n            YUY2\r\n            ":"\r\n            YUY2\r\n            \r\n","[i,j] <= this[i,j] <= ":"[i,j] <= 这个 [i,j] <=\r\n","\r\n            Element wise subtract another image from the current image\r\n            ":"\r\n            元素明智地从当前图像中减去另一个图像\r\n            \r\n","The color value to be added to the current image":"要添加到当前图像的颜色值\r\n","\r\n            Close sequence\r\n            ":"\r\n            关闭顺序\r\n            \r\n","\r\n            Vertical Binning - number of vertical photo-sensitive cells to combine together.\r\n            ":"\r\n            Vertical Binning - 要组合在一起的垂直光敏单元的数量。\r\n            \r\n","\r\n            Read point cloud from file\r\n            ":"\r\n            从文件中读取点云\r\n            \r\n","\r\n            Pointer to the previous ERStat\r\n            ":"\r\n            指向前一个 ERStat 的指针\r\n            \r\n","\r\n            Create a Matrix (only header is allocated) using the Pinned/Unmanaged ":"\r\n            使用 Pinned/Unmanaged 创建矩阵（仅分配标头）\r\n","The base type":"基础类型\r\n","\r\n            Create a Good Feature to Track detector\r\n            ":"\r\n            创建一个好的特征来跟踪检测器\r\n            \r\n","The destination array of the same type and the same size of the sources":"与源相同类型和相同大小的目标数组\r\n","\r\n            For each query descriptor, finds the training descriptors not farther than the specified distance.\r\n            ":"\r\n            对于每个查询描述符，查找不超过指定距离的训练描述符。\r\n            \r\n","\r\n            Mercator warper\r\n            ":"\r\n            墨卡托整经机\r\n            \r\n","\r\n            Accumulator threshold parameter. Only those lines are returned that get enough\r\n            ":"\r\n            累加器阈值参数。只返回那些足够的行\r\n            \r\n","Activate retina log sampling, if true, the 2 following parameters can be used":"激活 Retina 日志采样，如果为 true，可以使用以下 2 个参数\r\n","Parameter specifying how many pixels in each direction from the source image rectangle to extrapolate.":"指定从源图像矩形到每个方向要外推的像素数的参数。\r\n","\r\n            KMeans initialization type\r\n            ":"\r\n            KMeans初始化类型\r\n            \r\n","\r\n            Check if use of OpenVX is possible.\r\n            ":"\r\n            检查是否可以使用 OpenVX。\r\n            \r\n","System index of a CUDA device starting with 0.":"以 0 开头的 CUDA 设备的系统索引。\r\n","\r\n            Correctly rounded divide sqrt\r\n            ":"\r\n            正确四舍五入除开方\r\n            \r\n","\r\n            Convert BGR color to RGB color\r\n            ":"\r\n            将 BGR 颜色转换为 RGB 颜色\r\n            \r\n","\r\n            Shared Atomic\r\n            ":"\r\n            共享原子\r\n            \r\n","Currently the function is slower than cvSVD yet less accurate, so if A is known to be positivelydefined (for example, it is a covariance matrix)it is recommended to use cvSVD to find eigenvalues and eigenvectors of A, especially if eigenvectors are not required.":"目前该函数比 cvSVD 慢但精度较低，因此如果已知 A 是正定义的（例如，它是协方差矩阵），建议使用 cvSVD 来查找 A 的特征值和特征向量，尤其是在不需要特征向量的情况下。\r\n","border value.":"边界值。\r\n","\r\n            Get the amount of free memory at the moment\r\n            ":"\r\n            获取当前可用内存量\r\n            \r\n","\r\n            Macbeth ColorChecker\r\n            ":"\r\n            麦克白颜色检查器\r\n            \r\n","\r\n            Transforms grayscale image to binary image. \r\n            Threshold calculated individually for each pixel. \r\n            For the method CV_ADAPTIVE_THRESH_MEAN_C it is a mean of ":"\r\n            将灰度图像转换为二值图像。\r\n            为每个像素单独计算的阈值。\r\n            对于 CV_ADAPTIVE_THRESH_MEAN_C 方法，它是\r\n","\r\n            Managed Structure equivalent to CvPoint3D32f\r\n            ":"\r\n            等效于 CvPoint3D32f 的托管结构\r\n            \r\n","The first map of either (x,y) points or just x values having the type CV_16SC2, CV_32FC1, or CV_32FC2.":"(x,y) 点或只有 x 值的第一个映射具有类型 CV_16SC2、CV_32FC1 或 CV_32FC2。\r\n","The UMat to be written to. If no more frame is available, the resulting UMat will be empty.":"要写入的 UMat。如果没有更多的框架可用，则生成的 UMat 将为空。\r\n","The indices of the boxes to keep after NMS":"NMS 之后要保留的框的索引\r\n","An empty output array":"一个空的输出数组\r\n","\r\n            (open-only) Timeout in milliseconds for opening a video capture (applicable for FFmpeg back-end only)\r\n            ":"\r\n            (open-only) 打开视频捕获的超时时间（以毫秒为单位）（仅适用于 FFmpeg 后端）\r\n            \r\n","\r\n            Checks that every array element is neither NaN nor Infinity. If CV_CHECK_RANGE is set, it also checks that every element is greater than or equal to minVal and less than maxVal. \r\n            ":"\r\n            检查每个数组元素既不是 NaN 也不是 Infinity。如果设置了 CV_CHECK_RANGE，它还会检查每个元素是否大于或等于 minVal 且小于 maxVal。\r\n            \r\n","\r\n            Discrete AdaBoost.\r\n            ":"\r\n            离散 AdaBoost。\r\n            \r\n","\r\n            Get or Set the capture type\r\n            ":"\r\n            获取或设置捕获类型\r\n            \r\n","\r\n            Ultra fast\r\n            ":"\r\n            超快\r\n            \r\n","Vector of detected marker corners in all frames. The corners should have the same format returned by detectMarkers":"所有帧中检测到的标记角的向量。角点应具有与 detectMarkers 返回的相同格式\r\n","The valid pixel ROI for image2":"image2 的有效像素 ROI\r\n","\r\n            Equalizes the histogram of a grayscale image using Contrast Limited Adaptive Histogram Equalization.\r\n            ":"\r\n            使用对比度受限自适应直方图均衡化来均衡灰度图像的直方图。\r\n            \r\n","\r\n            Bad COI\r\n            ":"\r\n            坏 COI\r\n            \r\n","Main stereo matcher instance that will be used with the filter":"将与过滤器一起使用的主立体匹配器实例\r\n","\r\n            Finds the global minimum and maximum in an array\r\n            ":"\r\n            查找数组中的全局最小值和最大值\r\n            \r\n","\r\n            Epsilon\r\n            ":"\r\n            小量\r\n            \r\n","\r\n            Fills output variables with low-level information about the array data. All output parameters are optional, so some of the pointers may be set to NULL. If the array is IplImage with ROI set, parameters of ROI are returned. \r\n            ":"\r\n            使用有关数组数据的低级信息填充输出变量。所有输出参数都是可选的，因此一些指针可能会设置为 NULL。如果数组是设置了 ROI 的 IplImage，则返回 ROI 的参数。\r\n            \r\n","The maximum number of pyramid levels.":"金字塔等级的最大数量。\r\n","\r\n            Resize the CudaImage. The calling GpuMat be GpuMat%lt;Byte>. If stream is specified, it has to be either 1 or 4 channels.\r\n            ":"\r\n            调整 CudaImage 的大小。调用 GpuMat 为 GpuMat%lt;Byte>。如果指定了流，则它必须是 1 个或 4 个通道。\r\n            \r\n","Destination back projection image of the same type as the source images":"与源图像类型相同的目标反投影图像\r\n","The color for the XOR operation":"异或运算的颜色\r\n","Desired depth of the destination image.":"目标图像的所需深度。\r\n","\r\n            Flips the array in one of different 3 ways (row and column indices are 0-based)\r\n            ":"\r\n            以 3 种不同方式之一翻转数组（行和列索引从 0 开始）\r\n            \r\n","Mask that sets which pixels have to be used from the destination frame (CV_8UC1)":"设置必须使用目标帧中哪些像素的掩码 (CV_8UC1)\r\n","The optional output image containing rectified and binarized QR code":"可选的输出图像包含经过校正和二值化的 QR 码\r\n","Response for the provided sample":"对所提供样本的回应\r\n","\r\n            Assume a single uniform block of vertically aligned text.\r\n            ":"\r\n            假设有一个统一的垂直对齐文本块。\r\n            \r\n","New value of repainted domain pixels.":"重绘域像素的新值。\r\n","The disparity value used to paint-off the speckles":"用于去除斑点的视差值\r\n","\r\n            The leftmost (x) coordinate which is the inclusive start of the bounding box in the horizontal direction.\r\n            ":"\r\n            最左边的 (x) 坐标，它是边界框在水平方向上的包含起点。\r\n            \r\n","\r\n            Create a K-nearest neighbors - based Background/Foreground Segmentation Algorithm.\r\n            ":"\r\n            创建一个基于 K 最近邻的背景/前景分割算法。\r\n            \r\n","Input camera matrix A=[[fx 0 0] [0 fy 0] [cx cy 1]] .":"输入相机矩阵 A=[[fx 0 0] [0 fy 0] [cx cy 1]] 。\r\n","\r\n            H264_MVC\r\n            ":"\r\n            H264_MVC\r\n            \r\n","\r\n            Release the unmanaged memory associated with this BIF\r\n            ":"\r\n            释放与此 BIF 关联的非托管内存\r\n            \r\n","The comparison result: width = this.Width - template.Width + 1; height = this.Height - template.Height + 1 ":"比较结果：width = this.Width - template.Width + 1; height = this.Height - 模板.Height + 1\r\n","The next 32-bit random number":"下一个 32 位随机数\r\n","\r\n            Minimum Image Size\r\n            ":"\r\n            最小图像尺寸\r\n            \r\n","Undistorted image size.":"未失真的图像大小。\r\n","Histogram with evenly distributed bins":"具有均匀分布的 bin 的直方图\r\n","\r\n            Extension methods to the IAlgorithm interface\r\n            ":"\r\n            IAlgorithm 接口的扩展方法\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this gpu filter\r\n            ":"\r\n            释放与此 gpu 过滤器关联的所有非托管内存\r\n            \r\n","\r\n            Number of iterations of the k-means clustering. We use fixed number of iterations, since the modified clustering is pruning clusters (not iteratively refining k clusters).\r\n            ":"\r\n            k 均值聚类的迭代次数。我们使用固定次数的迭代，因为修改后的聚类是修剪聚类（而不是迭代细化 k 个聚类）。\r\n            \r\n","\r\n            (read-only) Time in microseconds since Jan 1 1970 when stream was opened. Applicable for FFmpeg backend only. Useful for RTSP and other live streams\r\n            ":"\r\n            （只读）自 1970 年 1 月 1 日打开流以来的时间（以微秒为单位）。仅适用于 FFmpeg 后端。对 RTSP 和其他实时流很有用\r\n            \r\n","\r\n            If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit.\r\n            ":"\r\n            如果设置，则当输入具有相应的深度时返回 16 位/32 位图像，否则将其转换为 8 位。\r\n            \r\n","Destination array depth":"目标数组深度\r\n","\r\n            Roll\r\n            ":"\r\n            卷\r\n            \r\n","\r\n            Create a two pass video stabilizer.\r\n            ":"\r\n            创建一个两次通过的视频稳定器。\r\n            \r\n","Source image channels.":"源图像通道。\r\n","\r\n            The enum specified format of result that you get from GapiInvoke.Stereo\r\n            ":"您从 GapiInvoke.Stereo 获得的结果的枚举指定格式\r\n            \r\n","Input source type. Only single channel are supported for now.":"输入源类型。目前只支持单通道。\r\n","\r\n            Schedule layers that support Halide backend. Then compile them for specific target. For layers that not represented in scheduling file or if no manual scheduling used at all, automatic scheduling will be applied.\r\n            ":"\r\n            安排支持 Halide 后端的图层。然后针对特定目标编译它们。对于计划文件中未表示的图层，或者如果根本没有使用手动计划，将应用自动计划。\r\n            \r\n","\r\n            The method updates the state using the MWC algorithm and returns the next 32-bit random number.\r\n            ":"\r\n            该方法使用 MWC 算法更新状态并返回下一个 32 位随机数。\r\n            \r\n","\r\n            Return parameters based on ROI\r\n            ":"\r\n            根据ROI返回参数\r\n            \r\n","\r\n            The function slides through image, compares overlapped patches of size wxh with templ using the specified method and return the comparison results \r\n            ":"\r\n            函数滑过图像，使用指定的方法将大小为 wxh 的重叠块与 templ 进行比较，并返回比较结果\r\n            \r\n","\r\n            Retrieves all the support vectors.\r\n            ":"\r\n            检索所有支持向量。\r\n            \r\n","\r\n            All the input vectors are stored in a single matrix, as its columns\r\n            ":"\r\n            所有输入向量都存储在一个矩阵中，作为它的列\r\n            \r\n","\r\n            CV_FM_RANSAC_ONLY | CV_FM_8POINT\r\n            ":"\r\n            CV_FM_RANSAC_ONLY | CV_FM_8POINT\r\n            \r\n","Value of the Rodrigues vector":"Rodrigues 向量的值\r\n","\r\n              distance = c^2(|x|/c-log(1+|x|/c)), c = 1.3998 \r\n            ":"\r\n              距离 = c^2(|x|/c-log(1+|x|/c)), c = 1.3998\r\n            \r\n","Type of norm":"规范类型\r\n","\r\n            Mask for format flags\r\n            ":"\r\n            格式标志的掩码\r\n            \r\n","\r\n            ANNEAL: Update cooling ratio.\r\n            ":"\r\n            ANNEAL：更新冷却比。\r\n            \r\n","\r\n            Pointer to the parent ERStat\r\n            ":"\r\n            指向父 ERStat 的指针\r\n            \r\n","\r\n            Spatial Moment M21\r\n            ":"\r\n            空间时刻M21\r\n            \r\n","\r\n            Convert Bayer GR to BGRA \r\n            ":"\r\n            Bayer GR 转换成 BGRA\r\n            \r\n"," Create a framesource using the specific camera":" 使用特定相机创建帧源\r\n","The location of the bottom left corner of the font":"字体左下角的位置\r\n"," The dilated image":" 膨胀图像\r\n","Text file contains network configuration.":"文本文件包含网络配置。\r\n","\r\n            Fit an ellipse to the points collection\r\n            ":"\r\n            将椭圆拟合到点集合\r\n            \r\n","\r\n            Set automatically when a value of the feature is set by the user\r\n            ":"\r\n            当用户设置特征值时自动设置\r\n            \r\n","Source image. CV_8U , CV_16U , or CV_16S depth and 1 or 4 channels are supported. For a four-channel image, all channels are processed separately.":"源图像。支持 CV_8U 、 CV_16U 或 CV_16S 深度以及 1 或 4 个通道。对于四通道图像，所有通道都单独处理。\r\n","The image to sample from":"要从中采样的图像\r\n","\r\n            double\r\n            ":"\r\n            双倍的\r\n            \r\n","\r\n            Convert BGRA color to BGR565 color\r\n            ":"\r\n            将 BGRA 颜色转换为 BGR565 颜色\r\n            \r\n","  \r\n            unspecified type of sequence elements \r\n            ":"  \r\n            未指定类型的序列元素\r\n            \r\n","\r\n            Create a locally uniform comparison image descriptor.\r\n            ":"\r\n            创建一个局部统一的比较图像描述符。\r\n            \r\n","The mat":"垫子\r\n","\r\n            value of first kneepoint (% of sensor saturation)\r\n            ":"\r\n            第一个拐点的值（传感器饱和度的百分比）\r\n            \r\n","\r\n            Training method for ANN_MLP\r\n            ":"\r\n            ANN_MLP 的训练方法\r\n            \r\n","nr feeds":"天然饲料\r\n","The inverse covariation matrix":"逆协方差矩阵\r\n","Upper boundary value.":"上限值。\r\n","\r\n              distance = max(|x1-x2|,|y1-y2|) \r\n            ":"\r\n              距离 = 最大值（|x1-x2|,|y1-y2|）\r\n            \r\n","\r\n            CvMat signature (CV_MAT_MAGIC_VAL), element type and flags\r\n            ":"\r\n            CvMat 签名 (CV_MAT_MAGIC_VAL)、元素类型和标志\r\n            \r\n","The detected points":"检测点\r\n","\r\n            Camera input\r\n            ":"\r\n            相机输入\r\n            \r\n","On Windows, \"{0}\".dll will be returned; On Linux, \"lib{0}.so\" will be returned; Otherwise {0} is returned.":"在 Windows 上，将返回“{0}”.dll；在 Linux 上，将返回“lib{0}.so”；否则返回 {0}。\r\n","Flag to specify how many times the src is repeated along the vertical axis.":"用于指定 src 沿垂直轴重复多少次的标志。\r\n","An estimation of the number of elements in this storage":"估计此存储中的元素数量\r\n","\r\n            Get the amount of total memory\r\n            ":"\r\n            获取总内存量\r\n            \r\n","If no frames has been grabbed (there are no more frames in video file), the methods return false . ":"如果没有抓取帧（视频文件中不再有帧），则方法返回 false 。\r\n","If true, use Harris detector":"如果为真，则使用 Harris 检测器\r\n","A coefficient in adaptive threshold":"自适应阈值中的一个系数\r\n",". In-place operation is supported (":".支持就地操作（\r\n","vector of exposure time values for each image":"每个图像的曝光时间值向量\r\n","\r\n            Hershey script simplex\r\n            ":"\r\n            Hershey 脚本单纯形\r\n            \r\n","minRegionSizeI":"minRegionSizeI\r\n","Vector of keypoints":"关键点向量\r\n","\r\n            Builds the projection maps according to the given camera data.\r\n            ":"\r\n            根据给定的相机数据构建投影图。\r\n            \r\n","\r\n            Black threshold is a number between 0-255 that represents the minimum brightness difference required for valid pixels, between the fully illuminated (white) and the not illuminated images (black), used in computeShadowMasks method\r\n            ":"\r\n            黑色阈值是一个介于 0-255 之间的数字，表示有效像素所需的最小亮度差，在完全照明（白色）和未照明图像（黑色）之间，用于 computeShadowMasks 方法\r\n            \r\n","The second input feature of the same size and the same type as ":"相同大小和相同类型的第二个输入特征\r\n","\r\n            Dict4X4_100\r\n            ":"\r\n            词典4X4_100\r\n            \r\n","array header":"数组头\r\n","Name of the window which is used as window identifier and appears in the window caption":"用作窗口标识符并出现在窗口标题中的窗口名称\r\n","\r\n            Release the unmanaged memory associated with this Object\r\n            ":"\r\n            释放与此对象关联的非托管内存\r\n            \r\n","\r\n            Gaussian motion filter\r\n            ":"\r\n            高斯运动滤波器\r\n            \r\n","\r\n            Disparity map filter based on Weighted Least Squares filter (in form of Fast Global Smoother that is a lot faster than traditional Weighted Least Squares filter implementations) and optional use of left-right-consistency-based confidence to refine the results in half-occlusions and uniform areas.\r\n            ":"\r\n            基于加权最小二乘滤波器的视差图滤波器（以比传统加权最小二乘滤波器实现快得多的快速全局平滑器的形式）和可选使用基于左右一致性的置信度来改进半遮挡和均匀的区域。\r\n            \r\n","\r\n            Kernel Structure Content Error\r\n            ":"\r\n            内核结构内容错误\r\n            \r\n","\r\n            Front\r\n            ":"\r\n            正面\r\n            \r\n","The resolution of x (y), (e.g. a value of 0.5 means each cell in the map is 0.5 unit in x (y) dimension)":"x (y) 的分辨率（例如，值为 0.5 表示地图中的每个单元格在 x (y) 维度上为 0.5 个单位）\r\n","\r\n            Inverts an affine transformation\r\n            ":"\r\n            反转仿射变换\r\n            \r\n","The hash mode":"哈希模式\r\n","Property identifier.":"属性标识符。\r\n"," \r\n            An array of single channel GpuMat where each item\r\n            in the array represent a single channel of the GpuMat \r\n            ":" \r\n            单通道 GpuMat 数组，其中每个项目\r\n            数组中代表 GpuMat 的单个通道\r\n            \r\n","\r\n            Wrapped AGAST detector\r\n            ":"\r\n            包裹式 AGAST 检测器\r\n            \r\n","Array of the second image points of the same size and format as points1 ":"与 points1 具有相同大小和格式的第二个图像点的数组\r\n","True if the two MatND equals":"如果两个 MatND 相等则为真\r\n","Output array of the same size and type as src1":"与 src1 大小和类型相同的输出数组\r\n","\r\n            Create a CudaImage from the specific region of ":"\r\n            从特定区域创建一个 CudaImage\r\n","Number of applications of the scale factor (octaves)":"比例因子的应用次数（八度）\r\n","\r\n              distance = c^2/2(1-exp(-(x/c)^2)), c = 2.9846 \r\n            ":"\r\n              距离 = c^2/2(1-exp(-(x/c)^2)), c = 2.9846\r\n            \r\n","\r\n            Create a new classification model\r\n            ":"\r\n            创建新的分类模型\r\n            \r\n"," pixel\r\n            neighborhood, subtracted by param1. \r\n            For the method CV_ADAPTIVE_THRESH_GAUSSIAN_C it is a weighted sum (gaussian) of ":" 像素\r\n            邻域，减去 param1。\r\n            对于 CV_ADAPTIVE_THRESH_GAUSSIAN_C 方法，它是以下的加权和（高斯）\r\n","\r\n            Rotation estimator base class.\r\n            ":"\r\n            旋转估计器基类。\r\n            \r\n","\r\n            Create a generic EventArgs with the specific value\r\n            ":"\r\n            创建具有特定值的通用 EventArgs\r\n            \r\n","\r\n            Create gradient mapper for a translation\r\n            ":"\r\n            为翻译创建梯度映射器\r\n            \r\n","Resulting image of autoscaling.":"自动缩放的结果图像。\r\n","Optional number of iterations used for filtering, 3 is quite enough.":"用于过滤的可选迭代次数，3 就足够了。\r\n"," The inclusive upper limit of color value":" 颜色值的包含上限\r\n","\r\n            R(x,y)=sumx',y'[T(x',y')-I(x+x',y+y')]2\r\n            ":"\r\n            R(x,y)=sumx',y'[T(x',y')-I(x+x',y+y')]2\r\n            \r\n","\r\n            Maximum saturation for a pixel to be included in the gray-world assumption\r\n            ":"\r\n            要包含在灰色世界假设中的像素的最大饱和度\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this bundle adjuster\r\n            ":"\r\n            释放所有与这个 bundle adjuster 关联的非托管内存\r\n            \r\n","Number of linear system solver iterations":"线性系统求解器迭代次数\r\n","\r\n            Draw a planar board.\r\n            ":"\r\n            画一个平面板。\r\n            \r\n","Minimal number of matches for sample to be considered as foreground.":"被视为前景的样本的最小匹配数。\r\n","\r\n            BPROP: Strength of the momentum term (the difference between weights on the 2 previous iterations)\r\n            ":"\r\n            BPROP：动量项的强度（前两次迭代的权重之间的差异）\r\n            \r\n","Optional scale factor for the computed Laplacian values. By default, no scaling is applied.":"计算拉普拉斯值的可选比例因子。默认情况下，不应用缩放。\r\n","\r\n            The length\r\n            ":"\r\n            长度\r\n            \r\n","\r\n            OpenNI IR generator\r\n            ":"\r\n            OpenNI 红外发生器\r\n            \r\n","\r\n            Create a panini portrait warper\r\n            ":"\r\n            创建帕尼尼人像变形器\r\n            \r\n","Input array or vector of matrices. all of the matrices must have the same number of rows and the same depth.":"输入数组或矩阵向量。所有矩阵必须具有相同的行数和相同的深度。\r\n","Locations for the computation. Can be null if not needed":"计算的位置。如果不需要可以为空\r\n"," subsampled with the specific rate ":" 以特定比率二次抽样\r\n","\r\n            Sets a CUDA device and initializes it for the current thread with OpenGL interoperability.\r\n            This function should be explicitly called after OpenGL context creation and before any CUDA calls.\r\n            ":"\r\n            设置 CUDA 设备并使用 OpenGL 互操作性为当前线程初始化它。\r\n            这个函数应该在 OpenGL 上下文创建之后和任何 CUDA 调用之前显式调用。\r\n            \r\n","\r\n            Properties of cameras available through OpenNI interfaces, in mm.\r\n            ":"\r\n            通过 OpenNI 接口可用的相机属性，以毫米为单位。\r\n            \r\n","\r\n            Decodes QR code on a curved surface in image once it's found by the detect() method.\r\n            ":"\r\n            一旦通过 detect() 方法找到图像中曲面上的 QR 码，就对其进行解码。\r\n            \r\n","The umat where the new UMat header will share data from":"新 UMat 标头将从中共享数据的 umat\r\n","\r\n            When using a parameters object of this type the index created uses multi-probe LSH (by Multi-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search by Qin Lv, William Josephson, Zhe Wang, Moses Charikar, Kai Li., Proceedings of the 33rd International Conference on Very Large Data Bases (VLDB). Vienna, Austria. September 2007)\r\n            ":"\r\n            当使用这种类型的参数对象时，创建的索引使用多探针 LSH（作者：Multi-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search by Qin Lv, William Josephson, Zhe Wang, Moses Charikar, Kai Li., Proceedings of第 33 届超大型数据库国际会议 (VLDB)。奥地利维也纳。2007 年 9 月）\r\n            \r\n","\r\n            The number of radial bins in the shape context descriptor.\r\n            ":"\r\n            形状上下文描述符中的径向箱数。\r\n            \r\n","\r\n            Get the host data packets\r\n            ":"\r\n            获取主机数据包\r\n            \r\n","\r\n            Release the unmanaged memory associated with this ShapeTransformer object\r\n            ":"\r\n            释放与此 ShapeTransformer 对象关联的非托管内存\r\n            \r\n","\r\n            The vertical size of the bounding box.\r\n            ":"\r\n            边界框的垂直尺寸。\r\n            \r\n","Pointer to the user data. Matrix constructors that take data and step parameters do not allocate matrix data. Instead, they just initialize the matrix header that points to the specified data, which means that no data is copied. This operation is very efficient and can be used to process external data using OpenCV functions. The external data is not automatically deallocated, so you should take care of it.":"指向用户数据的指针。采用数据和步骤参数的矩阵构造函数不分配矩阵数据。相反，它们只是初始化指向指定数据的矩阵头，这意味着没有数据被复制。此操作非常高效，可用于使用 OpenCV 函数处理外部数据。外部数据不会自动释放，所以你应该照顾好它。\r\n","\r\n            Given a board configuration and a set of detected markers, returns the corresponding image points and object points to call solvePnP.\r\n            ":"\r\n            给定板配置和一组检测到的标记，返回相应的图像点和对象点以调用 solvePnP。\r\n            \r\n","The per-element maximum of two matrices of the same size, number of channels and depth":"相同大小、通道数和深度的两个矩阵的每个元素最大值\r\n","The return codes":"返回码\r\n","Layer with specified name which the network use.":"网络使用的具有指定名称的层。\r\n","\r\n            A Normal Bayes Classifier\r\n            ":"\r\n            普通贝叶斯分类器\r\n            \r\n","\r\n            Supper resolution\r\n            ":"\r\n            超级分辨率\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of Size.\r\n            ":"\r\n            大小的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            High level function to execute a single rapid iteration\r\n            ":"\r\n            执行单个快速迭代的高级函数\r\n            \r\n","\r\n            Sets a visual vocabulary.\r\n            ":"\r\n            设置视觉词汇。\r\n            \r\n","The inclusive lower boundary of valid values range. It is used only if CHECK_RANGE is set.":"有效值范围的下边界。只有在设置了 CHECK_RANGE 时才使用它。\r\n","An array of Size":"大小数组\r\n","\r\n            True if eeprom is loaded\r\n            ":"\r\n            如果加载了 eeprom，则为真\r\n            \r\n","\r\n            Both callback\r\n            ":"\r\n            两者回调\r\n            \r\n","\r\n            HandEyeCalibration Method\r\n            ":"\r\n            手眼校准方法\r\n            \r\n","\r\n            Convert YUV (YUYV) to Gray\r\n            ":"\r\n            将 YUV (YUYV) 转换为灰色\r\n            \r\n","\r\n            Convert YUV (YV12) to BGRA\r\n            ":"\r\n            将 YUV (YV12) 转换成 BGRA\r\n            \r\n","\r\n            FrameHeight\r\n            ":"\r\n            框架高度\r\n            \r\n","\r\n            Film current position in milliseconds or video capture timestamp\r\n            ":"\r\n            以毫秒为单位的电影当前位置或视频捕获时间戳\r\n            \r\n","\r\n            Minimum InterContour Distance\r\n            ":"\r\n            最小轮廓间距离\r\n            \r\n","\r\n            Returns full configuration time cmake output.\r\n            Returned value is raw cmake output including version control system revision, compiler version, compiler flags, enabled modules and third party libraries, etc.Output format depends on target architecture.\r\n            ":"\r\n            返回完整的配置时间 cmake 输出。\r\n            返回值是原始 cmake 输出，包括版本控制系统修订、编译器版本、编译器标志、启用的模块和第三方库等。输出格式取决于目标体系结构。\r\n            \r\n","\r\n            Class implementing edge detection algorithm from Piotr Dollar and C Lawrence Zitnick. Structured forests for fast edge detection. In Computer Vision (ICCV), 2013 IEEE International Conference on, pages 1841-1848. IEEE, 2013.\r\n            ":"\r\n            实现 Piotr Dollar 和 C Lawrence Zitnick 的边缘检测算法的类。用于快速边缘检测的结构化森林。在计算机视觉 (ICCV)，2013 年 IEEE 国际会议上，第 1841-1848 页。 IEEE，2013 年。\r\n            \r\n","Vector containing ROIs of motion connected components.":"包含运动连接组件的 ROI 的向量。\r\n"," The smoothed image":" 平滑后的图像\r\n","The first input map of type CV_16SC2 , CV_32FC1 , or CV_32FC2 .":"类型为 CV_16SC2 、 CV_32FC1 或 CV_32FC2 的第一个输入映射。\r\n","\r\n            VC1\r\n            ":"\r\n            VC1\r\n            \r\n","\r\n            Write point cloud to file\r\n            ":"\r\n            将点云写入文件\r\n            \r\n","\r\n            Create a median filter\r\n            ":"\r\n            创建一个中值过滤器\r\n            \r\n","Optional input 3x3 floating-point camera matrix ":"可选输入 3x3 浮点相机矩阵\r\n","\r\n            A (3x1) Rodrigues rotation vector. Rotation vector is a compact representation of rotation matrix. Direction of the rotation vector is the rotation axis and the length of the vector is the rotation angle around the axis. \r\n            ":"\r\n            一个 (3x1) 罗德里格斯旋转矢量。旋转向量是旋转矩阵的紧凑表示。旋转矢量的方向是旋转轴，矢量的长度是绕轴的旋转角度。\r\n            \r\n","\r\n            Read specific dataset from hdf5 file into Mat object.\r\n            ":"\r\n            将特定数据集从 hdf5 文件读入 Mat 对象。\r\n            \r\n","\r\n            Release the histogram cost extractor\r\n            ":"\r\n            发布直方图成本提取器\r\n            \r\n","\r\n            Bone\r\n            ":"\r\n            骨\r\n            \r\n","\r\n            Create the standard vector of VectorOfByte \r\n            ":"\r\n            创建 VectorOfByte 的标准向量\r\n            \r\n"," = (1-alpha)*":" = (1-alpha)*\r\n","parameter in the original article, it's similar to the sigma in the coordinate space into bilateralFilter.":"原文中的参数，类似于坐标空间中的sigma进入bilateralFilter。\r\n","input image to compute hash value":"输入图像计算哈希值\r\n","\r\n            Horizontal cells gain. Use 0.0 for default\r\n            ":"\r\n            水平细胞增益。默认使用 0.0\r\n            \r\n","An array of DMatch":"一组 DMatch\r\n","\r\n            Get the center of the region\r\n            ":"\r\n            获取区域中心\r\n            \r\n","\r\n            Finds the geometric transform (warp) between two images in terms of the ECC criterion\r\n            ":"\r\n            根据 ECC 标准找到两个图像之间的几何变换（扭曲）\r\n            \r\n","\r\n            If set, do not rotate the image according to EXIF's orientation flag.\r\n            ":"\r\n            如果设置，则不要根据 EXIF 的方向标志旋转图像。\r\n            \r\n","Output full row length in bytes":"以字节为单位输出完整的行长度\r\n","\r\n            Returns true if an image with the specified filename can be encoded by OpenCV.\r\n            ":"\r\n            如果具有指定文件名的图像可以由 OpenCV 编码，则返回 true。\r\n            \r\n","\r\n            True if the value is valid\r\n            ":"\r\n            如果值有效则为真\r\n            \r\n","\r\n            Creat a new Tree Based Morse Regions\r\n            ":"\r\n            创建一个新的基于树的莫尔斯区域\r\n            \r\n","\r\n            The length of line\r\n            ":"\r\n            线的长度\r\n            \r\n"," \r\n            Perform an binary OR operation with some value\r\n            ":" \r\n            对某个值执行二元或运算\r\n            \r\n","\r\n            Minimum Contour Solidity\r\n            ":"\r\n            最小轮廓坚固度\r\n            \r\n","\r\n            posteriori error estimate covariance matrix (P(k)): P(k)=(I-K(k)*H)*P'(k)\r\n            ":"\r\n            后验误差估计协方差矩阵(P(k))：P(k)=(I-K(k)*H)*P'(k)\r\n            \r\n","The model parameters":"模型参数\r\n","Resulting scalar for unary computation":"一元计算的结果标量\r\n","\r\n            Create a sparse matrix of the specific dimension\r\n            ":"\r\n            创建特定维度的稀疏矩阵\r\n            \r\n","\r\n            Scale the result: divide it by the number of array elements. Usually, it is combined with CV_DXT_INVERSE, and one may use a shortcut \r\n            ":"\r\n            缩放结果：将其除以数组元素的数量。通常，它与 CV_DXT_INVERSE 结合使用，可以使用快捷方式\r\n            \r\n","The indices.":"指数。\r\n","\r\n            Min Repeatability\r\n            ":"\r\n            最小重复性\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this exposure compensator \r\n            ":"\r\n            释放与此曝光补偿器关联的所有非托管内存\r\n            \r\n","Use Size.Empty for default":"默认使用 Size.Empty\r\n","Size of the output image.":"输出图像的大小。\r\n","\r\n            Alternative Chi-Square\r\n            ":"\r\n            替代卡方\r\n            \r\n","Number of rows in a 2D array.":"二维数组中的行数。\r\n","The second parameter controlling the disparity smoothness. It is the penalty on the disparity change by more than 1 between neighbor pixels. The algorithm requires ":"控制视差平滑度的第二个参数。它是对相邻像素之间视差变化超过 1 的惩罚。该算法要求\r\n","\r\n            Sets the image ROI to a given rectangle. If ROI is NULL and the value of the parameter rect is not equal to the whole image, ROI is allocated. \r\n            ":"\r\n            将图像 ROI 设置为给定的矩形。如果ROI为NULL且参数rect的值不等于整幅图像，则分配ROI。\r\n            \r\n"," Draw a Circle of the specific color and thickness ":" 画一个特定颜色和粗细的圆\r\n","\r\n            Create a mapper for euclidean motion\r\n            ":"\r\n            为欧氏运动创建映射器\r\n            \r\n","\r\n            Get the equivalent size for a tile of data as it would be returned in a call to TIFFReadTile or as it would be expected in a call to TIFFWriteTile. \r\n            ":"\r\n            获取与在调用 TIFFReadTile 中返回的数据或在调用 TIFFWriteTile 中预期的大小相同的数据块大小。\r\n            \r\n","The GpuMat to store the result":"存储结果的 GpuMat\r\n","\r\n            the depth of decision tree, defines the size of feature\r\n            ":"\r\n            决策树的深度，定义特征的大小\r\n            \r\n","Scalar value to be added.":"要添加的标量值。\r\n","\r\n            The resulting HDR image is calculated as weighted average of the exposures considering exposure values and camera response\r\n            ":"\r\n            考虑到曝光值和相机响应，生成的 HDR 图像计算为曝光的加权平均值\r\n            \r\n","\r\n            Get or Set if the captured image should be flipped horizontally\r\n            ":"\r\n            获取或设置捕获的图像是否应水平翻转\r\n            \r\n","\r\n            (read-only) Number of video channels\r\n            ":"\r\n            （只读）视频通道数\r\n            \r\n","Source array, image or matrix":"源数组、图像或矩阵\r\n","\r\n            Get the exterior angle between this line and ":"\r\n            得到这条线和之间的外角\r\n","\r\n            Exposure speed. Can be readonly, depends on camera program.\r\n            ":"\r\n            曝光速度。可以是只读的，取决于相机程序。\r\n            \r\n","\r\n            Rotation part extracted from the homogeneous matrix that transforms a point expressed in the target frame to the camera frame.\r\n            This is a vector (vector<Mat>) that contains the rotation matrices for all the transformations from calibration target frame to camera frame.\r\n            ":"\r\n            从齐次矩阵中提取的旋转部分，将目标帧中表示的点转换为相机帧。\r\n            这是一个向量 (vector<Mat>)，其中包含从校准目标帧到相机帧的所有转换的旋转矩阵。\r\n            \r\n","\r\n            Bad callback\r\n            ":"\r\n            错误回调\r\n            \r\n","Image height":"图片高度\r\n","\r\n            Erodes an image by using 3 by 3 rectangular structuring element.\r\n            ":"\r\n            使用 3 x 3 矩形结构元素侵蚀图像。\r\n            \r\n","\r\n            Do not require any specific H/W acceleration, prefer software processing.\r\n            ":"\r\n            不需要任何特定的硬件加速，更喜欢软件处理。\r\n            \r\n","Output 2D affine transformation (4 degrees of freedom) matrix 2×3 or empty matrix if transformation could not be estimated.":"如果无法估计变换，则输出 2D 仿射变换（4 个自由度）矩阵 2×3 或空矩阵。\r\n","\r\n            The rotation type\r\n            ":"\r\n            旋转型\r\n            \r\n","\r\n            The number of columns\r\n            ":"\r\n            列数\r\n            \r\n","\r\n            Creates the algorithm instance using selected distance function, similarity function and similarity function parameter.\r\n            ":"\r\n            使用选定的距离函数、相似度函数和相似度函数参数创建算法实例。\r\n            \r\n","The number of cols of the depth image normals will be computed on":"将计算深度图像法线的列数\r\n","\r\n            Create a normal Bayes classifier\r\n            ":"\r\n            创建普通贝叶斯分类器\r\n            \r\n","Source chessboard view. It must be an 8-bit grayscale or color image.":"源棋盘视图。它必须是 8 位灰度或彩色图像。\r\n","The CvArray to be uploaded to GpuMat":"要上传到 GpuMat 的 CvArray\r\n","\r\n            Computes a convolution (or cross-correlation) of two images.\r\n            ":"\r\n            计算两个图像的卷积（或互相关）。\r\n            \r\n","The 'minimal work' distance between two weighted point configurations.":"两个加权点配置之间的“最小工作”距离。\r\n","\r\n            Create an empty GpuMat \r\n            ":"\r\n            创建一个空的 GpuMat\r\n            \r\n","\r\n            Neither FILL_OUTLIERS nor CV_WRAP_INVERSE_MAP\r\n            ":"\r\n            既不是 FILL_OUTLIERS 也不是 CV_WRAP_INVERSE_MAP\r\n            \r\n","Orientation image.":"方向图像。\r\n","\r\n            DNN-based face detector\r\n            ":"\r\n            基于 DNN 的人脸检测器\r\n            \r\n","Specifies the output label image type, an important consideration based on the total number of labels or alternatively the total number of pixels in the source image":"指定输出标签图像类型，这是基于标签总数或源图像中像素总数的重要考虑因素\r\n"," src.depth() = CV_16U/CV_16S, ddepth = -1/CV_32F/CV_64F":"src.depth() = CV_16U/CV_16S, ddepth = -1/CV_32F/CV_64F\r\n","\r\n            Minimum area containing line\r\n            ":"\r\n            最小面积包含线\r\n            \r\n","The name of the assembly":"大会名称\r\n","The int from the node.":"来自节点的整数。\r\n","\r\n            Type of chessboard calibration\r\n            ":"\r\n            棋盘标定类型\r\n            \r\n","\r\n            Converts an image from NV12 (YUV420p) color space to RGB.\r\n            ":"\r\n            将图像从 NV12 (YUV420p) 颜色空间转换为 RGB。\r\n            \r\n","\r\n            Debounce time (x * 10us)\r\n            ":"\r\n            去抖时间 (x * 10us)\r\n            \r\n","\r\n            Computes hash of the input image\r\n            ":"\r\n            计算输入图像的哈希值\r\n            \r\n","\r\n            Gaussian Mixture-based Background/Foreground Segmentation Algorithm.\r\n            The class implements the following algorithm:\r\n            \"An improved adaptive background mixture model for real-time tracking with shadow detection\"\r\n            P. KadewTraKuPong and R. Bowden,\r\n            Proc. 2nd European Workshp on Advanced Video-Based Surveillance Systems, 2001.\"\r\n            ":"\r\n            基于高斯混合的背景/前景分割算法。\r\n            该类实现了以下算法：\r\n            “一种改进的自适应背景混合模型，用于带阴影检测的实时跟踪”\r\n            P. KadewTraKuPong 和 R. Bowden，\r\n            过程。第二届欧洲高级视频监控系统研讨会，2001 年。”\r\n            \r\n","\r\n            The NVIDIA optical flow hardware generates flow vectors at granularity gridSize, which can be queried via function getGridSize(). Upsampler() helper function converts the hardware-generated flow vectors to dense representation (1 flow vector for each pixel) using nearest neighbour upsampling method.\r\n            ":"\r\n            NVIDIA 光流硬件生成粒度为 gridSize 的流向量，可以通过函数 getGridSize() 查询。 Upsampler() 辅助函数使用最近邻上采样方法将硬件生成的流向量转换为密集表示（每个像素 1 个流向量）。\r\n            \r\n","Vector of ER’s retrieved from the ERFilter algorithm from each channel":"从每个通道的 ERFilter 算法中检索到的 ER 向量\r\n","\r\n            Copies scalar value to every selected element of the destination GpuMat:\r\n            arr(I)=value if mask(I)!=0\r\n            ":"\r\n            将标量值复制到目标 GpuMat 的每个选定元素：\r\n            arr(I)=值如果掩码(I)!=0\r\n            \r\n","\r\n            Perform an binary XOR operation with some color using a mask\r\n            ":"\r\n            使用掩码对某些颜色执行二进制 XOR 运算\r\n            \r\n","\r\n            A simple white balance algorithm that works by independently stretching each of the input image channels to the specified range. For increased robustness it ignores the top and bottom p% of pixel values.\r\n            ":"\r\n            一种简单的白平衡算法，通过将每个输入图像通道独立拉伸到指定范围来工作。为了提高鲁棒性，它忽略了像素值的顶部和底部 p%。\r\n            \r\n","\r\n            Given a set of 3d points in a depth image, compute the normals at each point.\r\n            ":"\r\n            给定深度图像中的一组 3d 点，计算每个点的法线。\r\n            \r\n","\r\n            The image2d max height\r\n            ":"\r\n            image2d 最大高度\r\n            \r\n","\r\n            A Constant-Space Belief Propagation Algorithm for Stereo Matching.\r\n            Qingxiong Yang, Liang Wang, Narendra Ahuja.\r\n            http://vision.ai.uiuc.edu/~qyang6/\r\n            ":"\r\n            一种用于立体匹配的恒定空间置信度传播算法。\r\n            Qingxiong Yang、Liang Wang、Narendra Ahuja。\r\n            http://vision.ai.uiuc.edu/~qyang6/\r\n            \r\n","weights Lr":"权重 Lr\r\n","Specify if non-maximum suppression should be used.":"指定是否应使用非最大抑制。\r\n"," The hue value for this color ( 0 < hue < 180 )  ":" 此颜色的色调值 ( 0 < hue < 180 )\r\n","\r\n            Create an OutputArray from an existing unmanaged outputArray pointer\r\n            ":"\r\n            从现有的非托管 outputArray 指针创建 OutputArray\r\n            \r\n","\r\n            InputArrayOfArrays\r\n            ":"\r\n            InputArrayOfArrays\r\n            \r\n","\r\n            get the number of classes\r\n            ":"\r\n            获取类数\r\n            \r\n","\r\n            Returns a GpuMat corresponding to the ith column of the GpuMat. The data is shared with the current GpuMat. \r\n            ":"\r\n            返回对应于 GpuMat 的第 i 列的 GpuMat。数据与当前的 GpuMat 共享。\r\n            \r\n","Float multiplier for B channel.":"B 通道的浮动乘数。\r\n","\r\n            To detect white (inverted) markers\r\n            ":"\r\n            检测白色（倒置）标记\r\n            \r\n","\r\n            Applies a perspective transformation to an image\r\n            ":"\r\n            对图像应用透视变换\r\n            \r\n","\r\n            Compute the image pyramid\r\n            ":"\r\n            计算图像金字塔\r\n            \r\n","The native device pointer":"本机设备指针\r\n","Optional argument, some implementations might also use the right view of the original stereo-pair.":"可选参数，一些实现也可能使用原始立体对的右视图。\r\n","\r\n            Release the unmanaged resource associate to the Detector\r\n            ":"\r\n            释放与检测器关联的非托管资源\r\n            \r\n","The sub-sampled data in this storage":"此存储中的子采样数据\r\n","\r\n            Create the standard vector of VectorOfInt \r\n            ":"\r\n            创建 VectorOfInt 的标准向量\r\n            \r\n","\r\n            Connected Components Algorithms Types\r\n            ":"\r\n            连通分量算法类型\r\n            \r\n","2D or N-dimensional matrix; currently matrices with more than 4 channels are not supported by the methods, use Mat::reshape as a possible workaround.":"二维或 N 维矩阵；目前，这些方法不支持具有 4 个以上通道的矩阵，使用 Mat::reshape 作为可能的解决方法。\r\n","\r\n            Get the default OclContext. Do not dispose this context.\r\n            ":"\r\n            获取默认的 OclContext。不要处理这个上下文。\r\n            \r\n","\r\n            Current backend (enum VideoCaptureAPIs). Read-only property\r\n            ":"\r\n            当前后端（枚举 VideoCaptureAPIs）。只读属性\r\n            \r\n","adjust the sampling window of detected keypoints to 64.0f (VGG sampling window) 6.25f is default and fits for KAZE, SURF detected keypoints window ratio 6.75f should be the scale for SIFT detected keypoints window ratio 5.00f should be the scale for AKAZE, MSD, AGAST, FAST, BRISK keypoints window ratio 0.75f should be the scale for ORB keypoints ratio":"将检测到的关键点的采样窗口调整为 64.0f（VGG 采样窗口）6.25f 是默认值，适合 KAZE，SURF 检测到的关键点窗口比率 6.75f 应该是 SIFT 检测到的关键点窗口比率的比例 5.00f 应该是 AKAZE 的比例， MSD、AGAST、FAST、BRISK 关键点窗口比率 0.75f 应该是 ORB 关键点比率的比例\r\n","\r\n            Save the FaceRecognizer to a file\r\n            ":"\r\n            将 FaceRecognizer 保存到文件\r\n            \r\n","\r\n            If true then surrogate splits will be built\r\n            ":"\r\n            如果为真，则将建立代理拆分\r\n            \r\n","More details about the algorithm can be found at: L. Guo, D. Xu, and Z. Qiang. Background subtraction using local svd binary pattern. In 2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pages 1159–1167, June 2016.":"有关该算法的更多详细信息，请访问：L. Guo、D. Xu 和 Z. Qiang。使用局部 svd 二进制模式的背景减法。 2016 年 IEEE 计算机视觉和模式识别研讨会 (CVPRW)，第 1159-1167 页，2016 年 6 月。\r\n","\r\n            Set input size for frame.\r\n            ":"\r\n            设置帧的输入大小。\r\n            \r\n","\r\n            The device major version number\r\n            ":"\r\n            设备主版本号\r\n            \r\n","\r\n            unweighted\r\n            ":"\r\n            未加权\r\n            \r\n","\r\n            Release the unmanaged memory associated with this TonemapMantiuk\r\n            ":"\r\n            释放与此 TonemapMantiuk 关联的非托管内存\r\n            \r\n","\r\n            Returns 1 for cameras that support cooling.\r\n            ":"\r\n            对于支持冷却的相机，返回 1。\r\n            \r\n","Windows function":"窗函数\r\n","\r\n            Finds the best match for each descriptor from a query set (asynchronous version).\r\n            ":"\r\n            从查询集中（异步版本）找到每个描述符的最佳匹配。\r\n            \r\n","\r\n            Skew coefficient (alpha) is set to zero and stay zero.\r\n            ":"\r\n            偏斜系数 (alpha) 设置为零并保持为零。\r\n            \r\n","Used to allow the first N1cc vectors to adapt over time to changing background.":"用于允许第一个 N1cc 向量随着时间的推移适应不断变化的背景。\r\n","\r\n            Calculates fundamental matrix using one of four methods listed above and returns the number of fundamental matrices found (1 or 3) and 0, if no matrix is found. \r\n            ":"\r\n            使用上面列出的四种方法之一计算基本矩阵并返回找到的基本矩阵的数量（1 或 3）和 0，如果没有找到矩阵。\r\n            \r\n","\r\n            Rectangle intersect type\r\n            ":"\r\n            矩形相交型\r\n            \r\n","\r\n            Allocates new array data if needed.\r\n            ":"\r\n            如果需要，分配新的数组数据。\r\n            \r\n","The backend":"后端\r\n","\r\n            Spatial Moment M00\r\n            ":"\r\n            空间矩M00\r\n            \r\n","The inclusive stating row to be extracted":"要提取的包含说明行\r\n","Name of the window to be destroyed":"要销毁的窗口的名称\r\n","Destination CudaImage, containing color of mapped points. Will have the same size and type as src.":"目标 CudaImage，包含映射点的颜色。将具有与 src 相同的大小和类型。\r\n","All the text in the image":"图片中的所有文字\r\n","The second point on the line segment":"线段上的第二个点\r\n","The rectification homography matrices for the first images":"第一幅图像的校正单应矩阵\r\n",") rows of the GpuMat. The data is shared with the current GpuMat. \r\n            ":") 行的 GpuMat。数据与当前的 GpuMat 共享。\r\n            \r\n","Destination array of the same size and type as src.":"与 src 具有相同大小和类型的目标数组。\r\n","One form three modes DTF_NC, DTF_RF and DTF_IC which corresponds to three modes for filtering 2D signals in the article.":"一种形式三种模式DTF_NC、DTF_RF和DTF_IC对应文中对二维信号进行滤波的三种模式。\r\n","\r\n            This class allows to create and manipulate comprehensive artificial neural networks.\r\n            ":"\r\n            此类允许创建和操作综合人工神经网络。\r\n            \r\n","The depth of this map":"这张地图的深度\r\n","\r\n            Returns the tracked objects, each object corresponds to one tracker algorithm.\r\n            ":"\r\n            返回被跟踪的对象，每个对象对应一种跟踪器算法。\r\n            \r\n","The main diagonal element of this matrix":"该矩阵的主对角线元素\r\n","Radius of the cone.":"圆锥的半径。\r\n"," neighborhood \r\n            ":" 邻里\r\n            \r\n","The decoding result: a CV_64F Mat at image resolution, storing the computed disparity map.":"解码结果：图像分辨率的 CV_64F Mat，存储计算的视差图。\r\n","\r\n            Cuda GpuMat\r\n            ":"\r\n            Cuda GpuMat\r\n            \r\n","\r\n            Convolve an image with the kernel.\r\n            ":"\r\n            将图像与内核进行卷积。\r\n            \r\n","The first parameter controlling the disparity smoothness. It is the penalty on the disparity change by plus or minus 1 between neighbor pixels. Reasonably good value is 8*number_of_image_channels*SADWindowSize*SADWindowSize. Use 0 for default":"控制视差平滑度的第一个参数。它是对相邻像素之间视差变化正负 1 的惩罚。相当好的值是 8*number_of_image_channels*SADWindowSize*SADWindowSize。默认使用 0\r\n","The mean.":"均值。\r\n","\r\n            PCA Type\r\n            ":"\r\n            主成分分析类型\r\n            \r\n","The id of the widget that will be removed.":"将被删除的小部件的 ID。\r\n","2xN array of feature points in the first image. It can be also a vector of feature points or two-channel matrix of size 1xN or Nx1":"第一张图像中的 2xN 特征点数组。它也可以是特征点向量或大小为 1xN 或 Nx1 的双通道矩阵\r\n","\r\n            Order 2 central moments to construct the covariance matrix\r\n            ":"\r\n            订购2个中心矩来构造协方差矩阵\r\n            \r\n","The plot text color":"情节文本颜色\r\n","\r\n            Compute quality score per channel with the per-channel score in each element of the result\r\n            ":"\r\n            使用结果的每个元素中的每个通道分数计算每个通道的质量分数\r\n            \r\n"," The index of the camera to create capture from, starting from 0":" 创建捕获的相机索引，从 0 开始\r\n","\r\n            L infinity\r\n            ":"\r\n            L无穷大\r\n            \r\n","\r\n            This class contains the functions for drawing a detected chart. \r\n            ":"\r\n            此类包含绘制检测图表的函数。\r\n            \r\n","The point on map":"地图上的点\r\n","\r\n            Peak signal to noise ratio (PSNR) algorithm\r\n            ":"\r\n            峰值信噪比 (PSNR) 算法\r\n            \r\n","\r\n            DeepFlow optical flow algorithm implementation.\r\n            ":"\r\n            DeepFlow光流算法实现。\r\n            \r\n","The managed image from the iplImage pointer":"来自 iplImage 指针的托管图像\r\n","\r\n            Left to right distance in cm\r\n            ":"\r\n            左右距离 cm\r\n            \r\n","Result of the convolution":"卷积的结果\r\n","Scalar factor.":"标量因子。\r\n","\r\n            Get the quaternions that represent a rotation of 0 degrees.\r\n            ":"\r\n            获取表示旋转 0 度的四元数。\r\n            \r\n","\r\n            YV12\r\n            ":"\r\n            YV12\r\n            \r\n","Path to origin model from Caffe framework contains single precision floating point weights (usually has .caffemodel extension).":"来自 Caffe 框架的源模型路径包含单精度浮点权重（通常具有 .caffemodel 扩展名）。\r\n","\r\n            Convert Luv color to sBGR color\r\n            ":"\r\n            将 Luv 颜色转换为 sBGR 颜色\r\n            \r\n","The connected components labeled image of boolean image":"布尔图像的连通分量标记图像\r\n","\r\n            Support Vector Machine \r\n            ":"\r\n            支持向量机\r\n            \r\n","\r\n            Finds the neighbors and predicts responses for input vectors.\r\n            ":"\r\n            查找邻居并预测输入向量的响应。\r\n            \r\n","Lower bound for T-values.":"T 值的下限。\r\n","Second compared histogram of the same size as H1 .":"第二个比较了与 H1 相同大小的直方图。\r\n","Destination array channels":"目标阵列通道\r\n","Input CvMat, IplImage , or CvMatND.":"输入 CvMat、IplImage 或 CvMatND。\r\n","True if the GPU module is targeted for the specific device version.":"如果 GPU 模块针对特定设备版本，则为真。\r\n","The second zero-based component of the element index ":"元素索引的第二个从零开始的组件\r\n","The ouput min and max locations":"输出最小和最大位置\r\n","\r\n            The intensity of the z color channel\r\n            ":"\r\n            z 颜色通道的强度\r\n            \r\n","\r\n            Get the color at the specific location of the image\r\n            ":"\r\n            获取图片特定位置的颜色\r\n            \r\n","3x3 fundamental matrix.":"3x3 基本矩阵。\r\n","Mask used to discard shadow regions.":"用于丢弃阴影区域的蒙版。\r\n","\r\n            Mapping\r\n            ":"\r\n            测绘\r\n            \r\n","\r\n            Tools for features 2D\r\n            ":"\r\n            二维特征工具\r\n            \r\n","\r\n            Convert BGRA color to BGR555 color\r\n            ":"\r\n            将 BGRA 颜色转换为 BGR555 颜色\r\n            \r\n","\r\n            Sets a property in the VideoWriter.\r\n            ":"\r\n            在 VideoWriter 中设置一个属性。\r\n            \r\n","Look-up table of 256 elements; in case of multi-channel input array, the table should either have a single channel (in this case the same table is used for all channels) or the same number of channels as in the input matrix.":"256个元素的查找表；在多通道输入数组的情况下，该表应具有单个通道（在这种情况下，同一个表用于所有通道）或与输入矩阵中的通道数相同。\r\n","\r\n            Base class for tonemapping algorithms - tools that are used to map HDR image to 8-bit range.\r\n            ":"\r\n            色调映射算法的基类 - 用于将 HDR 图像映射到 8 位范围的工具。\r\n            \r\n","See: Thomas Brox, Andres Bruhn, Nils Papenberg, and Joachim Weickert. High accuracy optical flow estimation based on a theory for warping. In Computer Vision-ECCV 2004, pages 25-36. Springer, 2004.":"参见：Thomas Brox、Andres Bruhn、Nils Papenberg 和 Joachim Weickert。基于翘曲理论的高精度光流估计。在 Computer Vision-ECCV 2004，第 25-36 页。施普林格，2004 年。\r\n","Destination image with the same type as src. The size is Size(src.cols+left+right, src.rows+top+bottom).":"与 src 类型相同的目标图像。尺寸为Size(src.cols+left+right, src.rows+top+bottom)。\r\n","\r\n            Object Not Found\r\n            ":"\r\n            找不到对象\r\n            \r\n","\r\n            Create an standard vector of VectorOfPoint of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfPoint 标准向量\r\n            \r\n","Contour defining second shape":"轮廓定义第二个形状\r\n","Expansion if bigger than one, compression if smaller than one":"大于一则展开，小于一则压缩\r\n","\r\n            The red color\r\n            ":"\r\n            红色\r\n            \r\n","\r\n            Converts input image from one color space to another. The function ignores colorModel and channelSeq fields of IplImage header, so the source image color space should be specified correctly (including order of the channels in case of RGB space, e.g. BGR means 24-bit format with B0 G0 R0 B1 G1 R1 ... layout, whereas RGB means 24-bit format with R0 G0 B0 R1 G1 B1 ... layout). \r\n            ":"\r\n            将输入图像从一种颜色空间转换为另一种颜色空间。该函数忽略 IplImage 标头的 colorModel 和 channelSeq 字段，因此应正确指定源图像颜色空间（包括 RGB 空间情况下的通道顺序，例如 BGR 表示 24 位格式 B0 G0 R0 B1 G1 R1 ...布局，而 RGB 表示具有 R0 G0 B0 R1 G1 B1 ... 布局的 24 位格式）。\r\n            \r\n","\r\n            Relaxation factor in SOR\r\n            ":"\r\n            SOR 中的松弛因子\r\n            \r\n","The rectangle to draw":"要绘制的矩形\r\n","video writer structure.":"视频编写器结构。\r\n","Mask matrix to detect only KeyLines of interest":"仅检测感兴趣的 KeyLines 的掩码矩阵\r\n","\r\n            Time\r\n            ":"\r\n            时间\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of VectorOfByte.\r\n            ":"\r\n            VectorOfByte 的 C++ 标准向量的包装类。\r\n            \r\n","The algorithm to use for selecting the initial centers when performing a k-means clustering step. The possible values are CENTERS_RANDOM (picks the initial cluster centers randomly), CENTERS_GONZALES (picks the initial centers using Gonzales’ algorithm) and CENTERS_KMEANSPP (picks the initial centers using the algorithm suggested in arthur_kmeanspp_2007 )":"执行 k-means 聚类步骤时用于选择初始中心的算法。可能的值是 CENTERS_RANDOM（随机选择初始聚类中心）、CENTERS_GONZALES（使用 Gonzales 算法选择初始中心）和 CENTERS_KMEANSPP（使用 arthur_kmeanspp_2007 中建议的算法选择初始中心）\r\n","Type of the line":"线路类型\r\n","\r\n            Convert the mat into Bitmap\r\n            ":"\r\n            将垫子转换为位图\r\n            \r\n","G-channel multiply factor. Multiplication factor is between .5 to 2.5.":"G 通道乘数。乘数在 0.5 到 2.5 之间。\r\n","th row (y direction) and ":"第 行（y 方向）和\r\n","\r\n            Mask is tiled\r\n            ":"\r\n            面具是平铺的\r\n            \r\n","parameter in the original article, it's similar to the sigma in the color space into bilateralFilter.":"原文中的参数，类似于颜色空间中的sigma进入bilateralFilter。\r\n","\r\n            Image hash based on block mean.\r\n            ":"\r\n            基于块均值的图像哈希。\r\n            \r\n","Scale Lr":"比例尺\r\n","\r\n            BRISK: Binary Robust Invariant Scalable Keypoints\r\n            ":"\r\n            BRISK：二进制稳健不变可扩展关键点\r\n            \r\n","\r\n            Class implementing the Harris-Laplace feature detector\r\n            ":"\r\n            实现 Harris-Laplace 特征检测器的类\r\n            \r\n","\r\n            Exposure time in microseconds\r\n            ":"\r\n            曝光时间（微秒）\r\n            \r\n","The avg color":"平均颜色\r\n","Path to directory with negative (background) images":"带有负片（背景）图像的目录路径\r\n","The observed point coordinates":"观测点坐标\r\n","The output array of four vertices of rectangles.":"矩形的四个顶点的输出数组。\r\n","\r\n            Create a convolution kernel using the specific floating point matrix and center\r\n            ":"\r\n            使用特定的浮点矩阵和中心创建卷积核\r\n            \r\n","\r\n            Sets pose of a widget in the window.\r\n            ":"\r\n            在窗口中设置小部件的姿势。\r\n            \r\n","\r\n            Get the 4 verticies of this Box.\r\n            ":"\r\n            获取此 Box 的 4 个顶点。\r\n            \r\n","Maximum allowed difference (in integer pixel units) in the left-right disparity check. Set it to a non-positive value to disable the check.":"左右差异检查中的最大允许差异（以整数像素为单位）。将其设置为非正值以禁用检查。\r\n","\r\n            Atop Premul\r\n            ":"\r\n            在 Premul 之上\r\n            \r\n","Output image size":"输出图像大小\r\n","\r\n            Create an instance of DIS optical flow algorithm.\r\n            ":"\r\n            创建 DIS 光流算法实例。\r\n            \r\n","Pointer to the resultant sub-array header.":"指向结果子数组头的指针。\r\n","\r\n            Whether to use mean-normalization of patches when computing patch distance. It is turned on by default as it typically provides a noticeable quality boost because of increased robustness to illumination variations. Turn it off if you are certain that your sequence doesn't contain any changes in illumination.\r\n            ":"\r\n            计算补丁距离时是否使用补丁的均值归一化。默认情况下它是打开的，因为它通常会提供明显的质量提升，因为它对照明变化的鲁棒性更强。如果您确定您的序列不包含任何照明变化，请将其关闭。\r\n            \r\n","\r\n            for RANSAC algorithm. N >= 8\r\n            ":"\r\n            对于 RANSAC 算法。 N >= 8\r\n            \r\n","See Ximgproc.EdgeAwareInterpolator() sigma value.":"请参见 Ximgproc.EdgeAwareInterpolator() 西格玛值。\r\n","Second input image of the same size and the same type as prevImg.":"与 prevImg 具有相同大小和相同类型的第二个输入图像。\r\n","Radius for boundary suppression.":"边界抑制的半径。\r\n","\r\n            Returns the mask of the superpixel segmentation stored in SuperpixelLSC object.\r\n            ":"\r\n            返回存储在 SuperpixelLSC 对象中的超像素分割的掩码。\r\n            \r\n","\r\n            Create a CudaBruteForceMatcher using the specific distance type\r\n            ":"\r\n            使用特定距离类型创建 CudaBruteForceMatcher\r\n            \r\n","Optional 3x3 rotation matrix around y-axis.":"围绕 y 轴的可选 3x3 旋转矩阵。\r\n","\r\n            Create a blank Image of the specific size\r\n            ":"\r\n            创建特定尺寸的空白图像\r\n            \r\n","\r\n            Simple one-line Guided Filter call.\r\n            ":"\r\n            简单的一行 Guided Filter 调用。\r\n            \r\n","\r\n            Convert YUV (YUY2) to RGBA\r\n            ":"\r\n            将 YUV (YUY2) 转换为 RGBA\r\n            \r\n","\r\n            L0_25\r\n            ":"\r\n            L0_25\r\n            \r\n","True if the GPU module is targeted for equal or less PTX version.":"如果 GPU 模块的目标是相同或更低的 PTX 版本，则为真。\r\n","Aperture size for the Sobel operator in Canny().":"Canny() 中 Sobel 算子的孔径大小。\r\n","The source matrix in the LHS":"LHS 中的源矩阵\r\n","\r\n            Use least squares criteria. This is default and the only option for LogitBoost and Gentle AdaBoost\r\n            ":"\r\n            使用最小二乘标准。这是默认值，也是 LogitBoost 和 Gentle AdaBoost 的唯一选项\r\n            \r\n","Termination criteria for the iterative optimization algorithm.":"迭代优化算法的终止标准。\r\n","\r\n            Calculates the rotation angle of 2D vectors.\r\n            ":"\r\n            计算二维向量的旋转角度。\r\n            \r\n","Output Vec<4f> contains start point and end point of detected lines.":"输出 Vec<4f> 包含检测线的起点和终点。\r\n","\r\n            Another threshold for the laplacian to eliminate edges.\r\n            The larger the threshold, the more points you get.\r\n            ":"\r\n            拉普拉斯算子消除边缘的另一个阈值。\r\n            阈值越大，获得的积分就越多。\r\n            \r\n","\r\n            Create a hfs object\r\n            ":"\r\n            创建一个 hfs 对象\r\n            \r\n","The initial color of the image":"图像的初始颜色\r\n","\r\n            Ok.\r\n            ":"\r\n            好的。\r\n            \r\n","If 0, signal the process to continue":"如果为 0，表示进程继续\r\n","\r\n            Convert Bayer GBRG to RGB (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 Bayer GBRG 转换为 RGB（边缘感知去马赛克）\r\n            \r\n","The managed array where data will be copied to.":"数据将复制到的托管数组。\r\n","Use a Stream to call the function asynchronously (non-blocking) or IntPtr.Zero to call the function synchronously (blocking).":"使用 Stream 异步调用函数（非阻塞）或使用 IntPtr.Zero 同步调用函数（阻塞）。\r\n","If true, the output angle is in degrees, otherwise in radian":"如果为真，则输出角度以度为单位，否则以弧度为单位\r\n","\r\n            DirectX 11\r\n            ":"\r\n            DirectX 11\r\n            \r\n","\r\n            Creates an instance of BackgroundSubtractorLSBP algorithm.\r\n            ":"\r\n            创建 BackgroundSubtractorLSBP 算法的实例。\r\n            \r\n","True if all the corners have been found and they have been placed in a certain order (row by row, left to right in every row), otherwise, if the function fails to find all the corners or reorder them, it returns 0":"如果已找到所有角点并且它们已按特定顺序放置（逐行，每行从左到右），则为真，否则，如果函数未能找到所有角点或重新排序，则返回 0\r\n","The value to be written to the file storage":"要写入文件存储的值\r\n","The recognized text is returned coded as UNLV format Latin-1 with specific reject and suspect codes":"识别的文本被编码为 UNLV 格式 Latin-1 并带有特定的拒绝和可疑代码\r\n","Output Vec<6d> contains center point and perimeter for circles.":"输出 Vec<6d> 包含圆的中心点和周长。\r\n","get difference between results of two successive steps of the minimization.":"获得最小化的两个连续步骤的结果之间的差异。\r\n","\r\n            OpenNI (for Asus Xtion)\r\n            ":"\r\n            OpenNI（用于华硕 Xtion）\r\n            \r\n","\r\n            The CCM with the shape 4×3 performs affine transformation.\r\n            ":"\r\n            形状为 4×3 的 CCM 进行仿射变换。\r\n            \r\n","end index":"结束索引\r\n","Flag which indicates whether image will be cropped after resize or not.":"指示在调整大小后是否裁剪图像的标志。\r\n","\r\n            -d(c_i, c_j)\r\n            ":"\r\n            -d(c_i, c_j)\r\n            \r\n","The type of Depth":"深度类型\r\n","the specific column span of the matrix":"矩阵的特定列跨度\r\n","How far from the boundary the points should be.":"这些点应该离边界多远。\r\n","\r\n            The color\r\n            ":"\r\n            颜色\r\n            \r\n","\r\n            Bad number of channels 1U\r\n            ":"\r\n            坏道数 1U\r\n            \r\n"," \r\n            Defines a Ycc color (YCrCb JPEG)\r\n            ":" \r\n            定义 Ycc 颜色 (YCrCb JPEG)\r\n            \r\n","\r\n            Board config\r\n            ":"\r\n            电路板配置\r\n            \r\n","\r\n            Cuda compute 2.0\r\n            ":"\r\n            Cuda计算2.0\r\n            \r\n","The source GpuMat, support depth of Int16 and float.":"源码GpuMat，支持Int16和float的深度。\r\n","Another dot-product operand":"另一个点积操作数\r\n","Note, that it is not necessary that every two neighbor connected components are separated by a watershed boundary (-1's pixels), for example, in case when such tangent components exist in the initial marker image. ":"注意，没有必要每两个相邻的连通分量都由分水岭边界（-1 的像素）分隔，例如，在初始标记图像中存在此类切线分量的情况下。\r\n","\r\n            The maximum allowed reprojection error to treat a point pair as an inlier. \r\n            The parameter is only used in RANSAC-based homography estimation. \r\n            E.g. if dst_points coordinates are measured in pixels with pixel-accurate precision, it makes sense to set this parameter somewhere in the range ~1..3\r\n            ":"\r\n            将点对视为内点的最大允许重投影误差。\r\n            该参数仅用于基于 RANSAC 的单应性估计。\r\n            例如。如果 dst_points 坐标是以像素为单位测量的，具有像素精确度，将此参数设置在 ~1..3 范围内的某处是有意义的\r\n            \r\n","\r\n            Convert YUV color to RGB\r\n            ":"\r\n            将 YUV 颜色转换为 RGB\r\n            \r\n","\r\n            Access type\r\n            ":"\r\n            接入类型\r\n            \r\n","the size of the frame":"框架的大小\r\n","The frame meta data":"帧元数据\r\n","\r\n            Apply a transformation, given a pre-estimated transformation parameters, to an Image.\r\n            ":"\r\n            给定一个预先估计的变换参数，将一个变换应用于图像。\r\n            \r\n","The k parameter for the graph segmentation":"图分割的 k 参数\r\n","\r\n            Creates one 3-channel matrix out of 3 single-channel ones.\r\n            ":"\r\n            从 3 个单通道矩阵中创建一个 3 通道矩阵。\r\n            \r\n","The output plot":"输出图\r\n","\r\n            Run just the LSTM line recognizer.\r\n            ":"\r\n            只运行 LSTM 线识别器。\r\n            \r\n","The equation coefficients, array of 3 or 4 elements":"方程系数，3 或 4 个元素的数组\r\n","\r\n            Class that contains entry points for the Barcode module.\r\n            ":"\r\n            包含条码模块入口点的类。\r\n            \r\n","\r\n            Supported optical flow performance levels.\r\n            ":"\r\n            支持的光流性能级别。\r\n            \r\n","The angle":"角度\r\n","\r\n            Create instance of WBDetector.\r\n            ":"\r\n            创建 WBDetector 实例。\r\n            \r\n","\r\n            Time step of the numerical scheme\r\n            ":"\r\n            数值方案的时间步长\r\n            \r\n","\r\n            Definition of distance used for calculating the distance between two face features\r\n            ":"\r\n            距离定义用于计算两个人脸特征之间的距离\r\n            \r\n","Filter sigma in the color space. A larger value of the parameter means that farther colors within the pixel neighborhood (see sigmaSpace ) will be mixed together, resulting in larger areas of semi-equal color.":"在颜色空间中过滤 sigma。较大的参数值意味着像素邻域内更远的颜色（请参阅 sigmaSpace ）将混合在一起，从而产生更大的半等色区域。\r\n"," Get or set the intensity of the hue color channel ( 0 < hue < 180 ) ":" 获取或设置色调颜色通道的强度 ( 0 < hue < 180 )\r\n","\r\n            Construct an instance of the cylindrical warper class.\r\n            ":"\r\n            构造圆柱形变形器类的实例。\r\n            \r\n","\r\n            Read a UMat from file.\r\n            ":"\r\n            从文件中读取 UMat。\r\n            \r\n","The comparison operator type":"比较运算符类型\r\n"," Threshold the image such that: dst(x,y) = 0, if src(x,y)>threshold;  max_value, otherwise ":" 对图像进行阈值处理：dst(x,y) = 0，如果 src(x,y)>threshold；最大值，否则\r\n","An array of polylines each represented by an array of points":"一组多段线，每条多段线由一组点表示\r\n","Input image: 8-bit unsigned 1-channel":"输入图像：8 位无符号 1 通道\r\n","The unmanaged pointer the the InputArray":"InputArray 的非托管指针\r\n","The other Range to compare with":"另一个要比较的范围\r\n"," \r\n            Perform an elementwise AND operation with another image, using a mask, and return the result\r\n            ":" \r\n            使用掩码对另一个图像执行元素与操作，并返回结果\r\n            \r\n","\r\n            Search parameters\r\n            ":"\r\n            搜索参数\r\n            \r\n","For more details about this implementation, please see ":"有关此实现的更多详细信息，请参阅\r\n","The nearest neighbor (may be an approximation, depends in the index type).":"最近邻（可能是近似值，取决于索引类型）。\r\n","Second input matrix of the same size and the same depth as src1.":"与 src1 大小和深度相同的第二个输入矩阵。\r\n","\r\n            Class containing the methods needed for Quasi Dense Stereo computation.\r\n            ":"\r\n            包含准密集立体计算所需方法的类。\r\n            \r\n","\r\n            DIS optical flow algorithm.\r\n            This class implements the Dense Inverse Search(DIS) optical flow algorithm.Includes three presets with preselected parameters to provide reasonable trade-off between speed and quality.However, even the slowest preset is still relatively fast, use DeepFlow if you need better quality and don't care about speed.\r\n            More details about the algorithm can be found at:\r\n            Till Kroeger, Radu Timofte, Dengxin Dai, and Luc Van Gool. Fast optical flow using dense inverse search. In Proceedings of the European Conference on Computer Vision (ECCV), 2016.\r\n            ":"\r\n            DIS 光流算法。\r\n            此类实现了密集逆向搜索 (DIS) 光流算法。包括三个具有预选参数的预设，以在速度和质量之间提供合理的权衡。但是，即使是最慢的预设仍然相对较快，如果您需要更好的质量和不关心速度。\r\n            有关该算法的更多详细信息，请访问：\r\n            Till Kroeger、Radu Timofte、Dengxin Dai 和 Luc Van Gool。使用密集逆向搜索的快速光流。在欧洲计算机视觉会议 (ECCV) 的会议记录中，2016 年。\r\n            \r\n","The color to be set":"要设置的颜色\r\n","The first coordinate":"第一个坐标\r\n","The exterior angle between this line and ":"这条线和之间的外角\r\n","Unlike many other new-style C++ functions in OpenCV, mixChannels requires the output arrays to be pre-allocated before calling the function.":"与 OpenCV 中的许多其他新型 C++ 函数不同，mixChannels 要求在调用函数之前预先分配输出数组。\r\n","Input/output lens distortion coefficients for the second camera. The parameter is similar to ":"第二台摄像机的输入/输出镜头畸变系数。该参数类似于\r\n","If shape of the new blob less than 0, then frame size not change.":"如果新斑点的形状小于 0，则帧大小不变。\r\n","\r\n            FMA\r\n            ":"\r\n            FMA\r\n            \r\n","\r\n            Conjugate the second argument of cvMulSpectrums\r\n            ":"\r\n            共轭 cvMulSpectrums 的第二个参数\r\n            \r\n"," \r\n            Threshold the image such that: dst(x,y) = max_value, if src(x,y)>threshold; 0, otherwise \r\n            ":" \r\n            对图像进行阈值处理：dst(x,y) = max_value，如果 src(x,y)>threshold； 0，否则\r\n            \r\n","This can be used to specify a white list for OCR. e.g. specify \"1234567890\" to recognize digits only. Note that the white list currently seems to only work with OcrEngineMode.OEM_TESSERACT_ONLY":"这可用于为 OCR 指定白名单。例如指定“1234567890”以仅识别数字。请注意，白名单目前似乎只适用于 OcrEngineMode.OEM_TESSERACT_ONLY\r\n","\r\n            Mono setting\r\n            ":"\r\n            单声道设置\r\n            \r\n","\r\n            Division by zero\r\n            ":"\r\n            被零除\r\n            \r\n","\r\n            An upwards pointing triangle marker shape\r\n            ":"\r\n            向上指向的三角形标记形状\r\n            \r\n","number of chessboard squares in Y direction":"Y方向棋盘格数\r\n"," The image of the same size":" 相同尺寸的图像\r\n","\r\n            Sequence flag\r\n            ":"\r\n            序列标志\r\n            \r\n","\r\n            Blurs an image using a Gaussian filter.\r\n            ":"\r\n            使用高斯滤波器模糊图像。\r\n            \r\n","The calculated fundamental matrix ":"计算出的基本矩阵\r\n","\r\n            Number of channels per element(pixel). Can be 1, 2, 3 or 4. The channels are interleaved, for example the usual data layout of a color image is:\r\n            b0 g0 r0 b1 g1 r1 ...\r\n            ":"\r\n            每个元素（像素）的通道数。可以是 1、2、3 或 4。通道是交错的，例如彩色图像的通常数据布局是：\r\n            b0 g0 r0 b1 g1 r1 ...\r\n            \r\n","The optional output vector of images containing rectified and binarized QR codes":"包含经过调整和二值化的 QR 码的图像的可选输出向量\r\n","The source CudaImage where the filter will be applied to":"将应用过滤器的源 CudaImage\r\n","Algorithm type":"算法类型\r\n","Output vector (e.g. cv::Mat) corresponding to the translation vector of the board.":"输出向量（例如 cv::Mat）对应于棋盘的平移向量。\r\n","\r\n            Orientation of the keypoint\r\n            ":"\r\n            关键点的方向\r\n            \r\n","the output image depth (-1 to use src.depth())":"输出图像深度（-1 使用 src.depth()）\r\n","3x3 Rectification transforms (rotation matrices) for the second camera":"第二台摄像机的 3x3 校正变换（旋转矩阵）\r\n","\r\n            Get or set the intensity of the Cr color channel\r\n            ":"\r\n            获取或设置 Cr 颜色通道的强度\r\n            \r\n","Horizontal":"水平的\r\n","\r\n            Monochrome transfer\r\n            ":"\r\n            单色转印\r\n            \r\n","Center initialization method":"中心初始化方法\r\n"," Perform Gaussian Smoothing inplace for the current image ":" 对当前图像执行高斯平滑\r\n","\r\n            Element wise subtract value from the current mat\r\n            ":"\r\n            从当前垫中逐元素减去值\r\n            \r\n","An optional mean subtraction values.":"一个可选的平均减法值。\r\n","\r\n            Convert BayerGB to BGR (Edge-Aware Demosaicing)\r\n            ":"将 BayerGB 转换为 BGR（边缘感知去马赛克）\r\n            \r\n","\r\n            JPEG\r\n            ":"\r\n            JPEG格式\r\n            \r\n","\r\n            Get the number of dimensions\r\n            ":"\r\n            获取维数\r\n            \r\n","\r\n            Mat\r\n            ":"垫\r\n            \r\n","Reference image of the same size and the same type as input image.":"与输入图像大小和类型相同的参考图像。\r\n","\r\n            Retrieve the next frame from the FrameSource\r\n            ":"\r\n            从 FrameSource 检索下一帧\r\n            \r\n","The estimated size fo the uncompress data. Must be large enough to hold the decompressed data.":"解压缩数据的估计大小。必须足够大以容纳解压缩的数据。\r\n","In second. Any change happens between a time interval greater than this will not be considered":"在第二。在大于此时间间隔之间发生的任何更改都不会被考虑\r\n","The type to search from":"要搜索的类型\r\n","The point to be converted":"要转换的点\r\n","Number of used nearest neighbors. Should be greater than 1.":"使用的最近邻居的数量。应该大于 1。\r\n","The resulting GpuMat, as input it should be an empty GpuMat.":"作为输入的生成的 GpuMat 应该是一个空的 GpuMat。\r\n","Input bgr or grayscale image.":"输入 bgr 或灰度图像。\r\n","The exclusive upper boundary of valid values range. It is used only if CHECK_RANGE is set.":"有效值范围的唯一上限。只有在设置了 CHECK_RANGE 时才使用它。\r\n","The number of countours":"国家的数量\r\n","The other color to compare with":"要比较的其他颜色\r\n","\r\n            Release all the unmanaged resource associated with FREAK\r\n            ":"\r\n            释放所有与 FREAK 关联的非托管资源\r\n            \r\n","The foregroundMask":"前景遮罩\r\n","Allow to set markers on the patterns.":"允许在图案上设置标记。\r\n","compression learning rate":"压缩学习率\r\n","\r\n            Convert the standard vector to arrays of arrays of MCvPoint3D32f\r\n            ":"\r\n            将标准向量转换为 MCvPoint3D32f 数组的数组\r\n            \r\n","\r\n            Create an standard vector of VectorOfRect of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfRect 标准向量\r\n            \r\n","\r\n            Clockwise\r\n            ":"\r\n            顺时针\r\n            \r\n","\r\n            Distance\r\n            ":"\r\n            距离\r\n            \r\n","\r\n            Override EXR storage type (FLOAT (FP32) is default)\r\n            ":"\r\n            覆盖 EXR 存储类型（默认为 FLOAT (FP32)）\r\n            \r\n","\r\n            Detects edges and prepares them to detect lines and ellipses.\r\n            ":"\r\n            检测边缘并准备它们检测直线和椭圆。\r\n            \r\n","image input/output image. It must have 1 or 3 channels. The number of channels is not altered.":"图像输入/输出图像。它必须有 1 或 3 个通道。通道数没有改变。\r\n","\r\n            Correction of bad pixels\r\n            ":"\r\n            修正坏点\r\n            \r\n","\r\n            Median filter kernel size (1 = no filter) (3 or 5)\r\n            ":"\r\n            中值滤波器内核大小（1 = 无滤波器）（3 或 5）\r\n            \r\n","Second input matrix to be considered for vertical concatenation.":"要考虑垂直串联的第二个输入矩阵。\r\n","\r\n            Pointer to the native QualityBase object\r\n            ":"\r\n            指向本机 QualityBase 对象的指针\r\n            \r\n","Vector of 2D points for which the flow needs to be found.":"需要为其找到流的二维点的向量。\r\n","\r\n            OpenCL kernel arg\r\n            ":"\r\n            OpenCL 内核参数\r\n            \r\n","Pointer to an array of PointF, Coordinates of 3 triangle vertices in the source image.":"指向 PointF 数组的指针，源图像中 3 个三角形顶点的坐标。\r\n","\r\n            Create a Gaussian filter.\r\n            ":"\r\n            创建一个高斯滤波器。\r\n            \r\n","\r\n            Summation over a pixel param1 x param2 neighborhood. If scale is true, the result is subsequent scaled by 1/(param1 x param2)\r\n            ":"\r\n            对像素 param1 x param2 邻域求和。如果 scale 为真，则结果随后按 1/(param1 x param2) 缩放\r\n            \r\n","The initial guess for the map":"地图的初始猜测\r\n","A point2 on the axis of the cylinder.":"圆柱轴上的点 2。\r\n","\r\n            The inteface for writing a Mat into a file.\r\n            ":"\r\n            将 Mat 写入文件的接口。\r\n            \r\n","\r\n            Get the pixels list. \r\n            ":"\r\n            获取像素列表。\r\n            \r\n","The currently observed element":"当前观察到的元素\r\n","The computed flow image for y-velocity; will have the same size as prevImg":"y 速度的计算流图像；将具有与 prevImg 相同的大小\r\n","y coordinate of first point (r1, s1) in the transformation function.":"变换函数中第一个点 (r1, s1) 的 y 坐标。\r\n","\r\n            Returns true if there are no train descriptors in the both collections.\r\n            ":"\r\n            如果两个集合中都没有火车描述符，则返回 true。\r\n            \r\n","The camera matrix (A) [fx 0 cx; 0 fy cy; 0 0 1].":"相机矩阵 (A) [fx 0 cx; 0 个周期； 0 0 1]。\r\n","\r\n            Sample aspect ratio: num/den (num)\r\n            ":"\r\n            样本纵横比：num/den(num)\r\n            \r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are greater compare to the scalar value.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否大于标量值。\r\n            \r\n","The block size":"区块大小\r\n","Polyline color":"折线颜色\r\n","win det size, use (64, 128) for default":"win det 大小，默认使用 (64, 128)\r\n","\r\n            for 8-point algorithm. N >= 8\r\n            ":"\r\n            对于8点算法。 N >= 8\r\n            \r\n","\r\n            Parameter for KDTree implementation\r\n            ":"\r\n            KDTree 实现的参数\r\n            \r\n","It has a type of CV_32FC1 and the same size with src1.":"它的类型为 CV_32FC1，大小与 src1 相同。\r\n","First 8-bit single-channel input image.":"第一个 8 位单通道输入图像。\r\n","\r\n            Shift map\r\n            ":"\r\n            换挡图\r\n            \r\n","The value to be subtracted":"要减去的值\r\n","\r\n            Calculates the absolute L2 norm of a matrix.\r\n            ":"\r\n            计算矩阵的绝对 L2 范数。\r\n            \r\n",") columns of the CudaImage":") CudaImage 的列\r\n","\r\n            True if the matrix is empty\r\n            ":"\r\n            如果矩阵为空则为真\r\n            \r\n","The plot line color":"情节线颜色\r\n","\r\n            Copy a jagged two dimensional array to the unmanaged memory\r\n            ":"\r\n            将锯齿状二维数组复制到非托管内存\r\n            \r\n","\r\n            Device output data bit depth.\r\n            ":"\r\n            设备输出数据位深度。\r\n            \r\n","\r\n            Set the plot size\r\n            ":"\r\n            设置绘图大小\r\n            \r\n","\r\n            Contour retrieval mode\r\n            ":"\r\n            轮廓检索模式\r\n            \r\n","Second input matrix":"第二个输入矩阵\r\n","\r\n            Convert the standard vector to an array of Point\r\n            ":"\r\n            将标准向量转换为 Point 数组\r\n            \r\n","The destination mat":"目的地垫\r\n","\r\n            The default type\r\n            ":"默认类型\r\n            \r\n","\r\n            Compares two histograms.\r\n            ":"\r\n            比较两个直方图。\r\n            \r\n","\r\n            For JPEG2000, use to specify the target compression rate (multiplied by 1000). The value can be from 0 to 1000. Default is 1000.\r\n            ":"\r\n            对于 JPEG2000，用于指定目标压缩率（乘以 1000）。该值可以从 0 到 1000。默认值为 1000。\r\n            \r\n","\r\n              L1-L2 metric: distance = 2(sqrt(1+x*x/2) - 1)) \r\n            ":"\r\n              L1-L2 指标：距离 = 2(sqrt(1+x*x/2) - 1))\r\n            \r\n","\r\n            Construct an instance of the spherical warper class.\r\n            ":"\r\n            构造球形变形器类的实例。\r\n            \r\n","\r\n            Takes image on input and returns the selected regions in a vector of ERStat only distinctive ERs which correspond to characters are selected by a sequential classifier\r\n            ":"\r\n            在输入上获取图像并返回 ERStat 向量中的选定区域，只有与字符相对应的独特 ER 由顺序分类器选择\r\n            \r\n","\r\n            Type of circles grid calibration\r\n            ":"\r\n            圆网格校准类型\r\n            \r\n","\r\n            Connected components algorithm output formats\r\n            ":"连通分量算法输出格式\r\n            \r\n","\r\n            The default Exception callback to handle Error thrown by OpenCV\r\n            ":"\r\n            处理 OpenCV 抛出的错误的默认异常回调\r\n            \r\n","The model descriptors":"模型描述符\r\n","The input/output vectors of distortion coefficients for each camera, 4x1, 1x4, 5x1 or 1x5":"每个摄像机的失真系数的输入/输出向量，4x1、1x4、5x1 或 1x5\r\n","\r\n            Initializes a new instance of the CudaOpticalFlowDualTvl1 class.\r\n            ":"\r\n            初始化 CudaOpticalFlowDualTvl1 类的新实例。\r\n            \r\n","\r\n            Computes element-wise quotient of the two GpuMat (c = scale *  a / b).\r\n            ":"\r\n            计算两个 GpuMat 的逐元素商（c = scale * a / b）。\r\n            \r\n","\r\n            Get the pointer to the Feature2D object\r\n            ":"\r\n            获取指向 Feature2D 对象的指针\r\n            \r\n","The rectification homography matrices for the second images":"第二幅图像的校正单应矩阵\r\n","\r\n            Multiply the current Quaternions with ":"\r\n            将当前四元数乘以\r\n","The decompressed data":"解压后的数据\r\n","A GpuMat of different shape":"不同形状的 GpuMat\r\n","\r\n            Performs matrix transformation of every element of array src and stores the results in dst\r\n            Both source and destination arrays should have the same depth and the same size or selected ROI size. transmat and shiftvec should be real floating-point matrices.\r\n            ":"\r\n            对数组 src 的每个元素进行矩阵变换，并将结果存储在 dst 中\r\n            源和目标阵列应具有相同的深度和相同的大小或选定的 ROI 大小。 transmat 和 shiftvec 应该是真正的浮点矩阵。\r\n            \r\n","The origin of the data":"数据的来源\r\n","\r\n            Return the matrix without a specified row span of the input array\r\n            ":"\r\n            返回输入数组没有指定行跨度的矩阵\r\n            \r\n","The source three-channel floating-point array":"源三通道浮点数组\r\n","The higher threshold of the two passed to Canny edge detector (the lower one is twice smaller).":"两者中较高的阈值传递给 Canny 边缘检测器（较低的阈值小两倍）。\r\n","\r\n            Class that contains entry points for the Quality module.\r\n            ":"\r\n            包含质量模块入口点的类。\r\n            \r\n","\r\n            This class is used to track multiple objects using the specified tracker algorithm. The MultiTracker is naive implementation of multiple object tracking. It process the tracked objects independently without any optimization accross the tracked objects.\r\n            ":"\r\n            此类用于使用指定的跟踪器算法跟踪多个对象。 MultiTracker 是多目标跟踪的简单实现。它独立地处理被跟踪的对象，而不对被跟踪的对象进行任何优化。\r\n            \r\n","The Y component of the vector: rotation axis * sin(rotation angle / 2)":"矢量的Y分量：旋转轴*sin(旋转角度/2)\r\n","\r\n            Fisheye calibration flag.\r\n            ":"\r\n            鱼眼校准标志。\r\n            \r\n","An ellipse":"一个椭圆\r\n","Matches":"火柴\r\n","\r\n            Horizontal binning factor\r\n            ":"\r\n            水平合并因子\r\n            \r\n","Motion history image.":"运动历史图像。\r\n","The second map of y values having the type CV_16UC1 , CV_32FC1 , or none (empty map if map1 is (x,y) points), respectively.":"y 值的第二个映射分别具有 CV_16UC1 、 CV_32FC1 或无类型（如果 map1 是 (x,y) 点，则为空映射）。\r\n","\r\n            Inference Engine NN Builder 2019\r\n            ":"\r\n            推理引擎 NN Builder 2019\r\n            \r\n","\r\n            Mode for composing scans. Expects images under affine transformation does not compensate exposure by default.\r\n            ":"\r\n            组合扫描的模式。期望仿射变换下的图像默认不补偿曝光。\r\n            \r\n","The output matrix of eigenvectors, stored as subsequent rows":"特征向量的输出矩阵，存储为后续行\r\n","Accumulator threshold parameter. Only those lines are returned that get enough votes (> threshold).":"累加器阈值参数。仅返回获得足够票数（> 阈值）的那些行。\r\n","The feature detector. Use a SimpleBlobDetector for default":"特征检测器。默认使用 SimpleBlobDetector\r\n","the written frame":"书面框架\r\n","Source array of 8-bit elements":"8 位元素的源数组\r\n","The height":"高度\r\n","The minimum distance":"最小距离\r\n","\r\n            Create an standard vector of Float of the specific size\r\n            ":"\r\n            创建特定大小的 Float 标准向量\r\n            \r\n","\r\n            Min X\r\n            ":"\r\n            闵晓\r\n            \r\n","\r\n            texture threshold\r\n            ":"\r\n            纹理阈值\r\n            \r\n","\r\n            Blob color\r\n            ":"\r\n            斑点颜色\r\n            \r\n","length of the painted axis in the same unit than tvec (usually in meters)":"绘制轴的长度与 tvec 相同的单位（通常以米为单位）\r\n","\r\n            The CNNHostPipeline\r\n            ":"\r\n            CNN主机管道\r\n            \r\n","The device id":"设备编号\r\n","Affinity sensitivity.":"亲和敏感性。\r\n","\r\n            A collection of reflection function that can be applied to IImage object\r\n            ":"\r\n            可应用于 IImage 对象的反射函数集合\r\n            \r\n","\r\n            Attribute used to specify color information\r\n            ":"\r\n            用于指定颜色信息的属性\r\n            \r\n","The output mask of motion components":"运动组件的输出掩码\r\n","Key points detected in the input image.":"在输入图像中检测到的关键点。\r\n","Destination color type":"目标颜色类型\r\n","Radius":"半径\r\n","An array of ColorPoint":"ColorPoint 数组\r\n","Gaussian or linear.":"高斯或线性。\r\n","\r\n            The class is used to iterate over all the pixels on the raster line segment connecting two specified points.\r\n            ":"\r\n            该类用于迭代连接两个指定点的栅格线段上的所有像素。\r\n            \r\n","Take scale transformation into account.":"考虑尺度变换。\r\n","\r\n            Release all the unmanaged memory associate with this TextDetector\r\n            ":"\r\n            释放与此 TextDetector 关联的所有非托管内存\r\n            \r\n","\r\n            True if rgb connected\r\n            ":"\r\n            如果 rgb 连接则为真\r\n            \r\n","Declare amount of rows":"声明行数\r\n","\r\n            Constructor. In the case of trackerType is given, it will be set as the default algorithm for all trackers.\r\n            ":"\r\n            构造函数。在给定 trackerType 的情况下，它将被设置为所有跟踪器的默认算法。\r\n            \r\n","Arrays of arrays of the Rectangle":"矩形数组的数组\r\n","\r\n            Convert RGB color to HLS color\r\n            ":"\r\n            将 RGB 颜色转换为 HLS 颜色\r\n            \r\n","The dot-product of two vectors.":"两个向量的点积。\r\n","\r\n            The image 2d max width\r\n            ":"\r\n            图像 2d 最大宽度\r\n            \r\n","\r\n            This class represents high-level API for text detection DL networks compatible with DB model. \r\n            ":"\r\n            此类表示与 DB 模型兼容的文本检测 DL 网络的高级 API。\r\n            \r\n","3x3 Rectification transforms (rotation matrices) for the first camera":"第一个相机的 3x3 校正变换（旋转矩阵）\r\n","\r\n            Release the unmanaged memory associated with this WCoordinateSysyem object\r\n            ":"\r\n            释放与此 WCoordinateSysyem 对象关联的非托管内存\r\n            \r\n","The operation flags, CHECK_NAN_INFINITY or combination of\r\n            CHECK_RANGE - if set, the function checks that every value of array is within [minVal,maxVal) range, otherwise it just checks that every element is neither NaN nor Infinity.\r\n            CHECK_QUIET - if set, the function does not raises an error if an element is invalid or out of range \r\n            ":"操作标志，CHECK_NAN_INFINITY 或组合\r\n            CHECK_RANGE - 如果设置，该函数检查数组的每个值是否在 [minVal,maxVal) 范围内，否则它只检查每个元素既不是 NaN 也不是 Infinity。\r\n            CHECK_QUIET - 如果设置，该函数不会在元素无效或超出范围时引发错误\r\n            \r\n","Filter sigma in the coordinate space. A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough (see sigmaColor ). When d>0, it specifies the neighborhood size regardless of sigmaSpace. Otherwise, d is proportional to sigmaSpace.":"在坐标空间中过滤 sigma。较大的参数值意味着更远的像素将相互影响，只要它们的颜色足够接近（参见 sigmaColor ）。当 d>0 时，它指定邻域大小而不管 sigmaSpace。否则，d 与 sigmaSpace 成正比。\r\n","\r\n            Constructor used to deserialize 3D rotation vector\r\n            ":"\r\n            用于反序列化 3D 旋转向量的构造函数\r\n            \r\n","A set of trained models names. If it's empty then the name of each model will be constructed from the name of file containing the model. E.g. the model stored in \"/home/user/cat.xml\" will get the name \"cat\".":"一组经过训练的模型名称。如果它为空，那么每个模型的名称将从包含该模型的文件的名称构造。例如。存储在“/home/user/cat.xml”中的模型将获得名称“cat”。\r\n","\r\n            A solid resembling a cube, with the rectangular faces not all equal; a rectangular parallelepiped.\r\n            ":"\r\n            类似于立方体的实体，其矩形面不均等；一个长方体\r\n            \r\n","The output Hu moments. e.g. a Mat can be passed here.":"输出胡瞬间。例如垫子可以在这里传递。\r\n","\r\n            Get the area of this triangle\r\n            ":"\r\n            得到这个三角形的面积\r\n            \r\n"," Perform an element wise OR operation with another mat and return the result":" 与另一个垫执行元素明智的或操作并返回结果\r\n","Image data of the destination frame (CV_8UC1)":"目标帧的图像数据 (CV_8UC1)\r\n","Represent region of interest of the detected faces. Each face is stored in cv::Rect container.":"表示检测到的人脸的感兴趣区域。每张脸都存储在 cv::Rect 容器中。\r\n","\r\n            Hershey complex small\r\n            ":"\r\n            好时复小\r\n            \r\n","The source (input) image.":"源（输入）图像。\r\n","\r\n            Compute the saliency.\r\n            ":"\r\n            计算显着性。\r\n            \r\n","The homography matrix, if it cannot be found, null is returned":"单应矩阵，如果找不到则返回null\r\n","The result of median smooth":"中位数平滑的结果\r\n","The output Hu moments.":"输出胡瞬间。\r\n","\r\n            Create a hdf5 group with default properties. The group is closed automatically after creation.\r\n            ":"\r\n            创建具有默认属性的 hdf5 组。群组创建后自动关闭。\r\n            \r\n","True if the specified image can be decoded by OpenCV.":"如果 OpenCV 可以解码指定的图像，则为真。\r\n","\r\n            The types that can be used\r\n            ":"\r\n            可以使用的类型\r\n            \r\n","Input vector of distortion coefficients (k1,k2,k3,k4).":"失真系数的输入向量 (k1,k2,k3,k4)。\r\n","\r\n            Create a Cuda template matching filter\r\n            ":"\r\n            创建一个 Cuda 模板匹配过滤器\r\n            \r\n","An array of PointF":"PointF 数组\r\n","\r\n            Get the dimension of the color type\r\n            ":"\r\n            获取颜色类型的维度\r\n            \r\n","\r\n            Create an standard vector of GMat with the initial values\r\n            ":"\r\n            使用初始值创建 GMat 的标准向量\r\n            \r\n","\r\n            Release the unmanaged resource associated with this GridBoard\r\n            ":"释放与此 GridBoard 关联的非托管资源\r\n            \r\n","The GpuMat to be copied from":"要从中复制的 GpuMat\r\n","The features finder":"功能查找器\r\n"," regulates update speed (how fast accumulator forgets about previous frames). \r\n            ":" 调节更新速度（累加器忘记先前帧的速度）。\r\n            \r\n","The color type of the source image":"源图像的颜色类型\r\n","chessboard square side length (normally in meters)":"棋盘正方形的边长（通常以米为单位）\r\n","The parent GpuMat should never be released before the returned GpuMat the represent the subregion":"在返回的代表子区域的 GpuMat 之前，不应释放父 GpuMat\r\n","Aperture parameter for the Sobel operator.":"Sobel 算子的孔径参数。\r\n","The input 8-bit 3-channel image":"输入的8位3通道图像\r\n","Float multiplier for R channel.":"R 通道的浮动乘数。\r\n","\r\n            Using kd tree\r\n            ":"\r\n            使用 kd 树\r\n            \r\n","\r\n            Selects camera signaling LED\r\n            ":"\r\n            选择相机信号 LED\r\n            \r\n","\r\n            Apply the filter to the disparity image\r\n            ":"\r\n            将过滤器应用于视差图像\r\n            \r\n","\r\n            Number of taps\r\n            ":"\r\n            抽头数\r\n            \r\n"," Elementwise add another image with the current image ":" Elementwise 使用当前图像添加另一个图像\r\n","The all-white images needed for shadowMasks computation.":"shadowMasks 计算所需的全白图像。\r\n","The matrix that contains the same values as this GpuMat":"包含与此 GpuMat 相同值的矩阵\r\n","\r\n            The size of MCvPoint3D32f\r\n            ":"\r\n            MCvPoint3D32f 的大小\r\n            \r\n","array of LineSegment2D":"LineSegment2D 数组\r\n","\r\n            Performs linear blending of two images:\r\n            dst(i, j)=weights1(i, j) x src1(i, j) + weights2(i, j) x src2(i, j)\r\n            ":"\r\n            执行两个图像的线性混合：\r\n            dst(i, j)=weights1(i, j) x src1(i, j) + weights2(i, j) x src2(i, j)\r\n            \r\n","Input vector of 2D points (contour vertices), stored in std::vector or Mat. ":"二维点（轮廓顶点）的输入向量，存储在 std::vector 或 Mat 中。\r\n","Type of the chart to detect":"要检测的图表类型\r\n","\r\n            Create an Odometry instance.\r\n            ":"\r\n            创建一个里程计实例。\r\n            \r\n","\r\n            The W component of the quaternion: the value for cos(rotation angle / 2)\r\n            ":"\r\n            四元数的W分量：cos(旋转角度/2)的值\r\n            \r\n","\r\n            Min circularity\r\n            ":"\r\n            最小圆度\r\n            \r\n","Can be null if not needed. The operation mask, determines what pixels of the source images are counted":"如果不需要，可以为 null。操作掩码，确定源图像的哪些像素被计算在内\r\n","\r\n            Autumn\r\n            ":"\r\n            秋天\r\n            \r\n","Number of hog channels used":"使用的 hog 通道数\r\n","Dt filter mode":"Dt过滤模式\r\n","Harris K":"哈里斯\r\n","The path for the parameters":"参数路径\r\n","\r\n            The kaze upright\r\n            ":"\r\n            直立的风\r\n            \r\n","\r\n            Pointer to the StereoMatcher \r\n            ":"指向 StereoMatcher 的指针\r\n            \r\n","\r\n            Replace OpenCV parallel_for backend.\r\n            ":"\r\n            替换 OpenCV parallel_for 后端。\r\n            \r\n","\r\n            Returns a structuring element of the specified size and shape for morphological operations.\r\n            ":"\r\n            为形态学操作返回指定大小和形状的结构元素。\r\n            \r\n"," Perform an elementwise AND operation with another image and return the result":" 与另一个图像执行元素与操作并返回结果\r\n","\r\n            A unit quaternions that defines rotation in 3D\r\n            ":"\r\n            定义 3D 旋转的单位四元数\r\n            \r\n","Truncation value for the prefiltered image pixels. The algorithm first computes x-derivative at each pixel and clips its value by [-preFilterCap, preFilterCap] interval. The result values are passed to the Birchfield-Tomasi pixel cost function.":"预过滤图像像素的截断值。该算法首先计算每个像素的 x 导数，并按 [-preFilterCap, preFilterCap] 间隔裁剪其值。结果值被传递给 Birchfield-Tomasi 像素成本函数。\r\n","Output line parameters. In case of 2D fitting, it should be a vector of 4 elements (like Vec4f) - (vx, vy, x0, y0), where (vx, vy) is a normalized vector collinear to the line \r\n            and (x0, y0) is a point on the line. In case of 3D fitting, it should be a vector of 6 elements\r\n            (like Vec6f) - (vx, vy, vz, x0, y0, z0), where (vx, vy, vz) is a normalized vector\r\n            collinear to the line and (x0, y0, z0) is a point on the line.\r\n            ":"输出线路参数。在 2D 拟合的情况下，它应该是 4 个元素的向量（如 Vec4f）- (vx, vy, x0, y0)，其中 (vx, vy) 是与线共线的归一化向量\r\n            (x0, y0) 是直线上的一个点。在 3D 拟合的情况下，它应该是一个包含 6 个元素的向量\r\n            （如 Vec6f）- (vx, vy, vz, x0, y0, z0)，其中 (vx, vy, vz) 是归一化向量\r\n            与直线共线并且 (x0, y0, z0) 是直线上的一个点。\r\n            \r\n","The search parameters":"搜索参数\r\n","true if this is a color video, false otherwise":"如果这是彩色视频，则为 true，否则为 false\r\n","\r\n            Relative, flag\r\n            ":"\r\n            相对，标志\r\n            \r\n","End angle of the transform in degrees.":"转换的结束角度（以度为单位）。\r\n","Output vector of lines. Each line is represented by a 4-element vector (x1, y1, x2, y2) , where (x1, y1) and (x2, y2) are the ending points of each detected line segment.":"线的输出向量。每条线由一个 4 元素向量 (x1, y1, x2, y2) 表示，其中 (x1, y1) 和 (x2, y2) 是每个检测到的线段的终点。\r\n","\r\n            Get the equivalent euler angle\r\n            ":"\r\n            得到等效的欧拉角\r\n            \r\n","3 single-channel matrices.":"3 个单通道矩阵。\r\n","\r\n            Create a GridBoard object.\r\n            ":"\r\n            创建一个网格板对象。\r\n            \r\n","Color window radius.":"颜色窗口半径。\r\n","\r\n            Real AdaBoost\r\n            ":"\r\n            真正的 AdaBoost\r\n            \r\n","\r\n            Filter by inertia\r\n            ":"\r\n            按惯性过滤\r\n            \r\n","Retrieval mode":"检索方式\r\n","Optional output vector, containing information about the image topology.":"可选的输出向量，包含有关图像拓扑的信息。\r\n","\r\n            This is used store and set up the parameters of the robust local optical flow (RLOF) algorithm.\r\n            ":"\r\n            这用于存储和设置鲁棒局部光流 (RLOF) 算法的参数。\r\n            \r\n","\r\n            Convert Bayer GRBG to GRAY\r\n            ":"\r\n            将拜耳 GRBG 转换为 GRAY\r\n            \r\n","Result image. If image is W x H and templ is w x h, then result must be W-w+1 x H-h+1.":"结果图像。如果图像是 W x H，模板是 w x h，则结果必须是 W-w+1 x H-h+1。\r\n","y-coordinate":"y坐标\r\n","The kernel":"内核\r\n","\r\n            The intensity of the x color channel\r\n            ":"\r\n            x 颜色通道的强度\r\n            \r\n","The matrix to subtract":"要减去的矩阵\r\n","\r\n            Number of codecs\r\n            ":"\r\n            编解码器数量\r\n            \r\n","\r\n            similarity window\r\n            ":"\r\n            相似性窗口\r\n            \r\n","Image to be shown":"要显示的图像\r\n","\r\n            Pointer to the stereo matcher\r\n            ":"\r\n            指向立体声匹配器的指针\r\n            \r\n","Expected noise standard deviation":"预期噪声标准偏差\r\n","Output 3x3 floating-point camera matrix. If UseIntrisicGuess is specified, some or all of fx, fy, cx, cy must be initialized before calling the function. ":"输出 3x3 浮点相机矩阵。如果指定了 UseIntrisicGuess，则必须在调用函数之前初始化 fx、fy、cx、cy 的部分或全部。\r\n","\r\n            Returns number of rows (CvSize::height) and number of columns (CvSize::width) of the input matrix or image. In case of image the size of ROI is returned.\r\n            ":"\r\n            返回输入矩阵或图像的行数 (CvSize::height) 和列数 (CvSize::width)。在图像的情况下，返回 ROI 的大小。\r\n            \r\n","Specifying the type of motion. Use Affine for default":"指定运动类型。默认使用仿射\r\n","Color of the contours ":"轮廓的颜色\r\n"," \r\n            Return the weighted sum such that: res = this * alpha + img2 * beta + gamma\r\n            ":" \r\n            返回加权总和：res = this * alpha + img2 * beta + gamma\r\n            \r\n","Result of the morphological transformation.":"形态变换的结果。\r\n","\r\n            Sets training method and common parameters.\r\n            ":"\r\n            设置训练方法和常用参数。\r\n            \r\n","\r\n            Perform the predict operation using the option control input\r\n            ":"\r\n            使用选项控制输入执行预测操作\r\n            \r\n","The list of the rectangles' objectness value.":"矩形的对象值列表。\r\n","The center of the search area":"搜索区域的中心\r\n","\r\n            A simple interface to detect face from given image.\r\n            ":"\r\n            从给定图像中检测人脸的简单界面。\r\n            \r\n","\r\n            Create a super resolution solver for the given frameSource\r\n            ":"\r\n            为给定的 frameSource 创建超分辨率求解器\r\n            \r\n","\r\n            Managed structure equivalent to CvMat\r\n            ":"\r\n            等效于 CvMat 的托管结构\r\n            \r\n","A flag to specify how to rotate the array":"指定如何旋转数组的标志\r\n","the height of the resulting image":"结果图像的高度\r\n","\r\n            Convert RGBA to YUV_I420\r\n            ":"\r\n            将 RGBA 转换为 YUV_I420\r\n            \r\n","\r\n            Release all the unmanaged memory associate with this object\r\n            ":"\r\n            释放与该对象关联的所有非托管内存\r\n            \r\n"," Perform an elementwise OR operation with some color using a mask":"使用遮罩对某些颜色执行元素或运算\r\n","Output 3x3 homography matrix. Homography matrix is determined up to a scale, thus it is normalized to make h33=1":"输出 3x3 单应矩阵。单应矩阵被确定为一个尺度，因此归一化使h33=1\r\n","\r\n            Use grabcut to perform background foreground segmentation.\r\n            ":"\r\n            使用 grabcut 进行背景前景分割。\r\n            \r\n","see paper":"见论文\r\n","\r\n            Compute and return the disparity map based on the correspondences found in the \"process\" method.\r\n            ":"\r\n            根据在“处理”方法中找到的对应关系计算并返回视差图。\r\n            \r\n","\r\n            Enable applying of CMS profiles to xiGetImage (see XI_PRM_INPUT_CMS_PROFILE, XI_PRM_OUTPUT_CMS_PROFILE).\r\n            ":"\r\n            启用将 CMS 配置文件应用于 xiGetImage（请参阅 XI_PRM_INPUT_CMS_PROFILE、XI_PRM_OUTPUT_CMS_PROFILE）。\r\n            \r\n","\r\n            The size of IplImage\r\n            ":"\r\n            IplImage 的大小\r\n            \r\n","\r\n            Initializes CvMatND structure allocated by the user\r\n            ":"\r\n            初始化用户分配的 CvMatND 结构\r\n            \r\n","\r\n            Create an standard vector of DMatch of the specific size\r\n            ":"\r\n            创建特定大小的 DMatch 标准向量\r\n            \r\n","\r\n            Create an empty standard vector of KeyLine\r\n            ":"\r\n            创建 KeyLine 的空标准向量\r\n            \r\n","\r\n            Pointer to the native Tracker object.\r\n            ":"\r\n            指向本机 Tracker 对象的指针。\r\n            \r\n","Output 32-bit image.":"输出 32 位图像。\r\n","Enable scale normalization":"启用比例标准化\r\n","\r\n            UMat\r\n            ":"\r\n            大学垫\r\n            \r\n","The GpuMat where the result will be stored":"存储结果的 GpuMat\r\n","The border mode for pyramid layers.":"金字塔层的边界模式。\r\n","\r\n            Gradient mapper for a translation\r\n            ":"\r\n            用于翻译的渐变映射器\r\n            \r\n","\r\n            Set general purpose input mode\r\n            ":"\r\n            设置通用输入模式\r\n            \r\n","\r\n            Performs a radius nearest neighbor search for multiple query points\r\n            ":"\r\n            对多个查询点执行半径最近邻搜索\r\n            \r\n","\r\n            checks whether the window exists and is visible\r\n            ":"\r\n            检查窗口是否存在且可见\r\n            \r\n","Threshold for the distance between matched descriptors. Distance means here metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured in Pixels)!":"匹配描述符之间距离的阈值。这里的距离是指公制距离（例如汉明距离），而不是坐标之间的距离（以像素为单位）！\r\n"," as well for inplace rotation":" 以及就地旋转\r\n","Output quality map images that were generated during computation, if supported by the algorithm.":"如果算法支持，则输出在计算过程中生成的质量地图图像。\r\n","New camera matrix (3x3) or new projection matrix (3x4)":"新相机矩阵 (3x3) 或新投影矩阵 (3x4)\r\n","\r\n            ditto\r\n            ":"\r\n            同上\r\n            \r\n","\r\n            Apply the cuda filter\r\n            ":"\r\n            应用cuda过滤器\r\n            \r\n","\r\n            Check if the stream is completed\r\n            ":"\r\n            检查流是否完成\r\n            \r\n","\r\n            The function is used to detect translational shifts that occur between two images. The operation takes advantage of the Fourier shift theorem for detecting the translational shift in the frequency domain. It can be used for fast image registration as well as motion estimation. \r\n            ":"\r\n            该函数用于检测两个图像之间发生的平移。该操作利用傅里叶移位定理来检测频域中的平移。它可用于快速图像配准和运动估计。\r\n            \r\n","\r\n            Release the unmanaged resource associated with the BFMatcher\r\n            ":"\r\n            释放与 BFMatcher 关联的非托管资源\r\n            \r\n","Inlier threshold value used by the RANSAC procedure. The parameter value is the maximum allowed distance between the observed and computed point projections to consider it an inlier.":"RANSAC 程序使用的内点阈值。参数值是观察点投影和计算点投影之间的最大允许距离，以将其视为内点。\r\n","Input matrix.":"输入矩阵。\r\n","\r\n            Eliminate the matched features whose scale and rotation do not aggree with the majority's scale and rotation.\r\n            ":"\r\n            消除比例和旋转与大多数比例和旋转不一致的匹配特征。\r\n            \r\n","Destination histogram with one row, 256 columns, and the CV_32SC1 type.":"具有 1 行、256 列和 CV_32SC1 类型的目标直方图。\r\n","\r\n            Saturation of the image (only for cameras).\r\n            ":"\r\n            图像的饱和度（仅适用于相机）。\r\n            \r\n","If != 0, the encoder will expect and encode color frames, otherwise it will work with grayscale frames ":"如果 != 0，编码器将期望并编码彩色帧，否则它将使用灰度帧\r\n","v3":"v3\r\n","\r\n            Create a Capture frame source\r\n            ":"\r\n            创建捕获帧源\r\n            \r\n","\r\n            Unmatched formats\r\n            ":"\r\n            无与伦比的格式\r\n            \r\n","\r\n            Create an empty standard vector of VectorOfMat\r\n            ":"\r\n            创建一个空的 VectorOfMat 标准向量\r\n            \r\n","\r\n            The maximum variance\r\n            ":"\r\n            最大方差\r\n            \r\n","Output result.":"输出结果。\r\n","The index of the ocl device":"ocl设备的索引\r\n","\r\n            Create an standard vector of Rect with the initial values\r\n            ":"\r\n            使用初始值创建 Rect 的标准向量\r\n            \r\n","Short Range":"短距离\r\n","Indexes of initial clusterization seeds. Its size must be lower or equal to initSamplingPoints.size().":"初始聚类种子的索引。它的大小必须小于或等于 initSamplingPoints.size()。\r\n","\r\n            AdaptiveThreshold maximum window size\r\n            ":"\r\n            AdaptiveThreshold 最大窗口大小\r\n            \r\n","\r\n            Return the pointer to the StatModel object\r\n            ":"\r\n            返回指向 StatModel 对象的指针\r\n            \r\n","\r\n            Parameters for LK flow algorithm \r\n            ":"\r\n            LK流算法的参数\r\n            \r\n","\r\n            Applies a GNU Octave/MATLAB equivalent colormap on a given image.\r\n            ":"\r\n            在给定图像上应用 GNU Octave/MATLAB 等效颜色图。\r\n            \r\n","\r\n            Create an standard vector of Float with the initial values\r\n            ":"\r\n            使用初始值创建 Float 的标准向量\r\n            \r\n","\r\n            Divides a multi-channel array into separate single-channel arrays. Two modes are available for the operation. If the source array has N channels then if the first N destination channels are not IntPtr.Zero, all they are extracted from the source array, otherwise if only a single destination channel of the first N is not IntPtr.Zero, this particular channel is extracted, otherwise an error is raised. Rest of destination channels (beyond the first N) must always be IntPtr.Zero. For IplImage cvCopy with COI set can be also used to extract a single channel from the image\r\n            ":"\r\n            将多通道阵列分成单独的单通道阵列。有两种模式可供操作。如果源数组有 N 个通道，那么如果前 N 个目标通道不是 IntPtr.Zero，则从源数组中提取所有它们，否则如果前 N 个中只有一个目标通道不是 IntPtr.Zero，则此特定通道是提取，否则会引发错误。其余目标通道（超出前 N 个）必须始终为 IntPtr.Zero。对于设置了 COI 的 IplImage cvCopy 也可用于从图像中提取单个通道\r\n            \r\n","The kernelCls1 file":"kernelCls1 文件\r\n","\r\n            The size of the randomly selected subset of features at each tree node and that are used to find the best split(s)\r\n            ":"\r\n            每个树节点随机选择的特征子集的大小，用于找到最佳分割\r\n            \r\n","Net object.":"净对象。\r\n","\r\n            Release all the unmanaged resource associated with RadialVarianceHash\r\n            ":"\r\n            释放与 RadialVarianceHash 关联的所有非托管资源\r\n            \r\n","The observed image":"观察到的图像\r\n","\r\n            Calculates a dense optical flow.\r\n            ":"\r\n            计算密集光流。\r\n            \r\n"," The lightness for this color ":" 这种颜色的亮度\r\n","\r\n            Convert Bayer GB to BGRA \r\n            ":"\r\n            Bayer GB 转换为 BGRA\r\n            \r\n","\r\n            Number of channels\r\n            ":"\r\n            通道数\r\n            \r\n","Template size":"模板尺寸\r\n","Threshold on the squared distance between the pixel and the sample to decide whether a pixel is close to that sample. This parameter does not affect the background update.":"像素和样本之间平方距离的阈值，用于决定像素是否接近该样本。该参数不影响后台更新。\r\n","Pointer to the array header to be initialized":"指向要初始化的数组头的指针\r\n","\r\n            Draw a GridBoard.\r\n            ":"\r\n            画一个网格板。\r\n            \r\n","The sobel response for the selected point":"所选点的索贝尔响应\r\n","The specified element of the top-level mapping.":"顶级映射的指定元素。\r\n","Long Range":"长距离\r\n","\r\n            Warps the image using perspective transformation\r\n            ":"\r\n            使用透视变换扭曲图像\r\n            \r\n","\r\n            Calculates the first x- or y- image derivative using Scharr operator.\r\n            ":"\r\n            使用 Scharr 运算符计算第一个 x 或 y 图像导数。\r\n            \r\n",". Reasonably good value is 32*number_of_image_channels*SADWindowSize*SADWindowSize. Use 0 for default":".比较好的值是 32*number_of_image_channels*SADWindowSize*SADWindowSize。默认使用 0\r\n","\r\n            Output image range maximum value\r\n            ":"\r\n            输出图像范围最大值\r\n            \r\n","output image.":"输出图像。\r\n","Operation flags; currently, the only supported flag is DFT_ROWS, which indicates that each row of src1 and src2 is an independent 1D Fourier spectrum.":"操作标志；目前唯一支持的flag是DFT_ROWS，表示src1和src2的每一行都是一个独立的一维傅里叶谱。\r\n","\r\n            Returns the min / max location and values for the image\r\n            ":"\r\n            返回图像的最小/最大位置和值\r\n            \r\n","Chooses the enforcement of superpixel compactness factor of superpixel":"选择superpixel superpixel compactness factor的执行\r\n","\r\n            Create a Voronoi facet using the specific ":"\r\n            使用特定的创建 Voronoi 面\r\n","\r\n            Creates instance of DenseRLOFOpticalFlow\r\n            ":"\r\n            创建 DenseRLOFOpticalFlow 的实例\r\n            \r\n","\r\n            Bad ROI size\r\n            ":"\r\n            投资回报率不佳\r\n            \r\n","The returned minimum location":"返回的最小位置\r\n","\r\n            Make a copy of the specific ROI (Region of Interest) from the image\r\n            ":"\r\n            从图像中复制特定的 ROI（感兴趣区域）\r\n            \r\n","Optional output parameter for storing COI":"用于存储 COI 的可选输出参数\r\n","\r\n            Each matrix row is sorted in the \r\n            descending order; this flag and SortAscending are also\r\n            mutually exclusive.\r\n            ":"\r\n            每个矩阵行在\r\n            降序;这个标志和 SortAscending 也是\r\n            互斥的。\r\n            \r\n","\r\n            (bilateral filter) - applying bilateral 3x3 filtering with color sigma=param1 and space sigma=param2. Information about bilateral filtering can be found \r\n            ":"\r\n            （双边过滤器）- 应用双边 3x3 过滤，颜色 sigma=param1 和空间 sigma=param2。有关双边过滤的信息可以找到\r\n            \r\n","\r\n            This function computes a Hanning window coefficients in two dimensions.\r\n            ":"\r\n            此函数计算二维的汉宁窗系数。\r\n            \r\n","Prune areas bigger than maxArea = max_area_relative * input_image_size":"修剪大于 maxArea = max_area_relative * input_image_size 的区域\r\n","src.depth() = CV_64F, ddepth = -1/CV_64F":"src.depth() = CV_64F, ddepth = -1/CV_64F\r\n","\r\n            Compute the panoramic images given the images\r\n            ":"\r\n            计算给定图像的全景图像\r\n            \r\n","The vertically concatenated matrix":"垂直级联矩阵\r\n","\r\n            Bad Align\r\n            ":"\r\n            对齐不良\r\n            \r\n","Strength of the noise removal for foreground points.":"前景点的噪声去除强度。\r\n","\r\n            The local path to the local file given the file name\r\n            ":"给定文件名的本地文件的本地路径\r\n            \r\n","output image of the same size and type as src.":"输出与 src 相同大小和类型的图像。\r\n","\r\n            The type of the node.\r\n            ":"\r\n            节点的类型。\r\n            \r\n","The optimized points1.":"优化点1。\r\n","\r\n            Release the unmanaged memory associated with this warper\r\n            ":"\r\n            释放与此 warper 关联的非托管内存\r\n            \r\n","\r\n            Converts NaN's to the given number\r\n            ":"\r\n            将 NaN 转换为给定的数字\r\n            \r\n","The data to be logged":"要记录的数据\r\n","\r\n            Draw the text using the specific font on the image\r\n            ":"\r\n            使用图像上的特定字体绘制文本\r\n            \r\n","Radius of filtering kernel, should be a positive integer.":"滤波核的半径，应为正整数。\r\n","The scaled image":"缩放图像\r\n","\r\n            Selects ROIs on the given image. Function creates a window and allows user to select a ROIs using mouse. Controls: use space or enter to finish current selection and start a new one, use esc to terminate multiple ROI selection process.\r\n            ":"\r\n            选择给定图像上的 ROI。函数创建一个窗口并允许用户使用鼠标选择 ROI。控制：使用空格或回车完成当前选择并开始新的选择，使用esc终止多个ROI选择过程。\r\n            \r\n","Interpolation type":"插值类型\r\n","The array of corresponding image points":"对应图像点的数组\r\n","\r\n            Calculates per-element bit-wise logical not\r\n            dst(I)=~src(I) if mask(I)!=0\r\n            In the case of floating-point GpuMats their bit representations are used for the operation. All the GpuMats must have the same type, except the mask, and the same size\r\n            ":"\r\n            计算每个元素的按位逻辑非\r\n            dst(I)=~src(I) 如果掩码(I)!=0\r\n            在浮点 GpuMats 的情况下，它们的位表示用于操作。所有 GpuMats 必须具有相同的类型（掩码除外）和相同的大小\r\n            \r\n","input image: 8-bit unsigned 3-channel.":"输入图像：8 位无符号 3 通道。\r\n","Model pixel scale, an array of size 3":"模型像素比例，大小为 3 的数组\r\n","N scales":"N个秤\r\n","Thickness of lines that make up the rectangle. Negative values make the function to draw a filled rectangle.":"构成矩形的线的粗细。负值使函数绘制一个填充的矩形。\r\n","Rectification transformation in the object space: 3x3 1-channel, or vector: 3x1/1x3 1-channel or 1x1 3-channel":"对象空间中的整流变换：3x3 1-channel，或向量：3x1/1x3 1-channel 或 1x1 3-channel\r\n","\r\n            Get or Set if the captured image should be flipped vertically\r\n            ":"\r\n            获取或设置捕获的图像是否应垂直翻转\r\n            \r\n","\r\n            Get a submatrix corresponding to a specified rectangle\r\n            ":"\r\n            获取指定矩形对应的子矩阵\r\n            \r\n","optional, specify perform outliers adjust operation or not, (Eq. 9) in the original paper.":"可选，指定是否执行异常值调整操作，（等式 9）在原始文件中。\r\n","The point to be inserted":"要插入的点\r\n","The GpuMat type":"GpuMat 类型\r\n","True if the execution is sucessful":"如果执行成功则为真\r\n","\r\n            round to zero\r\n            ":"\r\n            四舍五入为零\r\n            \r\n","The matrix without a specified row span of the input array":"输入数组没有指定行跨度的矩阵\r\n","\r\n            Max threshold\r\n            ":"\r\n            最大阈值\r\n            \r\n","\r\n            Compares elements of two GpuMats (c = a <cmpop> b).\r\n            Supports CV_8UC4, CV_32FC1 types\r\n            ":"\r\n            比较两个 GpuMat 的元素 (c = a <cmpop> b)。\r\n            支持 CV_8UC4、CV_32FC1 类型\r\n            \r\n","\r\n            Margin type\r\n            ":"\r\n            保证金类型\r\n            \r\n","\r\n            Converts the hardware-generated flow vectors to floating point representation\r\n            ":"\r\n            将硬件生成的流向量转换为浮点表示\r\n            \r\n","Output array. It has the same number of cols and depth as the src, and the sum of rows of the src. same depth.":"输出数组。它具有与 src 相同的列数和深度，以及 src 的行数之和。同样的深度。\r\n","\r\n            Diff L1\r\n            ":"\r\n            差速器 L1\r\n            \r\n","ScaleAbs factor":"ScaleAbs 因子\r\n","\r\n            Create a RotatedRect structure with the specific parameters\r\n            ":"\r\n            使用特定参数创建 RotatedRect 结构\r\n            \r\n","\r\n            Apply a constant support region\r\n            ":"\r\n            应用恒定支撑区域\r\n            \r\n","\r\n            Create a Background/Foreground Segmentation model\r\n            ":"\r\n            创建背景/前景分割模型\r\n            \r\n","Location of the principal point in the new camera matrix. The parameter indicates whether this location should be at the image center or not.":"新相机矩阵中主点的位置。该参数指示该位置是否应位于图像中心。\r\n","\r\n            Get an empty input array\r\n            ":"\r\n            获取一个空的输入数组\r\n            \r\n","start value for alpha parameter (to fast initiate statistic model)":"alpha 参数的起始值（以快速启动统计模型）\r\n","Termination criteria for the iterative optimization algorithm":"迭代优化算法的终止标准\r\n","\r\n            True if the matrix is a submatrix of another matrix\r\n            ":"\r\n            如果矩阵是另一个矩阵的子矩阵则为真\r\n            \r\n","\r\n            True if the input array is a vector of UMat\r\n            ":"\r\n            如果输入数组是 UMat 的向量，则为真\r\n            \r\n","Type of the contour segments":"轮廓段的类型\r\n","\r\n            compress horizontal, vertical, and diagonal segments, that is, the function leaves only their ending points; \r\n            ":"\r\n            压缩水平、垂直和对角线段，即函数只留下它们的终点；\r\n            \r\n","The array of 2D points":"二维点数组\r\n","The destination image, should have 2x smaller width and height than the source.":"目标图像的宽度和高度应比源图像小 2 倍。\r\n","The result of blur":"模糊的结果\r\n","Pointer to the prelocate memory of the resulting sub-array header":"指向结果子数组头的预定位内存的指针\r\n","\r\n            Stereographic Warper\r\n            ":"\r\n            立体变形器\r\n            \r\n","The function returns the number of markers from the input employed for the board pose estimation. Note that returning a 0 means the pose has not been estimated.":"该函数返回用于板姿态估计的输入中的标记数。请注意，返回 0 表示尚未估计姿势。\r\n","The index parameter":"索引参数\r\n","\r\n            The bytes.\r\n            ":"\r\n            字节。\r\n            \r\n","The width step required to jump to the next row":"跳转到下一行所需的宽度步长\r\n","Array of corresponding image points, 3x2 1-channel or 1x3/3x1 2-channel. VectorOfPoint2f can be also passed here.":"相应图像点的数组，3x2 1 通道或 1x3/3x1 2 通道。 VectorOfPoint2f也可以在这里传递。\r\n","\r\n            Get or Set the value in the specific ":"\r\n            获取或设置特定的值\r\n","\r\n            The NNet and data packets\r\n            ":"\r\n            NNet 和数据包\r\n            \r\n","\r\n            Dnn backend. \r\n            ":"\r\n            Dnn 后端。\r\n            \r\n","Pyramid scale factor":"金字塔比例因子\r\n","\r\n            Buffer allocation policy is platform and usage specific \r\n            ":"\r\n            缓冲区分配策略是特定于平台和用途的\r\n            \r\n","\r\n            Element wise subtract another mat from the current mat\r\n            ":"\r\n            元素明智地从当前垫子中减去另一个垫子\r\n            \r\n","\r\n            The locale category\r\n            ":"\r\n            语言环境类别\r\n            \r\n","\r\n            Cividis\r\n            ":"\r\n            西维迪斯\r\n            \r\n","\r\n            A star marker shape, combination of cross and tilted cross\r\n            ":"\r\n            星形标记，十字和倾斜十字的组合\r\n            \r\n","\r\n            Plus Premul\r\n            ":"\r\n            加上 Premul\r\n            \r\n","File name of the image":"图片的文件名\r\n","Radius for NMS suppression.":"NMS 抑制的半径。\r\n","Scale factor along the vertical axis. If it is zero, it is computed as: (double)dsize.height/src.rows":"沿垂直轴的比例因子。如果为零，则计算为：(double)dsize.height/src.rows\r\n"," The source image, grayscale or colored of type CV_8UC1 or CV_8UC3. ":" CV_8UC1 或 CV_8UC3 类型的源图像、灰度或彩色。\r\n","Structuring element used for erosion. If it is IntPtr.Zero, a 3x3 rectangular structuring element is used":"用于侵蚀的结构元素。如果是 IntPtr.Zero，则使用 3x3 矩形结构元素\r\n","\r\n            Define an error callback that can be registered using cvRedirectError function\r\n            ":"\r\n            定义一个可以使用 cvRedirectError 函数注册的错误回调\r\n            \r\n","\r\n            Return the matrix corresponding to a specified row span of the input array\r\n            ":"\r\n            返回对应于输入数组的指定行跨度的矩阵\r\n            \r\n","\r\n            Modified-Local Difference Binary (M-LDB), upright\r\n            ":"\r\n            修正局部差分二进制 (M-LDB)，直立\r\n            \r\n","\r\n            When passing an object of this type the index constructed will be a hierarchical k-means tree.\r\n            ":"\r\n            当传递这种类型的对象时，构建的索引将是一个层次化的 k-means 树。\r\n            \r\n","Color of the cone.":"圆锥体的颜色。\r\n","Range between 0 to 200":"范围在 0 到 200 之间\r\n","\r\n            Intelperc Profile Count\r\n            ":"\r\n            Intelperc 配置文件计数\r\n            \r\n","ROI rectangle.":"投资回报率矩形。\r\n","\r\n            Return true if the local file exist and match the sha256hash (if specified in the constructor).\r\n            ":"\r\n            如果本地文件存在并匹配 sha256hash（如果在构造函数中指定），则返回 true。\r\n            \r\n","\r\n            The method by Alexandru Telea \r\n            ":"\r\n            Alexandru Telea 的方法\r\n            \r\n","\r\n            Enables or disables layer fusion in the network.\r\n            ":"\r\n            启用或禁用网络中的层融合。\r\n            \r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are less or equal compare to the scalar value.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否小于或等于标量值。\r\n            \r\n","The ellipse that fits best (in least-squares sense) to a set of 2D points":"最适合（在最小二乘意义上）一组二维点的椭圆\r\n","\r\n            BayerGB2BGR_MHT\r\n            ":"\r\n            拜耳GB2BGR_MHT\r\n            \r\n","The number of hash tables to use (between 10 and 30 usually).":"要使用的哈希表的数量（通常在 10 到 30 之间）。\r\n","Multiplier for images values.":"图像值的乘数。\r\n","\r\n            Fills convex polygon interior. This function is much faster than The function cvFillPoly and can fill not only the convex polygons but any monotonic polygon, i.e. a polygon whose contour intersects every horizontal line (scan line) twice at the most\r\n            ":"\r\n            填充凸多边形内部。该函数比函数 cvFillPoly 快得多，不仅可以填充凸多边形，还可以填充任何单调多边形，即轮廓与每条水平线（扫描线）最多相交两次的多边形\r\n            \r\n","\r\n            Returns an array of all 1's of the specified size and type.\r\n            ":"\r\n            返回指定大小和类型的全 1 数组。\r\n            \r\n","\r\n            value of second kneepoint (% of sensor saturation)\r\n            ":"\r\n            第二个拐点的值（传感器饱和度的百分比）\r\n            \r\n","Input image (CV_32FC1)":"输入图像 (CV_32FC1)\r\n","\r\n            Indicates if the value is signed\r\n            ":"\r\n            指示值是否已签名\r\n            \r\n","New number of channels. If the parameter is 0, the number of channels remains the same.":"新的频道数量。如果该参数为 0，则通道数保持不变。\r\n","Internally, this is a cvQueryFrame operation follow by a cvPyrDown":"在内部，这是一个 cvQueryFrame 操作，后面跟着一个 cvPyrDown\r\n","\r\n            Color Correction Matrix element [2][3]\r\n            ":"\r\n            颜色校正矩阵元素 [2][3]\r\n            \r\n","Ignore too small margin":"忽略太小的边距\r\n","\r\n            Stereo rectification for fisheye camera model.\r\n            ":"\r\n            鱼眼相机模型的立体校正。\r\n            \r\n","For the multi-scale Hough transform, it is a divisor for the distance resolution rho . The coarse accumulator distance resolution is rho and the accurate accumulator resolution is rho/srn . If both srn=0 and stn=0 , the classical Hough transform is used. Otherwise, both these parameters should be positive.":"对于多尺度霍夫变换，它是距离分辨率 rho 的除数。粗略的累加器距离分辨率为 rho ，准确的累加器距离分辨率为 rho/srn 。如果 srn=0 和 stn=0 ，则使用经典霍夫变换。否则，这两个参数都应该是正的。\r\n","The maximum number of iteration allowed":"允许的最大迭代次数\r\n","The histogram cost extractor, use ChiHistogramCostExtractor as default":"直方图成本提取器，默认使用 ChiHistogramCostExtractor\r\n","\r\n            Create an standard vector of PointF with the initial values\r\n            ":"\r\n            使用初始值创建 PointF 的标准向量\r\n            \r\n","The other coordinate to be compared with":"要与之比较的另一个坐标\r\n"," \r\n            Create a matrix using the specific data. \r\n            ":" \r\n            使用特定数据创建矩阵。\r\n            \r\n","\r\n            Class used for calculation sparse optical flow and feature tracking with robust local optical flow (RLOF) algorithms.\r\n            ":"\r\n            用于使用稳健的局部光流 (RLOF) 算法计算稀疏光流和特征跟踪的类。\r\n            \r\n","\r\n            The equivalent of cv::Mat\r\n            ":"\r\n            相当于 cv::Mat\r\n            \r\n","The 2x3 transformation matrix (pointer to CvArr)":"2x3 变换矩阵（指向 CvArr 的指针）\r\n","\r\n            The matrix dimensionality\r\n            ":"\r\n            矩阵维数\r\n            \r\n","\r\n            Given an original color image, two differently colored versions of this image can be mixed seamlessly.\r\n            ":"\r\n            给定一张原始彩色图像，该图像的两个不同颜色的版本可以无缝混合。\r\n            \r\n","Non maximum suppression":"非极大值抑制\r\n","\r\n            RGB FOV in degree\r\n            ":"\r\n            RGB FOV 度数\r\n            \r\n","\r\n            Calculates sum of all matrix elements.\r\n            ":"\r\n            计算所有矩阵元素的总和。\r\n            \r\n","\r\n            Library to invoke Features2D functions\r\n            ":"\r\n            调用 Features2D 函数的库\r\n            \r\n","Multiplier for image values.":"图像值的乘数。\r\n","\r\n            Diff L2\r\n            ":"\r\n            差分L2\r\n            \r\n","\r\n            Returns a CudaImage corresponding to a specified rectangle of the current CudaImage. The data is shared with the current matrix. In other words, it allows the user to treat a rectangular part of input array as a stand-alone array.\r\n            ":"\r\n            返回对应于当前 CudaImage 的指定矩形的 CudaImage。数据与当前矩阵共享。换句话说，它允许用户将输入数组的矩形部分视为独立数组。\r\n            \r\n","\r\n            Constructor which immediately sets the desired model.\r\n            ":"\r\n            立即设置所需模型的构造函数。\r\n            \r\n","\r\n            Returns the current error mode\r\n            ":"\r\n            返回当前错误模式\r\n            \r\n","Output aligned image":"输出对齐图像\r\n","\r\n            Variable specifies the iterative refinement strategy\r\n            ":"\r\n            变量指定迭代细化策略\r\n            \r\n","x coordinate of second point (r2, s2) in the transformation function.":"转换函数中第二个点 (r2, s2) 的 x 坐标。\r\n","\r\n            Upload data to GpuMat\r\n            ":"\r\n            上传数据到 GpuMat\r\n            \r\n","\r\n            Use misclassification rate. This is default option for Discrete AdaBoost; may be also used for Real AdaBoost\r\n            ":"\r\n            使用误分类率。这是 Discrete AdaBoost 的默认选项；也可用于 Real AdaBoost\r\n            \r\n","\r\n            Control matrix (B) (not used if there is no control)\r\n            ":"\r\n            控制矩阵 (B)（如果没有控制则不使用）\r\n            \r\n"," Get or set the intensity of the value color channel ":" 获取或设置值颜色通道的强度\r\n","Type of the matrix elements.":"矩阵元素的类型。\r\n","\r\n            Central Normalized Moment Nu12\r\n            ":"\r\n            中心归一化矩 Nu12\r\n            \r\n","\r\n            Create a new HOGDescriptor using the specific parameters\r\n            ":"\r\n            使用特定参数创建一个新的 HOGDescriptor\r\n            \r\n","\r\n            Selects which test pattern type is generated by the selected generator.\r\n            ":"\r\n            选择由所选生成器生成的测试模式类型。\r\n            \r\n","The first output map that has the type dstmap1type and the same size as src .":"类型为 dstmap1type 且大小与 src 相同的第一个输出映射。\r\n","\r\n            Calculates Optical Flow using NVIDIA Optical Flow SDK.\r\n            NVIDIA GPUs starting with Turing contain a dedicated hardware accelerator for computing optical flow vectors between pairs of images.\r\n            The optical flow hardware accelerator generates block-based optical flow vectors.\r\n            The size of the block depends on hardware in use, and can be queried using the function getGridSize().\r\n            The block-based flow vectors generated by the hardware can be converted to dense representation(i.e.per-pixel flow vectors) using upSampler() helper function, if needed.\r\n            The flow vectors are stored in CV_16SC2 format with x and y components of each flow vector in 16-bit signed fixed point representation S10.5.\r\n            ":"\r\n            使用 NVIDIA 光流 SDK 计算光流。\r\n            从 Turing 开始的 NVIDIA GPU 包含一个专用的硬件加速器，用于计算图像对之间的光流矢量。\r\n            光流硬件加速器生成基于块的光流矢量。\r\n            块的大小取决于使用的硬件，可以使用函数 getGridSize() 查询。\r\n            如果需要，可以使用 upSampler() 辅助函数将硬件生成的基于块的流向量转换为密集表示（即每像素流向量）。\r\n            流向量以 CV_16SC2 格式存储，每个流向量的 x 和 y 分量以 16 位带符号的定点表示法 S10.5 表示。\r\n            \r\n","The previous error mode":"之前的错误模式\r\n","\r\n            Panini portrait warper\r\n            ":"\r\n            帕尼尼人像变形器\r\n            \r\n","\r\n            Get the OclDevice with the specific index\r\n            ":"\r\n            获取具有特定索引的 OclDevice\r\n            \r\n","\r\n            The Codec\r\n            ":"\r\n            编解码器\r\n            \r\n","The size of the destination image":"目标图像的大小\r\n","The data to be compressed":"要压缩的数据\r\n","\r\n            Filter the matched Features, such that if a match is not unique, it is rejected.\r\n            ":"\r\n            过滤匹配的特征，如果匹配不唯一，则拒绝。\r\n            \r\n","\r\n            Inplace not supported\r\n            ":"\r\n            不支持就地\r\n            \r\n","The mask for the XOR operation":"XOR 运算的掩码\r\n","\r\n            Floating point 32 bit value, CV_32FC1.\r\n            ":"\r\n            浮点 32 位值，CV_32FC1。\r\n            \r\n"," is n x m2, the resulting matrix is n x (m1 + m2).\r\n            ":" 是 n x m2，得到的矩阵是 n x (m1 + m2)。\r\n            \r\n","\r\n            exp(-|I1-I2|^2/(2*sigma^2))\r\n            ":"\r\n            exp(-|I1-I2|^2/(2*sigma^2))\r\n            \r\n","\r\n            Convert Bayer GBRG pattern to RGB color using VNG\r\n            ":"\r\n            使用 VNG 将 Bayer GBRG 模式转换为 RGB 颜色\r\n            \r\n","\r\n            Set the Motion Filter\r\n            ":"\r\n            设置运动过滤器\r\n            \r\n","The background subtractor":"背景减法器\r\n","Source image with CV_8UC1 type.":"CV_8UC1 类型的源图像。\r\n","\r\n            property for highgui class CvCapture_Android only\r\n            ":"\r\n            仅限 highgui 类 CvCapture_Android 的属性\r\n            \r\n","\r\n            Returns the mask of the superpixel segmentation stored in SuperpixelSLIC object.\r\n            ":"\r\n            返回存储在 SuperpixelSLIC 对象中的超像素分割的掩码。\r\n            \r\n","The per-element difference between two matrices.":"两个矩阵之间的每个元素的差异。\r\n","\r\n            if arr2 is NULL, norm = ||arr1||_L1 = sum_I abs(arr1(I));\r\n            if arr2 is not NULL, norm = ||arr1-arr2||_L1 = sum_I abs(arr1(I)-arr2(I))\r\n            ":"\r\n            如果 arr2 为 NULL，norm = ||arr1||_L1 = sum_I abs(arr1(I));\r\n            如果 arr2 不为 NULL，则 norm = ||arr1-arr2||_L1 = sum_I abs(arr1(I)-arr2(I))\r\n            \r\n","\r\n            Positive value for gamma correction. Gamma value of 1.0 implies no correction, gamma equal to 2.2f is suitable for most displays.\r\n            ":"\r\n            伽玛校正的正值。 Gamma 值为 1.0 意味着没有校正，Gamma 等于 2.2f 适用于大多数显示器。\r\n            \r\n","\r\n            Make a clone of the current UMat.\r\n            ":"\r\n            克隆当前的 UMat。\r\n            \r\n","\r\n            Release the writer and write all data on to disk.\r\n            ":"\r\n            释放写入器并将所有数据写入磁盘。\r\n            \r\n","\r\n            Android focus mode\r\n            ":"\r\n            安卓专注模式\r\n            \r\n","\r\n            This event will be fired when the download progress is changed\r\n            ":"\r\n            下载进度改变时会触发此事件\r\n            \r\n","The dimension of the sparse matrix":"稀疏矩阵的维数\r\n","source image, it could be of any type and any number of channels from 1 to 4. In case of 3- and 4-channels images the function expect them in CIELab colorspace or similar one, where first color component shows intensity, while second and third shows colors. Nonetheless you can try any colorspaces.":"源图像，它可以是任何类型和从 1 到 4 的任意数量的通道。对于 3 通道和 4 通道图像，函数期望它们在 CIELab 色彩空间或类似的空间中，其中第一个颜色分量显示强度，而第二个和第三显示颜色。尽管如此，您可以尝试任何颜色空间。\r\n","\r\n            Convert HSV color to BGR color\r\n            ":"\r\n            将 HSV 颜色转换为 BGR 颜色\r\n            \r\n","\r\n            Computes the rectification transformations without knowing intrinsic parameters of the cameras and their relative position in space, hence the suffix \"Uncalibrated\". Another related difference from cvStereoRectify is that the function outputs not the rectification transformations in the object (3D) space, but the planar perspective transformations, encoded by the homography matrices H1 and H2. The function implements the following algorithm [Hartley99]. \r\n            ":"\r\n            在不知道相机的固有参数及其在空间中的相对位置的情况下计算整流变换，因此后缀“未校准”。与 cvStereoRectify 的另一个相关区别是该函数输出的不是对象 (3D) 空间中的校正变换，而是平面透视变换，由单应矩阵 H1 和 H2 编码。该函数实现了以下算法 [Hartley99]。\r\n            \r\n","\r\n            Sparse text with orientation and script det.\r\n            ":"\r\n            具有方向和脚本细节的稀疏文本。\r\n            \r\n"," \r\n            A Matrix is a wrapper to cvMat of OpenCV. \r\n            ":" \r\n            Matrix 是 OpenCV 的 cvMat 的包装器。\r\n            \r\n","\r\n            This function is the opposite to cvSplit. If the destination array has N channels then if the first N input channels are not IntPtr.Zero, all they are copied to the destination array, otherwise if only a single source channel of the first N is not IntPtr.Zero, this particular channel is copied into the destination array, otherwise an error is raised. Rest of source channels (beyond the first N) must always be IntPtr.Zero. For IplImage cvCopy with COI set can be also used to insert a single channel into the image. \r\n            ":"\r\n            这个函数与 cvSplit 相反。如果目标数组有 N 个通道，那么如果前 N 个输入通道不是 IntPtr.Zero，则将它们全部复制到目标数组，否则如果前 N 个中只有一个源通道不是 IntPtr.Zero，则此特定通道是复制到目标数组中，否则会引发错误。其余源通道（超出前 N 个）必须始终为 IntPtr.Zero。对于设置了 COI 的 IplImage，cvCopy 也可用于将单个通道插入图像。\r\n            \r\n","\r\n            Release all the unmanaged memory associated to this object\r\n            ":"\r\n            释放与该对象关联的所有非托管内存\r\n            \r\n","Output vector of lines. Each line is represented by a two-element vector":"线的输出向量。每条线由一个二元向量表示\r\n","The angle of the box in degrees. Possitive value means counter-clock wise rotation":"盒子的角度（以度为单位）。正值表示逆时针旋转\r\n","Operation mask of the same size as the umat.":"与 umat 大小相同的操作掩码。\r\n","Output image, 8-bit unsigned 3-channel.":"输出图像，8 位无符号 3 通道。\r\n","Source arrays. They all should have the same depth, CV_8U or CV_32F , and the same size. Each of them can have an arbitrary number of channels.":"源数组。它们都应具有相同的深度、CV_8U 或 CV_32F 以及相同的大小。它们中的每一个都可以有任意数量的通道。\r\n","The image format":"图片格式\r\n","Output array of the same size and type and the same number of channels as src.":"与 src 具有相同大小和类型以及相同通道数的输出数组。\r\n","\r\n            Loads algorithm from a String\r\n            ":"\r\n            从字符串加载算法\r\n            \r\n","If true, will use Harris corner detector.":"如果为真，将使用 Harris 角检测器。\r\n","\r\n            Real AdaBoost. It is a technique that utilizes confidence-rated predictions and works well with categorical data.\r\n            ":"\r\n            真正的 AdaBoost。它是一种利用置信度预测并适用于分类数据的技术。\r\n            \r\n","\r\n            Decodes the structured light pattern, generating a disparity map.\r\n            ":"\r\n            解码结构光图案，生成视差图。\r\n            \r\n","the source of memory copy":"内存拷贝的来源\r\n","\r\n            Current lens aperture value in stops. Examples: 2.8, 4, 5.6, 8, 11\r\n            ":"\r\n            当前镜头光圈值（以光圈为单位）。示例：2.8、4、5.6、8、11\r\n            \r\n","\r\n            Performs a singular value back substitution.\r\n            ":"\r\n            执行奇异值反向替换。\r\n            \r\n","\r\n              User defined distance \r\n            ":"\r\n              用户定义的距离\r\n            \r\n","The name of the kernel":"内核的名称\r\n","\r\n            Calculates covariation matrix for a set of vectors \r\n            transpose([v1-avg, v2-avg,...]) * [v1-avg,v2-avg,...] \r\n            ":"\r\n            计算一组向量的协方差矩阵\r\n            转置（[v1-avg，v2-avg，...]）* [v1-avg，v2-avg，...]\r\n            \r\n","The distance threshold":"距离阈值\r\n","The next index value to be set":"下一个要设置的索引值\r\n","The index, in case if this is an VectorOfMat":"索引，如果这是一个 VectorOfMat\r\n","\r\n            Release the unmanaged memory associated with this Layer.\r\n            ":"\r\n            释放与该层关联的非托管内存。\r\n            \r\n","\r\n            Create a new Edge Drawing object using default parameters.\r\n            ":"\r\n            使用默认参数创建一个新的边绘图对象。\r\n            \r\n","\r\n            Can be used to convert the second parameter of DetectAndDecode function from VectorOfMat to points\r\n            ":"\r\n            可用于将 DetectAndDecode 函数的第二个参数从 VectorOfMat 转换为点\r\n            \r\n","\r\n            The image expends as much as it can (no ratio constraint)\r\n            ":"\r\n            图像尽可能多地扩展（没有比例限制）\r\n            \r\n","\r\n            Get the source code as String\r\n            ":"\r\n            获取字符串形式的源代码\r\n            \r\n","The output segmentation. It's a CV_32SC1 Mat with the same number of cols and rows as input image, with an unique, sequential, id for each pixel.":"输出分割。它是一个 CV_32SC1 Mat，具有与输入图像相同的列数和行数，每个像素都有一个唯一的、连续的 ID。\r\n","The string variable containing the model you want to load.":"包含要加载的模型的字符串变量。\r\n","\r\n            Create an instance of bio-inspired features\r\n            ":"\r\n            创建仿生特征的实例\r\n            \r\n","Second frame, at time t + dt ":"第二帧，时间 t + dt\r\n","\r\n            A 2D triangle\r\n            ":"\r\n            二维三角形\r\n            \r\n","\r\n            Obtain the transpose of the convolution kernel\r\n            ":"\r\n            获取卷积核的转置\r\n            \r\n","\r\n            Decision Trees \r\n            ":"\r\n            决策树\r\n            \r\n","Output image depth. Only 32F type is supported for now.":"输出图像深度。目前只支持 32F 类型。\r\n","The result of the comparison as a mask":"比较结果作为掩码\r\n","vector of already detected markers corners. For each marker, its four corners are provided, (e.g VectorOfVectorOfPointF ). For N detected markers, the dimensions of this array should be Nx4.The order of the corners should be clockwise.":"已检测到的标记角的向量。对于每个标记，提供了它的四个角（例如 VectorOfVectorOfPointF ）。对于 N 个检测到的标记，这个数组的维度应该是 Nx4。角的顺序应该是顺时针的。\r\n","The id of the backend":"后端id\r\n","\r\n            Percent of top/bottom values to ignore\r\n            ":"\r\n            要忽略的最高值/最低值的百分比\r\n            \r\n","The size of the GpuMat":"GpuMat 的大小\r\n","The spatial window radius.":"空间窗口半径。\r\n","An array of key points":"关键点数组\r\n","\r\n            Gentle AdaBoost. It puts less weight on outlier data points and for that reason is often good with regression data.\r\n            ":"\r\n            温和的 AdaBoost。它对离群数据点的权重较小，因此通常适用于回归数据。\r\n            \r\n","Region of the disparity map to filter. Optional, usually it should be set automatically.":"要过滤的视差图区域。可选，通常应自动设置。\r\n","Source array channels":"源阵列通道\r\n","Initial coordinates of the input corners and refined coordinates on output":"输入角的初始坐标和输出的细化坐标\r\n","The Mat that contains the same data as this GpuMat":"包含与此 GpuMat 相同数据的 Mat\r\n","\r\n            Sets the new value for the layer output blob.\r\n            ":"\r\n            为层输出 blob 设置新值。\r\n            \r\n","\r\n            Retina parameters\r\n            ":"\r\n            视网膜参数\r\n            \r\n","\r\n            Class implementing the FLD (Fast Line Detector) algorithm\r\n            ":"\r\n            实现 FLD（快速线检测器）算法的类\r\n            \r\n","\r\n            Release the unmanaged memory associated with this OclImage2D\r\n            ":"\r\n            释放与此 OclImage2D 关联的非托管内存\r\n            \r\n","\r\n            Fill all the destination image pixels. If some of them correspond to outliers in the source image, they are set to fillval.\r\n            ":"\r\n            填充所有目标图像像素。如果其中一些对应于源图像中的异常值，则将它们设置为 fillval。\r\n            \r\n","gamma value for gamma correction.":"伽玛校正的伽玛值。\r\n","The optional mask.":"可选掩码。\r\n","\r\n            Class that contains entry points for the Face module.\r\n            ":"\r\n            包含 Face 模块入口点的类。\r\n            \r\n","\r\n            Write a single frame to the video writer\r\n            ":"\r\n            将单帧写入视频编写器\r\n            \r\n","\r\n            Plasma\r\n            ":"\r\n            等离子体\r\n            \r\n","\r\n            Image data release mode\r\n            ":"\r\n            图像数据发布方式\r\n            \r\n","\r\n            Constants used by the image class\r\n            ":"\r\n            图像类使用的常量\r\n            \r\n","\r\n            Computes undistortion and rectification maps for image transform by cv::remap(). If D is empty zero distortion is used, if R or P is empty identity matrixes are used.\r\n            ":"\r\n            通过 cv::remap() 计算图像变换的不失真和校正图。如果 D 为空，则使用零失真，如果 R 或 P 为空，则使用单位矩阵。\r\n            \r\n","The mask for the subtract operation":"减法运算的掩码\r\n","\r\n            Wrapped class of the C++ standard vector of TesseractResult.\r\n            ":"\r\n            TesseractResult 的 C++ 标准向量的包装类。\r\n            \r\n"," dst(x,y) = src(x,y), if src(x,y)>threshold;  0, otherwise ":" dst(x,y) = src(x,y)，如果 src(x,y)> 阈值； 0，否则\r\n","The location type of the point":"点的位置类型\r\n","\r\n            Calculates the magnitude and angle of 2D vectors.\r\n            ":"\r\n            计算二维向量的大小和角度。\r\n            \r\n","\r\n            The Fine Grained Saliency approach from \r\n            Sebastian Montabone and Alvaro Soto. Human detection using a mobile platform and novel features derived from a visual saliency mechanism. In Image and Vision Computing, Vol. 28 Issue 3, pages 391–402. Elsevier, 2010.\r\n            ":"\r\n            细粒度显着性方法来自\r\n            塞巴斯蒂安·蒙塔博内和阿尔瓦罗·索托。使用移动平台的人体检测和源自视觉显着性机制的新颖特征。在图像和视觉计算中，卷。 28 第 3 期，第 391-402 页。爱思唯尔，2010 年。\r\n            \r\n","\r\n            PM G2\r\n            ":"\r\n            PM G2\r\n            \r\n","The color conversion code for CvInvoke.cvCvtColor function":"CvInvoke.cvCvtColor函数的颜色转换代码\r\n","\r\n            Get or Set the exposable value, if true, this function will be displayed in Operation Menu of ImageBox\r\n            ":"\r\n            获取或设置曝光值，如果为真，该函数将显示在ImageBox的操作菜单中\r\n            \r\n","Currently the default and the only fully supported activation function is SigmoidSym ":"目前默认且唯一完全支持的激活函数是 SigmoidSym\r\n","\r\n            Identity function: f(x)=x\r\n            ":"\r\n            恒等函数：f(x)=x\r\n            \r\n","Robust outlier rejection is applied for robustness. This value actually corresponds to the standard deviation coefficient. Points with rejectionScale * sigma are ignored during registration.":"应用稳健的离群值拒绝以实现稳健性。这个值实际上对应于标准偏差系数。 rejectionScale * sigma 的点在注册过程中被忽略。\r\n","\r\n            Convert GRAY color to BGRA color\r\n            ":"\r\n            将 GRAY 颜色转换为 BGRA 颜色\r\n            \r\n","Minimum line length. Line segments shorter than that are rejected.":"最小行长度。短于此的线段将被拒绝。\r\n","Grid X":"网格 X\r\n","True if the point is in the cuboid":"如果点在长方体中则为真\r\n","\r\n            Gaussian Mixture-based Background/Foreground Segmentation Algorithm.\r\n            ":"\r\n            基于高斯混合的背景/前景分割算法。\r\n            \r\n","\r\n            Render the plot to the resulting Mat\r\n            ":"\r\n            将绘图渲染到生成的 Mat\r\n            \r\n","\r\n            allocates new GpuMat data unless the GpuMat already has specified size and type\r\n            ":"\r\n            分配新的 GpuMat 数据，除非 GpuMat 已经具有指定的大小和类型\r\n            \r\n","The result of the convolution":"卷积的结果\r\n","\r\n            The solver type\r\n            ":"\r\n            求解器类型\r\n            \r\n","\r\n            Make a clone of the current image. All image data as well as the COI and ROI are cloned\r\n            ":"\r\n            复制当前图像。克隆所有图像数据以及 COI 和 ROI\r\n            \r\n","Lower inclusive boundary of the returned random number.":"返回的随机数的下边界。\r\n","\r\n            Update the motion history with the specific image and current timestamp\r\n            ":"\r\n            使用特定图像和当前时间戳更新运动历史\r\n            \r\n","The CNNHostPipeline":"CNN主机管道\r\n","The maximum values for each channel":"每个通道的最大值\r\n","\r\n            OpenCV Image Sequence (e.g. img_%02d.jpg)\r\n            ":"\r\n            OpenCV 图像序列（例如 img_%02d.jpg）\r\n            \r\n","\r\n            Convert sBGR color to Lab color\r\n            ":"\r\n            将 sBGR 颜色转换为 Lab 颜色\r\n            \r\n","input image":"输入图像\r\n","\r\n            The 3rd distortion coefficient (k3) is fixed to 0 or to the initial passed value if CV_CALIB_USE_INTRINSIC_GUESS is passed\r\n            ":"\r\n            如果传递了 CV_CALIB_USE_INTRINSIC_GUESS，则第 3 个失真系数 (k3) 固定为 0 或初始传递值\r\n            \r\n","\r\n            Flag used for cvDCT\r\n            ":"\r\n            用于 cvDCT 的标志\r\n            \r\n","The orientation of the motion":"运动的方向\r\n","\r\n            The native pointer to the FaceRecognizer object \r\n            ":"\r\n            指向 FaceRecognizer 对象的本机指针\r\n            \r\n","\r\n            Vertically concatenate two images\r\n            ":"\r\n            垂直连接两个图像\r\n            \r\n","Output rotation matrix between the 1st and the 2nd camera coordinate systems.":"输出第一和第二相机坐标系之间的旋转矩阵。\r\n","Output image, 8-bit unsigned 3-channel image":"输出图像，8 位无符号 3 通道图像\r\n","\r\n            Creates a TLD tracker\r\n            ":"\r\n            创建 TLD 跟踪器\r\n            \r\n","\r\n            Gets the pointer to the index parameter.\r\n            ":"\r\n            获取指向索引参数的指针。\r\n            \r\n","The destination CvArray where the GpuMat data will be downloaded to.":"GpuMat 数据将下载到的目标 CvArray。\r\n","\r\n            This function load the image data from Mat\r\n            ":"\r\n            此函数从 Mat 加载图像数据\r\n            \r\n","level weights":"水平权重\r\n","\r\n            Calculates a histogram of a set of arrays.\r\n            ":"\r\n            计算一组数组的直方图。\r\n            \r\n","\r\n            The available flags for Farneback optical flow computation\r\n            ":"\r\n            Farneback 光流计算的可用标志\r\n            \r\n","Destination array depth.":"目标数组深度。\r\n","The vertives of this RotatedRect":"这个 RotatedRect 的原意\r\n"," The value to be subtracted from the current matrix":" 要从当前矩阵中减去的值\r\n","\r\n            Create a Gpu LinearFilter\r\n            ":"\r\n            创建一个 Gpu LinearFilter\r\n            \r\n","if true, the scale is preservered and the resulting image has maximum width(height) possible that is <= ":"如果为真，则保留比例并且生成的图像具有可能的最大宽度（高度）<=\r\n","Border mode used to extrapolate pixels outside of the image":"用于外推图像外部像素的边框模式\r\n","Number of times erosion is applied":"应用侵蚀的次数\r\n","The Mat header":"垫头\r\n","\r\n            Release the memory associated with this text detection model.\r\n            ":"\r\n            释放与此文本检测模型关联的内存。\r\n            \r\n","The sum of two GeodeticCoordinates":"两个 GeodeticCoordinates 的总和\r\n","A set of text recognition results.":"一组文本识别结果。\r\n","The number of classifiers to use in a OnlineBoosting algorithm":"OnlineBoosting 算法中使用的分类器数量\r\n","Maximal pyramid level number. If 0 , pyramids are not used (single level), if 1 , two levels are used, etc. ":"最大金字塔层数。如果为 0 ，则不使用金字塔（单层），如果为 1 ，则使用两层，依此类推。\r\n","\r\n            Returns uniformly distributed random float number from [a,b) range\r\n            ":"\r\n            从 [a,b) 范围返回均匀分布的随机浮点数\r\n            \r\n","\r\n            Calculates exponent of every element of input array:\r\n            dst(I)=exp(src(I))\r\n            ":"\r\n            计算输入数组的每个元素的指数：\r\n            dst(I)=exp(源(I))\r\n            \r\n"," Image of the specific depth, val = val * scale + shift ":" 具体深度的图像，val = val * scale + shift\r\n","\r\n            Release the memory associated with this keypoints model.\r\n            ":"\r\n            释放与此关键点模型关联的内存。\r\n            \r\n","The serialization info":"序列化信息\r\n","The intersection of the convex polygon":"凸多边形的交点\r\n","\r\n            Define framerate in Hz\r\n            ":"\r\n            以 Hz 为单位定义帧率\r\n            \r\n","Pointer to the destination unmanaged memory":"指向目标非托管内存的指针\r\n","\r\n            Managed structure equivalent to IplImage\r\n            ":"\r\n            等效于 IplImage 的托管结构\r\n            \r\n","\r\n            White balance green coefficient\r\n            ":"\r\n            白平衡绿色系数\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this optical flow solver.\r\n            ":"\r\n            释放与此光流求解器关联的所有非托管内存。\r\n            \r\n","\r\n            Bounding rectangle for the object (average rectangle of a group)\r\n            ":"\r\n            对象的边界矩形（组的平均矩形）\r\n            \r\n","\r\n            The center of the convolution kernel\r\n            ":"\r\n            卷积核的中心\r\n            \r\n","\r\n            Number of inner successive over-relaxation (SOR) iterations in the minimization procedure to solve the respective linear system.\r\n            ":"\r\n            求解相应线性系统的最小化过程中的内部连续过度松弛 (SOR) 迭代次数。\r\n            \r\n","\r\n            border completion mode, ignored by OpenCV \r\n            ":"\r\n            边界补全模式，被 OpenCV 忽略\r\n            \r\n","\r\n            Whether to use spatial propagation of good optical flow vectors. This option is turned on by default, as it tends to work better on average and can sometimes help recover from major errors introduced by the coarse-to-fine scheme employed by the DIS optical flow algorithm. Turning this option off can make the output flow field a bit smoother, however.\r\n            ":"\r\n            是否使用良好光流矢量的空间传播。默认情况下启用此选项，因为它往往平均工作得更好，有时可以帮助从 DIS 光流算法采用的由粗到细的方案引入的主要错误中恢复。但是，关闭此选项可以使输出流场更平滑一些。\r\n            \r\n","\r\n            Release all the unmanaged resource associated with BlockMeanHash\r\n            ":"\r\n            释放与 BlockMeanHash 关联的所有非托管资源\r\n            \r\n","A point1 on the axis of the cylinder.":"圆柱轴上的点 1。\r\n","Path to the .pb file with input tensor.":"带有输入张量的 .pb 文件的路径。\r\n","Value of the translation vector":"平移向量的值\r\n","Padding. Use Size.Empty for default":"填充。默认使用 Size.Empty\r\n","Number of matches threshold":"匹配阈值数\r\n","\r\n            It is used in combination with either CV_C, CV_L1 or CV_L2\r\n            ":"\r\n            它与 CV_C、CV_L1 或 CV_L2 结合使用\r\n            \r\n","\r\n            Get the average value on this image\r\n            ":"\r\n            获取此图像的平均值\r\n            \r\n","A set of bounding boxes to apply NMS.":"一组应用 NMS 的边界框。\r\n","\r\n            Size of the texture sampling window used to compute contrast and entropy. (center of the window is always in the pixel selected by x,y coordinates of the corresponding feature sample).\r\n            ":"\r\n            用于计算对比度和熵的纹理采样窗口的大小。 （窗口的中心始终位于相应特征样本的 x,y 坐标所选择的像素中）。\r\n            \r\n","The dense optical flow object":"稠密光流对象\r\n","\r\n             Temporary array for the background model. Do not modify it while you are\r\n             processing the same image.\r\n             ":"\r\n             背景模型的临时数组。不要修改它，而你是\r\n             处理同一张图片。\r\n             \r\n","\r\n            If set, use the gdal driver for loading the image.\r\n            ":"\r\n            如果设置，则使用 gdal 驱动程序加载图像。\r\n            \r\n","\r\n            An implementation of IInputArray intented to convert data to IInputArray\r\n            ":"\r\n            IInputArray 的实现，旨在将数据转换为 IInputArray\r\n            \r\n","Operation mask,\r\n            should be singe-channel 8-bit image, 2 pixels wider and 2 pixels taller than image.\r\n            If not IntPtr.Zero, the function uses and updates the mask, so user takes responsibility of initializing mask content.\r\n            Floodfilling can't go across non-zero pixels in the mask, for example, an edge detector output can be used as a mask to stop filling at edges.\r\n            Or it is possible to use the same mask in multiple calls to the function to make sure the filled area do not overlap.\r\n            Note: because mask is larger than the filled image, pixel in mask that corresponds to (x,y) pixel in image will have coordinates (x+1,y+1).":"手术面具，\r\n            应该是单通道 8 位图像，比图像宽 2 个像素，高 2 个像素。\r\n            如果不是 IntPtr.Zero，该函数使用并更新掩码，因此用户负责初始化掩码内容。\r\n            泛洪填充不能跨越掩码中的非零像素，例如，边缘检测器输出可以用作掩码以停止边缘处的填充。\r\n            或者可以在对该函数的多次调用中使用相同的掩码以确保填充区域不重叠。\r\n            注意：因为蒙版比填充后的图像大，蒙版中与图像中 (x,y) 像素对应的像素的坐标为 (x+1,y+1)。\r\n","\r\n            Spatial Moment M11\r\n            ":"\r\n            空间时刻M11\r\n            \r\n","Input size of image2.":"image2 的输入大小。\r\n","\r\n            Iterative algorithm running in more steps using partial computations.\r\n            ":"\r\n            使用部分计算以更多步骤运行的迭代算法。\r\n            \r\n","Vector of responses associated with the training samples.":"与训练样本相关的响应向量。\r\n","Defines whether initial guess for rvec and tvec will be used or not. Used as initial guess if not empty.":"定义是否使用 rvec 和 tvec 的初始猜测。如果不为空，则用作初始猜测。\r\n","\r\n            Create a FarnebackOpticalFlow object\r\n            ":"\r\n            创建 FarnebackOpticalFlow 对象\r\n            \r\n","Flag to specify how many times the src is repeated along the horizontal axis.":"用于指定 src 沿水平轴重复多少次的标志。\r\n","\r\n            Indicates if this is an Intel device\r\n            ":"\r\n            指示这是否是 Intel 设备\r\n            \r\n","Output array of angles that has the same size and type as x; the angles are measured in radians (from 0 to 2*Pi) or in degrees (0 to 360 degrees).":"输出与 x 具有相同大小和类型的角度数组；角度以弧度（从 0 到 2*Pi）或以度（0 到 360 度）为单位测量。\r\n","\r\n            Convert the standard vector to an array of String\r\n            ":"\r\n            将标准向量转换为字符串数组\r\n            \r\n"," Perform an element wise OR operation with another image and return the result":"对另一个图像执行元素明智的或操作并返回结果\r\n"," with the current image, using a mask":" 使用当前图像，使用遮罩\r\n","\r\n            Insert a collection of points to this planar subdivision\r\n            ":"\r\n            向该平面细分插入一组点\r\n            \r\n","\r\n            Get or Set the log level.\r\n            ":"\r\n            获取或设置日志级别。\r\n            \r\n","\r\n            Converts CvMat, IplImage , or CvMatND to Mat.\r\n            ":"\r\n            将 CvMat、IplImage 或 CvMatND 转换为 Mat。\r\n            \r\n","\r\n            The maximum allowed reprojection error to treat a point pair as an inlier. \r\n            If srcPoints and dstPoints are measured in pixels, it usually makes sense to set this parameter somewhere in the range 1 to 10.\r\n            ":"\r\n            将点对视为内点的最大允许重投影误差。\r\n            如果 srcPoints 和 dstPoints 以像素为单位测量，则将此参数设置在 1 到 10 范围内的某个位置通常是有意义的。\r\n            \r\n","Distribution of generated points.":"生成点的分布。\r\n","Destination image":"目标图像\r\n","\r\n            No size\r\n            ":"\r\n            没有尺码\r\n            \r\n","\r\n            Rotate 270 degrees clockwise\r\n            ":"\r\n            顺时针旋转270度\r\n            \r\n","\r\n            Convert BayerRG pattern to BGR color using VNG\r\n            ":"\r\n            使用 VNG 将 BayerRG 图案转换为 BGR 颜色\r\n            \r\n","\r\n            Perform image denoising using Non-local Means Denoising algorithm (modified for color image): \r\n            http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/ \r\n            with several computational optimizations. Noise expected to be a Gaussian white noise.\r\n            The function converts image to CIELAB colorspace and then separately denoise L and AB components with given h parameters using fastNlMeansDenoising function.\r\n            ":"\r\n            使用非局部均值去噪算法（针对彩色图像修改）执行图像去噪：\r\n            http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/\r\n            有几个计算优化。噪声预计为高斯白噪声。\r\n            该函数将图像转换为 CIELAB 颜色空间，然后使用 fastNlMeansDenoising 函数分别对具有给定 h 参数的 L 和 AB 分量进行去噪。\r\n            \r\n","\r\n            fullscreen property    (can be WINDOW_NORMAL or WINDOW_FULLSCREEN).\r\n            ":"\r\n            全屏属性（可以是 WINDOW_NORMAL 或 WINDOW_FULLSCREEN）。\r\n            \r\n","\r\n            Base interface for StaticSaliency algorithms\r\n            ":"\r\n            StaticSaliency 算法的基本接口\r\n            \r\n","Number of features, a good value would be 10*numClassifiers + iterationInit":"特征数量，一个好的值是 10*numClassifiers + iterationInit\r\n","\r\n            kind shift\r\n            ":"\r\n            善意的转变\r\n            \r\n","\r\n            Regression. The distance between feature vectors from the training set and the fitting hyper-plane must be less than p. For outliers the penalty multiplier C is used\r\n            ":"\r\n            回归。来自训练集的特征向量与拟合超平面之间的距离必须小于 p。对于异常值，使用惩罚乘数 C\r\n            \r\n","\r\n            Applies X Deriche filter to an image.\r\n            ":"\r\n            将 X Deriche 滤镜应用于图像。\r\n            \r\n","\r\n            The function equalizes the histogram of the input image\r\n            ":"\r\n            该函数均衡输入图像的直方图\r\n            \r\n","\r\n            Finds the edges on the input ":"\r\n            查找输入的边缘\r\n","Desired number of superpixels. Note that the actual number may be smaller due to restrictions (depending on the image size and num_levels). Use getNumberOfSuperpixels() to get the actual number.":"所需的超像素数量。请注意，由于限制（取决于图像大小和 num_levels），实际数量可能会更小。使用 getNumberOfSuperpixels() 获取实际数字。\r\n","The first GpuMat to be element-wise multiplied.":"第一个按元素相乘的 GpuMat。\r\n","The third image":"第三张图片\r\n","\r\n            Compares two shapes. The 3 implemented methods all use Hu moments\r\n            ":"\r\n            比较两个形状。 3个实现的方法都使用了胡矩\r\n            \r\n","Output 2D affine transformation matrix 2×3 or empty matrix if transformation could not be estimated.":"如果无法估计变换，则输出 2D 仿射变换矩阵 2×3 或空矩阵。\r\n","Pointer to returned minimum location":"指向返回的最小位置的指针\r\n","B-channel multiply factor. Multiplication factor is between .5 to 2.5.":"B 通道乘数。乘数在 0.5 到 2.5 之间。\r\n","The values of the (3 x 1) Rodrigues rotation vector":"(3 x 1) Rodrigues 旋转向量的值\r\n","\r\n            BayerBG2GRAY_MHT\r\n            ":"\r\n            拜耳BG2GRAY_MHT\r\n            \r\n","Source image. Must be RGB CV_8UC3.":"源图像。必须是 RGB CV_8UC3。\r\n","An exception handler. If provided, it will be used to handle exception in the capture thread.":"异常处理程序。如果提供，它将用于处理捕获线程中的异常。\r\n","Input vector of 2D points.":"二维点的输入向量。\r\n","The detector type":"探测器类型\r\n","Is a number between 0 and 1 indicating what fraction of the dataset to use in the automatic parameter configuration algorithm. Running the algorithm on the full dataset gives the most accurate results, but for very large datasets can take longer than desired. In such case using just a fraction of the data helps speeding up this algorithm while still giving good approximations of the optimum parameters.":"是一个介于 0 和 1 之间的数字，指示在自动参数配置算法中使用的数据集部分。在完整数据集上运行该算法可提供最准确的结果，但对于非常大的数据集，可能需要比预期更长的时间。在这种情况下，仅使用一小部分数据有助于加快该算法的速度，同时仍能提供最佳参数的良好近似值。\r\n","\r\n            Release all the unmanaged memory associated with this seam finder\r\n            ":"\r\n            释放与此接缝查找器关联的所有非托管内存\r\n            \r\n","The source code":"源代码\r\n","\r\n            Class implementing BEBLID (Boosted Efficient Binary Local Image Descriptor)\r\n            ":"\r\n            实现 BEBLID（提升高效二进制本地图像描述符）的类\r\n            \r\n","\r\n            Filled\r\n            ":"\r\n            填充\r\n            \r\n","\r\n            Selects the type of trigger.\r\n            ":"\r\n            选择触发类型。\r\n            \r\n","The output array where the location of the pixels are sorted":"像素位置排序后的输出数组\r\n","\r\n            Set magic val\r\n            ":"\r\n            设置魔法值\r\n            \r\n","Centroid output for each label, including the background label. Centroids are accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.":"每个标签的质心输出，包括背景标签。通过 x 的 centroids(label, 0) 和 y 的 centroids(label, 1) 访问质心。数据类型 CV_64F。\r\n","The numbers of bins for rotation, a good value might be 20 (which means each bin covers 18 degree)":"旋转的箱子数量，一个好的值可能是 20（这意味着每个箱子覆盖 18 度）\r\n","\r\n            Grabcut initialization type\r\n            ":"\r\n            Grabcut初始化类型\r\n            \r\n","Option error message container that can be passed to this function":"可以传递给此函数的选项错误消息容器\r\n","New number of channels. newCn = 0 means that the number of channels remains unchanged.":"新的频道数量。 newCn = 0 表示通道数保持不变。\r\n","\r\n            Pointer to the child ERStat\r\n            ":"\r\n            指向子 ERStat 的指针\r\n            \r\n","The result of the adaptive threshold":"自适应阈值的结果\r\n","Order of the derivative x":"导数 x 的阶数\r\n","Sobel kernel size":"索贝尔核大小\r\n","\r\n            Convert YUV (YUYV) to RGBA\r\n            ":"\r\n            将 YUV (YUYV) 转换为 RGBA\r\n            \r\n","\r\n            The structured light pattern decode flag\r\n            ":"\r\n            结构光模式解码标志\r\n            \r\n","The W component of the quaternion: the value for cos(rotation angle / 2)":"四元数的W分量：cos(旋转角度/2)的值\r\n","\r\n            The recognized text is returned coded as UNLV format Latin-1 with specific reject and suspect codes\r\n            ":"\r\n            识别的文本被编码为 UNLV 格式 Latin-1 并带有特定的拒绝和可疑代码\r\n            \r\n","Maximal duration of motion track in milliseconds, the same as in cvUpdateMotionHistory":"以毫秒为单位的运动轨迹的最大持续时间，与 cvUpdateMotionHistory 相同\r\n","The array of pairs of indices of the planes copied. from_to[k*2] is the 0-based index of the input plane, and from_to[k*2+1] is the index of the output plane, where the continuous numbering of the planes over all the input and over all the output arrays is used. When from_to[k*2] is negative, the corresponding output plane is filled with 0's.":"复制的平面索引对数组。 from_to[k*2] 是输入平面从 0 开始的索引，from_to[k*2+1] 是输出平面的索引，其中平面在所有输入和所有输出上的连续编号使用数组。当from_to[k*2]为负时，对应的输出平面用0填充。\r\n","\r\n            The locally uniform comparison image descriptor:\r\n            An image descriptor that can be computed very fast, while being\r\n            about as robust as, for example, SURF or BRIEF.\r\n            ":"\r\n            局部统一比较图像描述符：\r\n            可以非常快速地计算的图像描述符，同时\r\n            与例如 SURF 或 BRIEF 一样健壮。\r\n            \r\n","Array of histogram sizes in each dimension.":"每个维度的直方图大小数组。\r\n","\r\n            A covariation matrix of each mixture may be arbitrary symmetrical positively defined matrix, so the number of free parameters in each matrix is about d2/2. It is not recommended to use this option, unless there is pretty accurate initial estimation of the parameters and/or a huge number of training samples\r\n            ":"\r\n            每个混合的协方差矩阵可以是任意对称的正定义矩阵，因此每个矩阵中的自由参数个数约为d2/2。不建议使用这个选项，除非有相当准确的参数初始估计和/或大量的训练样本\r\n            \r\n","\r\n            Draws the checker to the given image.\r\n            ":"\r\n            将检查器绘制到给定图像。\r\n            \r\n","\r\n            Line detection.\r\n            ":"\r\n            线路检测。\r\n            \r\n","\r\n            Get the number of elements in the descriptor.\r\n            ":"\r\n            获取描述符中的元素数。\r\n            \r\n","If set to true, the search result is sorted":"如果设置为true，则搜索结果排序\r\n","\r\n            Openni generator registration\r\n            ":"\r\n            Openni生成器注册\r\n            \r\n","\r\n            Min Convexity\r\n            ":"\r\n            最小凸度\r\n            \r\n","\r\n            Create a mapper that calculates a similarity transformation between two images (scale, rotation, and shift)\r\n            ":"\r\n            创建一个映射器来计算两个图像之间的相似性变换（缩放、旋转和移位）\r\n            \r\n","The input (distorted) image":"输入（失真）图像\r\n","Input vector of 2D or 3D points, stored in std::vector or Mat.":"2D 或 3D 点的输入向量，存储在 std::vector 或 Mat 中。\r\n","\r\n            Convert YUV (i420) to BGRA\r\n            ":"\r\n            将 YUV (i420) 转换成 BGRA\r\n            \r\n","\r\n            Transforms every element of src in the following way:\r\n            (x, y) -> (x'/w, y'/w),\r\n            where\r\n            (x', y', w') = mat3x3 * (x, y, 1)\r\n            and w = w'   if w'!=0,\r\n                   inf  otherwise\r\n            ":"\r\n            按以下方式转换 src 的每个元素：\r\n            (x, y) -> (x'/w, y'/w),\r\n            在哪里\r\n            (x', y', w') = mat3x3 * (x, y, 1)\r\n            并且 w = w' 如果 w'!=0,\r\n                   inf否则\r\n            \r\n","\r\n            Transform the image using the lookup table\r\n            ":"\r\n            使用查找表转换图像\r\n            \r\n","\r\n            Check to make sure all the unmanaged libraries are loaded\r\n            ":"\r\n            检查以确保加载所有非托管库\r\n            \r\n","\r\n            Get the compute capability of the device\r\n            ":"\r\n            获取设备的计算能力\r\n            \r\n","\r\n            Create an edge detection algorithm.\r\n            ":"\r\n            创建边缘检测算法。\r\n            \r\n","\r\n            Window with opengl support\r\n            ":"\r\n            支持 opengl 的窗口\r\n            \r\n","\r\n            Pointer to the InputOutputArray\r\n            ":"\r\n            指向 InputOutputArray 的指针\r\n            \r\n","The gpuMat to extract regions from.":"从中提取区域的 gpuMat。\r\n","Image width and height.":"图像宽度和高度。\r\n"," \r\n            The direction of the line, the norm of which is 1 \r\n            ":" \r\n            线的方向，范数为 1\r\n            \r\n","\r\n            Fills a connected component with given color.\r\n            ":"\r\n            用给定的颜色填充连接的组件。\r\n            \r\n","\r\n            Histogram intersection kernel. A fast kernel. K(xi,xj)=min(xi,xj).\r\n            ":"\r\n            直方图交集内核。一个快速的内核。 K(xi,xj)=min(xi,xj)。\r\n            \r\n","\r\n            Subtracts one array from another one:\r\n            dst(I)=src1(I)-src2(I) if mask(I)!=0\r\n            All the arrays must have the same type, except the mask, and the same size (or ROI size)\r\n            ":"\r\n            从一个数组中减去另一个数组：\r\n            dst(I)=src1(I)-src2(I) 如果掩码(I)!=0\r\n            所有数组必须具有相同的类型（掩码除外）和相同的大小（或 ROI 大小）\r\n            \r\n","\r\n            Create AGAST using the specific values\r\n            ":"\r\n            使用特定值创建 AGAST\r\n            \r\n","\r\n             This function is similiar to cvCalcBackProjectPatch. It slids through image, compares overlapped patches of size wxh with templ using the specified method and stores the comparison results to result\r\n            ":"\r\n             这个函数类似于 cvCalcBackProjectPatch。它滑过图像，使用指定的方法将大小为 wxh 的重叠块与 templ 进行比较，并将比较结果存储到 result\r\n            \r\n","\r\n            Linemod\r\n            ":"线路模组\r\n            \r\n"," The result of elementwise subtracting mat2 from the current matrix":" 当前矩阵逐元素减去mat2的结果\r\n","\r\n            Projects the image.\r\n            ":"\r\n            投影图像。\r\n            \r\n","\r\n            sizeof(IplImage) \r\n            ":"\r\n            sizeof(IplImage)\r\n            \r\n","The input/output matrix. It is shuffled in-place. ":"输入/输出矩阵。它就地洗牌。\r\n","\r\n            Applies Ridge Detection Filter to an input image.\r\n            Implements Ridge detection similar to the one in [Mathematica] (http://reference.wolfram.com/language/ref/RidgeFilter.html)\r\n            using the eigen values from the Hessian Matrix of the input image using Sobel Derivatives.\r\n            Additional refinement can be done using Skeletonization and Binarization.\r\n            ":"\r\n            将脊检测滤波器应用于输入图像。\r\n            实现类似于 [Mathematica] 中的 Ridge 检测 (http://reference.wolfram.com/language/ref/RidgeFilter.html)\r\n            使用 Sobel 导数使用来自输入图像的 Hessian 矩阵的特征值。\r\n            可以使用骨架化和二值化进行额外的细化。\r\n            \r\n","\r\n            The orientation\r\n            ":"\r\n            方向\r\n            \r\n","Optional depth type for the dst array":"dst 数组的可选深度类型\r\n","Line type":"线型\r\n"," The rotation angle in radian for the ellipse":" 椭圆的旋转角度（以弧度为单位）\r\n","\r\n            Use zlib included in OpenCV to perform in-memory binary compression and decompression\r\n            ":"\r\n            使用OpenCV中包含的zlib进行内存中的二进制压缩和解压缩\r\n            \r\n"," Find the edges on this image and marked them in the returned image.":" 找到此图像上的边缘并在返回的图像中标记它们。\r\n","\r\n            Batch method\r\n            ":"\r\n            批处理方法\r\n            \r\n","the point":"重点\r\n","\r\n            True if right connected\r\n            ":"\r\n            如果正确连接则为真\r\n            \r\n"," Create a Bgr565 color using the specific values":" 使用特定值创建 Bgr565 颜色\r\n","\r\n            Core class of ccm model.\r\n            ":"\r\n            ccm模型的核心类。\r\n            \r\n","\r\n            Convert Bayer GB color to BGR color\r\n            ":"\r\n            将 Bayer GB 颜色转换为 BGR 颜色\r\n            \r\n","The source which the subsamples will be derived from":"子样本的来源\r\n","The integral image, W+1xH+1, 32-bit integer or double precision floating-point (64f). ":"积分图像，W+1xH+1，32 位整数或双精度浮点数 (64f)。\r\n","\r\n            Create an standard vector of Mat with the initial values\r\n            ":"\r\n            使用初始值创建 Mat 的标准向量\r\n            \r\n","\r\n            Lanczos interpolation over 8x8 neighborhood\r\n            ":"\r\n            8x8 邻域上的 Lanczos 插值\r\n            \r\n","\r\n            Convert BGR color to Lab color\r\n            ":"\r\n            将 BGR 颜色转换为 Lab 颜色\r\n            \r\n","\r\n            Create a 3D rotation vector (3x1 Matrix).\r\n            ":"\r\n            创建一个 3D 旋转矢量（3x1 矩阵）。\r\n            \r\n","number of adjacent markers that must be detected to return a charuco corner":"返回 charuco 角必须检测到的相邻标记的数量\r\n","\r\n            Current sensor mode. Allows to select sensor mode by one integer. Setting of this parameter affects: image dimensions and downsampling.\r\n            ":"\r\n            电流传感器模式。允许通过一个整数选择传感器模式。此参数的设置会影响：图像尺寸和下采样。\r\n            \r\n","Output 8-bit 3-channel image":"输出 8 位 3 通道图像\r\n","\r\n            A convolution kernel \r\n            ":"\r\n            一个卷积核\r\n            \r\n"," The intensity for this color ":" 这种颜色的强度\r\n","Prune the area which bigger than max_area":"修剪大于 max_area 的区域\r\n","\r\n            Alpha composite types\r\n            ":"\r\n            Alpha 复合类型\r\n            \r\n","\r\n            The color correction model type\r\n            ":"\r\n            颜色校正模型类型\r\n            \r\n","\r\n            Apply convertor and compute result for each channel of the image.\r\n            ":"\r\n            为图像的每个通道应用转换器和计算结果。\r\n            \r\n","\r\n            offset for the loaded face landmark points\r\n            ":"\r\n            加载的面部标志点的偏移量\r\n            \r\n","Fast Pyramids":"快速金字塔\r\n","The file name to be saved":"要保存的文件名\r\n","\r\n            Base class for computation of odometry.\r\n            ":"\r\n            用于计算里程计的基类。\r\n            \r\n","Number of initial clusterization seeds. Must be lower or equal to initSamplingPoints.size().":"初始聚类种子数。必须小于或等于 initSamplingPoints.size()。\r\n","Number of times erosion and dilation to be applied.":"应用腐蚀和膨胀的次数。\r\n","\r\n            A (2x3) 2D rotation matrix. This Matrix defines an Affine Transform\r\n            ":"\r\n            一个 (2x3) 二维旋转矩阵。这个矩阵定义了一个仿射变换\r\n            \r\n","\r\n            Android flash mode\r\n            ":"\r\n            安卓闪光模式\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of VideoCapture.\r\n            ":"\r\n            VideoCapture 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            CV TERMCRIT type\r\n            ":"\r\n            CV TERMCRIT 类型\r\n            \r\n","\r\n            Indicates that matrix is inverse transform from destination image to source and, thus, can be used directly for pixel interpolation. Otherwise, the function finds the inverse transform from map_matrix.\r\n            ":"\r\n            表示矩阵是从目标图像到源图像的逆变换，因此可以直接用于像素插值。否则，该函数从 map_matrix 找到逆变换。\r\n            \r\n","\r\n            Release the memory associated with this network.\r\n            ":"\r\n            释放与该网络关联的内存。\r\n            \r\n","Maximum reprojection error in the RANSAC algorithm to consider a point as an inlier. Applies only to RANSAC.":"将点视为内点的 RANSAC 算法中的最大重投影误差。仅适用于 RANSAC。\r\n","The output image":"输出图像\r\n","\r\n            Parameter coef0 of a kernel function\r\n            ":"\r\n            核函数的参数 coef0\r\n            \r\n","Feature vector (CV_32FC1)":"特征向量 (CV_32FC1)\r\n","Optical flow algorithm may optionally involve cuda post processing on the output flow vectors. The output cuda stream can be used to pipeline and synchronize the cuda post processing tasks with OF HW engine. If output stream is not set, the execute function will use default stream which is NULL stream":"光流算法可以选择涉及对输出流向量的 cuda 后处理。输出 cuda 流可用于将 cuda 后处理任务与 OF HW 引擎进行流水线化和同步。如果未设置输出流，则执行函数将使用默认流，即 NULL 流\r\n","\r\n            Performs a per-element multiplication of two Fourier spectrums.\r\n            ":"\r\n            执行两个傅里叶谱的每个元素乘法。\r\n            \r\n","Minimum distance between the corners of the rejected candidate and the reprojected marker in order to consider it as a correspondence. (default 10)":"被拒绝候选的角与重新投影的标记之间的最小距离，以便将其视为对应关系。 （默认 10）\r\n","Window stride. Must be a multiple of block stride.":"窗口步幅。必须是块步幅的倍数。\r\n","\r\n            The size of CvBox2D\r\n            ":"\r\n            CvBox2D 的大小\r\n            \r\n","\r\n            L2-Hys normalization method shrinkage.\r\n            ":"\r\n            L2-Hys归一化方法收缩。\r\n            \r\n","\r\n            Learning rate\r\n            ":"\r\n            学习率\r\n            \r\n"," The result of elementwise subtracting img2 from the current image":" 当前图像逐元素减去img2的结果\r\n","grid for degree":"学位网格\r\n","The right image of the same size and the same type":"相同尺寸和相同类型的右侧图像\r\n","\r\n            The center of the box\r\n            ":"\r\n            盒子的中心\r\n            \r\n","\r\n            Use initial flow\r\n            ":"\r\n            使用初始流量\r\n            \r\n","True if the attribute exists, False otherwise.":"如果属性存在，则为 True，否则为 False。\r\n","\r\n            Pointer owner to horizontal crossings\r\n            ":"\r\n            指向水平交叉点的指针所有者\r\n            \r\n","Type of filter coefficients. It can be CV_32f or CV_64F .":"滤波器系数的类型。它可以是 CV_32f 或 CV_64F 。\r\n","The result of the transformation":"改造的结果\r\n","Mask used for unwanted area marking.":"用于不需要的区域标记的掩码。\r\n","\r\n            Create a random tree\r\n            ":"\r\n            创建一个随机树\r\n            \r\n","\r\n            Resulting contrast on logarithmic scale, i. e. log(max / min), where max and min are maximum and minimum luminance values of the resulting image.\r\n            ":"\r\n            在对数刻度上产生的对比，i。 e. log(max / min)，其中 max 和 min 是结果图像的最大和最小亮度值。\r\n            \r\n","It true, the number of threads of the current enviroment will be passed to the new backend.":"确实，当前环境的线程数将传递给新的后端。\r\n","The color for the line":"线的颜色\r\n","\r\n            Create a pipeline\r\n            ":"\r\n            创建管道\r\n            \r\n","A flag to specify how to flip the array.":"指定如何翻转数组的标志。\r\n","\r\n            Create the Brox optical flow solver\r\n            ":"\r\n            创建 Brox 光流求解器\r\n            \r\n","\r\n            The minimum variance\r\n            ":"\r\n            最小方差\r\n            \r\n","compressed descriptors of TrackerKCF::MODE":"TrackerKCF::MODE 的压缩描述符\r\n","Destination image of the same size and the same number of channels as src.":"与 src 具有相同大小和相同通道数的目标图像。\r\n"," Elementwise subtract another image from the current image, using a mask":" Elementwise 使用掩码从当前图像中减去另一个图像\r\n","\r\n            Convert Bayer Gr to RGBA\r\n            ":"\r\n            将 Bayer Gr 转换为 RGBA\r\n            \r\n","The training method.":"训练方法。\r\n","\r\n            Setting of key enables file operations on some cameras.\r\n            ":"\r\n            设置键可以在某些相机上启用文件操作。\r\n            \r\n","\r\n            BTVL using gpu\r\n            ":"\r\n            使用 gpu 的 BTVL\r\n            \r\n","\r\n            True if the input array is a vector of Mat\r\n            ":"\r\n            如果输入数组是 Mat 的向量，则为真\r\n            \r\n","The vectors of distortion coefficients for first camera, 4x1, 1x4, 5x1 or 1x5":"第一个相机的畸变系数向量，4x1、1x4、5x1 或 1x5\r\n","\r\n            Returns the mask of the superpixel segmentation stored in the ScanSegment object.\r\n            ":"\r\n            返回存储在 ScanSegment 对象中的超像素分割的掩码。\r\n            \r\n","A CudaImage that represent the region of the current CudaImage.":"代表当前 CudaImage 区域的 CudaImage。\r\n","The element-wise multiplication of the two GpuMat":"两个 GpuMat 的逐元素乘法\r\n","\r\n            Create a BoxMax filter.\r\n            ":"\r\n            创建一个 BoxMax 过滤器。\r\n            \r\n","\r\n            Reflect\r\n            ":"\r\n            反映\r\n            \r\n","Transformation flags":"转换标志\r\n","\r\n            Create OpenCL program source code\r\n            ":"\r\n            创建 OpenCL 程序源代码\r\n            \r\n","\r\n            Pointer to the native cv::reg::Mapper object\r\n            ":"\r\n            指向本机 cv::reg::Mapper 对象的指针\r\n            \r\n","\r\n            Output buffer grid size is 4x4\r\n            ":"\r\n            输出缓冲区网格大小为 4x4\r\n            \r\n","\r\n            optionally encrypt images with random convolution\r\n            ":"\r\n            可选择使用随机卷积加密图像\r\n            \r\n","The first source GpuMat":"第一个源码GpuMat\r\n","\r\n            Bad Data pointer\r\n            ":"\r\n            坏数据指针\r\n            \r\n","The new camera matrix (3x3) or the new projection matrix (3x4). P1 or P2, computed by cvStereoRectify can be passed here. If the parameter is IntPtr.Zero, the identity matrix is used.":"新的相机矩阵 (3x3) 或新的投影矩阵 (3x4)。由 cvStereoRectify 计算的 P1 或 P2 可以在这里传递。如果参数是 IntPtr.Zero，则使用单位矩阵。\r\n","\r\n            Convert a RectangleF to RotatedRect\r\n            ":"\r\n            将 RectangleF 转换为 RotatedRect\r\n            \r\n","The cvArray to be pushed into the vector":"要被推入向量的 cvArray\r\n","size of the markers in pixels.":"标记的大小（以像素为单位）。\r\n","kernel size":"内核大小\r\n"," Get a flipped copy of the convolution kernel":" 获取卷积核的翻转副本\r\n","Guided image (used to build transformed distance, which describes edge structure of guided image).":"引导图像（用于构建变换距离，描述引导图像的边缘结构）。\r\n","The initialization type":"初始化类型\r\n"," \r\n            Computes absolute different between ":" \r\n            计算之间的绝对差异\r\n","Optional output Jacobian matrix, 3x9 or 9x3 - partial derivatives of the output array components w.r.t the input array components":"可选输出雅可比矩阵，3x9 或 9x3 - 输出数组分量的偏导数 w.r.t 输入数组分量\r\n","Here the denoised image will be stored. There is no need to do pre-allocation of storage space, as it will be automatically allocated, if necessary.":"这里将存储去噪后的图像。不需要预先分配存储空间，因为它会在必要时自动分配。\r\n","\r\n            Shaves\r\n            ":"\r\n            刮胡子\r\n            \r\n","The second image for the AND operation":"AND 运算的第二张图片\r\n","\r\n            Max Area\r\n            ":"\r\n            最大面积\r\n            \r\n","\r\n            Download the files. \r\n            ":"\r\n            下载文件。\r\n            \r\n","Warp type":"经纱类型\r\n","\r\n            Given the pose estimation of a marker or board, this function draws the axis of the world coordinate system, i.e. the system centered on the marker/board. Useful for debugging purposes.\r\n            ":"\r\n            给定标记或板的姿态估计，此函数绘制世界坐标系的轴，即以标记/板为中心的系统。用于调试目的。\r\n            \r\n","The image to be converted to GPU image":"要转换为GPU图像的图像\r\n","\r\n            Get an enumerator of the file node children\r\n            ":"\r\n            获取文件节点子节点的枚举器\r\n            \r\n","The rectangle to initialize the segmentation":"初始化分割的矩形\r\n","\r\n            IEEE 1394 drivers\r\n            ":"\r\n            IEEE 1394 驱动程序\r\n            \r\n","\r\n            Convert the standard vector to an array of KeyPoint\r\n            ":"\r\n            将标准向量转换为 KeyPoint 数组\r\n            \r\n","\r\n            Release all unmanaged memory associate with the image\r\n            ":"\r\n            释放与图像关联的所有非托管内存\r\n            \r\n","The mean value":"平均值\r\n","The input image to be processed.":"要处理的输入图像。\r\n","filter Lr":"滤波器 Lr\r\n","\r\n            Change the window to fullscreen\r\n            ":"\r\n            将窗口更改为全屏\r\n            \r\n","\r\n            Create a new MCvScalar structure using the specific values\r\n            ":"\r\n            使用特定值创建新的 MCvScalar 结构\r\n            \r\n","Nms threshold for object proposals.":"目标提议的 Nms 阈值。\r\n","\r\n            Min area\r\n            ":"\r\n            最小面积\r\n            \r\n","\r\n            Return true if the two RangeF equals\r\n            ":"\r\n            如果两个 RangeF 相等则返回 true\r\n            \r\n","\r\n            Convert YUV (UYNV) to RGBA \r\n            ":"\r\n            将 YUV (UYNV) 转换为 RGBA\r\n            \r\n","\r\n            Predicts response(s) for the provided sample(s)\r\n            ":"\r\n            预测所提供样本的响应\r\n            \r\n","\r\n            The gamma value of gamma correction\r\n            ":"\r\n            伽玛校正的伽玛值\r\n            \r\n","The details channel of the retina.":"视网膜的细节通道。\r\n","\r\n            Dict7X7_250\r\n            ":"\r\n            词典7X7_250\r\n            \r\n","grayscale or color (BGR) image containing QR code.":"包含二维码的灰度或彩色 (BGR) 图像。\r\n","\r\n            Hcells spatial constant. Use 7.0 for default\r\n            ":"\r\n            H细胞空间常数。默认使用 7.0\r\n            \r\n","The output image descriptors.":"输出图像描述符。\r\n","\r\n            Finds all real and complex roots of any degree polynomial with real coefficients\r\n            ":"\r\n            找出任何具有实系数的次数多项式的所有实根和复根\r\n            \r\n","The generated all-black CV_8U image, at projector's resolution.":"以投影仪的分辨率生成的全黑 CV_8U 图像。\r\n","Statistics output for each label, including the background label, see below for available statistics. Statistics are accessed via stats(label, COLUMN) where COLUMN is one of cv::ConnectedComponentsTypes. The data type is CV_32S":"每个标签的统计输出，包括背景标签，请参阅下面的可用统计信息。通过 stats(label, COLUMN) 访问统计信息，其中 COLUMN 是 cv::ConnectedComponentsTypes 之一。数据类型为 CV_32S\r\n","\r\n            This class wraps the functional calls to the OpenCV Freetype modules\r\n            ":"\r\n            此类包装了对 OpenCV Freetype 模块的功能调用\r\n            \r\n","The color used to draw the keypoints":"用于绘制关键点的颜色\r\n","\r\n            Create an standard vector of VectorOfPoint3D32F with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfPoint3D32F 的标准向量\r\n            \r\n","\r\n            Sobel filter\r\n            ":"\r\n            索贝尔滤波器\r\n            \r\n","Single channel image CV_8UC1":"单通道图像 CV_8UC1\r\n","\r\n            Wrapped class of the C++ standard vector of Float.\r\n            ":"\r\n            Float 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Returns the hash code for this color\r\n            ":"\r\n            返回此颜色的哈希码\r\n            \r\n","Longitude in radian":"以弧度表示的经度\r\n","\r\n            Class that contains ocl functions\r\n            ":"\r\n            包含 ocl 函数的类\r\n            \r\n","Resolution of the camera.":"相机的分辨率。\r\n","Distance type":"距离型\r\n","The id of the device to be setted as current":"要设置为当前的设备的id\r\n","\r\n            The alpha channel of RGB32 output image format.\r\n            ":"\r\n            RGB32输出图像格式的alpha通道。\r\n            \r\n"," with the specified node name.\r\n            ":" 具有指定的节点名称。\r\n            \r\n","\r\n            Parse a 4D blob and output the images it contains as 2D arrays through a simpler data structure (std::vector<cv::Mat>).\r\n            ":"\r\n            解析 4D blob 并通过更简单的数据结构 (std::vector<cv::Mat>) 将其包含的图像输出为 2D 数组。\r\n            \r\n","Optional mask":"可选面罩\r\n","\r\n            Calculate the blurriness of a frame\r\n            ":"\r\n            计算帧的模糊度\r\n            \r\n","\r\n            Creates one 4-channel matrix out of 4 single-channel ones.\r\n            ":"\r\n            从 4 个单通道矩阵中创建一个 4 通道矩阵。\r\n            \r\n","\r\n            Reconstructs points by triangulation.\r\n            ":"\r\n            通过三角测量重建点。\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of KeyPoint.\r\n            ":"\r\n            KeyPoint 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            A class to upscale images via convolutional neural networks. The following four models are implemented:\r\n            \"edsr\", \"espcn\", \"fsrcnn\", \"lapsrn\"\r\n            ":"\r\n            通过卷积神经网络放大图像的类。实现了以下四种模型：\r\n            “edsr”、“espcn”、“fsrcnn”、“lapsrn”\r\n            \r\n","\r\n            Set debug level\r\n            ":"\r\n            设置调试级别\r\n            \r\n","Type of the ellipse boundary":"椭圆边界的类型\r\n","Specify the hdf5 group label.":"指定 hdf5 组标签。\r\n","The optional mask":"可选掩码\r\n","Specifies the way the template must be compared with image regions ":"指定模板必须与图像区域进行比较的方式\r\n","\r\n            The pointer to the TextDetectionModel object\r\n            ":"\r\n            指向 TextDetectionModel 对象的指针\r\n            \r\n","\r\n            Saves the image to the specified file. The image format is chosen depending on the filename extension, see cvLoadImage. Only 8-bit single-channel or 3-channel (with 'BGR' channel order) images can be saved using this function. If the format, depth or channel order is different, use cvCvtScale and cvCvtColor to convert it before saving, or use universal cvSave to save the image to XML or YAML format\r\n            ":"\r\n            将图像保存到指定文件。图像格式的选择取决于文件扩展名，参见 cvLoadImage。使用此功能只能保存 8 位单通道或 3 通道（具有“BGR”通道顺序）图像。如果格式、深度或通道顺序不同，请在保存前使用 cvCvtScale 和 cvCvtColor 进行转换，或者使用通用的 cvSave 将图像保存为 XML 或 YAML 格式\r\n            \r\n","String identifying the C locale after applying the changes, if any, or null pointer on failure. A copy of the returned string along with the category used in this call to std::setlocale may be used later in the program to restore the locale back to the state at the end of this call.":"应用更改后标识 C 语言环境的字符串（如果有）或失败时为空指针。返回的字符串的副本连同在此调用 std::setlocale 中使用的类别可以稍后在程序中用于将语言环境恢复到此调用结束时的状态。\r\n","Diameter of each pixel neighborhood that is used during filtering. If it is non-positive, it is computed from sigmaSpace .":"过滤期间使用的每个像素邻域的直径。如果它是非正数，则根据 sigmaSpace 计算。\r\n","Maximum level of the pyramid for the segmentation. Use 1 as default value":"用于分段的金字塔的最大级别。使用 1 作为默认值\r\n","\r\n            KCF is a novel tracking framework that utilizes properties of circulant matrix to enhance the processing speed.\r\n            The original paper of KCF is available at http://home.isr.uc.pt/~henriques/circulant/index.html\r\n            as well as the matlab implementation.\r\n            ":"\r\n            KCF 是一种新颖的跟踪框架，它利用循环矩阵的特性来提高处理速度。\r\n            KCF 的原始论文可以在 http://home.isr.uc.pt/~henriques/circulant/index.html 找到\r\n            以及matlab实现。\r\n            \r\n","\r\n            Fast geodesic interpolation\r\n            ":"\r\n            快速测地线插值\r\n            \r\n","\r\n            Get the interface implementation from assemblies\r\n            ":"\r\n            从程序集中获取接口实现\r\n            \r\n","\r\n            Not Implemented\r\n            ":"\r\n            未实现\r\n            \r\n","Name of the window":"窗口名称\r\n","\r\n            The lines extraction methodology described in the following is mainly based on: R Grompone Von Gioi, Jeremie Jakubowicz, Jean-Michel Morel, and Gregory Randall. Lsd: A fast line segment detector with a false detection control. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(4):722-732, 2010.\r\n            ":"\r\n            下面描述的线条提取方法主要基于：R Grompone Von Gioi、Jeremie Jakubowicz、Jean-Michel Morel 和 Gregory Randall。 Lsd：具有错误检测控制的快速线段检测器。 IEEE 模式分析和机器智能汇刊，32(4):722-732, 2010。\r\n            \r\n","\r\n            A generalized Deriv operator.\r\n            ":"\r\n            广义 Deriv 运算符。\r\n            \r\n","If true, we will try to see if we can create an Image object that shared the pixel memory with this Mat.":"如果为真，我们将尝试查看是否可以创建一个与此 Mat 共享像素内存的 Image 对象。\r\n","Full affine":"全仿射\r\n","True if barcode is detected and decoded.":"如果检测到并解码条形码，则为真。\r\n","The image such that: dst(x,y) = 0, if src(x,y)>threshold;  src(x,y), otherwise":"图像满足：dst(x,y) = 0，如果 src(x,y)>threshold； src(x,y)，否则\r\n","\r\n            Creates implementation for the minimum eigen value of a 2x2 derivative covariation matrix (the cornerness criteria).\r\n            ":"\r\n            为 2x2 导数协方差矩阵（拐点标准）的最小特征值创建实现。\r\n            \r\n","The size of the vector":"矢量的大小\r\n"," Get or set the intensity of the green color channel ":" 获取或设置绿色通道的强度\r\n","\r\n              an integer\r\n            ":"\r\n              一个整数\r\n            \r\n","\r\n            An Efficient Algebraic Solution to the Perspective-Three-Point Problem\r\n            ":"\r\n            透视三点问题的有效代数解法\r\n            \r\n","\r\n            General enumeration\r\n            ":"\r\n            一般枚举\r\n            \r\n","\r\n            if arr2 is NULL, norm = ||arr1||_L2 = sqrt( sum_I arr1(I)^2);\r\n            if arr2 is not NULL, norm = ||arr1-arr2||_L2 = sqrt( sum_I (arr1(I)-arr2(I))^2 )\r\n            ":"\r\n            如果 arr2 为 NULL，norm = ||arr1||_L2 = sqrt( sum_I arr1(I)^2);\r\n            如果 arr2 不为 NULL，则 norm = ||arr1-arr2||_L2 = sqrt( sum_I (arr1(I)-arr2(I))^2 )\r\n            \r\n","\r\n            Returns true if the node is empty\r\n            ":"\r\n            如果节点为空则返回真\r\n            \r\n","True if the property is supported by backend used by the VideoCapture instance.":"如果 VideoCapture 实例使用的后端支持该属性，则为真。\r\n","Type of the polygon boundaries":"多边形边界的类型\r\n","\r\n            The scalar value\r\n            ":"\r\n            标量值\r\n            \r\n","\r\n            Fills arrays with random numbers.\r\n            ":"\r\n            用随机数填充数组。\r\n            \r\n","\r\n            Uncompress the data \r\n            ":"\r\n            解压缩数据\r\n            \r\n","\r\n            Reads the double from the node.\r\n            ":"\r\n            从节点读取双精度值。\r\n            \r\n","\r\n            Convert YCrCb color to RGB color\r\n            ":"\r\n            将 YCrCb 颜色转换为 RGB 颜色\r\n            \r\n","\r\n            Renders the text in the image with the specified font and color. The printed text is clipped by ROI rectangle. Symbols that do not belong to the specified font are replaced with the rectangle symbol.\r\n            ":"\r\n            使用指定的字体和颜色呈现图像中的文本。打印的文本被 ROI 矩形裁剪。不属于指定字体的符号将替换为矩形符号。\r\n            \r\n","\r\n            Get or set the intensity of the z color channel\r\n            ":"\r\n            获取或设置 z 颜色通道的强度\r\n            \r\n","\r\n            Reconstructs the selected image area from the pixel near the area boundary. The function may be used to remove dust and scratches from a scanned photo, or to remove undesirable objects from still images or video.\r\n            ":"\r\n            从区域边界附近的像素重建选定的图像区域。该功能可用于去除扫描照片中的灰尘和划痕，或去除静止图像或视频中不需要的对象。\r\n            \r\n","If set to true the image is cropped to its original size, possibly losing corners information. If set to false the result image has different size than original and all rotation information is preserved":"如果设置为 true，图像将被裁剪为其原始大小，可能会丢失边角信息。如果设置为 false，则结果图像的大小与原始图像的大小不同，并且会保留所有旋转信息\r\n","Threshold for LSBP binary string.":"LSBP 二进制字符串的阈值。\r\n","The depth type of the image that will be used in the template matching":"将在模板匹配中使用的图像的深度类型\r\n","dictionary of markers indicating the type of markers.":"指示标记类型的标记字典。\r\n","The sub-sample rate":"子采样率\r\n","\r\n            Ocean\r\n            ":"\r\n            海洋\r\n            \r\n","\r\n            version (=0)\r\n            ":"\r\n            版本 (=0)\r\n            \r\n","The points to be fitted":"需要拟合的点\r\n","\r\n            result = val - this, using a mask\r\n            ":"\r\n            result = val - 这个，使用掩码\r\n            \r\n","Names for layers which outputs are needed to get":"需要获取输出的层的名称\r\n","\r\n            RF\r\n            ":"\r\n            射频\r\n            \r\n","\r\n            The KNearest classifier\r\n            ":"\r\n            KNearest 分类器\r\n            \r\n","Input image. Supported format: CV_8UC3. Image size must match with the initialized image size with the function createScanSegment(). It MUST be in Lab color space.":"输入图像。支持的格式：CV_8UC3。图像大小必须与使用函数 createScanSegment() 初始化的图像大小匹配。它必须在 Lab 色彩空间中。\r\n","\r\n            Start the Delaunay's triangulation in the specific region of interest.\r\n            ":"\r\n            在特定的感兴趣区域启动 Delaunay 的三角测量。\r\n            \r\n","\r\n            Override EXR compression type (ZIP_COMPRESSION = 3 is default)\r\n            ":"\r\n            覆盖 EXR 压缩类型（ZIP_COMPRESSION = 3 是默认值）\r\n            \r\n","16-bit y derivative of input image":"输入图像的 16 位 y 导数\r\n","Sets the new focal length in range between the min focal length and the max focal length. Balance is in range of [0, 1].":"在最小焦距和最大焦距之间的范围内设置新的焦距。余额在 [0, 1] 范围内。\r\n","\r\n            median filtering for each point of the source image.\r\n            ":"\r\n            对源图像的每个点进行中值滤波。\r\n            \r\n"," The result of element wise subtracting ":" 逐元素相减的结果\r\n","\r\n            Delete an attribute from the root group.\r\n            ":"\r\n            从根组中删除一个属性。\r\n            \r\n"," Elementwise subtract another image from the current image ":" Elementwise 从当前图像中减去另一个图像\r\n","The same as h but for color components. For most images value equals 10 will be enought to remove colored noise and do not distort colors.":"与 h 相同，但用于颜色分量。对于大多数图像，值等于 10 将足以去除彩色噪声并且不会扭曲颜色。\r\n","\r\n            Return device serial number\r\n            ":"\r\n            返回设备序列号\r\n            \r\n","\r\n            Convert YUV (YV12) to RGB\r\n            ":"\r\n            将 YUV (YV12) 转换为 RGB\r\n            \r\n","\r\n            Remove centroids in k-means whose weight is lesser or equal to given threshold.\r\n            ":"\r\n            删除 k-means 中权重小于或等于给定阈值的质心。\r\n            \r\n","\r\n            Create an standard vector of CvString with the initial values\r\n            ":"\r\n            使用初始值创建 CvString 的标准向量\r\n            \r\n","Cluster min magnitude. Increase to trade off accuracy for speed.":"聚类最小震级。增加以牺牲速度的准确性。\r\n","Minimum gap between lines":"最小线间距\r\n","contrast measure weight.":"对比测量体重。\r\n","Optional depth of the output array; when both input arrays have the same depth":"输出数组的可选深度；当两个输入数组具有相同的深度时\r\n","\r\n            Create a  new homography based rotation estimator\r\n            ":"\r\n            创建一个新的基于单应性的旋转估计器\r\n            \r\n","The size of the input image":"输入图像的大小\r\n","The second zero-based component of the element index":"元素索引的第二个从零开始的组件\r\n","\r\n            Create an EMD-L1 based cost extraction.\r\n            ":"\r\n            创建基于 EMD-L1 的成本提取。\r\n            \r\n","\r\n            Current quality (0..100%) of the encoded videostream. Can be adjusted dynamically in some codecs.\r\n            ":"\r\n            编码视频流的当前质量 (0..100%)。可以在某些编解码器中动态调整。\r\n            \r\n","\r\n            Color Correction Matrix element [1][0]\r\n            ":"\r\n            颜色校正矩阵元素 [1][0]\r\n            \r\n","\r\n            src1(I) \"less or equal\" src2(I)\r\n            ":"\r\n            src1(I) \"小于或等于\" src2(I)\r\n            \r\n"," The value to be added to the pixel":"要添加到像素的值\r\n","Vector that will store extracted lines for one or more images":"将存储一个或多个图像的提取线的矢量\r\n","\r\n            Size of file.\r\n            ":"\r\n            文件大小。\r\n            \r\n","The data for the Y-axis":"Y轴的数据\r\n","\r\n            Initializes the image header structure, pointer to which is passed by the user, and returns the pointer.\r\n            ":"\r\n            初始化图像头结构，指向用户传递的指针，并返回指针。\r\n            \r\n","\r\n            constant for adaptive thresholding before finding contours (default 7)\r\n            ":"\r\n            查找轮廓前的自适应阈值常数（默认 7）\r\n            \r\n","\r\n            Create a new keypoints model\r\n            ":"\r\n            创建一个新的关键点模型\r\n            \r\n","Caffe file path for the super resolution model":"超分辨率模型的 Caffe 文件路径\r\n","The next frame":"下一帧\r\n","\r\n            Reset the native pointer to the MergeExposure object\r\n            ":"\r\n            将本机指针重置为 MergeExposure 对象\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of KeyLine.\r\n            ":"\r\n            KeyLine 的 C++ 标准向量的包装类。\r\n            \r\n","size of the output image in pixels.":"输出图像的大小（以像素为单位）。\r\n","\r\n            Get the color type of the image\r\n            ":"\r\n            获取图片的颜色类型\r\n            \r\n","\r\n            Same as Grana. It is preferable to use the flag with the name of the algorithm (BBDT) rather than the one with the name of the first author (Grana).\r\n            ":"\r\n            和格拉纳一样。最好使用带有算法名称 (BBDT) 的标志，而不是带有第一作者 (Grana) 名称的标志。\r\n            \r\n","\r\n            Convert RGBA color to GRAY color\r\n            ":"\r\n            将 RGBA 颜色转换为 GRAY 颜色\r\n            \r\n","\r\n            Pointer to the unmanaged Algorithm object\r\n            ":"\r\n            指向非托管算法对象的指针\r\n            \r\n","The output matrix of N x M size and the same type as src.":"N x M 大小和与 src 相同类型的输出矩阵。\r\n","First threshold for hysteresis procedure in Canny().":"Canny() 中滞后程序的第一个阈值。\r\n","\r\n            Return True if mask is supported\r\n            ":"\r\n            如果支持掩码则返回 True\r\n            \r\n","Only useful if param useRetinaLogSampling=true, specifies the reduction factor of the output frame (as the center (fovea) is high resolution and corners can be underscaled, then a reduction of the output is allowed without precision leak":"仅当参数 useRetinaLogSampling = true 时有用，指定输出帧的缩减因子（因为中心（中央凹）是高分辨率并且角落可以缩小，然后允许减少输出而不会出现精度泄漏\r\n","The N 2D-points to be rotated":"要旋转的 N 个 2D 点\r\n","\r\n            Waits for key event infinitely (delay <= 0) or for \"delay\" milliseconds. \r\n            ":"\r\n            无限等待按键事件（延迟 <= 0）或“延迟”毫秒。\r\n            \r\n","\r\n            Applies a fixed-level threshold to each array element.\r\n            The function applies fixed-level thresholding to a multiple-channel array. The function is typically used to get a bi-level (binary) image out of a grayscale image ( compare could be also used for this purpose) or for removing a noise, that is, filtering out pixels with too small or too large values. There are several types of thresholding supported by the function. They are determined by type parameter.\r\n            ":"\r\n            对每个数组元素应用固定级别的阈值。\r\n            该函数将固定级别的阈值应用于多通道数组。该函数通常用于从灰度图像中获取二值（二进制）图像（比较也可用于此目的）或用于去除噪声，即过滤掉值过小或过大的像素。该函数支持多种类型的阈值。它们由类型参数确定。\r\n            \r\n","True if the two points are equal":"如果两点相等则为真\r\n","\r\n            This function has several different purposes and thus has several synonyms. It copies one array to another with optional scaling, which is performed first, and/or optional type conversion, performed after:\r\n            dst(I)=src(I)*scale + (shift,shift,...)\r\n            All the channels of multi-channel arrays are processed independently.\r\n            The type conversion is done with rounding and saturation, that is if a result of scaling + conversion can not be represented exactly by a value of destination array element type, it is set to the nearest representable value on the real axis.\r\n            In case of scale=1, shift=0 no prescaling is done. This is a specially optimized case and it has the appropriate cvConvert synonym. If source and destination array types have equal types, this is also a special case that can be used to scale and shift a matrix or an image and that fits to cvScale synonym.\r\n            ":"\r\n            这个函数有几个不同的用途，因此有几个同义词。它使用可选缩放将一个数组复制到另一个数组，首先执行，和/或可选类型转换，之后执行：\r\n            dst(I)=src(I)*scale + (shift,shift,...)\r\n            多通道阵列的所有通道都是独立处理的。\r\n            类型转换是通过舍入和饱和来完成的，也就是说，如果缩放 + 转换的结果不能用目标数组元素类型的值准确表示，则将其设置为实轴上最接近的可表示值。\r\n            在 scale=1，shift=0 的情况下，不进行预缩放。这是一个特别优化的案例，它有适当的 cvConvert 同义词。如果源和目标数组类型具有相同的类型，这也是一种特殊情况，可用于缩放和移动矩阵或图像并且适合 cvScale 同义词。\r\n            \r\n","\r\n            Returns list of available backends which works via cv::VideoCapture(int index)\r\n            ":"\r\n            返回通过 cv::VideoCapture(int index) 工作的可用后端列表\r\n            \r\n","iwscale":"iwscale\r\n","\r\n            UPC-E\r\n            ":"\r\n            UPC-E\r\n            \r\n","\r\n            The wave correction type.\r\n            ":"\r\n            波形校正类型。\r\n            \r\n","\r\n            Use the input flow as the initial flow approximation\r\n            ":"\r\n            使用输入流量作为初始流量近似值\r\n            \r\n","The optional operation mask":"可选操作掩码\r\n","\r\n            use fewer block and generate 16*16/8 uchar hash value\r\n            ":"\r\n            使用更少的块并生成 16*16/8 uchar 哈希值\r\n            \r\n","\r\n            Inner iterations (between outlier filtering) used in the numerical scheme\r\n            ":"\r\n            数值方案中使用的内部迭代（异常值过滤之间）\r\n            \r\n",") rows of the CudaImage":") CudaImage 的行\r\n","\r\n            SLIC segments image using a desired region_size\r\n            ":"\r\n            SLIC 使用所需的 region_size 分割图像\r\n            \r\n","Sequence or array of 2D points":"二维点序列或数组\r\n","The images plus the color":"图片加上颜色\r\n","The minor version of the compute capability":"计算能力的次要版本\r\n","\r\n            Convert YUV (YUNV) to BGR\r\n            ":"\r\n            将 YUV (YUNV) 转换成 BGR\r\n            \r\n","\r\n            Convert double scalar to InputArray\r\n            ":"\r\n            将双标量转换为 InputArray\r\n            \r\n","\r\n            Reset the pointer that points to the CalibrateCRF object.\r\n            ":"\r\n            重置指向 CalibrateCRF 对象的指针。\r\n            \r\n","\r\n            Methods for comparing two array\r\n            ":"比较两个数组的方法\r\n            \r\n","\r\n            Generate 4-character code of codec used to compress the frames. For example, CV_FOURCC('P','I','M','1') is MPEG-1 codec, CV_FOURCC('M','J','P','G') is motion-jpeg codec etc.\r\n            ":"\r\n            生成用于压缩帧的编解码器的 4 字符代码。例如，CV_FOURCC('P','I','M','1') 是 MPEG-1 编解码器，CV_FOURCC('M','J','P','G') 是 motion-jpeg 编解码器ETC。\r\n            \r\n","Size of the averaging block, passed to underlying cvCornerMinEigenVal or cvCornerHarris used by the function.":"平均块的大小，传递给函数使用的底层 cvCornerMinEigenVal 或 cvCornerHarris。\r\n","\r\n             The grab cut algorithm for segmentation\r\n             ":"\r\n             用于分割的抓取算法\r\n             \r\n","The function can be used to dynamically turn on and off optimized code (code that uses SSE2, AVX, and other instructions on the platforms that support it). It sets a global flag that is further checked by OpenCV functions. Since the flag is not checked in the inner OpenCV loops, it is only safe to call the function on the very top level in your application where you can be sure that no other OpenCV function is currently executed.":"该函数可用于动态打开和关闭优化代码（在支持它的平台上使用 SSE2、AVX 和其他指令的代码）。它设置一个全局标志，由 OpenCV 函数进一步检查。由于在内部 OpenCV 循环中未检查该标志，因此只有在您的应用程序的最顶层调用该函数才是安全的，您可以确保当前没有其他 OpenCV 函数被执行。\r\n","\r\n            Returns the norm of a matrix.\r\n            ":"\r\n            返回矩阵的范数。\r\n            \r\n",", predict the probability of the ":", 预测的概率\r\n","\r\n            IC\r\n            ":"\r\n            我知道了\r\n            \r\n","\r\n            Finishes writing to video file and releases the structure.\r\n            ":"\r\n            完成写入视频文件并释放结构。\r\n            \r\n","Layout of markers in the board.":"板上标记的布局。\r\n","The method for solving the equation":"解方程的方法\r\n"," An image where each pixel is the minimum of ":" 每个像素是以下最小值的图像\r\n"," Get or set the intensity of the red color channel ":" 获取或设置红色通道的强度\r\n","\r\n            Computes Signature Quadratic Form Distance between the reference signature and each of the other image signatures.\r\n            ":"\r\n            计算参考签名和每个其他图像签名之间的签名二次形式距离。\r\n            \r\n","\r\n            Min Area\r\n            ":"\r\n            最小面积\r\n            \r\n","\r\n            Updates window title\r\n            ":"\r\n            更新窗口标题\r\n            \r\n","\r\n            Color Correction Matrix element [3][2]\r\n            ":"\r\n            颜色校正矩阵元素 [3][2]\r\n            \r\n","Constant subtracted from mean or weighted mean. It may be negative. ":"从平均值或加权平均值中减去常数。它可能是负面的。\r\n","Matches returned by the GMS matching strategy.":"GMS 匹配策略返回的匹配项。\r\n","\r\n            Accerlerator\r\n            ":"\r\n            加速器\r\n            \r\n","\r\n            Spring\r\n            ":"\r\n            春天\r\n            \r\n","The color with with to fill the background":"填充背景的颜色\r\n","\r\n            Normalise output\r\n            ":"\r\n            标准化输出\r\n            \r\n","Left view of the original stereo-pair to guide the filtering process, 8-bit single-channel or three-channel image.":"左视图原始立体对引导滤波过程，8 位单通道或三通道图像。\r\n","\r\n            Reject quads where pairs of edges have angles that are close to straight or close to\r\n            180 degrees.Zero means that no quads are rejected. (In radians).\r\n            ":"\r\n            拒绝边对的角度接近直线或接近直线的四边形\r\n            180 度。零意味着没有四边形被拒绝。 （以弧度为单位）。\r\n            \r\n","\r\n            Calculates absolute difference between two arrays.\r\n            dst(I)c = abs(src1(I)c - src2(I)c).\r\n            All the arrays must have the same data type and the same size (or ROI size)\r\n            ":"\r\n            计算两个数组之间的绝对差。\r\n            dst(I)c = abs(src1(I)c - src2(I)c)。\r\n            所有数组必须具有相同的数据类型和相同的大小（或 ROI 大小）\r\n            \r\n","The found line segments":"找到的线段\r\n","\r\n            Convert YUV320i to RGBA\r\n            ":"\r\n            将 YUV320i 转换为 RGBA\r\n            \r\n","The name of the file to be saved to":"要保存到的文件的名称\r\n","\r\n            Max X\r\n            ":"\r\n            最大 X\r\n            \r\n","\r\n            Bit exact nearest neighbor interpolation. This will produce same results as\r\n            the nearest neighbor method in PIL, scikit-image or Matlab.\r\n            ":"\r\n            位精确最近邻插值。这将产生与以下相同的结果\r\n            PIL、scikit-image 或 Matlab 中的最近邻方法。\r\n            \r\n","\r\n            Return the matrix without a specified column span of the input array\r\n            ":"\r\n            返回输入数组没有指定列跨度的矩阵\r\n            \r\n","\r\n            Convert RGBA color to BGR555 color\r\n            ":"\r\n            将 RGBA 颜色转换为 BGR555 颜色\r\n            \r\n","\r\n            The name of the function the error is encountered\r\n            ":"\r\n            遇到错误的函数名\r\n            \r\n","Output GScalar of the defined binary computation":"定义的二进制计算的输出 GScalar\r\n","\r\n            Pencil-like non-photorealistic line drawing\r\n            ":"\r\n            类似铅笔的非真实感线条图\r\n            \r\n","The other matrix to concate":"要连接的另一个矩阵\r\n"," The standard deviation of the Gaussian kernel in the horizontal dimension":" 高斯核在水平维度上的标准差\r\n","3d points":"3d点\r\n","The pointer to the matrix":"指向矩阵的指针\r\n","\r\n            Performs marker detection in the input image. Only markers included in the specific dictionary are searched. For each detected marker, it returns the 2D position of its corner in the image and its corresponding identifier. Note that this function does not perform pose estimation.\r\n            ":"\r\n            在输入图像中执行标记检测。仅搜索包含在特定词典中的标记。对于每个检测到的标记，它返回其角在图像中的二维位置及其相应的标识符。请注意，此功能不执行姿势估计。\r\n            \r\n","The number of desired features. ":"所需功能的数量。\r\n","\r\n            Type of a SVM formulation\r\n            ":"\r\n            SVM 公式的类型\r\n            \r\n","If non-zero, the function accepts multi-dimensional dense arrays (CvMatND*) and returns 2D (if CvMatND has two dimensions) or 1D matrix (when CvMatND has 1 dimension or more than 2 dimensions). The array must be continuous":"如果非零，该函数接受多维密集数组 (CvMatND*) 并返回 2D（如果 CvMatND 具有二维）或 1D 矩阵（当 CvMatND 具有 1 维或多于 2 维时）。数组必须是连续的\r\n","Camera intrinsic":"相机本征\r\n","Output 3D affine transformation matrix 3 x 4":"输出 3D 仿射变换矩阵 3 x 4\r\n","\r\n            Computes eigenvalues and eigenvectors of a symmetric matrix\r\n            ":"\r\n            计算对称矩阵的特征值和特征向量\r\n            \r\n","Pointer to the array header":"指向数组头的指针\r\n","\r\n            Number of buffers to commit to low level\r\n            ":"\r\n            提交到低级别的缓冲区数\r\n            \r\n","Value of the window property":"窗口属性的值\r\n","GpuMat representation of the keypoints.":"关键点的 GpuMat 表示。\r\n","Per-element difference between given scalar and the matrix.":"给定标量和矩阵之间的每个元素差异。\r\n","value used in case of a constant border":"在恒定边界的情况下使用的值\r\n","\r\n            Color resolution of the greyscale bitmap represented in allocated bits (i.e., value 4 means that 16 shades of grey are used). The greyscale bitmap is used for computing contrast and entropy values.\r\n            ":"\r\n            以分配的位表示的灰度位图的颜色分辨率（即值 4 表示使用 16 种灰色阴影）。灰度位图用于计算对比度和熵值。\r\n            \r\n","\r\n            full row length in bytes\r\n            ":"\r\n            以字节为单位的完整行长度\r\n            \r\n","Output header to be filled":"需要填充的输出头\r\n","\r\n            Max buffer size\r\n            ":"\r\n            最大缓冲区大小\r\n            \r\n","\r\n            Constructs an WArrow.\r\n            ":"\r\n            构造一个 WArrow。\r\n            \r\n","\r\n            Image width\r\n            ":"\r\n            图片宽度\r\n            \r\n","Optional camera calibration matrix.":"可选的相机校准矩阵。\r\n","Vector size":"矢量大小\r\n","border style.":"边框样式。\r\n","Histogram bins":"直方图箱\r\n","The image to read the pixel intensities values from":"从中读取像素强度值的图像\r\n","Pre-saturation flag; for uniform distribution only; if true, the method will first convert a and b to the acceptable value range (according to the mat datatype) and then will generate uniformly distributed random numbers within the range [saturate(a), saturate(b)), if saturateRange=false, the method will generate uniformly distributed random numbers in the original range [a, b) and then will saturate them":"预饱和标志；仅用于均匀分布；如果为真，该方法将首先将 a 和 b 转换到可接受的值范围（根据 mat 数据类型），然后将生成范围 [saturate(a), saturate(b)) 内的均匀分布的随机数，如果 saturateRange=false ，该方法将在原始范围 [a, b) 内生成均匀分布的随机数，然后将它们饱和\r\n","Optional scale factor for the computed derivative values. By default, no scaling is applied.":"计算导数值的可选比例因子。默认情况下，不应用缩放。\r\n","The per-element bit-wise logical \"exclusive or\" of two matrices of the same size.":"两个相同大小的矩阵的每个元素按位逻辑“异或”。\r\n","Border value in case of a constant border. ":"边界不变时的边界值。\r\n","The maximum location":"最大位置\r\n","\r\n            Release the unmanaged resources associated with the ICP\r\n            ":"\r\n            释放与 ICP 关联的非托管资源\r\n            \r\n","\r\n            Classical or standard Hough transform. Every line is represented by two floating-point numbers (rho, theta), where rho is a distance between (0,0) point and the line, and theta is the angle between x-axis and the normal to the line. Thus, the matrix must be (the created sequence will be) of CV_32FC2 type\r\n            ":"\r\n            经典或标准霍夫变换。每条线由两个浮点数 (rho, theta) 表示，其中 rho 是 (0,0) 点与线之间的距离，theta 是 x 轴与线的法线之间的角度。因此，矩阵必须是（创建的序列将是）CV_32FC2 类型\r\n            \r\n","\r\n            This is a variation of\r\n            \"Stereo Processing by Semiglobal Matching and Mutual Information\"\r\n            by Heiko Hirschmuller.\r\n            We match blocks rather than individual pixels, thus the algorithm is called\r\n            SGBM (Semi-global block matching)\r\n            ":"\r\n            这是一个变体\r\n            “通过半全局匹配和互信息进行立体处理”\r\n            海科·赫斯穆勒 (Heiko Hirschmuller) 着。\r\n            我们匹配块而不是单个像素，因此该算法称为\r\n            SGBM（半全局块匹配）\r\n            \r\n","\r\n            Fourier-assisted phase-shifting profilometry\r\n            ":"\r\n            傅里叶辅助相移轮廓测量法\r\n            \r\n","Border mode. Use BORDER_CONSTANT for default.":"边界模式。默认使用 BORDER_CONSTANT。\r\n","The image to be subtracted":"要减去的图像\r\n","tream for the asynchronous version.":"tream 为异步版本。\r\n","\r\n            Filter by circularity\r\n            ":"\r\n            按循环过滤\r\n            \r\n","The name of the predefined dictionary":"预定义词典的名称\r\n","\r\n            32bit signed \r\n            ":"\r\n            32位签名\r\n            \r\n","The center for the convolution kernel":"卷积核的中心\r\n","\r\n            Entry points to the Open CV Stitching module.\r\n            ":"\r\n            Open CV Stitching 模块的入口点。\r\n            \r\n","Gain for the R channel":"R 通道的增益\r\n","First input matrix":"第一个输入矩阵\r\n","\r\n            Predict auto\r\n            ":"\r\n            预测汽车\r\n            \r\n"," The line segment to be drawn":" 要绘制的线段\r\n","\r\n            Max y value\r\n            ":"\r\n            最大 y 值\r\n            \r\n","\r\n            Perform inplace advanced morphological transformations using erosion and dilation as basic operations.\r\n            ":"\r\n            使用腐蚀和膨胀作为基本操作执行就地高级形态转换。\r\n            \r\n","Parameter of Gaussian weighting.":"高斯加权参数。\r\n","\r\n            Parameters for LK flow algorithm\r\n            ":"\r\n            LK流算法的参数\r\n            \r\n","\r\n            MPEG4\r\n            ":"\r\n            MPEG4\r\n            \r\n","\r\n            Automatic white balance\r\n            ":"\r\n            自动白平衡\r\n            \r\n","The minimum size of segments":"段的最小尺寸\r\n","The scalar to shift by.":"要移动的标量。\r\n","\r\n            Method for solving a PnP problem\r\n            ":"\r\n            解决 PnP 问题的方法\r\n            \r\n","\r\n            Convert YUV (YUYV) to BGRA\r\n            ":"\r\n            将 YUV (YUYV) 转换成 BGRA\r\n            \r\n","joint (also called as guided) image or array of images with any numbers of channels.":"具有任意数量通道的联合（也称为引导）图像或图像阵列。\r\n","input floating-point array of angles of 2D vectors.":"输入二维向量角度的浮点数组。\r\n","The GpuMat to be reshaped.":"要重塑的 GpuMat。\r\n","\r\n            Get the size of the bin dimensions\r\n            ":"\r\n            获取 bin 维度的大小\r\n            \r\n","\r\n            Pointer to the native BackgroundSubstractor object\r\n            ":"\r\n            指向本机 BackgroundSubstractor 对象的指针\r\n            \r\n","The default parameter grid for the specific SVM type ":"特定 SVM 类型的默认参数网格\r\n","The number of channels for this matrix":"该矩阵的通道数\r\n","\r\n            Create a new DataLogger\r\n            ":"\r\n            创建一个新的数据记录器\r\n            \r\n","\r\n            Convert Luv color to RGB color\r\n            ":"\r\n            将 Luv 颜色转换为 RGB 颜色\r\n            \r\n","Resulting array.":"结果数组。\r\n","\r\n            Train the face recognizer with the specific images and labels\r\n            ":"\r\n            使用特定图像和标签训练人脸识别器\r\n            \r\n","\r\n            Execute the kernel\r\n            ":"\r\n            执行内核\r\n            \r\n","The relative or absolute path to the prototxt file describing the classifiers architecture.":"描述分类器架构的 prototxt 文件的相对或绝对路径。\r\n","Array of points for which the flow needs to be found":"需要找到流的点数组\r\n","The function finds minimum (m(x,y)) and maximum (M(x,y)) mhi values over each pixel (x,y) neihborhood and assumes the gradient is valid only if min(delta1,delta2) <= M(x,y)-m(x,y) <= max(delta1,delta2). ":"该函数找到每个像素 (x,y) 邻域的最小 (m(x,y)) 和最大 (M(x,y)) mhi 值，并假设梯度仅在 min(delta1,delta2) <= M 时有效(x,y)-m(x,y) <= max(delta1,delta2)。\r\n","True if successfully encoded the image into the buffer.":"如果成功将图像编码到缓冲区中，则为真。\r\n","\r\n            Pass2 only\r\n            ":"\r\n            仅限 Pass2\r\n            \r\n","A transposed convolution kernel":"转置卷积核\r\n","Coordinates of the 4 corresponding quadrangle vertices in the destination image":"目标图像中4个对应四边形顶点的坐标\r\n","\r\n            Sorts each matrix row or each matrix column in\r\n            ascending or descending order.So you should pass two operation flags to\r\n            get desired behaviour.\r\n            ":"\r\n            对每个矩阵行或每个矩阵列进行排序\r\n            升序或降序。所以你应该将两个操作标志传递给\r\n            获得所需的行为。\r\n            \r\n","\r\n            The native pointer to the tracker\r\n            ":"\r\n            指向跟踪器的本机指针\r\n            \r\n"," A copy of the image":" 图像的副本\r\n","\r\n            All the input vectors are stored in a single matrix, as its rows \r\n            ":"\r\n            所有输入向量都存储在一个矩阵中，作为它的行\r\n            \r\n","\r\n            Create an standard vector of ERStat of the specific size\r\n            ":"\r\n            创建特定大小的 ERStat 标准向量\r\n            \r\n","\r\n            Spatial Moment M01\r\n            ":"\r\n            空间时刻M01\r\n            \r\n","\r\n            Convert BGR555 color to BGR color\r\n            ":"\r\n            将 BGR555 颜色转换为 BGR 颜色\r\n            \r\n","\r\n            Performs soft non maximum suppression given boxes and corresponding scores. Reference: https://arxiv.org/abs/1704.04503\r\n            ":"\r\n            执行给定框和相应分数的软非最大抑制。参考：https://arxiv.org/abs/1704.04503\r\n            \r\n","The bin values":"bin 值\r\n","\r\n            Create a Marr-Hildreth operator based hash.\r\n            ":"\r\n            创建基于 Marr-Hildreth 运算符的哈希。\r\n            \r\n","\r\n            Return True if the matcher is empty \r\n            ":"\r\n            如果匹配器为空则返回 True\r\n            \r\n","Maximal level for drawn contours. If 0, only contour is drawn. If 1, the contour and all contours after it on the same level are drawn. If 2, all contours after and all contours one level below the contours are drawn, etc. If the value is negative, the function does not draw the contours following after contour but draws child contours of contour up to abs(maxLevel)-1 level. ":"绘制轮廓的最大级别。如果为 0，则只绘制轮廓。如果为 1，则绘制同一级别的等高线及其后的所有等高线。如果为 2，则绘制轮廓之后的所有轮廓以及轮廓下一层的所有轮廓，等等。如果值为负，则该函数不绘制轮廓之后的轮廓，而是绘制轮廓的子轮廓，直到 abs(maxLevel)-1 级别.\r\n","The first coordinate to be added":"要添加的第一个坐标\r\n","The transposes of the matrix.":"矩阵的转置。\r\n","\r\n            Convert Bayer BGGR to BGRA \r\n            ":"\r\n            将拜耳 BGGR 转换为 BGRA\r\n            \r\n","Vector of already detected marker identifiers.":"已检测到的标记标识符的向量。\r\n","\r\n            Calculates the actual amount of superpixels on a given segmentation computed and stored in SuperpixelSLIC object. \r\n            ":"\r\n            计算在 SuperpixelSLIC 对象中计算和存储的给定分割上的实际超像素数量。\r\n            \r\n","input images (all with 1-, 3- or 4-channels).":"输入图像（均具有 1、3 或 4 通道）。\r\n","The flag indicating whether the angles are measured in radians or in degrees":"指示角度是以弧度还是以度为单位测量的标志\r\n","This array should contain one or more noised versions of the image that is to be restored.":"该数组应包含要恢复的图像的一个或多个噪声版本。\r\n","\r\n            Possible functions to calculate the distance between colors.\r\n            ":"\r\n            计算颜色之间距离的可能函数。\r\n            \r\n","\r\n            use block blocks(step sizes/2), generate 31*31/8 + 1 uchar hash value\r\n            ":"\r\n            使用 block 块（步长/2），生成 31*31/8 + 1 uchar 哈希值\r\n            \r\n","Mat element type":"垫元素类型\r\n","\r\n            Create a downloadable file from the url\r\n            ":"\r\n            从 url 创建一个可下载的文件\r\n            \r\n","SVMSGD type":"SVMSGD型\r\n","\r\n            Suppress Nonmax Size\r\n            ":"\r\n            抑制非最大尺寸\r\n            \r\n","\r\n            Create and allocate storage for two dimensional single or multi channel dataset.\r\n            ":"\r\n            为二维单通道或多通道数据集创建和分配存储。\r\n            \r\n","The dot product of the two 3D point":"两个3D点的点积\r\n","\r\n            Prepares a map of optimal paths for the given source point on the image.\r\n            ":"\r\n            为图像上的给定源点准备最佳路径图。\r\n            \r\n","\r\n            Shifts a matrix to the left (c = a << scalar)\r\n            ":"\r\n            将矩阵左移（c = a << 标量）\r\n            \r\n","The mask for the AND operation":"AND 运算的掩码\r\n","\r\n            Bad step\r\n            ":"\r\n            错误的一步\r\n            \r\n","\r\n            The type of Programming languages\r\n            ":"\r\n            编程语言的类型\r\n            \r\n","The upper exclusive boundary of the range":"范围的上排他边界\r\n","The labels corresponding to the images":"图片对应的标签\r\n","Border value in case of a constant border ":"边界不变时的边界值\r\n","The termination criteria. Use 5 iteration and 1.5 eps for default.":"终止标准。默认使用 5 次迭代和 1.5 eps。\r\n","\r\n            Euclidean distance\r\n            ":"\r\n            欧氏距离\r\n            \r\n","The width of the projector.":"投影仪的宽度。\r\n","\r\n            Coordinates of the middlepoint\r\n            ":"\r\n            中点坐标\r\n            \r\n","The image to extract keypoints from":"从中提取关键点的图像\r\n","\r\n            GUID\r\n            ":"\r\n            GUID\r\n            \r\n","\r\n            Convert GRAY color to RGBA color\r\n            ":"\r\n            将 GRAY 颜色转换为 RGBA 颜色\r\n            \r\n","The blurred image":"模糊的图像\r\n","array of output rotation vectors. Each element in rvecs corresponds to the specific marker in imgPoints.":"输出旋转向量数组。 rvecs 中的每个元素对应于 imgPoints 中的特定标记。\r\n","\r\n            Types for WarpAffine\r\n            ":"\r\n            WarpAffine 的类型\r\n            \r\n","Scalar with mean values which are subtracted from channels.":"具有从通道中减去的平均值的标量。\r\n","The depth type to convert to":"要转换为的深度类型\r\n","\r\n            The number of data samples in the background model\r\n            ":"\r\n            背景模型中的数据样本数量\r\n            \r\n","\r\n            The type mask\r\n            ":"\r\n            类型掩码\r\n            \r\n","\r\n            Returns layer with specified name which the network use.\r\n            ":"\r\n            返回网络使用的具有指定名称的图层。\r\n            \r\n","\r\n            A horizontal 1D box filter.\r\n            ":"\r\n            水平一维盒式过滤器。\r\n            \r\n","Detection method to use. Currently, the only implemented method is CV_HOUGH_GRADIENT , which is basically 21HT":"使用的检测方法。目前，唯一实现的方法是 CV_HOUGH_GRADIENT ，基本上是 21HT\r\n","\r\n            Open the file for writing\r\n            ":"\r\n            打开文件进行写入\r\n            \r\n","\r\n            Bhattacharyya distance\r\n            ":"\r\n            巴氏距离\r\n            \r\n","\r\n            CMX slices\r\n            ":"\r\n            CMX切片\r\n            \r\n","Input floating-point array of x-coordinates of 2D vectors.":"输入二维向量 x 坐标的浮点数组。\r\n","Resulting transformation from the source frame to the destination one (rigid body motion): dst_p = Rt * src_p, where dst_p is a homogeneous point in the destination frame and src_p is homogeneous point in the source frame, Rt is 4x4 matrix of CV_64FC1 type.":"从源帧到目标帧（刚体运动）的转换结果：dst_p = Rt * src_p，其中 dst_p 是目标帧中的齐次点，src_p 是源帧中的齐次点，Rt 是 CV_64FC1 类型的 4x4 矩阵。\r\n","Type of the layout.":"布局类型。\r\n","\r\n            Max Error\r\n            ":"\r\n            最大误差\r\n            \r\n","A bitmap representation of the image.":"图像的位图表示。\r\n","Array of 2D points containing calculated new positions of input ":"包含计算出的新输入位置的二维点数组\r\n","Font to use":"使用的字体\r\n","\r\n            ML implements logistic regression, which is a probabilistic classification technique. \r\n            ":"\r\n            ML 实现逻辑回归，这是一种概率分类技术。\r\n            \r\n",". The search range can then be shifted by changing the minimum disparity.":".然后可以通过更改最小差异来移动搜索范围。\r\n","\r\n            This is a global tonemapping operator that models human visual system.\r\n            Mapping function is controlled by adaptation parameter, that is computed using light adaptation and color adaptation.\r\n            ":"\r\n            这是一个模拟人类视觉系统的全局色调映射运算符。\r\n            映射函数由适应参数控制，该参数使用光适应和颜色适应计算。\r\n            \r\n","True if the query is the same":"如果查询相同则为真\r\n","Second input matrix of the same depth as first input matrix.":"与第一个输入矩阵深度相同的第二个输入矩阵。\r\n","Pointer to the sequence of circles":"指向圆圈序列的指针\r\n","The lower level":"下层\r\n","Inversion method":"反演法\r\n","\r\n            Apply Ridge detection filter on input image.\r\n            ":"\r\n            在输入图像上应用脊检测滤波器。\r\n            \r\n","the name of the file that contains the image":"包含图像的文件的名称\r\n","The input array ":"输入数组\r\n","number of bits per dimension of each markers":"每个标记的每个维度的位数\r\n","Returns true if successful, false on error.":"成功则返回 true，错误则返回 false。\r\n","Result of applying the filter":"应用过滤器的结果\r\n","the axis color":"轴颜色\r\n","\r\n            Create an standard vector of VideoCapture with the initial values\r\n            ":"\r\n            使用初始值创建 VideoCapture 的标准向量\r\n            \r\n","\r\n            Minimum Contour Length Allowed\r\n            ":"\r\n            允许的最小轮廓长度\r\n            \r\n","Point in dst image where object is placed.":"dst 图像中放置对象的点。\r\n","Number of control points":"控制点数\r\n","\r\n            Convert BayerRG to BGR (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 BayerRG 转换为 BGR（边缘感知去马赛克）\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this look up table\r\n            ":"\r\n            释放与此查找表关联的所有非托管内存\r\n            \r\n","Sufficient accuracy for radius (distance between the coordinate origin and the line), 0.01 would be a good default":"半径（坐标原点和直线之间的距离）的足够精度，0.01 是一个很好的默认值\r\n","The output edge the point falls onto or right to":"点落在或右边的输出边\r\n","\r\n            Utility to draw the detected facial landmark points.\r\n            ":"\r\n            绘制检测到的面部标志点的实用程序。\r\n            \r\n","Shift all the point coordinates by the specified value. It is useful in case if the contours retrieved in some image ROI and then the ROI offset needs to be taken into account during the rendering. ":"按指定值移动所有点坐标。如果在某些图像 ROI 中检索到轮廓，然后在渲染过程中需要考虑 ROI 偏移，则它很有用。\r\n","The ith column of the CudaImage":"CudaImage 的第 i 列\r\n","\r\n            Error, homography estimateion failed.\r\n            ":"\r\n            错误，单应性估计失败。\r\n            \r\n","layout of ChArUco board.":"ChArUco 板的布局。\r\n","The other box to compare with":"另一个要比较的盒子\r\n","The mat to be subtracted":"要减去的垫子\r\n","Diameter of each pixel neighborhood that is used during filtering. If it is non-positive, it is computed from sigmaSpace.":"过滤期间使用的每个像素邻域的直径。如果它是非正数，则它是从 sigmaSpace 计算得出的。\r\n","\r\n            UPC-A\r\n            ":"\r\n            UPC-A\r\n            \r\n","\r\n            Applies bilateral filter to the image.\r\n            ":"\r\n            对图像应用双边过滤器。\r\n            \r\n","\r\n            Finds the best match for each descriptor from a query set (blocking version).\r\n            ":"\r\n            从查询集中（阻塞版本）找到每个描述符的最佳匹配。\r\n            \r\n","\r\n            ditto \r\n            ":"\r\n            同上\r\n            \r\n","\r\n            (Gaussian blur) - convolving image with param1 x param2 Gaussian kernel. \r\n            ":"\r\n            （高斯模糊）- 使用 param1 x param2 高斯核对图像进行卷积。\r\n            \r\n","Input image: 8-bit unsigned 3-channel image.":"输入图像：8 位无符号 3 通道图像。\r\n","negative samples to use during tracking":"跟踪期间使用的负样本\r\n","Scale sensitivity.":"尺度敏感性。\r\n","Thickness of the lines used to draw a text when negative, the glyph is filled. Otherwise, the glyph is drawn with this thickness.":"用于绘制文本的线条粗细，当负数时，字形被填充。否则，将使用此厚度绘制字形。\r\n","Discard foreground blobs whose bounding box is smaller than this threshold.":"丢弃边界框小于此阈值的前景斑点。\r\n","\r\n            Create hough circles detector\r\n            ":"\r\n            创建霍夫圆检测器\r\n            \r\n","\r\n            Step between scales (less than 1)\r\n            ":"\r\n            尺度之间的步长（小于 1）\r\n            \r\n","Contains the data of points which will be drawn.":"包含将要绘制的点的数据。\r\n","The intersect type":"相交类型\r\n","Grayscale Source image.":"灰度源图像。\r\n","\r\n            Release all the unmanaged memory associated with this OclInfo\r\n            ":"\r\n            释放与此 OclInfo 关联的所有非托管内存\r\n            \r\n","\r\n            Medium\r\n            ":"\r\n            中等的\r\n            \r\n","\r\n            Equalizes the histogram of a grayscale image.\r\n            ":"\r\n            均衡灰度图像的直方图。\r\n            \r\n","The image for detection.":"用于检测的图像。\r\n","\r\n            Release the unmanaged memory associated with this GpuMat\r\n            ":"\r\n            释放与此 GpuMat 关联的非托管内存\r\n            \r\n","number of chessboard squares in X direction":"X方向的棋盘格数\r\n","\r\n            This function calculates the Radon Transform of a given image in any range.\r\n            See https://engineering.purdue.edu/~malcolm/pct/CTI_Ch03.pdf for detail.\r\n            If the input type is CV_8U, the output will be CV_32S.\r\n            If the input type is CV_32F or CV_64F, the output will be CV_64F\r\n            The output size will be num_of_integral x src_diagonal_length.\r\n            If crop is selected, the input image will be crop into square then circle,\r\n            and output size will be num_of_integral x min_edge.\r\n            ":"\r\n            此函数计算给定图像在任何范围内的 Radon 变换。\r\n            有关详细信息，请参阅 https://engineering.purdue.edu/~malcolm/pct/CTI_Ch03.pdf。\r\n            如果输入类型为 CV_8U，则输出将为 CV_32S。\r\n            如果输入类型为 CV_32F 或 CV_64F，则输出将为 CV_64F\r\n            输出大小将为 num_of_integral x src_diagonal_length。\r\n            如果选择裁剪，输入图像将被裁剪成正方形然后是圆形，\r\n            输出大小将为 num_of_integral x min_edge。\r\n            \r\n","\r\n            Returns an identity matrix of the specified size and type.\r\n            ":"\r\n            返回指定大小和类型的单位矩阵。\r\n            \r\n","\r\n            Convert BayerGR to GRAY\r\n            ":"\r\n            将 BayerGR 转换为 GREY\r\n            \r\n","Specify the target hdf5 dataset label.":"指定目标 hdf5 数据集标签。\r\n","\r\n            Convert Bayer RGGB pattern to RGB color using VNG\r\n            ":"\r\n            使用 VNG 将 Bayer RGGB 模式转换为 RGB 颜色\r\n            \r\n","The optional output fundamental matrix ":"可选的输出基础矩阵\r\n","Contour defining first shape.":"定义第一个形状的轮廓。\r\n","Optional operation mask":"可选操作面罩\r\n","\r\n            Convert Bayer GBRG color to RGB color\r\n            ":"\r\n            将 Bayer GBRG 颜色转换为 RGB 颜色\r\n            \r\n","Desired number of superpixels. Note that the actual number may be smaller due to restrictions (depending on the image size). Use NumberOfSuperpixels to get the actual number.":"所需的超像素数量。请注意，由于限制（取决于图像大小），实际数量可能会更小。使用 NumberOfSuperpixels 获取实际数字。\r\n","First point of the line segment":"线段的第一个点\r\n","  \r\n            vertex of the binary tree   \r\n            ":"  \r\n            二叉树的顶点\r\n            \r\n","Length of the history.":"历史的长度。\r\n","First frame, at time t. ":"第一帧，时间 t。\r\n","True if two quaternions equals, false otherwise":"如果两个四元数相等则为真，否则为假\r\n","The center of circles detected if the chess board pattern is found, otherwise null is returned":"如果找到棋盘图案，则检测圆心，否则返回 null\r\n","Projector's pixel corresponding to the camera's pixel: projPix.x and projPix.y are the image coordinates of the projector's pixel corresponding to the pixel being decoded in a camera. If failed to calculate the project, null will be returned.":"投影仪像素对应相机像素：projPix.x和projPix.y是投影仪像素对应相机解码像素的图像坐标。如果计算项目失败，则返回null。\r\n","\r\n            Returns channel of interest of the image (it returns 0 if all the channels are selected).\r\n            ":"\r\n            返回图像的感兴趣通道（如果选择了所有通道，则返回 0）。\r\n            \r\n","the mask for copy":"复制掩码\r\n"," pixel neighborhood, subtracted by param1.\r\n            ":" 像素邻域，减去 param1。\r\n            \r\n","The values to be pushed to the vector":"要推送到向量的值\r\n","\r\n            Create an empty standard vector of VectorOfERStat\r\n            ":"\r\n            创建 VectorOfERStat 的空标准向量\r\n            \r\n","The per-element difference between matrix and given scalar.":"矩阵和给定标量之间的每个元素差异。\r\n","border mode used to extrapolate pixels outside of the image":"用于推断图像外部像素的边界模式\r\n","\r\n            Release the classifier and all the memory associated with it\r\n            ":"\r\n            释放分类器及其关联的所有内存\r\n            \r\n","The file where the FaceRecognizer will be loaded from":"FaceRecognizer 将从中加载的文件\r\n","\r\n            Find the bounding rectangle for the specific array of points\r\n            ":"\r\n            查找特定点数组的边界矩形\r\n            \r\n","\r\n            Perform a binary map of given saliency map\r\n            ":"\r\n            执行给定显着图的二进制图\r\n            \r\n","\r\n            Convert YUV (YUNV) to RGBA\r\n            ":"\r\n            将 YUV (YUNV) 转换为 RGBA\r\n            \r\n","Sliding step to process every next reference block.":"滑动步骤以处理每个下一个参考块。\r\n","The optional flags, model-dependent.":"可选标志，依赖于模型。\r\n","The foreground of the image to be added to history":"要添加到历史记录的图像的前景\r\n","Final pano.":"最后全景。\r\n","\r\n            Runs forward pass for the whole network.\r\n            ":"\r\n            为整个网络运行正向传播。\r\n            \r\n","\r\n            Base class for lines detector algorithm.\r\n            ":"\r\n            线检测器算法的基类。\r\n            \r\n","Text content of the widget.":"小部件的文本内容。\r\n","Destination image size. If it is zero, it is computed as: dsize = Size(round(fx* src.cols), round(fy* src.rows)). Either dsize or both fx and fy must be non-zero.":"目标图像大小。如果它为零，则计算为：dsize = Size(round(fx* src.cols), round(fy* src.rows))。 dsize 或 fx 和 fy 都必须非零。\r\n","\r\n            Circle buffer\r\n            ":"\r\n            环形缓冲区\r\n            \r\n","The input disparity map":"输入视差图\r\n","\r\n            The function addC adds a given scalar value to each element of given matrix.\r\n            ":"\r\n            函数 addC 将给定的标量值添加到给定矩阵的每个元素。\r\n            \r\n","\r\n            there are multiple maxima for target function - the arbitrary one is returned\r\n            ":"\r\n            目标函数有多个最大值 - 返回任意一个\r\n            \r\n","\r\n            Perform registration.\r\n            ":"\r\n            进行注册。\r\n            \r\n","First ending point of the line segment. It is modified by the function":"线段的第一个终点。它由函数修改\r\n","The 3D points of the mesh":"网格的 3D 点\r\n","The color with which to fill the background":"填充背景的颜色\r\n","\r\n            Cuda template matching filter.\r\n            ":"\r\n            Cuda 模板匹配过滤器。\r\n            \r\n","The program source":"程序源\r\n","scalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true.":"具有从通道中减去的平均值的标量。如果图像具有 BGR 排序且 swapRB 为真，则值旨在按（mean-R、mean-G、mean-B）顺序排列。\r\n","The number of levels in the scale pyramid.":"比例金字塔中的级别数。\r\n","\r\n            Convert BayerBG pattern to BGR color using VNG\r\n            ":"\r\n            使用 VNG 将 BayerBG 图案转换为 BGR 颜色\r\n            \r\n","\r\n            Convert YUV (Y422) to BGRA\r\n            ":"\r\n            将 YUV (Y422) 转换成 BGRA\r\n            \r\n","\r\n            Get or Set the data for this matrix. The Get function has O(1) complexity. The Set function make a copy of the data\r\n            ":"\r\n            获取或设置此矩阵的数据。 Get 函数的复杂度为 O(1)。 Set 函数复制数据\r\n            \r\n","optional vector of distortion coefficients, (k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]]) of 4, 5, 8 or 12 elements ":"失真系数的可选向量，(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]]) 4、5、8 或 12 个元素\r\n","\r\n            The distance\r\n            ":"\r\n            距离\r\n            \r\n","\r\n            Convert degree to radian\r\n            ":"\r\n            将度数转换为弧度\r\n            \r\n"," Image of the specific color and depth ":" 图像的具体颜色和深度\r\n","\r\n            Calculating the distance between two face features.\r\n            ":"\r\n            计算两个面部特征之间的距离。\r\n            \r\n","\r\n            Cuda compute 1.1\r\n            ":"\r\n            Cuda 计算 1.1\r\n            \r\n","\r\n            Get the address of the pinned array\r\n            ":"\r\n            获取固定数组的地址\r\n            \r\n","\r\n            Draws signature in the source image and outputs the result. Signatures are visualized as a circle with radius based on signature weight and color based on signature color. Contrast and entropy are not visualized.\r\n            ":"\r\n            在源图像中绘制签名并输出结果。签名被可视化为一个圆，其半径基于签名重量，颜色基于签名颜色。对比度和熵没有可视化。\r\n            \r\n","Destination image of the same size and the same number of channels as src .":"与 src 具有相同大小和相同通道数的目标图像。\r\n","Input floating-point CV_32FC1 matrix (1xN) of angles of 2D vectors.":"输入二维向量角度的浮点 CV_32FC1 矩阵 (1xN)。\r\n","\r\n            Create an standard vector of VectorOfByte of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfByte 标准向量\r\n            \r\n","\r\n            Calculates a square root of each input array element. In case of multi-channel arrays, each channel is processed independently.\r\n            ":"\r\n            计算每个输入数组元素的平方根。在多通道阵列的情况下，每个通道都是独立处理的。\r\n            \r\n","\r\n            More sophisticated learning-based automatic white balance algorithm.\r\n            As GrayworldWB, this algorithm works by applying different gains to the input image channels, but their computation is a bit more involved compared to the simple gray-world assumption. \r\n            More details about the algorithm can be found in: Dongliang Cheng, Brian Price, Scott Cohen, and Michael S Brown. Effective learning-based illuminant estimation using simple features. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1000-1008, 2015.\r\n            To mask out saturated pixels this function uses only pixels that satisfy the following condition:\r\n            max(R,G,B) / range_max_val < saturation_thresh \r\n            Currently supports images of type CV_8UC3 and CV_16UC3.\r\n            ":"\r\n            更复杂的基于学习的自动白平衡算法。\r\n            与 GrayworldWB 一样，该算法通过对输入图像通道应用不同的增益来工作，但与简单的灰色世界假设相比，它们的计算要复杂一些。\r\n            有关该算法的更多详细信息，请参阅：Dongliang Cheng、Brian Price、Scott Cohen 和 Michael S Brown。使用简单特征进行有效的基于学习的光源估计。在 IEEE 计算机视觉和模式识别会议记录中，第 1000-1008 页，2015 年。\r\n            要屏蔽掉饱和像素，此函数仅使用满足以下条件的像素：\r\n            最大（R，G，B）/ range_max_val < saturation_thresh\r\n            目前支持 CV_8UC3 和 CV_16UC3 类型的图像。\r\n            \r\n","\r\n            Create an empty standard vector of CvString\r\n            ":"\r\n            创建 CvString 的空标准向量\r\n            \r\n","\r\n            Convert a CvArray to Mat and push it into the vector\r\n            ":"\r\n            将 CvArray 转换为 Mat 并将其推入向量\r\n            \r\n","\r\n            Release all the unmanaged resource associated with MarrHildrethHash\r\n            ":"\r\n            释放与 MarrHildrethHash 关联的所有非托管资源\r\n            \r\n","\r\n            Constants used by the MCvMat structure\r\n            ":"\r\n            MCvMat 结构使用的常量\r\n            \r\n","First input array.":"第一个输入数组。\r\n","Input image(s) to use as the source for comparison":"输入图像用作比较源\r\n","The video writer":"视频作者\r\n","Returns true if dataset exists, and false otherwise.":"如果数据集存在则返回 true，否则返回 false。\r\n","Contour perimeter or a curve length":"轮廓周长或曲线长度\r\n","\r\n            Convert this GpuMat to a Matrix\r\n            ":"\r\n            将此 GpuMat 转换为矩阵\r\n            \r\n","Structuring element":"结构元素\r\n","\r\n            Set the line color\r\n            ":"\r\n            设置线条颜色\r\n            \r\n","Specifies when the iteration process of finding the flow for each point on each pyramid level should be stopped.":"指定何时应停止查找每个金字塔级别上每个点的流量的迭代过程。\r\n","\r\n            Set the estimator for this stitcher\r\n            ":"\r\n            设置此缝合器的估算器\r\n            \r\n","\r\n            Entry points for the Aruco module.\r\n            ":"\r\n            Aruco 模块的入口点。\r\n            \r\n","Interpolation mode":"插补方式\r\n","The vertices of this convex polygon":"这个凸多边形的顶点\r\n","Step size of sliding window search.":"滑动窗口搜索的步长。\r\n","\r\n            Entry points for the cv::plot functions\r\n            ":"\r\n            cv::plot 函数的入口点\r\n            \r\n","\r\n            One of input arguments is invalid.\r\n            ":"\r\n            输入参数之一无效。\r\n            \r\n","3x3 input matrix.":"3x3 输入矩阵。\r\n","\r\n            Create a fisheye warper\r\n            ":"\r\n            创建鱼眼变形器\r\n            \r\n","The first map of either (x,y) points or just x values having the type CV_16SC2 , CV_32FC1 , or CV_32FC2 . See convertMaps() for details on converting a floating point representation to fixed-point for speed.":"(x,y) 点或只是 x 值的第一个映射具有类型 CV_16SC2 、 CV_32FC1 或 CV_32FC2 。有关将浮点表示转换为定点以提高速度的详细信息，请参阅 convertMaps()。\r\n","\r\n            Cpu\r\n            ":"\r\n            中央处理器\r\n            \r\n","The size of the matrix":"矩阵的大小\r\n","Zero-based index of the starting column (inclusive) of the span":"跨度起始列（含）的从零开始的索引\r\n","\r\n            Create an standard vector of ColorPoint with the initial values\r\n            ":"\r\n            使用初始值创建 ColorPoint 的标准向量\r\n            \r\n","\r\n            Use additional criteria (like contour area, perimeter, square-like shape) to filter out false quads that are extracted at the contour retrieval stage\r\n            ":"\r\n            使用附加条件（如轮廓面积、周长、正方形形状）过滤掉在轮廓检索阶段提取的假四边形\r\n            \r\n","\r\n            Gamma\r\n            ":"\r\n            伽马\r\n            \r\n","Number of channels ":"通道数\r\n","\r\n            Number of enum entries.\r\n            ":"\r\n            枚举条目数。\r\n            \r\n","\r\n            Default flag\r\n            ":"\r\n            默认标志\r\n            \r\n","The search lines will be centered at this points and orthogonal to the contour defined by them. The bundle will have as many rows.":"搜索线将以这些点为中心并与它们定义的轮廓正交。束将有尽可能多的行。\r\n","\r\n            Elementwise add ":"按元素添加\r\n","The first source array. ":"第一个源数组。\r\n","\r\n            Check if the GPU module is build with the specific feature set.\r\n            ":"\r\n            检查 GPU 模块是否使用特定功能集构建。\r\n            \r\n","the threshold for the Harris cornerness measure":"哈里斯角测度的阈值\r\n","\r\n            Calculates per-element product of two arrays:\r\n            dst(I)=scale*src1(I)*src2(I)\r\n            All the arrays must have the same type, and the same size (or ROI size)\r\n            ":"\r\n            计算两个数组的每个元素的乘积：\r\n            dst(I)=scale*src1(I)*src2(I)\r\n            所有数组必须具有相同的类型和相同的大小（或 ROI 大小）\r\n            \r\n","\r\n            BPROP: Strength of the weight gradient term\r\n            ":"\r\n            BPROP：权重梯度项的强度\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this blender\r\n            ":"\r\n            释放与此搅拌机关联的所有非托管内存\r\n            \r\n","The output array to be copied to":"要复制到的输出数组\r\n","\r\n            If true then a pruning will be harsher\r\n            ":"\r\n            如果为真，那么修剪会更严厉\r\n            \r\n","Source array depth":"源阵列深度\r\n","\r\n            Create an empty standard vector of Point3D32F\r\n            ":"\r\n            创建 Point3D32F 的空标准向量\r\n            \r\n","Motion gradient orientation image; contains angles from 0 to ~360. ":"运动梯度方向图像；包含从 0 到 ~360 的角度。\r\n","The shape transformer, use ThinPlateSplineSphapeTransformer as default":"形状变换器，默认使用 ThinPlateSplineSphapeTransformer\r\n","Maximum allowed gap between points on the same line to link them.":"同一条线上的点之间允许的最大间隙以链接它们。\r\n","\r\n            Create a MCvPoint2D64f structure with the specific x and y coordinates\r\n            ":"\r\n            创建具有特定 x 和 y 坐标的 MCvPoint2D64f 结构\r\n            \r\n","Pointer to the previously assigned user data pointer.":"指向先前分配的用户数据指针。\r\n","\r\n            If set, return the loaded image as is (with alpha channel, otherwise it gets cropped).\r\n            ":"\r\n            如果设置，则按原样返回加载的图像（带 alpha 通道，否则会被裁剪）。\r\n            \r\n","\r\n            Specifies the delay in microseconds (us) to apply after the trigger reception before activating it.\r\n            ":"\r\n            指定以微秒 (us) 为单位的延迟，以在触发接收之后应用，然后再激活它。\r\n            \r\n","\r\n            Divides each element of matrix src by given scalar value\r\n            ":"\r\n            将矩阵 src 的每个元素除以给定的标量值\r\n            \r\n","The async Task":"异步任务\r\n","\r\n            A QR code detector\r\n            ":"\r\n            二维码检测器\r\n            \r\n","\r\n            Native algorithm pointer\r\n            ":"\r\n            本机算法指针\r\n            \r\n","\r\n            Sync video meta streams\r\n            ":"\r\n            同步视频元流\r\n            \r\n","the rectangle area of the sub-matrix":"子矩阵的矩形区域\r\n","\r\n            Asymmetric grid\r\n            ":"\r\n            不对称网格\r\n            \r\n","\r\n            Retrieve all the contours and organizes them into two-level hierarchy: top level are external boundaries of the components, second level are bounda boundaries of the holes \r\n            ":"\r\n            检索所有轮廓并将它们组织成两级层次结构：顶层是组件的外部边界，第二层是孔的边界\r\n            \r\n","The type of comparison":"比较的类型\r\n","Anchor position within the element. The value (-1, -1) means that the anchor is at the center. Note that only the shape of a cross-shaped element depends on the anchor position. In other cases the anchor just regulates how much the result of the morphological operation is shifted.":"元素内的锚点位置。值 (-1, -1) 表示锚点位于中心。请注意，只有十字形元素的形状取决于锚点位置。在其他情况下，锚点只是调节形态学操作的结果移动了多少。\r\n","\r\n            Convert Bayer BG color to BGR color\r\n            ":"\r\n            将 Bayer BG 颜色转换为 BGR 颜色\r\n            \r\n","Optional parameter. Must be specified if subset of features is specified (non-specified features are calculated internally)":"可选参数。如果指定了特征的子集，则必须指定（未指定的特征在内部计算）\r\n","\r\n            Type used for Reduce function\r\n            ":"\r\n            用于 Reduce 函数的类型\r\n            \r\n","The EM model":"电磁模型\r\n","Image header to initialize.":"要初始化的图像标题。\r\n","The data for the X-axis":"X轴的数据\r\n","\r\n            Provide interfaces to the Open CV Saliency functions\r\n            ":"\r\n            为 Open CV Saliency 函数提供接口\r\n            \r\n","Blinking supression decay factor.":"闪烁抑制衰减因子。\r\n","\r\n            Create a flann index\r\n            ":"\r\n            创建法兰索引\r\n            \r\n","8-bit input image":"8 位输入图像\r\n","\r\n            Create a video writer that write images to video format\r\n            ":"\r\n            创建一个将图像写入视频格式的视频编写器\r\n            \r\n","\r\n            The cost. The lower it is, the more confident is the result\r\n            ":"\r\n            成本。越低，结果越有信心\r\n            \r\n","\r\n            Convert raw data to bitmap\r\n            ":"\r\n            将原始数据转换为位图\r\n            \r\n","Source image CV_8UC1 from which the MSERs where extracted.":"从中提取 MSER 的源图像 CV_8UC1。\r\n","\r\n            The Facemark AMM model\r\n            ":"\r\n            Facemark AMM 模型\r\n            \r\n","Pointer to the random tree":"指向随机树的指针\r\n","BuildMap() must be called before this call":"必须在此调用之前调用 BuildMap()\r\n","\r\n            Create a blank Image of the specified width, height and color.\r\n            ":"\r\n            创建指定宽度、高度和颜色的空白图像。\r\n            \r\n","\r\n            Create an empty Moment object\r\n            ":"\r\n            创建一个空的 Moment 对象\r\n            \r\n","Input CV_8UC4 matrix.":"输入 CV_8UC4 矩阵。\r\n","\r\n            src1(I) \"greater or equal\" src2(I)\r\n            ":"\r\n            src1(I) \"大于或等于\" src2(I)\r\n            \r\n","The center of rotation":"旋转中心\r\n","Optional output vector that contains error response for each point (inverse confidence).":"包含每个点的错误响应的可选输出向量（逆置信度）。\r\n","\r\n            Convert this Mat to Image\r\n            ":"\r\n            将此垫子转换为图像\r\n            \r\n","The integral for the image rotated by 45 degrees":"图像旋转 45 度的积分\r\n","the linear size of the blocks compared by the algorithm. The size should be odd (as the block is centered at the current pixel). Larger block size implies smoother, though less accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher chance for algorithm to find a wrong correspondence.":"算法比较的块的线性大小。大小应该是奇数（因为块以当前像素为中心）。较大的块大小意味着更平滑，但不太准确的视差图。较小的块大小提供更详细的视差图，但算法找到错误对应的机会更高。\r\n","Scaling of the description pattern":"描述模式的缩放\r\n","\r\n            Destroys the window with a given name\r\n            ":"\r\n            销毁具有给定名称的窗口\r\n            \r\n","\r\n            Aravis SDK\r\n            ":"\r\n            Aravis SDK\r\n            \r\n","\r\n              | 1  2  1|\r\n              | 0  0  0|\r\n              |-1 -2 -1|":"\r\n              | 1 2 1|\r\n              | 0 0 0|\r\n              |-1 -2 -1|\r\n","Contrast threshold. Use 0.04 as default":"对比度阈值。使用 0.04 作为默认值\r\n","\r\n            The prediction result\r\n            ":"\r\n            预测结果\r\n            \r\n","The number of active disparity on the first level. Use 4 as default.":"第一层的活动差异数。使用 4 作为默认值。\r\n","\r\n            L1\r\n            ":"L1\r\n            \r\n","\r\n            Release the unmanaged memory associated with this TonemapReinhard\r\n            ":"\r\n            释放与此 TonemapReinhard 关联的非托管内存\r\n            \r\n","\r\n            Polls for a key event without waiting.\r\n            ":"\r\n            无需等待即可轮询关键事件。\r\n            \r\n","\r\n            FFmpeg back-end only - Indicates whether the Last Raw Frame (LRF), output from VideoCapture::read() when VideoCapture is initialized with VideoCapture::open(CAP_FFMPEG, {CAP_PROP_FORMAT, -1}) or VideoCapture::set(CAP_PROP_FORMAT,-1) is called before the first call to VideoCapture::read(), contains encoded data for a key frame.\r\n            ":"\r\n            仅限 FFmpeg 后端 - 指示当使用 VideoCapture::open(CAP_FFMPEG, {CAP_PROP_FORMAT, -1}) 或 VideoCapture::set(CAP_PROP_FORMAT) 初始化 VideoCapture 时，最后一个原始帧 (LRF) 是否从 VideoCapture::read() 输出,-1) 在第一次调用 VideoCapture::read() 之前调用，包含关键帧的编码数据。\r\n            \r\n","One of the three neighborhoods as defined in the paper":"论文中定义的三个社区之一\r\n","destination image.":"目标图像。\r\n","\r\n            Last image black level counts. Can be used for Offline processing to recall it.\r\n            ":"\r\n            最后一张图像的黑电平很重要。可用于离线处理以调用它。\r\n            \r\n","\r\n            Weight parameter for the data term, attachment parameter\r\n            ":"\r\n            数据项的权重参数，附件参数\r\n            \r\n","Input image channel. Only single channel type is supported for now.":"输入图像通道。目前仅支持单通道类型。\r\n","\r\n            Problem is unfeasible (there are no points that satisfy all the constraints imposed)\r\n            ":"\r\n            问题是不可行的（没有满足所有施加的约束的点）\r\n            \r\n","\r\n            Create an standard vector of VectorOfDMatch of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfDMatch 标准向量\r\n            \r\n","\r\n            Cascade Classifier for object detection using Cuda\r\n            ":"\r\n            使用 Cuda 进行对象检测的级联分类器\r\n            \r\n","The first image to AND":"AND 的第一张图片\r\n"," The result of elementwise adding color ":" 逐元素添加颜色的结果\r\n","An array of all 1's of the specified size and type.":"指定大小和类型的全 1 数组。\r\n","\r\n            Background Subtractor module based on the algorithm given in:\r\n            Andrew B. Godbehere, Akihiro Matsukawa, Ken Goldberg, \r\n            \"Visual Tracking of Human Visitors under Variable-Lighting Conditions for a Responsive Audio Art Installation\", \r\n            American Control Conference, Montreal, June 2012.\r\n            ":"\r\n            Background Subtractor模块基于给出的算法：\r\n            Andrew B. Godbehere，松川明弘，肯戈德堡，\r\n            “响应式音频艺术装置在可变照明条件下对人类访客的视觉跟踪”，\r\n            美国控制会议，蒙特利尔，2012 年 6 月。\r\n            \r\n","\r\n            Release the unmanaged resources associated with the filter.\r\n            ":"\r\n            释放与筛选器关联的非托管资源。\r\n            \r\n","The rectangle":"长方形\r\n","Size of the Mat":"垫子尺寸\r\n","\r\n            Whether classification or regression model should be trained\r\n            ":"\r\n            是否应该训练分类或回归模型\r\n            \r\n","\r\n            A statistic model\r\n            ":"\r\n            统计模型\r\n            \r\n","The start time of the motion history":"运动历史的开始时间\r\n","Array header":"数组头\r\n","\r\n            Sequence Number\r\n            ":"\r\n            序列号\r\n            \r\n","\r\n            Info message\r\n            ":"\r\n            资讯讯息\r\n            \r\n","\r\n            Dict5X5_250\r\n            ":"\r\n            Dict5X5_250\r\n            \r\n","\r\n            Create an standard vector of Double of the specific size\r\n            ":"\r\n            创建特定大小的 Double 标准向量\r\n            \r\n","\r\n            Performs up-sampling step of Gaussian pyramid decomposition.\r\n            ":"\r\n            执行高斯金字塔分解的上采样步骤。\r\n            \r\n","Fourth input CV_8UC1 matrix to be merged.":"要合并的第四个输入 CV_8UC1 矩阵。\r\n","The number of filter bands used for computing BIF.":"用于计算 BIF 的滤波器频带数。\r\n","\r\n            Refine not detected markers based on the already detected and the board layout.\r\n            ":"\r\n            根据已经检测到的和电路板布局优化未检测到的标记。\r\n            \r\n","\r\n             Approximates a polygonal curve(s) with the specified precision.\r\n             ":"\r\n             以指定精度逼近多边形曲线。\r\n             \r\n","\r\n            In N&M algorithm, the combination of intensity (I), hue (H), saturation (S), and gradient magnitude\r\n            channels (Grad) are used in order to obtain high localization recall. \r\n            ":"\r\n            在 N&M 算法中，强度 (I)、色调 (H)、饱和度 (S) 和梯度幅度的组合\r\n            使用通道（Grad）以获得高定位召回率。\r\n            \r\n","Warped image":"扭曲的图像\r\n","The next frame. If no more frames, null will be returned.":"下一帧。如果没有更多帧，则返回 null。\r\n","\r\n            Check if the other point equals to this point\r\n            ":"\r\n            检查其他点是否等于此点\r\n            \r\n","\r\n            The region of the QR code.\r\n            ":"\r\n            QR码的区域。\r\n            \r\n","\r\n            underlying data reference counter\r\n            ":"\r\n            底层数据引用计数器\r\n            \r\n","\r\n            Returns uniformly distributed random double number from [a,b) range\r\n            ":"\r\n            返回 [a,b) 范围内均匀分布的随机双精度数\r\n            \r\n","The Matrix to be added":"要添加的矩阵\r\n","\r\n            Moves lens focus motor by steps set in XI_PRM_LENS_FOCUS_MOVEMENT_VALUE.\r\n            ":"\r\n            按 XI_PRM_LENS_FOCUS_MOVEMENT_VALUE 中设置的步长移动镜头对焦马达。\r\n            \r\n","Second input image, the same format as the first one":"第二个输入图像，格式与第一个相同\r\n","\r\n            Changes shape of GpuMat without copying data.\r\n            ":"\r\n            在不复制数据的情况下更改 GpuMat 的形状。\r\n            \r\n","Maximum number of components that PCA should retain; by default, all the components are retained.":"PCA 应保留的最大组件数；默认情况下，保留所有组件。\r\n","\r\n            The bits to shift for SEQ_KIND\r\n            ":"\r\n            SEQ_KIND 要移位的位\r\n            \r\n","\r\n            Creates MergeMertens object.\r\n            ":"\r\n            创建 MergeMertens 对象。\r\n            \r\n","\r\n            Create a GpuMat from an CvArray of the same depth type\r\n            ":"\r\n            从相同深度类型的 CvArray 创建 GpuMat\r\n            \r\n","\r\n            A collection of points\r\n            ":"\r\n            积分的集合\r\n            \r\n","The sum of array elements":"数组元素之和\r\n","Result of the approximation. The type should match the type of the input curve. ":"近似的结果。该类型应与输入曲线的类型匹配。\r\n","\r\n            Convert Lab color to RGB color\r\n            ":"\r\n            将 Lab 颜色转换为 RGB 颜色\r\n            \r\n","\r\n            Unclip ratio\r\n            ":"\r\n            解扣率\r\n            \r\n","A threshold used to filter boxes by score.":"用于按分数过滤框的阈值。\r\n","Affects color and color co-occurrence quantization, typically set to 2.":"影响颜色和颜色共现量化，通常设置为 2。\r\n"," Range between 0 to 1.":" 范围在 0 到 1 之间。\r\n","Line thickness. ":"线的粗细。\r\n","The mat where the new Mat header will share data from":"新垫头将从中共享数据的垫子\r\n"," \r\n            Capture a Bgr image frame\r\n            ":" \r\n            捕获 Bgr 图像帧\r\n            \r\n","\r\n            Parameters for the QuasiDenseStereo class\r\n            ":"\r\n            QuasiDenseStereo 类的参数\r\n            \r\n","\r\n            Prefer to use H/W acceleration. If no one supported, then fallback to software processing.\r\n            ":"\r\n            更喜欢使用硬件加速。如果无人支持，则回退到软件处理。\r\n            \r\n","Background ratio.":"背景比。\r\n","\r\n            Loads an image from the specified file and returns the pointer to the loaded image. Currently the following file formats are supported: \r\n            Windows bitmaps - BMP, DIB; \r\n            JPEG files - JPEG, JPG, JPE; \r\n            Portable Network Graphics - PNG; \r\n            Portable image format - PBM, PGM, PPM; \r\n            Sun rasters - SR, RAS; \r\n            TIFF files - TIFF, TIF; \r\n            OpenEXR HDR images - EXR; \r\n            JPEG 2000 images - jp2. \r\n            ":"\r\n            从指定文件加载图像并返回指向加载图像的指针。目前支持以下文件格式：\r\n            Windows 位图 - BMP、DIB；\r\n            JPEG 文件 - JPEG、JPG、JPE；\r\n            便携式网络图形 - PNG；\r\n            便携式图像格式——PBM、PGM、PPM；\r\n            太阳光栅 - SR、RAS；\r\n            TIFF 文件 - TIFF、TIF；\r\n            OpenEXR HDR 图像 - EXR；\r\n            JPEG 2000 图像 - jp2。\r\n            \r\n","\r\n            minimum window size for adaptive thresholding before finding contours (default 3)\r\n            ":"\r\n            找到轮廓之前自适应阈值的最小窗口大小（默认 3）\r\n            \r\n","\r\n            Computes an optimal affine transformation between two 2D point sets.\r\n            ":"\r\n            计算两个 2D 点集之间的最佳仿射变换。\r\n            \r\n","\r\n            standard ArUco Library Markers. 1024 markers, 5x5 bits, 0 minimum distance\r\n            ":"\r\n            标准 ArUco 库标记。 1024 个标记，5x5 位，0 最小距离\r\n            \r\n","\r\n            Another threshold for the feature size to eliminate edges. \r\n            The larger the threshold, the more points you get.":"\r\n            消除边缘的特征尺寸的另一个阈值。\r\n            阈值越大，获得的积分就越多。\r\n"," only. Otherwise, this is the GpuMat of type CV_8UC1":" 仅有的。否则，这是 CV_8UC1 类型的 GpuMat\r\n","The code of the pressed key or -1 if no key were pressed until the specified timeout has elapsed":"按下的键的代码或 -1 如果在指定的超时之前没有按下任何键\r\n","Aperture linear size; it must be odd and greater than 1, for example: 3, 5, 7 ...":"孔径线性尺寸；它必须是奇数且大于 1，例如：3, 5, 7 ...\r\n","The operation flags, use ZeroDisparity for default":"操作标志，默认使用 ZeroDisparity\r\n","\r\n            Create an standard vector of GMat of the specific size\r\n            ":"\r\n            创建特定大小的 GMat 标准向量\r\n            \r\n","When the argument is zero or negative, and at the beginning of the program, the number of threads is set to the number of processors in the system, as returned by the function omp_get_num_procs() from OpenMP runtime. ":"当参数为零或负数时，并且在程序开始时，线程数设置为系统中的处理器数，由 OpenMP 运行时的函数 omp_get_num_procs() 返回。\r\n","\r\n            Convert the standard vector to arrays of arrays of int\r\n            ":"\r\n            将标准向量转换为 int 数组的数组\r\n            \r\n"," during object disposal":" 在对象处理期间\r\n","\r\n            Manhattan distance (city block distance)\r\n            ":"\r\n            曼哈顿距离（城市街区距离）\r\n            \r\n","\r\n            Converts string name of the layer to the integer identifier.\r\n            ":"\r\n            将层的字符串名称转换为整数标识符。\r\n            \r\n","\r\n            If set, always convert image to the single channel grayscale image and the image size reduced 1/2.\r\n            ":"\r\n            如果设置，则始终将图像转换为单通道灰度图像并且图像尺寸缩小 1/2。\r\n            \r\n","Source image (8-bit or 16-bit single channel).":"源图像（8 位或 16 位单通道）。\r\n","Half size of the dead region in the middle of the search zone over which the summation in formulae below is not done. It is used sometimes to avoid possible singularities of the autocorrelation matrix. The value of (-1,-1) indicates that there is no such size":"搜索区中间死区的一半大小，未在下面的公式中进行求和。它有时用于避免自相关矩阵可能出现的奇点。 (-1,-1)的值表示没有这个尺寸\r\n","Mock parameter used for CPU/CUDA interfaces similarity.":"用于 CPU/CUDA 接口相似性的模拟参数。\r\n","\r\n            Create an empty standard vector of RotatedRect\r\n            ":"\r\n            创建 RotatedRect 的空标准向量\r\n            \r\n","radius for gathering positive instances during tracking":"跟踪期间收集正实例的半径\r\n"," The threshold used for edge Linking":" 用于边缘链接的阈值\r\n","The search epsilon":"搜索小量\r\n","\r\n            Pointer to cv::Algorithm\r\n            ":"\r\n            指向 cv::Algorithm 的指针\r\n            \r\n"," is null, the default location on windows is the dll's path appended by either \"x64\" or \"x86\", depends on the applications current mode.":" 为空，Windows 上的默认位置是附加“x64”或“x86”的 dll 路径，具体取决于应用程序的当前模式。\r\n","The storage for the circles detected. It can be a memory storage (in this case a sequence of circles is created in the storage and returned by the function) or single row/single column matrix (CvMat*) of type CV_32FC3, to which the circles' parameters are written. The matrix header is modified by the function so its cols or rows will contain a number of lines detected. If circle_storage is a matrix and the actual number of lines exceeds the matrix size, the maximum possible number of circles is returned. Every circle is encoded as 3 floating-point numbers: center coordinates (x,y) and the radius":"检测到的圆的存储。它可以是内存存储（在这种情况下，一系列圆在存储中创建并由函数返回）或 CV_32FC3 类型的单行/单列矩阵 (CvMat*)，圆的参数写入其中。矩阵标题由函数修改，因此它的列或行将包含检测到的行数。如果 circle_storage 是一个矩阵并且实际行数超过矩阵大小，则返回最大可能的圆数。每个圆都被编码为 3 个浮点数：圆心坐标 (x,y) 和半径\r\n","The first vertex":"第一个顶点\r\n","The source GpuMat, support depth of byte, UInt16, Int16 and float.":"源码GpuMat，支持字节深度、UInt16、Int16和float。\r\n","The lower (inclusive) and upper (exclusive) boundaries of the bins":"bins 的下边界（包含）和上边界（不包含）\r\n","The starting col for the tile":"图块的起始列\r\n","\r\n            Convert BayerRG pattern to RGB color using VNG\r\n            ":"\r\n            使用 VNG 将 BayerRG 图案转换为 RGB 颜色\r\n            \r\n","\r\n            EpsX\r\n            ":"\r\n            每股收益\r\n            \r\n","The point tested against the contour":"对照轮廓测试的点\r\n","\r\n            Color Correction Matrix element [3][1]\r\n            ":"\r\n            颜色校正矩阵元素 [3][1]\r\n            \r\n","\r\n            True if the Mat is empty\r\n            ":"\r\n            如果 Mat 为空则为真\r\n            \r\n","When false (default value), no data is copied and only the new header is created, in this case, the original array should not be deallocated while the new matrix header is used; if the parameter is true, all the data is copied and you may deallocate the original array right after the conversion.":"当为 false（默认值）时，不复制数据，只创建新的头，在这种情况下，在使用新的矩阵头时不应释放原始数组；如果参数为真，则复制所有数据，您可以在转换后立即释放原始数组。\r\n","true if the two triangles equals, false otherwise":"如果两个三角形相等则为真，否则为假\r\n","\r\n            Release all unmanaged memory associated with the CNNHostPipeline.\r\n            ":"\r\n            释放与 CNNHostPipeline 关联的所有非托管内存。\r\n            \r\n","\r\n            Makes the principal points of each camera have the same pixel coordinates in the rectified views\r\n            ":"\r\n            使每个相机的主点在校正视图中具有相同的像素坐标\r\n            \r\n","\r\n            Adds elements to the bottom of the matrix\r\n            ":"\r\n            将元素添加到矩阵的底部\r\n            \r\n","The compressed data":"压缩数据\r\n","\r\n            Convert Bayer RGGB to GRAY\r\n            ":"\r\n            将 Bayer RGGB 转换为 GRAY\r\n            \r\n","\r\n            Compares two Mats and check if they are equal\r\n            ":"\r\n            比较两个垫子并检查它们是否相等\r\n            \r\n","\r\n            Word within a textline.\r\n            ":"\r\n            文本行中的单词。\r\n            \r\n","Number of warping iterations (number of pyramid levels)":"翘曲迭代次数（金字塔级别数）\r\n","a Mat with query image":"带有查询图像的垫子\r\n","The rotation matrix between the 1st and the 2nd cameras' coordinate systems ":"第一和第二相机坐标系之间的旋转矩阵\r\n","\r\n            Dict6X6_1000\r\n            ":"\r\n            Dict6X6_1000\r\n            \r\n"," Create a Xyz color using the specific values":" 使用特定值创建 Xyz 颜色\r\n","\r\n            Draw detected markers in image.\r\n            ":"\r\n            在图像中绘制检测到的标记。\r\n            \r\n","\r\n            Perform advanced morphological transformations using erosion and dilation as basic operations.\r\n            ":"\r\n            使用腐蚀和膨胀作为基本操作执行高级形态转换。\r\n            \r\n","\r\n            Create a new minimum graph cut-based seam estimator.\r\n            ":"\r\n            创建一个新的基于最小图切割的接缝估计器。\r\n            \r\n","\r\n            Y,UV  (4:2:0)\r\n            ":"\r\n            Y、紫外线 (4:2:0)\r\n            \r\n","\r\n            A 3D line segment\r\n            ":"\r\n            3D 线段\r\n            \r\n","The object representation as a result of the deserialization of the xml document":"作为 xml 文档反序列化结果的对象表示\r\n","\r\n            Concate the current matrix with another matrix horizontally. If this matrix is n x m1 and ":"\r\n            水平连接当前矩阵和另一个矩阵。如果这个矩阵是 n x m1 并且\r\n","Optional output 3x3 rotation matrix around y-axis.":"围绕 y 轴的可选输出 3x3 旋转矩阵。\r\n","Contains a path to the BRISQUE model data. If empty, attempts to load from ${OPENCV_DIR}/testdata/contrib/quality/brisque_model_live.yml":"包含 BRISQUE 模型数据的路径。如果为空，则尝试从 ${OPENCV_DIR}/testdata/contrib/quality/brisque_model_live.yml 加载\r\n","\r\n            Returns a CudaImage corresponding to the ith row of the CudaImage. The data is shared with the current Image. \r\n            ":"\r\n            返回对应于 CudaImage 的第 i 行的 CudaImage。数据与当前图像共享。\r\n            \r\n","\r\n            Perform an element wise AND operation using a mat and a scalar\r\n            ":"\r\n            使用垫子和标量执行元素明智的 AND 操作\r\n            \r\n","Alignment for image rows, typically 4 or 8 bytes.":"图像行的对齐方式，通常为 4 或 8 个字节。\r\n","\r\n            The type5_8\r\n            ":"\r\n            type5_8\r\n            \r\n","\r\n            Pointer to the unmanaged Objectness object\r\n            ":"\r\n            指向非托管 Objectness 对象的指针\r\n            \r\n","optional delta value that is added to the results prior to storing them in dst.":"在将结果存储到 dst 之前添加到结果中的可选增量值。\r\n","\r\n            Pink\r\n            ":"\r\n            粉色的\r\n            \r\n","output image with the marker":"带标记的输出图像\r\n","The minimum probability P(er|character) allowed for retreived ER’s.":"允许检索 ER 的最小概率 P(er|character)。\r\n","\r\n            This function retrieve the Open CV structure sizes in unmanaged code\r\n            ":"\r\n            此函数检索非托管代码中的 Open CV 结构大小\r\n            \r\n","\r\n            Create a default decision tree\r\n            ":"\r\n            创建默认决策树\r\n            \r\n","Color of marker borders. Rest of colors (text color and first corner color) are calculated based on this one to improve visualization.":"标记边框的颜色。其余颜色（文本颜色和第一个角颜色）是基于此计算的，以提高可视化效果。\r\n","The aperture size, use 3 for default":"孔径大小，默认3\r\n","\tflag which indicates whether image will be cropped after resize or not":"指示图像在调整大小后是否将被裁剪的标志\r\n","The boxed region of the image":"图像的盒装区域\r\n","\r\n            DNN-based face recognizer\r\n            ":"\r\n            基于 DNN 的人脸识别器\r\n            \r\n","Spatial aspect ratio.":"空间纵横比。\r\n","The image where prediction will be based on":"预测将基于的图像\r\n","CV_8UC1 image mask where 255 indicates that the pixel is a superpixel border, and 0 otherwise.":"CV_8UC1 图像掩码，其中 255 表示该像素是超像素边界，否则为 0。\r\n"," to the current image using the specific mask\r\n            ":" 使用特定掩码到当前图像\r\n            \r\n","Input CV_8UC3 matrix.":"输入 CV_8UC3 矩阵。\r\n","\r\n            Calculates the width and height of a text string.\r\n            ":"\r\n            计算文本字符串的宽度和高度。\r\n            \r\n","\r\n            Threshold euclidean distance between two centroids. If two cluster centers are closer than this distance, one of the centroid is dismissed and points are reassigned.\r\n            ":"\r\n            两个质心之间的阈值欧氏距离。如果两个聚类中心比此距离更近，则取消其中一个质心并重新分配点。\r\n            \r\n","\r\n            Convert this matrix to different depth\r\n            ":"\r\n            将此矩阵转换为不同的深度\r\n            \r\n","Input point":"输入点\r\n","\r\n            minimum distance of any corner to the image border for detected markers (in pixels) (default 3)\r\n            ":"\r\n            检测到的标记的任何角落到图像边界的最小距离（以像素为单位）（默认为 3）\r\n            \r\n","The column range.":"列范围。\r\n","Angle resolution of the accumulator in radians":"累加器的角度分辨率（以弧度为单位）\r\n","\r\n            Threshold the image such that: dst(x,y) = threshold, if src(x,y)>threshold; src(x,y), otherwise \r\n            ":"\r\n            阈值图像使得： dst(x,y) = threshold, if src(x,y)>threshold; src(x,y)，否则\r\n            \r\n","Optional output 3x3 rotation matrix around z-axis.":"围绕 z 轴的可选输出 3x3 旋转矩阵。\r\n","a flag, indicating whether a more accurate norm should be used to calculate the image gradient magnitude ( L2gradient=true ), or whether the default norm is enough ( L2gradient=false ).":"一个标志，指示是否应使用更准确的范数来计算图像梯度幅度（ L2gradient=true ），或者默认范数是否足够（ L2gradient=false ）。\r\n","Output vector indicating which points are inliers (1-inlier, 0-outlier).":"指示哪些点是异常值的输出向量（1 异常值，0 异常值）。\r\n","\r\n            Create an Chi based cost extraction.\r\n            ":"\r\n            创建基于 Chi 的成本提取。\r\n            \r\n","\r\n            Create a transformation that consists on a simple displacement\r\n            ":"\r\n            创建一个包含简单位移的变换\r\n            \r\n","The input 16-bit signed disparity image":"输入的 16 位有符号视差图像\r\n"," \r\n            Backproject the histogram into a matrix\r\n            ":" \r\n            将直方图反向投影到矩阵中\r\n            \r\n","\r\n            Release the GCHandle\r\n            ":"\r\n            释放 GCHandle\r\n            \r\n","\r\n            Element size\r\n            ":"\r\n            元件尺寸\r\n            \r\n","Channel of interest starting from 1. If 0, the COI is unset.":"感兴趣的频道从 1 开始。如果为 0，则 COI 未设置。\r\n","Checks that image elements lie between two scalars":"检查图像元素是否位于两个标量之间\r\n","The first image to be added":"要添加的第一张图片\r\n","A path to output text file to be created.":"要创建的输出文本文件的路径。\r\n","Gaussian smoothing window parameter.":"高斯平滑窗口参数。\r\n","buffer containing the content of the pb file":"包含 pb 文件内容的缓冲区\r\n","Size of the UMat":"UMat 的大小\r\n","Take rotation transformation into account.":"考虑旋转变换。\r\n","\r\n            Returns true if the two GpuMat equals\r\n            ":"\r\n            如果两个 GpuMat 相等则返回 true\r\n            \r\n","The input contour stored as a point vector.":"输入轮廓存储为点向量。\r\n","\r\n            IYUV\r\n            ":"\r\n            IYUV\r\n            \r\n","\r\n            Smartek Giganetix Ethernet Vision: frame width max\r\n            ":"\r\n            Smartek Giganetix Ethernet Vision：最大帧宽\r\n            \r\n","The foreground mask used to calculate the motion info.":"用于计算运动信息的前景遮罩。\r\n","The 2D image location of the points for camera 2. The first index is the index of the image, second index is the index of the point":"相机 2 点的二维图像位置。第一个索引是图像的索引，第二个索引是点的索引\r\n","Optional output distances from the input vectors to the corresponding neighbors. It is a single-precision floating-point matrix of <number_of_samples> * k size.":"从输入向量到相应邻居的可选输出距离。它是 <number_of_samples> * k 大小的单精度浮点矩阵。\r\n","\r\n            Finds subdivision vertex that is the closest to the input point. It is not necessarily one of vertices of the facet containing the input point, though the facet (located using cvSubdiv2DLocate) is used as a starting point.\r\n            ":"\r\n            查找最接近输入点的细分顶点。它不一定是包含输入点的小平面的顶点之一，尽管小平面（使用 cvSubdiv2DLocate 定位）用作起点。\r\n            \r\n","True if we need to call Release function to ":"如果我们需要调用 Release 函数，则为真\r\n","\r\n            Enable/Disable debounce to selected GPI\r\n            ":"\r\n            启用/禁用选定 GPI 的去抖动\r\n            \r\n","\r\n            Loads algorithm from the file\r\n            ":"\r\n            从文件加载算法\r\n            \r\n","\r\n            High level function to execute a rapid iteration\r\n            ":"\r\n            执行快速迭代的高级函数\r\n            \r\n","\r\n            Regularization disabled.\r\n            ":"\r\n            禁用正则化。\r\n            \r\n","\r\n            Mapper for euclidean motion: rotation plus shift\r\n            ":"\r\n            欧几里德运动的映射器：旋转加移位\r\n            \r\n","Hash value two":"哈希值二\r\n","True if library loaded":"如果库已加载则为真\r\n","\r\n            For using in setLogVevel() call\r\n            ":"\r\n            在 setLogVevel() 调用中使用\r\n            \r\n","Order of the derivative y":"导数 y 的阶数\r\n"," if [use optimized]; otherwise, ":" 如果[使用优化]；否则，\r\n","\r\n            Release the unmanaged memory associated to this line detector.\r\n            ":"\r\n            释放与此线路检测器关联的非托管内存。\r\n            \r\n","\r\n            Stop the grabbing thread\r\n            ":"停止抓取线程\r\n            \r\n","\r\n            Nearest-neighbor interpolation\r\n            ":"\r\n            最近邻插值\r\n            \r\n","\r\n            Classic Niblack binarization.\r\n            ":"\r\n            经典的 Niblack 二值化。\r\n            \r\n","\r\n            Uniform distribution\r\n            ":"\r\n            均匀分布\r\n            \r\n","The image from which the features will be detected from":"从中检测特征的图像\r\n","Weight parameter for (u - v)^2, tightness parameter. It serves as a link between the attachment and the regularization terms. In theory, it should have a small value in order to maintain both parts in correspondence. The method is stable for a large range of values of this parameter.":"(u - v)^2 的权重参数，紧度参数。它充当附件和正则化项之间的链接。理论上，它应该有一个小的值，以保持两个部分的对应关系。对于该参数的大范围值，该方法是稳定的。\r\n","\r\n            The output is the minimum (column/row-wise) of all the matrix rows/columns\r\n            ":"\r\n            输出是所有矩阵行/列的最小值（列/行）\r\n            \r\n","\r\n            Open and record video file or stream using the FFMPEG library\r\n            ":"\r\n            使用 FFMPEG 库打开和录制视频文件或流\r\n            \r\n","Number of pyramid levels to proceed. Deep pyramids increase speed but decrease accuracy. Too coarse pyramids might have computational overhead on top of the inaccurate registrtaion. This parameter should be chosen to optimize a balance. Typical values range from 4 to 10.":"要进行的金字塔级别数。深金字塔提高速度但降低准确性。太粗糙的金字塔可能会在不准确的注册之上产生计算开销。应选择此参数以优化天平。典型值范围为 4 到 10。\r\n","\r\n            (read-only) Number of audio channels in the selected audio stream (mono, stereo, etc)\r\n            ":"（只读）所选音频流中的音频通道数（单声道、立体声等）\r\n            \r\n","3x4 projection matrix of the first camera.":"第一个摄像机的 3x4 投影矩阵。\r\n","The 3x3 matrix's value as a double vector (of size 9)":"3x3 矩阵的值作为双精度向量（大小为 9）\r\n","The number of elements in the descriptor":"描述符中的元素数量\r\n","Array of corresponding image points, 2xN/Nx2 1-channel or 1xN/Nx1 2-channel, where N is the number of points. VectorOfPointF can be also passed here.":"相应图像点的数组，2xN/Nx2 1 通道或 1xN/Nx1 2 通道，其中 N 是点数。 VectorOfPointF也可以在这里传递。\r\n","\r\n            Types of thresholding \r\n            ":"\r\n            阈值类型\r\n            \r\n","\r\n            Computes per-element minimum of two GpuMats (dst = min(src1, src2))\r\n            ":"\r\n            计算两个 GpuMat 的每个元素的最小值 (dst = min(src1, src2))\r\n            \r\n","\r\n            Fits line to 2D or 3D point set \r\n            ":"\r\n            将线拟合到 2D 或 3D 点集\r\n            \r\n","The index parameters":"索引参数\r\n","If you are using the default sigmoid activation function with the default parameter values\r\n            fparam1 = 0 and fparam2 = 0 then the function used is y = 1.7159 * tanh(2/3 * x), so the output\r\n            will range from[-1.7159, 1.7159], instead of[0, 1].\r\n            ":"如果您使用默认参数值的默认 sigmoid 激活函数\r\n            fparam1 = 0 和 fparam2 = 0 然后使用的函数是 y = 1.7159 * tanh(2/3 * x)，所以输出\r\n            范围从 [-1.7159, 1.7159]，而不是 [0, 1]。\r\n            \r\n","\r\n            LogitBoost. It can produce good regression fits.\r\n            ":"\r\n            对数提升。它可以产生良好的回归拟合。\r\n            \r\n","\r\n            Create a gradient mapper for a projective transformation\r\n            ":"\r\n            为投影变换创建梯度映射器\r\n            \r\n","Array diagonal. Zero corresponds to the main diagonal, -1 corresponds to the diagonal above the main etc., 1 corresponds to the diagonal below the main etc":"阵列对角线。零对应于主对角线，-1 对应于主对角线上方等，1 对应于主对角线下方等\r\n","\r\n            Image filtering.\r\n            ":"\r\n            图像过滤。\r\n            \r\n","\r\n            (**open-only**) If non-zero, create new OpenCL context and bind it to current thread. The OpenCL context created with Video Acceleration context attached it (if not attached yet) for optimized GPU data copy between cv::UMat and HW accelerated encoder.\r\n            ":"\r\n            (**open-only**) 如果非零，则创建新的 OpenCL 上下文并将其绑定到当前线程。使用视频加速上下文创建的 OpenCL 上下文附加它（如果尚未附加）以优化 cv::UMat 和 HW 加速编码器之间的 GPU 数据复制。\r\n            \r\n","width of the marker border.":"标记边框的宽度。\r\n","\r\n            image data size in bytes\r\n            (=image->height*image->widthStep in case of interleaved data)\r\n            ":"\r\n            以字节为单位的图像数据大小\r\n            （=image->height*image->widthStep 在交错数据的情况下）\r\n            \r\n","\r\n            Performs range check for every element of the input array:\r\n            dst(I)=lower(I)_0 <= src(I)_0 <= upper(I)_0\r\n            For single-channel arrays,\r\n            dst(I)=lower(I)_0 <= src(I)_0 <= upper(I)_0 &&\r\n            lower(I)_1 <= src(I)_1 <= upper(I)_1\r\n            For two-channel arrays etc.\r\n            dst(I) is set to 0xff (all '1'-bits) if src(I) is within the range and 0 otherwise. All the arrays must have the same type, except the destination, and the same size (or ROI size)\r\n            ":"\r\n            对输入数组的每个元素执行范围检查：\r\n            dst(I)=lower(I)_0 <= src(I)_0 <= upper(I)_0\r\n            对于单通道阵列，\r\n            dst(I)=低(I)_0 <= src(I)_0 <= 上(I)_0 &&\r\n            较低（I）_1 <= src（I）_1 <= 较高（I）_1\r\n            对于双通道阵列等\r\n            如果 src(I) 在范围内，则 dst(I) 设置为 0xff（全“1”位），否则设置为 0。所有数组必须具有相同的类型（目标除外）和相同的大小（或 ROI 大小）\r\n            \r\n","\r\n            Hot\r\n            ":"\r\n            热的\r\n            \r\n","4xN array of reconstructed points in homogeneous coordinates.":"齐次坐标中的 4xN 重建点阵列。\r\n","Output translation vector between the coordinate systems of the cameras.":"相机坐标系之间的输出平移向量。\r\n","\r\n            Calculates the per-element difference between two matrices.\r\n            ":"\r\n            计算两个矩阵之间的每个元素的差异。\r\n            \r\n","\r\n            The base class for auto white balance algorithms.\r\n            ":"\r\n            自动白平衡算法的基类。\r\n            \r\n","\r\n            Computes the multiplication of two quaternions\r\n            ":"\r\n            计算两个四元数的乘法\r\n            \r\n","The inclusive stating column to be extracted":"要提取的包含说明列\r\n","Signal power within the 5x5 centroid around the peak, between 0 and 1 ":"峰值周围 5x5 质心内的信号功率，介于 0 和 1 之间\r\n","The row range. Use MCvSlice.WholeSeq for all rows.":"行范围。对所有行使用 MCvSlice.WholeSeq。\r\n","defines whether initial guess for rvec and  tvec will be used or not.":"定义是否使用 rvec 和 tvec 的初始猜测。\r\n","Anchor position within the element. Both negative values mean that the anchor is at the kernel center.":"元素内的锚点位置。两个负值都表示锚点位于内核中心。\r\n","\r\n            Fill the (3x3) rotation matrix with the value such that it represent the quaternions\r\n            ":"\r\n            用代表四元数的值填充 (3x3) 旋转矩阵\r\n            \r\n","\r\n            iOS device flash\r\n            ":"\r\n            iOS 设备闪存\r\n            \r\n","\r\n            Groups the object candidate rectangles.\r\n            ":"\r\n            对对象候选矩形进行分组。\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of VectorOfPointF.\r\n            ":"\r\n            VectorOfPointF 的 C++ 标准向量的包装类。\r\n            \r\n","Coordinates of 4 quadrangle vertices in the source image":"源图中4个四边形顶点的坐标\r\n","\r\n            Numerical or Ordered\r\n            ":"\r\n            数字或有序\r\n            \r\n","\r\n            Converts an image from BGR color space to I420 color space.\r\n            ":"\r\n            将图像从 BGR 色彩空间转换为 I420 色彩空间。\r\n            \r\n","\r\n             Pose estimation for a ChArUco board given some of their corners\r\n            ":"\r\n             给定一些角的 ChArUco 板的姿势估计\r\n            \r\n","\r\n            Plot line width\r\n            ":"\r\n            绘图线宽\r\n            \r\n","Segment shorter than this will be discarded.":"短于此的段将被丢弃。\r\n","Size of a discrete Fourier transform.":"离散傅立叶变换的大小。\r\n","Range between 0 to 200.":"范围在 0 到 200 之间。\r\n","The input/output camera matrices [fxk 0 cxk; 0 fyk cyk; 0 0 1]. If CV_CALIB_USE_INTRINSIC_GUESS or CV_CALIB_FIX_ASPECT_RATIO are specified, some or all of the elements of the matrices must be initialized":"输入/输出相机矩阵 [fxk 0 cxk; 0 飞克赛克； 0 0 1]。如果指定了 CV_CALIB_USE_INTRINSIC_GUESS 或 CV_CALIB_FIX_ASPECT_RATIO，则必须初始化矩阵的部分或全部元素\r\n","The length of this array is the dimension of the histogram. The values of the array contains the number of bins in each dimension. The total number of bins eaquals the multiplication of all numbers in the array":"这个数组的长度就是直方图的维度。数组的值包含每个维度中的 bin 数。箱子的总数等于数组中所有数字的乘积\r\n","\r\n            Convert BayerBG to GRAY\r\n            ":"\r\n            将 BayerBG 转换为 GREY\r\n            \r\n","Upper range boundary in case of the range normalization; it is not used for the norm normalization.":"范围归一化情况下的范围上限；它不用于范数归一化。\r\n","\r\n            Create an empty CudaImage\r\n            ":"\r\n            创建一个空的 CudaImage\r\n            \r\n","\r\n            Int32\r\n            ":"\r\n            整数32\r\n            \r\n","kernel anchor point. The default value of Point(-1, -1) denotes that the anchor is at the kernel center":"内核锚点。 Point(-1, -1) 的默认值表示锚点在内核中心\r\n","A rows x cols x 3 matrix of CV_32F/CV64F or a rows x cols x 1 CV_U16S":"CV_32F/CV64F 的行 x 列 x 3 矩阵或行 x 列 x 1 CV_U16S\r\n","\r\n            Backlight\r\n            ":"\r\n            背光\r\n            \r\n","\r\n            Initialize the BarcodeDetector.\r\n            ":"\r\n            初始化 BarcodeDetector。\r\n            \r\n","\r\n            Assume a single column of text of variable sizes.\r\n            ":"\r\n            假设有一列可变大小的文本。\r\n            \r\n","The value to AND":"AND 的值\r\n","\r\n            Write only\r\n            ":"\r\n            只写\r\n            \r\n","\r\n            Create an standard vector of VideoCapture of the specific size\r\n            ":"\r\n            创建特定大小的 VideoCapture 标准向量\r\n            \r\n","Size of the image used for stereo calibration.":"用于立体校准的图像大小。\r\n","The first source array.":"第一个源数组。\r\n","Keep top K bboxes before NMS":"在 NMS 之前保留前 K 个 bboxes\r\n","\r\n            Enables or disables the optimized code.\r\n            ":"\r\n            启用或禁用优化代码。\r\n            \r\n","\r\n            Pointer to the InputArray\r\n            ":"\r\n            指向 InputArray 的指针\r\n            \r\n","The distance between the histogram":"直方图之间的距离\r\n","\r\n            Release the memory associated with this Model.\r\n            ":"\r\n            释放与此模型关联的内存。\r\n            \r\n","\r\n            Construct an instance of the plane warper class.\r\n            ":"\r\n            构造平面变形器类的一个实例。\r\n            \r\n","Property identifier":"属性标识符\r\n","\r\n            Generates a single uniformly-distributed random number or an array of random numbers.\r\n            ":"\r\n            生成单个均匀分布的随机数或随机数数组。\r\n            \r\n","The image format is chosen depending on the filename extension, see cvLoadImage. Only 8-bit single-channel or 3-channel (with 'BGR' channel order) images can be saved using this function. If the format, depth or channel order is different, use cvCvtScale and cvCvtColor to convert it before saving, or use universal cvSave to save the image to XML or YAML format.":"图像格式的选择取决于文件扩展名，参见 cvLoadImage。使用此功能只能保存 8 位单通道或 3 通道（具有“BGR”通道顺序）图像。如果格式、深度或通道顺序不同，请在保存前使用 cvCvtScale 和 cvCvtColor 进行转换，或者使用通用的 cvSave 将图像保存为 XML 或 YAML 格式。\r\n","\r\n            Clear the list of files\r\n            ":"\r\n            清除文件列表\r\n            \r\n","The calibration flags":"校准标志\r\n","Phase map height.":"相图高度。\r\n","\r\n            Class for computing the optical flow vectors between two images using NVIDIA Optical Flow hardware and Optical Flow SDK 1.0.\r\n            ":"\r\n            使用 NVIDIA 光流硬件和光流 SDK 1.0 计算两个图像之间的光流向量的类。\r\n            \r\n","\r\n            use pre-computed average vector\r\n            ":"\r\n            使用预先计算的平均向量\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of CvString.\r\n            ":"\r\n            CvString 的 C++ 标准向量的包装类。\r\n            \r\n","The depth type of the result image":"结果图像的深度类型\r\n","Size of the extended Sobel kernel, must be 1, 3, 5 or 7. In all cases except 1, aperture_size xaperture_size separable kernel will be used to calculate the derivative.":"扩展 Sobel 内核的大小，必须是 1、3、5 或 7。在除 1 之外的所有情况下，aperture_size xaperture_size 可分离内核将用于计算导数。\r\n","\r\n            Fast\r\n            ":"\r\n            快速地\r\n            \r\n","The other RangeF to compare with":"另一个要与之比较的 RangeF\r\n","true if the each of the pixels for the two images are equal, false otherwise":"如果两个图像的每个像素都相等，则为 true，否则为 false\r\n","\r\n            inf, nan\r\n            ":"\r\n            inf, 楠\r\n            \r\n","Mono setting":"单声道设置\r\n","If true, window renders.":"如果为真，则窗口呈现。\r\n","\r\n            Transforms every element of src (by treating it as 2D or 3D vector) in the following way:\r\n            (x, y, z) -> (x'/w, y'/w, z'/w) or\r\n            (x, y) -> (x'/w, y'/w),\r\n            where\r\n            (x', y', z', w') = mat4x4 * (x, y, z, 1) or\r\n            (x', y', w') = mat3x3 * (x, y, 1)\r\n            and w = w'   if w'!=0,\r\n                   inf  otherwise\r\n            ":"\r\n            按以下方式转换 src 的每个元素（通过将其视为 2D 或 3D 向量）：\r\n            (x, y, z) -> (x'/w, y'/w, z'/w) 或者\r\n            (x, y) -> (x'/w, y'/w),\r\n            在哪里\r\n            (x', y', z', w') = mat4x4 * (x, y, z, 1) 或\r\n            (x', y', w') = mat3x3 * (x, y, 1)\r\n            并且 w = w' 如果 w'!=0,\r\n                   inf否则\r\n            \r\n","\r\n            Min inertia ratio\r\n            ":"\r\n            最小惯量比\r\n            \r\n","\r\n            determine maximum perimeter for marker contour to be detected. This is defined as a rate respect to the maximum dimension of the input image (default 4.0).\r\n            ":"\r\n            确定要检测的标记轮廓的最大周长。这被定义为相对于输入图像最大维度的速率（默认 4.0）。\r\n            \r\n","Cost buffer contains numbers indicating the confidence associated with each of the generated flow vectors. Higher the cost, lower the confidence. Cost buffer is of type CV_32SC1.":"成本缓冲区包含指示与每个生成的流矢量相关联的置信度的数字。成本越高，信心越低。成本缓冲区的类型为 CV_32SC1。\r\n","The number of channels.":"通道数。\r\n","Output image depth.":"输出图像深度。\r\n","Input array.":"输入数组。\r\n","\r\n            Create a fast detector with the specific parameters\r\n            ":"\r\n            创建具有特定参数的快速检测器\r\n            \r\n","\r\n            Computes bitwise conjunction of the two matrices (src1 & src2) Calculates the per-element bit-wise logical conjunction of two matrices of the same size.\r\n            ":"\r\n            Computes bitwise conjunction of the two matrices (src1 & src2) 计算两个相同大小的矩阵的每个元素的按位逻辑结合。\r\n            \r\n","\r\n            indicates that only a vector of singular values 'w' is to be processed, while u and vt will be set to empty matrices\r\n            ":"\r\n            表示只处理一个奇异值向量'w'，而u和vt将被设置为空矩阵\r\n            \r\n","\r\n            Pointer to the unmanaged BackgroundSubtractor object\r\n            ":"\r\n            指向非托管 BackgroundSubtractor 对象的指针\r\n            \r\n","Projected image":"投影图像\r\n","\r\n            Eigen face recognizer\r\n            ":"\r\n            特征人脸识别器\r\n            \r\n","\r\n            Cost\r\n            ":"\r\n            成本\r\n            \r\n"," + alpha*img, using the mask\r\n            ":" + alpha*img，使用蒙版\r\n            \r\n","\r\n            Draws contours outlines or filled contours.\r\n            ":"\r\n            绘制等高线轮廓或填充等高线。\r\n            \r\n","The start value of this range":"该范围的起始值\r\n","The output array of the verticies of the intersecting region. It returns at most 8 vertices. Stored as VectorOfPointF or Mat as Mx1 of type CV_32FC2.":"相交区域顶点的输出数组。它最多返回 8 个顶点。存储为 VectorOfPointF 或 Mat 作为 CV_32FC2 类型的 Mx1。\r\n","\r\n            BayerGR2GRAY_MHT\r\n            ":"\r\n            拜耳GR2GRAY_MHT\r\n            \r\n","Output status vector. Each element of the vector is set to 1 if the flow for the corresponding features has been found.Otherwise, it is set to 0.":"输出状态向量。如果已找到对应特征的流，则向量的每个元素设置为 1。否则，设置为 0。\r\n","\r\n            The number of rows\r\n            ":"\r\n            行数\r\n            \r\n","\r\n            The selected generic parameter type\r\n            ":"\r\n            选择的泛型参数类型\r\n            \r\n","List of identifiers for each marker in corners":"角落中每个标记的标识符列表\r\n","\r\n            Process noise covariance matrix (Q)\r\n            ":"\r\n            过程噪声协方差矩阵 (Q)\r\n            \r\n"," The color of the circle ":" 圆圈的颜色\r\n","\r\n            Create an empty standard vector of Triangle2DF\r\n            ":"\r\n            创建 Triangle2DF 的空标准向量\r\n            \r\n","\r\n            Parameters for the detectMarker process\r\n            ":"\r\n            detectMarker 进程的参数\r\n            \r\n","\r\n            The output is the sum of all the matrix rows/columns\r\n            ":"\r\n            输出是所有矩阵行/列的总和\r\n            \r\n","The name of the opencl device":"opencl 设备的名称\r\n","Joint 8-bit, 1-channel or 3-channel image.":"联合 8 位、1 通道或 3 通道图像。\r\n","\r\n            Run Tesseract only - fastest\r\n            ":"\r\n            仅运行 Tesseract - 最快\r\n            \r\n","\r\n            Maximum possible value of the input image (e.g. 255 for 8 bit images, 4095 for 12 bit images)\r\n            ":"输入图像的最大可能值（例如 8 位图像为 255，12 位图像为 4095）\r\n            \r\n","The initial bounding box":"初始边界框\r\n","\r\n            Bayer Demosaicing (Malvar, He, and Cutler)\r\n            ":"\r\n            拜耳去马赛克（Malvar、He 和 Cutler）\r\n            \r\n","Rotation around x-axis (roll) in radian":"以弧度为单位绕 x 轴旋转（滚动）\r\n","\r\n            Convert BGR color to XYZ color\r\n            ":"\r\n            将 BGR 颜色转换为 XYZ 颜色\r\n            \r\n","\r\n            Coefficient for additional illumination variation term\r\n            ":"\r\n            附加光照变化项的系数\r\n            \r\n","Warp method":"翘曲法\r\n","\r\n            MAX DC1394\r\n            ":"\r\n            最大DC1394\r\n            \r\n","\r\n            TwilightShifted\r\n            ":"\r\n            暮光之城\r\n            \r\n","The second mat to apply bitwise OR operation":"应用按位或运算的第二个垫\r\n","\r\n            Convert YUV color to BGR\r\n            ":"\r\n            将 YUV 颜色转换为 BGR\r\n            \r\n","\r\n            Converts an image from YUV color space to RGB.\r\n            ":"\r\n            将图像从 YUV 颜色空间转换为 RGB。\r\n            \r\n","\r\n            Train image index\r\n            ":"\r\n            训练图像索引\r\n            \r\n","\r\n            Dict7X7_100\r\n            ":"\r\n            词典7X7_100\r\n            \r\n","Specifies when the iteration process of finding the flow for each point on each pyramid level should be stopped":"指定何时应停止查找每个金字塔级别上每个点的流的迭代过程\r\n","\r\n            Converts objects array from internal representation to standard vector.\r\n            ":"\r\n            将对象数组从内部表示转换为标准向量。\r\n            \r\n","Contains all output blobs for specified layer.":"包含指定层的所有输出 blob。\r\n","\r\n            Convert RGBA color to BGR565 color\r\n            ":"\r\n            将 RGBA 颜色转换为 BGR565 颜色\r\n            \r\n","\r\n            Gain in dB\r\n            ":"\r\n            以 dB 为单位的增益\r\n            \r\n","\r\n            Convert BGRA to YUV_IYUV\r\n            ":"\r\n            BGRA转YUV_IYUV\r\n            \r\n","\r\n            Create a Pinnned array of the specific type\r\n            ":"\r\n            创建特定类型的 Pinnned 数组\r\n            \r\n","\r\n            Computes squared magnitude of each (x(i), y(i)) vector\r\n            ":"\r\n            计算每个 (x(i), y(i)) 向量的平方幅度\r\n            \r\n","\r\n            Recover the homography matrix using RANDSAC. If the matrix cannot be recovered, null is returned.\r\n            ":"\r\n            使用 RANDSAC 恢复单应矩阵。如果无法恢复矩阵，则返回 null。\r\n            \r\n","Source floating point array (CV_32FC1 or CV_64FC1)":"源浮点数组（CV_32FC1 或 CV_64FC1）\r\n","Basic function used in axis x.":"x 轴中使用的基本函数。\r\n","\r\n            VAAPI\r\n            ":"\r\n            VAAPI\r\n            \r\n","\r\n            Gets the dense optical flow pointer.\r\n            ":"\r\n            获取密集光流指针。\r\n            \r\n"," The satuation value for this color ":" 这种颜色的饱和度值\r\n","\r\n            Convex hull ratio\r\n            ":"\r\n            凸包比\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of VectorOfDMatch.\r\n            ":"\r\n            VectorOfDMatch 的 C++ 标准向量的包装类。\r\n            \r\n","Maximum size of smooth disparity regions to consider their noise speckles and invalidate. Set it to 0 to disable speckle filtering. Otherwise, set it somewhere in the 50-200 range":"平滑视差区域的最大尺寸，以考虑其噪声斑点并使其失效。将其设置为 0 以禁用斑点过滤。否则，将其设置在 50-200 范围内的某个位置\r\n","\r\n            Entry points for LineDescriptor module\r\n            ":"\r\n            LineDescriptor 模块的入口点\r\n            \r\n","The converted point":"转换点\r\n","Second point of the line segment":"线段的第二个点\r\n","Output image, 8-bit unsigned 2-channel":"输出图像，8 位无符号 2 通道\r\n"," A point on the line ":" 直线上的一个点\r\n","The computed threshold value if Otsu's or Triangle methods used.":"如果使用 Otsu 或 Triangle 方法，则计算阈值。\r\n","A clone of the current UMat.":"当前 UMat 的克隆。\r\n","\r\n            Converts an image from RGB color space to HSV.\r\n            ":"\r\n            将图像从 RGB 颜色空间转换为 HSV。\r\n            \r\n","\r\n            By retaining only the gradients at edge locations, before integrating with the Poisson solver, one washes out the texture of the selected region, giving its contents a flat aspect. Here Canny Edge Detector is used.\r\n            ":"\r\n            通过仅保留边缘位置的梯度，在与泊松解算器集成之前，可以洗掉所选区域的纹理，使其内容呈现平坦的外观。这里使用了 Canny 边缘检测器。\r\n            \r\n","\r\n            Create an standard vector of PointF of the specific size\r\n            ":"\r\n            创建特定大小的 PointF 标准向量\r\n            \r\n","Order of derivative y":"导数 y 的阶数\r\n","\r\n            This structure is primary used for PInvoke\r\n            ":"\r\n            此结构主要用于 PInvoke\r\n            \r\n","Count the non Zero elements for each channel":"计算每个通道的非零元素\r\n","\r\n            Binary level PNG, 0 or 1, default is 0.\r\n            ":"\r\n            二进制级别 PNG，0 或 1，默认为 0。\r\n            \r\n","Magnitude scale parameter":"震级参数\r\n","\r\n            Window stride. It must be a multiple of block stride.\r\n            ":"\r\n            窗口步幅。它必须是块步幅的倍数。\r\n            \r\n","Final 32-b kernel derived from A and B.":"从 A 和 B 派生的最终 32-b 内核。\r\n","\r\n            Convert RGB color to GRAY color\r\n            ":"\r\n            将 RGB 颜色转换为 GRAY 颜色\r\n            \r\n","\r\n            Provide interfaces to the Open CV StructuredLight functions\r\n            ":"\r\n            为 Open CV StructuredLight 函数提供接口\r\n            \r\n","The location to sample a pixel":"采样像素的位置\r\n","The threshold value":"阈值\r\n","\r\n            Number of maximal iterations used for the iterative refinement. Lower values can reduce the runtime but also the accuracy.\r\n            ":"\r\n            用于迭代细化的最大迭代次数。较低的值可以减少运行时间，但也会降低准确性。\r\n            \r\n","\r\n            norm = ||arr1-arr2||_L2/||arr2||_L2\r\n            ":"\r\n            范数 = ||arr1-arr2||_L2/||arr2||_L2\r\n            \r\n","\r\n            Calculates the average value and standard deviation of array elements, independently for each channel\r\n            ":"\r\n            计算数组元素的平均值和标准偏差，独立于每个通道\r\n            \r\n","Third input CV_8UC1 matrix to be merged.":"要合并的第三个输入 CV_8UC1 矩阵。\r\n","\r\n            Convert Bayer GBRG pattern to BGR color using VNG\r\n            ":"\r\n            使用 VNG 将 Bayer GBRG 图案转换为 BGR 颜色\r\n            \r\n","Number of lagged non-linearity iterations (inner loop)":"滞后非线性迭代次数（内循环）\r\n","Algorithm preset":"算法预设\r\n","\r\n            Tilted model\r\n            ":"\r\n            倾斜模型\r\n            \r\n","\r\n            Convert YUV (YVYU) to Gray\r\n            ":"\r\n            将 YUV (YVYU) 转换为灰色\r\n            \r\n","Blinking supression multiplier.":"闪烁抑制倍数。\r\n","Output vector of standard deviations estimated for extrinsic parameters. Order of deviations values: (R1,T1,…,RM,TM) where M is number of pattern views, Ri,Ti are concatenated 1x3 vectors.":"为外部参数估计的标准偏差的输出向量。偏差值的顺序：(R1,T1,…,RM,TM) 其中 M 是模式视图的数量，Ri,Ti 是串联的 1x3 向量。\r\n","Destination image.":"目标图像。\r\n","\r\n            Entry points to the Open CV HDF module\r\n            ":"\r\n            Open CV HDF 模块的入口点\r\n            \r\n","\r\n            Performs lines sort by votes\r\n            ":"\r\n            按投票执行行排序\r\n            \r\n","\r\n            Over Premul\r\n            ":"\r\n            超前乳\r\n            \r\n","Specify whether or not cross check is needed. Use false for default.":"指定是否需要交叉检查。默认使用 false。\r\n","\r\n            Get and set the flip type. If null, no flipping will be done.\r\n            ":"\r\n            获取和设置翻转类型。如果为空，则不会进行翻转。\r\n            \r\n","Optional output 2Nx(10+<numDistCoeffs>) jacobian matrix of derivatives of image points with respect to components of the rotation vector, translation vector, focal lengths, coordinates of the principal point and the distortion coefficients. In the old interface different components of the jacobian are returned via different output parameters.":"可选输出 2Nx(10+<numDistCoeffs>) 图像点关于旋转矢量、平移矢量、焦距、主点坐标和畸变系数分量的雅可比矩阵。在旧界面中，jacobian 的不同组件通过不同的输出参数返回。\r\n","Optional scale factor for the computed derivative values; by default, no scaling is applied":"计算导数值的可选比例因子；默认情况下，不应用缩放\r\n","\r\n            Release all the unmanaged memory associated with this background model.\r\n            ":"\r\n            释放与此后台模型关联的所有非托管内存。\r\n            \r\n","Optional left orthogonal matrix (MxM or MxN). If CV_SVD_U_T is specified, the number of rows and columns in the sentence above should be swapped":"可选的左正交矩阵（MxM 或 MxN）。如果指定了CV_SVD_U_T，则上面句子中的行数和列数应该交换\r\n","Output histogram":"输出直方图\r\n","Enables Ximgproc.fastGlobalSmootherFilter":"启用 Ximgproc.fastGlobalSmootherFilter\r\n"," The result of elementwise adding ":" 逐元素相加的结果\r\n","Tip of the cone.":"锥体的尖端。\r\n","Second input matrix of the same size and depth as src1.":"与 src1 具有相同大小和深度的第二个输入矩阵。\r\n","A single multi-channel matrix":"单个多通道矩阵\r\n","\r\n            0-based index of the frame to be decoded/captured next\r\n            ":"\r\n            下一个要解码/捕获的帧的基于 0 的索引\r\n            \r\n","\r\n            Gradient\r\n            ":"\r\n            坡度\r\n            \r\n","Matched block size. It must be an odd number >=1 . Normally, it should be somewhere in the 3..11 range. Use 0 for default. ":"匹配的块大小。它必须是一个奇数 >=1 。通常，它应该在 3..11 范围内的某个地方。默认使用 0。\r\n","\r\n            Ai\r\n            ":"\r\n            艾\r\n            \r\n","\r\n            Convert the standard vector to arrays of arrays of MDMatch\r\n            ":"\r\n            将标准向量转换为 MDMatch 数组的数组\r\n            \r\n","list of detected marker corners from detectMarkers function.":"从 detectMarkers 函数中检测到的标记角列表。\r\n","\r\n            BGR\r\n            ":"\r\n            BGR\r\n            \r\n","\r\n            Convert YUV 420 to Gray\r\n            ":"\r\n            将 YUV 420 转换为灰色\r\n            \r\n","cuda device id":"cuda 设备标识\r\n"," from the current matrix":" 从当前矩阵\r\n","\r\n             Calculates Laplacian of the source image by summing second x- and y- derivatives calculated using Sobel operator.\r\n             Specifying aperture_size=1 gives the fastest variant that is equal to convolving the image with the following kernel:\r\n            \r\n             |0  1  0|\r\n             |1 -4  1|\r\n             |0  1  0|\r\n             ":"\r\n             通过对使用 Sobel 运算符计算的二阶 x 和 y 导数求和来计算源图像的拉普拉斯算子。\r\n             指定 aperture_size=1 给出了最快的变体，它等于用以下内核对图像进行卷积：\r\n            \r\n             |0 1 0|\r\n             |1 -4 1|\r\n             |0 1 0|\r\n             \r\n","\r\n            Convert Bayer GBRG color to BGR color\r\n            ":"\r\n            将 Bayer GBRG 颜色转换为 BGR 颜色\r\n            \r\n","Optional three-element vector containing three Euler angles of rotation in degrees.":"包含三个欧拉旋转角（以度为单位）的可选三元素向量。\r\n","The unmanaged pointer to the GpuMat. It is the user's responsibility that the Color type and depth matches between the managed class and unmanaged pointer.":"指向 GpuMat 的非托管指针。托管类和非托管指针之间的颜色类型和深度匹配是用户的责任。\r\n","\r\n            Return the header, corresponding to a specified row of the input array\r\n            ":"\r\n            返回表头，对应输入数组的指定行\r\n            \r\n","\r\n            Returns layer with specified id which the network use.\r\n            ":"\r\n            返回网络使用的具有指定 id 的层。\r\n            \r\n","\r\n            Positive index indicates that returning extra data is supported by the video back end.  This can be retrieved as cap.retrieve(data, <returned index>).  E.g. When reading from a h264 encoded RTSP stream, the FFmpeg backend could return the SPS and/or PPS if available (if sent in reply to a DESCRIBE request), from calls to cap.retrieve(data, <returned index>).\r\n            ":"\r\n            正索引表示视频后端支持返回额外数据。这可以作为 cap.retrieve(data, <returned index>) 检索。例如。当从 h264 编码的 RTSP 流中读取时，FFmpeg 后端可以返回 SPS 和/或 PPS（如果可用）（如果发送以回复 DESCRIBE 请求），调用 cap.retrieve(data, <returned index>)。\r\n            \r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are less than elements in second.\r\n             ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否小于第二个矩阵中的元素。\r\n             \r\n","A submatrix corresponding to a specified rectangle":"指定矩形对应的子矩阵\r\n","\r\n            Get the cuda platform summary as a string\r\n            ":"\r\n            以字符串形式获取 cuda 平台摘要\r\n            \r\n","Criteria for termination of the iterative process of corner refinement. That is, the process of corner position refinement stops either after certain number of iteration or when a required accuracy is achieved. The criteria may specify either of or both the maximum number of iteration and the required accuracy":"角点细化迭代过程的终止标准。也就是说，角点位置细化过程在一定次数的迭代后或达到所需精度时停止。该标准可以指定最大迭代次数和所需精度中的一个或两个\r\n","\r\n            Output image range minimum value\r\n            ":"\r\n            输出图像范围最小值\r\n            \r\n","The position to start the search from":"开始搜索的位置\r\n","Vector of distortion coefficients (k1,k2,p1,p2[,k3[,k4,k5,k6],[s1,s2,s3,s4]]) of 4, 5, 8 or 12 elements":"4、5、8 或 12 个元素的失真系数向量 (k1,k2,p1,p2[,k3[,k4,k5,k6],[s1,s2,s3,s4]])\r\n","The region of interest":"感兴趣的区域\r\n","\r\n            Objectness algorithms based on [3] [3] Cheng, Ming-Ming, et al. \"BING: Binarized normed gradients for objectness estimation at 300fps.\" IEEE CVPR. 2014\r\n            ":"\r\n            基于 [3] [3] Cheng，Ming-Ming 等人的对象算法。 “BING：用于 300fps 物体估计的二值化归一化梯度。” IEEE CVPR。 2014\r\n            \r\n","The programming language to generate code from":"从中生成代码的编程语言\r\n","\r\n            Create a stereoBM \r\n            ":"\r\n            创建立体 BM\r\n            \r\n","\r\n            Create a new CCheckerDraw object.\r\n            ":"\r\n            创建一个新的 CCheckerDraw 对象。\r\n            \r\n","\r\n            [v1-avg, v2-avg,...] * transpose([v1-avg,v2-avg,...])\r\n            ":"\r\n            [v1-avg, v2-avg,...] * 转置([v1-avg,v2-avg,...])\r\n            \r\n","\r\n            Create the standard vector of VectorOfRect \r\n            ":"\r\n            创建 VectorOfRect 的标准向量\r\n            \r\n","\r\n            Estimated rotation part extracted from the homogeneous matrix that transforms a point expressed in the camera frame to the gripper frame.\r\n            ":"从齐次矩阵中提取的估计旋转部分，将相机框架中表示的点转换为夹持器框架。\r\n            \r\n","\r\n            Assume a single uniform block of text. (Default.)\r\n            ":"\r\n            假设有一个统一的文本块。 （默认。）\r\n            \r\n","y-coordinate of the baseline relative to the bottom-most text point.":"相对于最底部文本点的基线的 y 坐标。\r\n","The number of channels in the source image":"源图像中的通道数\r\n","\r\n            Translate the Affine3 matrix by the given value\r\n            ":"\r\n            按给定值平移 Affine3 矩阵\r\n            \r\n","\r\n            Convert BayerGB pattern to BGR color using VNG\r\n            ":"\r\n            使用 VNG 将 BayerGB 模式转换为 BGR 颜色\r\n            \r\n","\r\n            The AddressBits\r\n            ":"\r\n            地址位\r\n            \r\n","The thickness of the line":"线的粗细\r\n","Pixel extrapolation method in the horizontal direction":"水平方向像素外推法\r\n","\r\n            The type7_12\r\n            ":"\r\n            type7_12\r\n            \r\n","The box the define the ellipse area":"定义椭圆区域的框\r\n","\r\n            FrameType\r\n            ":"\r\n            帧类型\r\n            \r\n","Weights for second image. Must have tha same size as img2. Supports only CV_32F type.":"第二张图片的权重。必须具有与 img2 相同的大小。仅支持 CV_32F 类型。\r\n","\r\n            Create an Extremal Region Filter for the 2nd stage classifier of N&M algorithm\r\n            ":"\r\n            为 N&M 算法的第二阶段分类器创建一个极值区域过滤器\r\n            \r\n","optional object inheriting from RFFeatureGetter. You need it only if you would like to train your own forest, pass NULL otherwise":"继承自 RFFeatureGetter 的可选对象。仅当您想训练自己的森林时才需要它，否则传递 NULL\r\n","\r\n            Fix S1, S2, S3, S4\r\n            ":"\r\n            修复 S1、S2、S3、S4\r\n            \r\n","\r\n            The number of gaussian components in the background model\r\n            ":"\r\n            背景模型中高斯分量的数量\r\n            \r\n","\r\n            Class that provide access to native GAPI functions from OpenCV\r\n            ":"\r\n            提供从 OpenCV 访问本机 GAPI 函数的类\r\n            \r\n","Second source matrix (if any) with the same size and type as src1.":"与 src1 具有相同大小和类型的第二个源矩阵（如果有）。\r\n","Input histogram that can be dense or sparse.":"输入直方图可以是密集的或稀疏的。\r\n","\r\n            Oil Painting effect\r\n            ":"\r\n            油画效果\r\n            \r\n","The reprojected 3D points":"重新投影的 3D 点\r\n","\r\n            This 3D Widget represents a coordinate system.\r\n            ":"\r\n            这个 3D Widget 代表一个坐标系。\r\n            \r\n"," Create a HSV color using the specific values":" 使用特定值创建 HSV 颜色\r\n","\r\n            Change image downsampling type.\r\n            ":"\r\n            更改图像下采样类型。\r\n            \r\n","\r\n            The source file name where error is encountered\r\n            ":"\r\n            遇到错误的源文件名\r\n            \r\n","\r\n            Base class for all camera parameters refinement methods.\r\n            ":"\r\n            所有相机参数优化方法的基类。\r\n            \r\n","\r\n            The coordinate of the lower corner\r\n            ":"\r\n            下角坐标\r\n            \r\n","\r\n            The maximum value of N\r\n            ":"\r\n            N的最大值\r\n            \r\n","Shift along the verticle axis":"沿垂直轴移动\r\n","The bundle adjuster":"束调节器\r\n","The thickness with which the squares will be drawn":"绘制正方形的厚度\r\n","The source GpuMat. supports 1, 3 and 4 channels GpuMat with Byte, UInt16, int or float depth":"来源 GpuMat。支持具有 Byte、UInt16、int 或 float 深度的 1、3 和 4 通道 GpuMat\r\n","Input/output vector of rectangles. Output vector includes retained and grouped rectangles.":"矩形的输入/输出向量。输出向量包括保留和分组的矩形。\r\n","Input matrix to be subtracted.":"要减去的输入矩阵。\r\n","Accumulator threshold at the center detection stage. The smaller it is, the more false circles may be detected. Circles, corresponding to the larger accumulator values, will be returned first":"中央检测阶段的累加器阈值。它越小，可能检测到的错误圆圈就越多。与较大的累加器值相对应的圆圈将首先返回\r\n","The Mat representation of the UMat":"UMat 的 Mat 表示\r\n","\r\n            (simple blur with no scaling) - summation over a pixel param1 x param2 neighborhood. If the neighborhood size may vary, one may precompute integral image with cvIntegral function\r\n            ":"\r\n            （没有缩放的简单模糊）- 对像素 param1 x param2 邻域求和。如果邻域大小可能不同，可以使用 cvIntegral 函数预先计算积分图像\r\n            \r\n","\r\n            Refine the corners using the contour-points\r\n            ":"\r\n            使用轮廓点细化角落\r\n            \r\n","\r\n            Create a new instance containing the methods needed for Quasi Dense Stereo computation.\r\n            ":"\r\n            创建一个包含准密集立体计算所需方法的新实例。\r\n            \r\n","\r\n            The region where the character is detected.\r\n            ":"\r\n            检测到字符的区域。\r\n            \r\n","\r\n            If true, only return the largest object\r\n            ":"\r\n            如果为真，只返回最大的对象\r\n            \r\n","\r\n            The compute capability\r\n            ":"\r\n            计算能力\r\n            \r\n","The height of the input image":"输入图像的高度\r\n","The image to be saved":"要保存的图像\r\n","\r\n            Convert HLS color to BGR color\r\n            ":"\r\n            将 HLS 颜色转换为 BGR 颜色\r\n            \r\n","The multi-dimensional data where the 1st dimension is # of rows (height), the 2nd dimension is # cols (width) and the 3rd dimension is the channel ":"多维数据，第一维是行数（高度），第二维是列数（宽度），第三维是通道\r\n","\r\n            Convert the standard vector to an array of Byte\r\n            ":"\r\n            将标准向量转换为 Byte 数组\r\n            \r\n","\r\n            Selects the current feature which is accessible by XI_PRM_LENS_FEATURE.\r\n            ":"\r\n            选择 XI_PRM_LENS_FEATURE 可访问的当前特征。\r\n            \r\n","The input image. Any number of channel (1 (Eg: Gray), 3 (Eg: RGB), 4 (Eg: RGB-D)) can be provided":"输入图像。可以提供任意数量的通道（1（例如：灰色）、3（例如：RGB）、4（例如：RGB-D））\r\n","\r\n            Get the rotation axis of the quaternion\r\n            ":"\r\n            获取四元数的旋转轴\r\n            \r\n","First distribution parameter; in case of the uniform distribution, this is an inclusive lower boundary, in case of the normal distribution, this is a mean value.":"第一分布参数；在均匀分布的情况下，这是一个包容性的下边界，在正态分布的情况下，这是一个平均值。\r\n","\r\n            Create a BOWImgDescriptorExtractor\r\n            ":"创建一个 BOWImgDescriptorExtractor\r\n            \r\n","In the code, it compares (size_{i}-size_{i-delta})/size_{i-delta}":"在代码中，它比较 (size_{i}-size_{i-delta})/size_{i-delta}\r\n","Minimal radius of the circles to search for":"要搜索的圆的最小半径\r\n","\r\n            Trains the statistical model.\r\n            ":"\r\n            训练统计模型。\r\n            \r\n","The source GpuMat, single-channel":"源码GpuMat，单通道\r\n"," The number of non-zero elements in the resulting mask":" 结果掩码中非零元素的数量\r\n","\r\n            The pointer to the unmanaged MergeExposure object\r\n            ":"\r\n            指向非托管 MergeExposure 对象的指针\r\n            \r\n","\r\n            Convert Bayer RGGB color to RGB color\r\n            ":"\r\n            将 Bayer RGGB 颜色转换为 RGB 颜色\r\n            \r\n","Margin type":"保证金类型\r\n","\r\n            Number of frames in video file\r\n            ":"\r\n            视频文件中的帧数\r\n            \r\n","An n x m matrix of descriptors to be query for nearest neighbours. n is the number of descriptor and m is the size of the descriptor":"要查询最近邻居的 n x m 描述符矩阵。 n是描述符的数量，m是描述符的大小\r\n","\r\n            Use the Capture class as a FrameSource\r\n            ":"\r\n            使用 Capture 类作为 FrameSource\r\n            \r\n","\r\n            AI\r\n            ":"\r\n            人工智能\r\n            \r\n","A new matrix that is the vertical concatening of this matrix and ":"一个新的矩阵，它是这个矩阵的垂直串联和\r\n","Sample patterns using keypoints orientation, disabled by default.":"使用关键点方向的示例模式，默认情况下禁用。\r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are greater or equal compare to elements in second.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否大于或等于第二个矩阵中的元素。\r\n            \r\n","The type of depth of the image":"图像的深度类型\r\n","\r\n            Native pointer to the pixel data at the current position\r\n            ":"\r\n            指向当前位置像素数据的本机指针\r\n            \r\n","Robust method used to compute transformation.":"用于计算转换的稳健方法。\r\n","\r\n            Rotate the image the specified angle cropping the result to the original size\r\n            ":"\r\n            将图像旋转指定角度裁剪结果到原始大小\r\n            \r\n","\r\n            Planar board with grid arrangement of markers More common type of board. All markers are placed in the same plane in a grid arrangment.\r\n            ":"\r\n            带标记网格排列的平面板 更常见的板类型。所有标记都以网格排列方式放置在同一平面上。\r\n            \r\n","\r\n            Performs object detection with increasing detection window.\r\n            ":"\r\n            使用增加的检测窗口执行对象检测。\r\n            \r\n","\r\n            The type of color map\r\n            ":"\r\n            彩色地图的类型\r\n            \r\n","\r\n            Release the unmanaged resources\r\n            ":"\r\n            释放非托管资源\r\n            \r\n","\r\n            Get the centroid of this cuboid\r\n            ":"\r\n            获取这个长方体的质心\r\n            \r\n","\r\n            The window renders and starts the event loop.\r\n            ":"\r\n            窗口呈现并启动事件循环。\r\n            \r\n","\r\n            Specifies the kind of regularization to be applied. \r\n            ":"\r\n            指定要应用的正则化类型。\r\n            \r\n","True if the two Range equals":"如果两个范围相等则为真\r\n","The name of the base class to search":"要搜索的基类的名称\r\n","The sub-folder to store the model":"存放模型的子文件夹\r\n","\r\n            Planar Subdivision, can be use to compute Delaunnay's triangulation or Voroni diagram.\r\n            ":"\r\n            平面细分，可用于计算 Delaunnay 三角剖分或 Voroni 图。\r\n            \r\n","First input image, 1- or 3-channel, 8-bit or 32-bit floating point (each channel of multi-channel image is processed independently)":"第一张输入图像，1或3通道，8位或32位浮点数（多通道图像的每个通道独立处理）\r\n","\r\n            Calculates the weighted distance between two vectors and returns it\r\n            ":"\r\n            计算两个向量之间的加权距离并返回它\r\n            \r\n","The point where the crosshair is positioned.":"十字准线所在的点。\r\n","\r\n            Similar to CvArray but use GPU for processing\r\n            ":"\r\n            类似于 CvArray 但使用 GPU 进行处理\r\n            \r\n","Matrices to project":"投影矩阵\r\n","The result GpuMat":"结果 GpuMat\r\n","\r\n            Create the termination criteria using the constrain of maximum iteration\r\n            ":"\r\n            使用最大迭代约束创建终止条件\r\n            \r\n","Size of the descriptor in bits. 0 -> Full size":"描述符的大小（以位为单位）。 0 -> 全尺寸\r\n","\r\n            calculates matrix of perspective transform such that:\r\n            (t_i x'_i,t_i y'_i,t_i)^T=map_matrix (x_i,y_i,1)T\r\n            where dst(i)=(x'_i,y'_i), src(i)=(x_i,y_i), i=0..3.\r\n            ":"\r\n            计算透视变换矩阵，使得：\r\n            (t_i x'_i,t_i y'_i,t_i)^T=map_matrix (x_i,y_i,1)T\r\n            其中 dst(i)=(x'_i,y'_i), src(i)=(x_i,y_i), i=0..3。\r\n            \r\n","\r\n            Box filter\r\n            ":"箱式过滤器\r\n            \r\n","Filter radius, use 3 as default":"过滤半径，默认使用3\r\n","\r\n            Binning pattern type.\r\n            ":"\r\n            装箱模式类型。\r\n            \r\n","\r\n            Retrieves contours from the binary image as a contour tree. The pointer firstContour is filled by the function. It is provided as a convenient way to obtain the hierarchy value as int[,].\r\n            The function modifies the source image content\r\n            ":"\r\n            从二值图像中检索轮廓作为轮廓树。函数填充指针 firstContour。它是作为获取层次结构值的便捷方式而提供的，如 int[,]。\r\n            函数修改源图片内容\r\n            \r\n"," Create a Ycc color using the specific values":" 使用特定值创建 Ycc 颜色\r\n","\r\n            dot(I1,I2)/(|I1|*|I2|)\r\n            ":"\r\n            点（I1，I2）/（|I1|*|I2|）\r\n            \r\n","\r\n            Create the CudaImage from the unmanaged pointer.\r\n            ":"\r\n            从非托管指针创建 CudaImage。\r\n            \r\n","\r\n            Floating point 16 bit value, CV_16FC1.\r\n            ":"\r\n            浮点 16 位值，CV_16FC1。\r\n            \r\n","\r\n            Bad Alpha channel\r\n            ":"\r\n            坏的 Alpha 通道\r\n            \r\n","\r\n            Get the name of the algorithm.\r\n            ":"\r\n            获取算法的名称。\r\n            \r\n","\r\n            Height of frames in the video stream\r\n            ":"\r\n            视频流中帧的高度\r\n            \r\n","\r\n            The intensity of the y color channel\r\n            ":"\r\n            y 颜色通道的强度\r\n            \r\n","\r\n            ReadMat data from source or write data to the internal buffer\r\n            ":"\r\n            从源中读取数据或将数据写入内部缓冲区\r\n            \r\n","\r\n            Segmentation with cpu. This method is only implemented for reference. It is highly NOT recommended to use it.\r\n            ":"\r\n            用cpu分割。此方法仅供参考。强烈不建议使用它。\r\n            \r\n","\r\n            This function performs the same as MakeType macro\r\n            ":"\r\n            此函数执行与 MakeType 宏相同的操作\r\n            \r\n","\r\n            Change sensor shutter type(CMOS sensor).\r\n            ":"\r\n            更改传感器快门类型（CMOS 传感器）。\r\n            \r\n","\r\n            RPROP: Update-values lower limit\r\n            ":"\r\n            RPROP：更新值下限\r\n            \r\n","\r\n            Abstract base class for shape transformation algorithms.\r\n            ":"\r\n            形状变换算法的抽象基类。\r\n            \r\n","The maximum locations for each channel ":"每个通道的最大位置\r\n","Zero-based coordinates of the rectangle of interest.":"感兴趣的矩形的从零开始的坐标。\r\n","Method-specific parameter (is not used now)":"方法特定参数（现在不使用）\r\n","Color space conversion code (see the description below).":"颜色空间转换代码（见下面的描述）。\r\n","Input 1-, 3-, or 4-channel image; when ksize is 3 or 5, the image depth should be CV_8U, CV_16U, or CV_32F, for larger aperture sizes, it can only be CV_8U.":"输入 1、3 或 4 通道图像；当ksize为3或5时，图像深度应为CV_8U、CV_16U或CV_32F，对于更大的孔径尺寸，只能为CV_8U。\r\n","\r\n            For TIFF, use to specify the Y direction DPI\r\n            ":"\r\n            对于 TIFF，用于指定 Y 方向 DPI\r\n            \r\n","\r\n            ParasolCells_k. Use 7.0 for default\r\n            ":"\r\n            ParasolCells_k。默认使用 7.0\r\n            \r\n","The depth type of the dest image":"目标图像的深度类型\r\n","The height of the returned image.":"返回图像的高度。\r\n","\r\n            The region\r\n            ":"\r\n            该区域\r\n            \r\n","\r\n            The mask matrix of which the value might be modified by the function. \r\n            As input, if the value is 0, the corresponding match will be ignored when computing the homography matrix. \r\n            If the value is 1 and RANSAC determine the match is an outlier, the value will be set to 0.\r\n            ":"\r\n            值可能被函数修改的掩码矩阵。\r\n            作为输入，如果值为 0，则在计算单应矩阵时将忽略相应的匹配。\r\n            如果值为 1 并且 RANSAC 确定匹配是异常值，则该值将设置为 0。\r\n            \r\n","A new single column Mat of the same data type. The number of rows equals to the number of points on the sample line.":"相同数据类型的新单列 Mat。行数等于采样线上的点数。\r\n","\r\n            Distance function selector used for measuring distance between two points in k-means.\r\n            ":"\r\n            距离函数选择器，用于测量 k-means 中两点之间的距离。\r\n            \r\n","\r\n            The main threshold on the squared Mahalanobis distance to decide if the sample is well described by the background model or not. Related to Cthr from the paper.\r\n            ":"\r\n            马氏距离平方的主要阈值，用于决定样本是否被背景模型很好地描述。与论文中的 Cthr 相关。\r\n            \r\n","\r\n            The bits to shift for SEQ_FLAG\r\n            ":"\r\n            SEQ_FLAG 要移位的位\r\n            \r\n","grayscale or color (BGR) image containing bar code.":"包含条形码的灰度或彩色 (BGR) 图像。\r\n","\r\n            Auto detect\r\n            ":"\r\n            自动侦测\r\n            \r\n","\r\n            Number of scales used to create the pyramid of images\r\n            ":"\r\n            用于创建图像金字塔的比例数\r\n            \r\n","A look-up table transform of a matrix.":"矩阵的查找表变换。\r\n","Input 2D point set":"输入二维点集\r\n","The output image depth":"输出图像深度\r\n","\r\n            Rotate the single channel Nx2 matrix where N is the number of 2D points. The value of the matrix is changed after rotation.\r\n            ":"\r\n            旋转单通道 Nx2 矩阵，其中 N 是二维点的数量。旋转后矩阵的值发生变化。\r\n            \r\n","\r\n            Calculated weighted sum of two arrays as following:\r\n            dst(I)=src1(I)*alpha+src2(I)*beta+gamma\r\n            All the arrays must have the same type and the same size (or ROI size)\r\n            ":"\r\n            计算两个数组的加权和如下：\r\n            dst(I)=src1(I)*alpha+src2(I)*beta+伽玛\r\n            所有数组必须具有相同的类型和相同的大小（或 ROI 大小）\r\n            \r\n","\r\n            Computes angle (angle(i)) of each (x(i), y(i)) vector\r\n            ":"\r\n            计算每个 (x(i), y(i)) 向量的角度 (angle(i))\r\n            \r\n"," Selected ROI or empty rect if selection canceled.":" 如果取消选择，则选择 ROI 或空矩形。\r\n"," this .* img2 ":" 这个 .* img2\r\n","\r\n            Detector the location of the QR code\r\n            ":"\r\n            检测二维码的位置\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of ERStat.\r\n            ":"\r\n            ERStat 的 C++ 标准向量的包装类。\r\n            \r\n","If true, a jagged array will returned. Otherwise it will return a regular array.":"如果为真，将返回锯齿状数组。否则它将返回一个常规数组。\r\n","The scalar to AND":"AND 的标量\r\n","\r\n            Release the MergeDebevec object\r\n            ":"\r\n            释放 MergeDebevec 对象\r\n            \r\n","vector of rotated rectangle vertices found by detect() method (or some other algorithm).":"通过 detect() 方法（或其他算法）找到的旋转矩形顶点向量。\r\n","Image header":"图片标题\r\n","The current error status":"当前错误状态\r\n","\r\n            Provide extension method to convert IInputArray to and from Bitmap\r\n            ":"\r\n            提供将 IInputArray 与 Bitmap 相互转换的扩展方法\r\n            \r\n","\r\n            Radial-basis-function kernel; a good choice in most cases: d(x,y) = exp(-gamma*|x-y|^2)\r\n            ":"\r\n            径向基函数内核；在大多数情况下是一个不错的选择：d(x,y) = exp(-gamma*|x-y|^2)\r\n            \r\n","\r\n            Color Correction Matrix element [2][2]\r\n            ":"\r\n            颜色校正矩阵元素 [2][2]\r\n            \r\n","\r\n            Termination criteria of the iterative SVM training procedure which solves a partial case of constrained quadratic optimization problem\r\n            ":"\r\n            解决约束二次优化问题的部分情况的迭代 SVM 训练过程的终止准则\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this Boosting Tracker\r\n            ":"\r\n            释放与此 Boosting Tracker 关联的所有非托管内存\r\n            \r\n","Array. Every element of the array is set to 1 if the flow for the corresponding feature has been found, 0 otherwise":"大批。如果找到相应特征的流，则数组的每个元素都设置为 1，否则设置为 0\r\n","Block height":"区块高度\r\n","The observed keypoints":"观察到的关键点\r\n","\r\n            Create an Expectation Maximization model\r\n            ":"\r\n            创建期望最大化模型\r\n            \r\n","A matrix header for the specified matrix row.":"指定矩阵行的矩阵标题。\r\n","\r\n            Used only when reading FileStorage. If set, means that all the collection elements are numbers of the same type (real's or int's).\r\n            ":"\r\n            仅在读取 FileStorage 时使用。如果设置，则意味着所有集合元素都是相同类型的数字（实数或整数）。\r\n            \r\n","\r\n            Create a empty OclContext object\r\n            ":"\r\n            创建一个空的 OclContext 对象\r\n            \r\n","val - this":"val-这个\r\n","\r\n            Sets the layer sizes.\r\n            ":"\r\n            设置图层大小。\r\n            \r\n","A pointer to the address of the the pinned array":"指向固定数组地址的指针\r\n","Inverse ratio of the accumulator resolution to the image resolution. For example, if dp=1 , the accumulator has the same resolution as the input image. If dp=2 , the accumulator has half as big width and height.":"累加器分辨率与图像分辨率的反比。例如，如果 dp=1 ，则累加器具有与输入图像相同的分辨率。如果 dp=2 ，则累加器的宽度和高度为一半。\r\n","\r\n            Applies a perspective transformation to an image.\r\n            ":"\r\n            对图像应用透视变换。\r\n            \r\n","\r\n            Runs forward pass to compute output of layer with name outputName.\r\n            ":"\r\n            运行正向传递以计算名称为 outputName 的层的输出。\r\n            \r\n","\r\n            Find groups of Extremal Regions that are organized as text blocks.\r\n            ":"\r\n            查找组织为文本块的极值区域组。\r\n            \r\n","The maximum number of results to return":"返回的最大结果数\r\n","The query points, one per row":"查询点，每行一个\r\n","3x3 or 4x4 floating-point transformation matrix.":"3x3 或 4x4 浮点变换矩阵。\r\n","\r\n            Size of free camera FFS.\r\n            ":"\r\n            自由相机 FFS 的大小。\r\n            \r\n","\r\n            Convert HSV color to RGB color\r\n            ":"\r\n            将 HSV 颜色转换为 RGB 颜色\r\n            \r\n","Optional argument, some implementations might also use the disparity map of the right view to compute confidence maps, for instance.":"可选参数，例如，一些实现也可能使用右视图的视差图来计算置信度图。\r\n","A VectorOfMat with the train images":"带有火车图像的 VectorOfMat\r\n"," Elementwise add a color ":" 按元素添加颜色\r\n","Number of bands":"波段数\r\n","\r\n            Dict5X5_1000\r\n            ":"\r\n            Dict5X5_1000\r\n            \r\n","Camera rotation matrix":"相机旋转矩阵\r\n","\r\n            The platform name\r\n            ":"\r\n            平台名称\r\n            \r\n","color space standard deviation, it is similar to the sigma in the color space into bilateralFilter.":"颜色空间标准差，类似于颜色空间中的sigma进入bilateralFilter。\r\n","\r\n            This class implements variational refinement of the input flow field.\r\n            ":"\r\n            此类实现输入流场的变分细化。\r\n            \r\n","\r\n            Entry points to the Open CV HFS module\r\n            ":"\r\n            Open CV HFS 模块的入口点\r\n            \r\n","\r\n            Read detector from FileNode.\r\n            ":"\r\n            从 FileNode 读取检测器。\r\n            \r\n","\r\n            Generates the all-black and all-white images needed for shadowMasks computation. To identify shadow regions, the regions of two images where the pixels are not lit by projector's light and thus where there is not coded information, the 3DUNDERWORLD algorithm computes a shadow mask for the two cameras views, starting from a white and a black images captured by each camera. This method generates these two additional images to project.\r\n            ":"\r\n            生成 shadowMasks 计算所需的全黑和全白图像。为了识别阴影区域，即像素未被投影仪光线照亮的两个图像区域，因此没有编码信息，3DUNDERWORLD 算法从捕获的白色和黑色图像开始计算两个相机视图的阴影掩模通过每个摄像头。此方法生成这两个附加图像以进行投影。\r\n            \r\n","\r\n            Calculates the per-element scaled product of two matrices.\r\n            ":"\r\n            计算两个矩阵的每个元素缩放乘积。\r\n            \r\n","Depth data of the source frame (CV_32FC1, in meters)":"源帧的深度数据（CV_32FC1，以米为单位）\r\n","\r\n            Returns true if there are no layers in the network.\r\n            ":"\r\n            如果网络中没有层，则返回 true。\r\n            \r\n","An array of Int":"Int 数组\r\n","\r\n            A Direct Least-Squares (DLS) Method for PnP\r\n            ":"\r\n            PnP 的直接最小二乘 (DLS) 方法\r\n            \r\n","\r\n            Transparent\r\n            ":"\r\n            透明的\r\n            \r\n","\r\n            Computes a background image.\r\n            ":"\r\n            计算背景图像。\r\n            \r\n","Derivative order in respect of y.":"关于 y 的导数阶数。\r\n","If true, will use usb 2 mode":"如果为 true，将使用 usb 2 模式\r\n","output image with first-order derivative in x.":"在 x 中具有一阶导数的输出图像。\r\n","\r\n            Lens focus distance in cm.\r\n            ":"\r\n            以厘米为单位的镜头焦距。\r\n            \r\n","\r\n            Iterates to find the object center given its back projection and initial position of search window. The iterations are made until the search window center moves by less than the given value and/or until the function has done the maximum number of iterations. \r\n            ":"\r\n            迭代以在给定其反投影和搜索窗口的初始位置的情况下找到对象中心。进行迭代直到搜索窗口中心移动小于给定值和/或直到函数完成最大迭代次数。\r\n            \r\n","Input 8-bit 3-channel image":"输入 8 位 3 通道图像\r\n","input 3x3 floating-point camera matrix":"输入 3x3 浮点相机矩阵\r\n","\r\n            Treat the image as a single word in a circle.\r\n            ":"\r\n            将图像视为圆圈中的单个词。\r\n            \r\n","The color of this map":"这张地图的颜色\r\n","\r\n            CV_TERMCRIT value\r\n            ":"CV_TERMCRIT 值\r\n            \r\n","The per-element scaled product of the matrix and the scale.":"矩阵和尺度的每个元素缩放乘积。\r\n","The window size specifications":"窗口尺寸规格\r\n","\r\n            FPGA device with CPU fallbacks using Inference Engine's Heterogeneous plugin.\r\n            ":"\r\n            具有使用推理引擎的异构插件的 CPU 回退的 FPGA 设备。\r\n            \r\n","The right Channel of a stereo image pair.":"立体图像对的右通道。\r\n","Destination image of the same size and the same type as src. The function can work in-place.":"与 src 大小和类型相同的目标图像。该功能可以就地工作。\r\n","Output GMat of the defined unary computation":"定义的一元计算的输出 GMat\r\n","\r\n            A generic parameter for the Operation class\r\n            ":"\r\n            Operation 类的通用参数\r\n            \r\n","The Feature2DAsync object":"Feature2DAsync 对象\r\n","The third zero-based component of the element index":"元素索引的第三个从零开始的组成部分\r\n","The keypoints where the descriptor computation is perfromed":"执行描述符计算的关键点\r\n","\r\n            Halide backend\r\n            ":"\r\n            卤化物后端\r\n            \r\n","\r\n            Release unmanaged resources\r\n            ":"\r\n            释放非托管资源\r\n            \r\n","\r\n            File storage mode\r\n            ":"\r\n            文件存储方式\r\n            \r\n","\r\n            multiplier for augment the training data\r\n            ":"\r\n            用于增加训练数据的乘数\r\n            \r\n","\r\n            Abstract base class for histogram cost algorithms.\r\n            ":"\r\n            直方图成本算法的抽象基类。\r\n            \r\n","Gaussian standard deviation. If it is non-positive, it is computed from ksize.":"高斯标准偏差。如果它是非正数，则它是根据 ksize 计算的。\r\n","\r\n             Temporary arrays for the foreground model. Do not modify it while you are\r\n             processing the same image.\r\n             ":"\r\n             前景模型的临时数组。不要修改它，而你是\r\n             处理同一张图片。\r\n             \r\n","\r\n            UInt16\r\n            ":"\r\n            UInt16\r\n            \r\n","\r\n            If true, the Bitmap created will try to use the same raw pixel data from the Mat if possible.\r\n            In which case, do not disposed the input Mat before you disposed the Bitmap, or you will get an memory access violation.\r\n            If you are not sure about it, use the default value of \"false\", in which case the data will be copied over to the Bitmap.":"\r\n            如果为 true，创建的位图将尽可能使用来自 Mat 的相同原始像素数据。\r\n            在这种情况下，不要在处理 Bitmap 之前处理输入 Mat，否则会发生内存访问冲突。\r\n            如果您不确定，请使用默认值“false”，在这种情况下数据将被复制到位图中。\r\n","Joint 8-bit or floating-point, 1-channel or 3-channel image.":"联合 8 位或浮点数、1 通道或 3 通道图像。\r\n","\r\n            The score type\r\n            ":"\r\n            分数类型\r\n            \r\n","\r\n            cvLoadImage type\r\n            ":"\r\n            cvLoadImage 类型\r\n            \r\n","The resulting GpuMat of the DST, must be pre-allocated and continious. If single channel, the result is real. If double channel, the result is complex":"DST 的结果 GpuMat 必须预先分配且连续。如果是单通道，结果是真实的。如果双通道，结果很复杂\r\n","\r\n            Updates the motion history image as following:\r\n            mhi(x,y)=timestamp  if silhouette(x,y)!=0\r\n                    0          if silhouette(x,y)=0 and mhi(x,y)<timestamp-duration\r\n                    mhi(x,y)   otherwise\r\n            That is, MHI pixels where motion occurs are set to the current timestamp, while the pixels where motion happened far ago are cleared. \r\n            ":"\r\n            更新运动历史图像如下：\r\n            mhi(x,y)=时间戳如果 silhouette(x,y)!=0\r\n                    0 如果 silhouette(x,y)=0 且 mhi(x,y)<timestamp-duration\r\n                    mhi(x,y) 否则\r\n            即，将发生运动的 MHI 像素设置为当前时间戳，而清除很久以前发生运动的像素。\r\n            \r\n","The first point to be added":"第一点要补充的\r\n","Optional 3x3 rotation matrix around x-axis.":"围绕 x 轴的可选 3x3 旋转矩阵。\r\n","\r\n            For JPEG, it can be a quality from 0 to 100 (the higher is the better). Default value is 95.\r\n            ":"\r\n            对于 JPEG，它可以是从 0 到 100 的质量（越高越好）。默认值为 95。\r\n            \r\n","\r\n            Convert BGR to YUV_IYUV\r\n            ":"\r\n            BGR转YUV_IYUV\r\n            \r\n","\r\n            Wrapper class for the OpenCV Affine Transformation algorithm.\r\n            ":"\r\n            OpenCV 仿射变换算法的包装类。\r\n            \r\n","\r\n            This algorithm transforms image to contrast using gradients on all levels of gaussian pyramid, transforms contrast values to HVS response and scales the response. After this the image is reconstructed from new contrast values.\r\n            ":"\r\n            该算法使用高斯金字塔各级上的梯度将图像转换为对比度，将对比度值转换为 HVS 响应并缩放响应。在此之后，根据新的对比度值重建图像。\r\n            \r\n","Type of the extracted descriptor":"提取描述符的类型\r\n","The directory to be searched for DLLs":"要搜索 DLL 的目录\r\n","\r\n            Returns sum of diagonal elements of the matrix ":"\r\n            返回矩阵对角线元素的总和\r\n","\r\n            Close and release hdf5 object.\r\n            ":"\r\n            关闭并释放 hdf5 对象。\r\n            \r\n","\r\n            Release the memory associated with this text recognition model.\r\n            ":"\r\n            释放与此文本识别模型关联的内存。\r\n            \r\n","The line number in the source where error is encountered":"源代码中遇到错误的行号\r\n","The minimum probability difference between local maxima and local minima ERs.":"局部最大值和局部最小值 ER 之间的最小概率差。\r\n","The wrapped phase map that needs to be unwrapped.":"需要展开的包裹相图。\r\n","interpolated chessboard corners identifiers":"内插棋盘角标识符\r\n","\r\n            Release all the memory associated with this IndexParam\r\n            ":"\r\n            释放与此 IndexParam 关联的所有内存\r\n            \r\n","\r\n            Selects the current feature which is accessible by XI_PRM_SENSOR_FEATURE_VALUE.\r\n            ":"\r\n            选择 XI_PRM_SENSOR_FEATURE_VALUE 可访问的当前特征。\r\n            \r\n","Phase map width.":"相图宽度。\r\n","\r\n            Convert RGB color to BGR color\r\n            ":"\r\n            将 RGB 颜色转换为 BGR 颜色\r\n            \r\n","Second image. Must have the same size and the same type as img1 .":"第二张图。必须与 img1 具有相同的大小和相同的类型。\r\n","\r\n            Calculates natural logarithm of absolute value of every element of input array:\r\n            dst(I)=log(abs(src(I))), src(I)!=0\r\n            dst(I)=C,  src(I)=0\r\n            Where C is large negative number (-700 in the current implementation)\r\n            ":"\r\n            计算输入数组每个元素的绝对值的自然对数：\r\n            dst(I)=log(abs(src(I))), src(I)!=0\r\n            dst(I)=C, src(I)=0\r\n            其中 C 是大负数（当前实现中为 -700）\r\n            \r\n","Fundamental matrix used to compute epipolar lines and ease the matching step.":"用于计算极线和简化匹配步骤的基本矩阵。\r\n","The RGB charts":"RGB 图表\r\n","\r\n            Fills the output matrix with values from the look-up table. Indices of the entries are taken from the input matrix.\r\n            ":"\r\n            用查找表中的值填充输出矩阵。条目的索引取自输入矩阵。\r\n            \r\n","\r\n            Get or set the pano confidence threshold\r\n            ":"\r\n            获取或设置全景置信度阈值\r\n            \r\n","Output array of the same size and type as src.":"与 src 大小和类型相同的输出数组。\r\n","Buffer of type CV_16FC2 containing flow vectors generated by Calc().":"CV_16FC2 类型的缓冲区包含由 Calc() 生成的流向量。\r\n","\r\n            Clustering\r\n            ":"\r\n            聚类\r\n            \r\n","\r\n            Number of formats\r\n            ":"\r\n            格式数\r\n            \r\n","\r\n            Create a matrix using the specific ":"\r\n            使用特定的创建矩阵\r\n","\r\n            Defines a binary (two inputs – one output) computation.\r\n            ":"\r\n            定义二进制（两个输入 - 一个输出）计算。\r\n            \r\n","Buffer of type CV_32FC2, containing upsampled flow vectors, each flow vector for 1 pixel, in the pitch-linear layout.":"CV_32FC2 类型的缓冲区，包含上采样流向量，每个流向量对应 1 个像素，采用间距线性布局。\r\n","The rotation center":"旋转中心\r\n","Threshold on difference between intensity of center pixel and pixels on circle around\r\n            this pixel.":"中心像素强度与周围像素强度差异的阈值\r\n            这个像素。\r\n","\r\n            Subtract ":"\r\n            减去\r\n","\r\n            Calculates the Laplacian of an image.\r\n            ":"计算图像的拉普拉斯算子。\r\n            \r\n","The source points":"源点\r\n","\r\n            The index that will be used for interpolation\r\n            ":"\r\n            将用于插值的索引\r\n            \r\n","Standard deviation of the Gaussian that is used to smooth derivatives that are used as a basis for the polynomial expansion. For poly n=5 you can set poly sigma=1.1, for poly n=7 a good value would be poly sigma=1.5":"用于平滑用作多项式展开基础的导数的高斯标准偏差。对于 poly n=5，您可以设置 poly sigma=1.1，对于 poly n=7，一个好的值是 poly sigma=1.5\r\n","Number of scales":"鳞片数量\r\n","Flag specifying the alpha-blending operation":"指定 alpha 混合操作的标志\r\n","\r\n            Calculates vertices of the input 2d box.\r\n            ":"\r\n            计算输入二维框的顶点。\r\n            \r\n","Scale constant.":"比例常数。\r\n","\r\n            Computes the dot product of two mats\r\n            ":"\r\n            计算两个垫子的点积\r\n            \r\n","An array of Float":"一组浮点数\r\n","Refined corner coordinates":"细化角坐标\r\n","The types that can be used":"可以使用的类型\r\n","The compression level, 0-9 where 0 mean no compression at all":"压缩级别，0-9，其中 0 表示完全不压缩\r\n","\r\n            Create DNN model from network represented in one of the supported formats.\r\n            ":"\r\n            从以一种受支持格式表示的网络创建 DNN 模型。\r\n            \r\n","Supports NN, LINEAR, CUBIC":"支持 NN、LINEAR、CUBIC\r\n","Mask of searched template. It must have the same datatype and size with templ. It is not set by default.":"搜索模板的掩码。它必须与 templ 具有相同的数据类型和大小。它不是默认设置的。\r\n","\r\n            Performs downsampling step of Gaussian pyramid decomposition. \r\n            First it convolves ":"\r\n            执行高斯金字塔分解的下采样步骤。\r\n            首先它卷积\r\n","\r\n            Print cuda device info\r\n            ":"\r\n            打印cuda设备信息\r\n            \r\n","\r\n            Refine a pose (the translation and the rotation that transform a 3D point expressed in the object coordinate frame to the camera coordinate frame) from a 3D-2D point correspondences and starting from an initial solution.\r\n            ":"\r\n            从 3D-2D 点对应并从初始解决方案开始，细化姿势（将对象坐标系中表示的 3D 点转换为相机坐标系的平移和旋转）。\r\n            \r\n","\r\n            Spatial Moment M02\r\n            ":"\r\n            空间瞬间M02\r\n            \r\n","\r\n            Convert YUV (i420) to Gray\r\n            ":"\r\n            将 YUV (i420) 转换为灰色\r\n            \r\n","\r\n            Line's extremes in image it was extracted from\r\n            ":"\r\n            从中提取线的图像中的极端\r\n            \r\n","\r\n            Filtering is the fundamental operation in image and video processing. Edge-preserving smoothing filters are used in many different applications.\r\n            ":"\r\n            过滤是图像和视频处理中的基本操作。保边平滑滤波器用于许多不同的应用。\r\n            \r\n","\r\n            Euler number\r\n            ":"\r\n            欧拉数\r\n            \r\n","indicate similarity between inOne and inTwo, the meaning of the value vary from algorithms to algorithms":"表示inOne和inTwo之间的相似性，值的含义因算法而异\r\n","The number of iterations the algorithm does at each pyramid level":"算法在每个金字塔级别进行的迭代次数\r\n","\r\n            Create a stub seam estimator which does nothing.\r\n            ":"\r\n            创建一个什么都不做的存根接缝估计器。\r\n            \r\n","\r\n            Stopping criterion threshold used in the numerical scheme, which is a trade-off between precision and running time\r\n            ":"\r\n            数值方案中使用的停止准则阈值，这是精度和运行时间之间的权衡\r\n            \r\n","\r\n            Release the unmanaged memory associated with this object\r\n            ":"\r\n            释放与此对象关联的非托管内存\r\n            \r\n","\r\n            Selects ROI on the given image. Function creates a window and allows user to select a ROI using mouse. Controls: use space or enter to finish selection, use key c to cancel selection (function will return the zero cv::Rect).\r\n            ":"\r\n            在给定图像上选择 ROI。函数创建一个窗口并允许用户使用鼠标选择 ROI。控制：使用空格或回车完成选择，使用键c取消选择（函数将返回零cv::Rect）。\r\n            \r\n","Type of morphological operation.":"形态学操作的类型。\r\n","use image sample intensity normalization":"使用图像样本强度归一化\r\n","\r\n            Translation part extracted from the homogeneous matrix that transforms a point expressed in the gripper frame to the robot base frame.\r\n            This is a vector (vector<Mat>) that contains the translation vectors for all the transformations from gripper frame to robot base frame.\r\n            ":"\r\n            从齐次矩阵中提取的平移部分，将夹持器框架中表示的点转换为机器人基架。\r\n            这是一个向量 (vector<Mat>)，其中包含从夹具框架到机器人基础框架的所有转换的平移向量。\r\n            \r\n","The first stage local adaptation area":"第一阶段局部适应区\r\n","\r\n            ANNEAL: Update final temperature.\r\n            ":"\r\n            ANNEAL：更新最终温度。\r\n            \r\n","If >0, keep at most top_k picked indices.":"如果 >0，则最多保留 top_k 个选择的索引。\r\n","\r\n            Finds an object pose from 3D-2D point correspondences. \r\n            ":"\r\n            从 3D-2D 点对应中查找对象姿势。\r\n            \r\n"," src.depth() = CV_32F, ddepth = -1/CV_32F/CV_64F":" src.depth() = CV_32F, ddepth = -1/CV_32F/CV_64F\r\n","The number of attempts. Use 3 for default":"尝试次数。默认使用 3\r\n","\r\n            Border Width\r\n            ":"\r\n            边框宽度\r\n            \r\n","False if no frames has been grabbed":"如果没有抓取帧则为假\r\n","\r\n            Enumeration used by SoftNMS\r\n            ":"\r\n            SoftNMS 使用的枚举\r\n            \r\n","Coefficient of the detection window increase.":"检测窗口系数增加。\r\n","The numeric code for error status":"错误状态的数字代码\r\n","\r\n            Turn the feature off (not controlled manually nor automatically)\r\n            ":"\r\n            关闭该功能（不是手动控制也不是自动控制）\r\n            \r\n","\r\n            computeNMChannels operation modes\r\n            ":"\r\n            computeNMChannels 操作模式\r\n            \r\n","Coordinates of the input corners, the values will be modified by this function call":"输入角的坐标，值将被此函数调用修改\r\n","\r\n            Base Interface for optical flow algorithms using NVIDIA Optical Flow SDK\r\n            ":"\r\n            使用 NVIDIA Optical Flow SDK 的光流算法基本接口\r\n            \r\n","\r\n            Convert Bayer RGGB to RGB (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 Bayer RGGB 转换为 RGB（边缘感知去马赛克）\r\n            \r\n","The comparison type":"比较类型\r\n","\r\n            Given an input bgr or grayscale image, apply linear contrast stretching on domain [0, 255] and return the resulting image.\r\n            ":"\r\n            给定输入 bgr 或灰度图像，在域 [0, 255] 上应用线性对比度拉伸并返回结果图像。\r\n            \r\n","Array containing the samples for which votes will be calculated.":"包含将为其计算选票的样本的数组。\r\n","\r\n            Similar to the << operator in C++, we cannot have the operator overload to << in C# where the second parameter is not an int. Therefore we use this function instead.\r\n            ":"\r\n            类似于 C++ 中的 << 运算符，我们不能在 C# 中将运算符重载为 <<，其中第二个参数不是 int。因此我们改用这个函数。\r\n            \r\n","\r\n            Convert the DepthType to a string that represent the OpenCL value type.\r\n            ":"\r\n            将 DepthType 转换为表示 OpenCL 值类型的字符串。\r\n            \r\n","The CudaImage where the region is extracted from":"从中提取区域的 CudaImage\r\n","The point on the image":"图像上的点\r\n","\r\n            value = value > threshold ? max_value : 0\r\n            ":"\r\n            价值=价值>阈值？最大值：0\r\n            \r\n","\r\n            The device name\r\n            ":"\r\n            设备名称\r\n            \r\n","\r\n            Defines for Distance Transform\r\n            ":"\r\n            定义距离变换\r\n            \r\n","A vector of the lines that needed to be drawn.":"需要绘制的线条的向量。\r\n","\r\n            The name of the backend used by this VideoCapture\r\n            ":"\r\n            此 VideoCapture 使用的后端名称\r\n            \r\n","The image load type.":"图片加载类型。\r\n","\r\n            Convert YUV (iYUV) to RGBA\r\n            ":"\r\n            将 YUV (iYUV) 转换为 RGBA\r\n            \r\n","\r\n            Projects points using fisheye model. The function computes projections of 3D points to the image plane given intrinsic and extrinsic camera parameters. Optionally, the function computes Jacobians - matrices of partial derivatives of image points coordinates (as functions of all the input parameters) with respect to the particular parameters, intrinsic and/or extrinsic.\r\n            ":"使用鱼眼模型投影点。该函数在给定内在和外在相机参数的情况下计算 3D 点到图像平面的投影。可选地，该函数计算雅可比矩阵 - 图像点坐标的偏导数矩阵（作为所有输入参数的函数）关于特定参数，内在和/或外在。\r\n            \r\n","the new size":"新尺寸\r\n","Source image size":"源图像大小\r\n","1 if detection is successful, 0 otherwise.":"如果检测成功则为 1，否则为 0。\r\n"," Elementwise subtract a color ":" 按元素减去颜色\r\n","The output gradient image":"输出梯度图像\r\n","\r\n            Long-term tracker\r\n            ":"\r\n            长期跟踪器\r\n            \r\n","\r\n            Changes parameters of a window dynamically.\r\n            ":"\r\n            动态更改窗口的参数。\r\n            \r\n","Point coordinates in the destination plane":"目标平面中的点坐标\r\n","\r\n            Check if we have OpenCL\r\n            ":"\r\n            检查我们是否有 OpenCL\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this GMat\r\n            ":"\r\n            释放与此 GMat 关联的所有非托管内存\r\n            \r\n","\r\n            Draw UTF-8 strings with freetype/harfbuzz.\r\n            ":"\r\n            使用 freetype/harfbuzz 绘制 UTF-8 字符串。\r\n            \r\n","\r\n            There is only one maximum for target function\r\n            ":"\r\n            目标函数只有一个最大值\r\n            \r\n","\r\n            Class implementing the F-DBSCAN (Accelerated superpixel image segmentation with a parallelized DBSCAN algorithm) superpixels algorithm by Loke SC, et al.\r\n            ":"\r\n            实现 F-DBSCAN（使用并行化 DBSCAN 算法的加速超像素图像分割）超像素算法的类，由 Loke SC 等人提出。\r\n            \r\n","\r\n            Interface to the Facemark class\r\n            ":"\r\n            Facemark 类的接口\r\n            \r\n","Output GScalar of the defined unary computation":"定义的一元计算的输出 GScalar\r\n","The estimator":"估算器\r\n","\r\n            Calculates per-element maximum of two arrays:\r\n            dst(I)=max(src1(I), src2(I))\r\n            All the arrays must have a single channel, the same data type and the same size (or ROI size).\r\n            ":"\r\n            计算两个数组的每个元素最大值：\r\n            dst(I)=max(src1(I), src2(I))\r\n            所有数组必须具有单个通道、相同的数据类型和相同的大小（或 ROI 大小）。\r\n            \r\n","True if the current iterator equals to the other":"如果当前迭代器等于另一个，则为真\r\n","The distance different ratio which a match is consider unique, a good number will be 0.8":"匹配被认为是唯一的距离差异比率，一个好的数字将是 0.8\r\n","Output image channel.":"输出图像通道。\r\n","\r\n            Returns true if the descriptor matcher supports masking permissible matches.\r\n            ":"\r\n            如果描述符匹配器支持屏蔽允许的匹配，则返回 true。\r\n            \r\n","\r\n            XINE engine (Linux)\r\n            ":"\r\n            XINE 引擎 (Linux)\r\n            \r\n","The second source GpuMat":"第二个来源GpuMat\r\n","\r\n            Swaps two matrices\r\n            ":"\r\n            交换两个矩阵\r\n            \r\n","Input image for detection":"用于检测的输入图像\r\n","vector of identifiers for diamonds in diamondCorners, in the same format returned by detectCharucoDiamond() (e.g. VectorOfMat ). Optional, if not provided, ids are not painted. ":"diamondCorners 中钻石标识符的向量，格式与 detectCharucoDiamond() 返回的格式相同（例如 VectorOfMat ）。可选，如果未提供，则不绘制 ID。\r\n","\r\n            Create a MessageLogger and register the callback function\r\n            ":"\r\n            创建 MessageLogger 并注册回调函数\r\n            \r\n","Color of the text.":"文本的颜色。\r\n","\r\n            Release the unmanaged resource related to the GpuDevice\r\n            ":"\r\n            释放GpuDevice相关的非托管资源\r\n            \r\n","The interpolation method":"插值法\r\n","The input images. This can be, for example, a VectorOfMat":"输入图像。例如，这可以是 VectorOfMat\r\n","Number of nonzero rows to in the source array (in case of forward 2d transform), or a number of rows of interest in the destination array (in case of inverse 2d transform). If the value is negative, zero, or greater than the total number of rows, it is ignored. The parameter can be used to speed up 2d convolution/correlation when computing them via DFT. See the sample below":"源数组中的非零行数（在正向二维变换的情况下），或目标数组中感兴趣的行数（在逆二维变换的情况下）。如果该值为负数、零或大于总行数，则会被忽略。通过 DFT 计算时，该参数可用于加速二维卷积/相关。请参阅下面的示例\r\n","Buffer of type CV_16FC2 containing flow vectors generated by calc().":"CV_16FC2 类型的缓冲区包含由 calc() 生成的流向量。\r\n","\r\n            Minimal window size of the support region. This parameter is only used if supportRegionType is Cross\r\n            ":"\r\n            支持区域的最小窗口大小。仅当 supportRegionType 为 Cross 时才使用此参数\r\n            \r\n","Structuring element used for dilation; if element=Mat(), a 3 x 3 rectangular structuring element is used. Kernel can be created using getStructuringElement.":"用于扩张的结构元素；如果 element=Mat()，则使用 3 x 3 矩形结构元素。可以使用 getStructuringElement 创建内核。\r\n","Input 3x3 floating-point camera matrix":"输入 3x3 浮点相机矩阵\r\n","\r\n            Create an instance of FacemarkAAM model\r\n            ":"\r\n            创建 FacemarkAAM 模型的实例\r\n            \r\n","\r\n            Create an empty standard vector of VectorOfPoint\r\n            ":"创建一个空的 VectorOfPoint 标准向量\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of ColorPoint.\r\n            ":"\r\n            ColorPoint 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Add the model descriptors\r\n            ":"\r\n            添加模型描述符\r\n            \r\n","\r\n            L2 squared\r\n            ":"\r\n            L2平方\r\n            \r\n","\r\n            Pointer the the native cuda::sparseOpticalFlow object.\r\n            ":"\r\n            指向原生 cuda::sparseOpticalFlow 对象。\r\n            \r\n","A matrix corresponding to a specified row span of the input array":"与输入数组的指定行跨度对应的矩阵\r\n","\r\n            Ptr only\r\n            ":"\r\n            仅 Ptr\r\n            \r\n","Cell size. Use (8, 8) for default.":"细胞大小。默认使用 (8, 8)。\r\n","\r\n            Average Stochastic Gradient Descent\r\n            ":"\r\n            平均随机梯度下降\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of Triangle2DF.\r\n            ":"\r\n            Triangle2DF 的 C++ 标准向量的包装类。\r\n            \r\n","the number of real roots found":"找到的实根数\r\n","\r\n            Convert Bayer BG to RGBA \r\n            ":"\r\n            将 Bayer BG 转换为 RGBA\r\n            \r\n","\r\n            Median kernel size\r\n            ":"\r\n            中值内核大小\r\n            \r\n","This is a fast image hashing algorithm, but only work on simple case.":"这是一种快速的图像哈希算法，但只适用于简单的情况。\r\n","\r\n            Create an object which calculates quality.\r\n            ":"\r\n            创建一个计算质量的对象。\r\n            \r\n","An OpenCL platform summary":"OpenCL 平台总结\r\n","\r\n            Max dim\r\n            ":"\r\n            最大暗淡\r\n            \r\n","Input GpuMat":"输入 GpuMat\r\n","\r\n            Create an empty standard vector of VectorOfDMatch\r\n            ":"\r\n            创建一个空的 VectorOfDMatch 标准向量\r\n            \r\n","\r\n            Call a command from command line\r\n            ":"\r\n            从命令行调用命令\r\n            \r\n","IPL_ORIGIN_TL or IPL_ORIGIN_BL.":"IPL_ORIGIN_TL 或 IPL_ORIGIN_BL。\r\n","\r\n            Applies a generic geometrical transformation to an image.\r\n            ":"\r\n            对图像应用通用几何变换。\r\n            \r\n","Depth of this matrix (either Byte, SByte, Single, double, UInt16, Int16 or Int32)":"此矩阵的深度（Byte、SByte、Single、double、UInt16、Int16 或 Int32）\r\n","\r\n            Set the features finder for this stitcher.\r\n            ":"\r\n            为此缝合器设置特征查找器。\r\n            \r\n","\r\n            Create an standard vector of VectorOfPoint3D32F of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfPoint3D32F 标准向量\r\n            \r\n","\r\n            Fast dense optical flow computation based on robust local optical flow (RLOF) algorithms and sparse-to-dense interpolation scheme.\r\n            ":"\r\n            基于鲁棒局部光流 (RLOF) 算法和稀疏到密集插值方案的快速密集光流计算。\r\n            \r\n","\r\n            When fitting lines to the contours, what is the maximum mean squared error\r\n            allowed? This is useful in rejecting contours that are far from being quad shaped; rejecting\r\n            these quads \"early\" saves expensive decoding processing.\r\n            ":"\r\n            将线拟合到轮廓时，最大均方误差是多少\r\n            允许？这对于拒绝远离四边形的轮廓很有用；拒绝\r\n            这些四边形“早期”节省了昂贵的解码处理。\r\n            \r\n","\r\n            A collection of reflection function that can be applied to ColorType object\r\n            ":"\r\n            可应用于 ColorType 对象的反射函数集合\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of VectorOfRect.\r\n            ":"\r\n            VectorOfRect 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            512 bit descriptor\r\n            ":"\r\n            512 位描述符\r\n            \r\n","Uniformly distributed random float number from [a,b) range":"来自 [a,b) 范围的均匀分布的随机浮点数\r\n","\r\n            Create a FrameMetaData object\r\n            ":"\r\n            创建一个 FrameMetaData 对象\r\n            \r\n","\r\n            Converts keypoints array from internal representation to standard vector.\r\n            ":"\r\n            将关键点数组从内部表示转换为标准向量。\r\n            \r\n","\r\n            Finds the inverse or pseudo-inverse of a matrix. This function inverts the matrix src and stores the result in dst . When the matrix src is singular or non-square, the function calculates the pseudo-inverse matrix (the dst matrix) so that norm(src*dst - I) is minimal, where I is an identity matrix.\r\n            ":"\r\n            查找矩阵的逆矩阵或伪逆矩阵。此函数反转矩阵 src 并将结果存储在 dst 中。当矩阵 src 为奇异或非方阵时，函数计算伪逆矩阵（dst 矩阵）以使 norm(src*dst - I) 最小，其中 I 为单位矩阵。\r\n            \r\n","\r\n            Compressed rectilinear warper\r\n            ":"\r\n            压缩直线整经机\r\n            \r\n","\r\n            Cuda compute 3.2\r\n            ":"\r\n            Cuda 计算 3.2\r\n            \r\n","\r\n            Binary file contains trained weights. The following file extensions are expected for models from different frameworks:\r\n               *.caffemodel(Caffe, http://caffe.berkeleyvision.org/)\r\n               *.pb (TensorFlow, https://www.tensorflow.org/)\r\n               *.t7 | *.net (Torch, http://torch.ch/)\r\n               *.weights (Darknet, https://pjreddie.com/darknet/)\r\n               *.bin (DLDT, https://software.intel.com/openvino-toolkit)":"\r\n            二进制文件包含经过训练的权重。来自不同框架的模型需要以下文件扩展名：\r\n               *.caffemodel(Caffe, http://caffe.berkeleyvision.org/)\r\n               *.pb（TensorFlow，https://www.tensorflow.org/）\r\n               *.t7 | *.net（火炬，http://torch.ch/）\r\n               *.weights（暗网，https://pjreddie.com/darknet/）\r\n               *.bin（DLDT，https://software.intel.com/openvino-toolkit）\r\n","\r\n            Create detection model from network represented in one of the supported formats.\r\n            ":"\r\n            从以一种受支持的格式表示的网络创建检测模型。\r\n            \r\n","\r\n            Target devices for computations.\r\n            ":"\r\n            计算的目标设备。\r\n            \r\n","\r\n            Both detects and decodes QR code.\r\n            ":"\r\n            两者都检测和解码 QR 码。\r\n            \r\n","If a query descriptor is masked out in mask , no match is added for this descriptor. So, matches size may be smaller than the query descriptors count.":"如果在 mask 中屏蔽了查询描述符，则不会为该描述符添加任何匹配项。因此，匹配大小可能小于查询描述符计数。\r\n","\r\n            Return true if the location of the two points are equal\r\n            ":"\r\n            如果两个点的位置相等则返回真\r\n            \r\n","\r\n            Cache the size of various header in bytes\r\n            ":"\r\n            以字节为单位缓存各种标头的大小\r\n            \r\n","\r\n            The MCvMat structure format  \r\n            ":"\r\n            MCvMat 结构格式\r\n            \r\n","Destination array of arbitrary depth and of the same number of channels as the source array":"任意深度的目标数组和与源数组相同的通道数\r\n","\r\n            Create a new MCvSlice using the specific start and end index\r\n            ":"\r\n            使用特定的开始和结束索引创建一个新的 MCvSlice\r\n            \r\n","\r\n            Android anti banding\r\n            ":"\r\n            安卓反绑定\r\n            \r\n","The name of the windows":"窗户的名字\r\n","\r\n            This is used to hold the sizes of the Open CV structures\r\n            ":"\r\n            这用于保存 Open CV 结构的大小\r\n            \r\n","\r\n            Draws a marker on a predefined position in an image.\r\n            ":"\r\n            在图像中的预定义位置绘制标记。\r\n            \r\n","Number of channels in the descriptor (1, 2, 3)":"描述符中的通道数 (1, 2, 3)\r\n","Flag indicating whether to normalize (scale down) the filter coefficients or not. ":"指示是否标准化（缩小）滤波器系数的标志。\r\n","\r\n            Zoom\r\n            ":"\r\n            飞涨\r\n            \r\n","If quiet, return true if all values are in range":"如果安静，如果所有值都在范围内则返回 true\r\n","\r\n            Draw a canonical marker image.\r\n            ":"\r\n            绘制规范标记图像。\r\n            \r\n","\r\n            Locates input point within subdivision\r\n            ":"\r\n            在细分内定位输入点\r\n            \r\n","\r\n            Create an standard vector of VectorOfMat of the specific size\r\n            ":"\r\n            创建特定大小的 VectorOfMat 标准向量\r\n            \r\n","The returned maximum location":"返回的最大位置\r\n","\r\n            Random\r\n            ":"\r\n            随机的\r\n            \r\n","Either 1 or 3":"1 或 3\r\n","A set of bounding boxes to apply Soft NMS.":"一组应用 Soft NMS 的边界框。\r\n","\r\n            Returns uniformly distributed integer random number from [a,b) range\r\n            ":"\r\n            返回 [a,b) 范围内均匀分布的整数随机数\r\n            \r\n","\r\n            Release all unmanaged memory associated with the RetinaFastToneMapping model.\r\n            ":"\r\n            释放与 RetinaFastToneMapping 模型关联的所有非托管内存。\r\n            \r\n","Defining the similarity with optional values":"用可选值定义相似度\r\n","Number of columns.":"列数。\r\n","\r\n            Constructs a WCoordinateSystem.\r\n            ":"\r\n            构造一个 WCoordinateSystem。\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of RotatedRect.\r\n            ":"\r\n            RotatedRect 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Query the information of the gpu device that is currently in use.\r\n            ":"\r\n            查询当前使用的gpu设备信息。\r\n            \r\n","Optional scale factor for the computed Laplacian values. By default, no scaling is applied. ":"计算拉普拉斯值的可选比例因子。默认情况下，不应用缩放。\r\n","\r\n            Create a GpuMat of the specified size\r\n            ":"\r\n            创建指定大小的 GpuMat\r\n            \r\n","The tracker to use for tracking the image":"用于跟踪图像的跟踪器\r\n","Optional mask. If the matrix is not empty, it must be an 8-bit array of the same size as images[i] . The non-zero mask elements mark the array elements counted in the histogram.":"可选面具。如果矩阵不为空，则它必须是与 images[i] 大小相同的 8 位数组。非零掩码元素标记直方图中计数的数组元素。\r\n","Source arrays. They all should have the same depth, CV_8U, CV_16U or CV_32F , and the same size. Each of them can have an arbitrary number of channels.":"源数组。它们都应具有相同的深度 CV_8U、CV_16U 或 CV_32F 以及相同的大小。它们中的每一个都可以有任意数量的通道。\r\n","\r\n            Remove keypoints of sizes out of range.\r\n            ":"\r\n            删除尺寸超出范围的关键点。\r\n            \r\n","\r\n            Algorithm automaticaly increasing radius of the basic function.\r\n            ":"\r\n            算法自动增加基本函数的半径。\r\n            \r\n","\r\n            Sequence type for point sets\r\n            ":"\r\n            点集的序列类型\r\n            \r\n","\r\n            The MatND Dimension\r\n            ":"\r\n            MatND 维度\r\n            \r\n","Arrays of arrays of the MDMatch":"MDMatch 的数组数组\r\n","\r\n            Color Correction Matrix element [3][0]\r\n            ":"\r\n            颜色校正矩阵元素 [3][0]\r\n            \r\n","The eigenvectors.":"特征向量。\r\n","Angle resolution of the transform in degrees.":"以度为单位的变换的角度分辨率。\r\n"," The type of pixel depth to be converted to ":" 要转换为的像素深度类型\r\n","\r\n            Check if the current iterator equals to the other.\r\n            ":"\r\n            检查当前迭代器是否等于另一个。\r\n            \r\n","Array of double numbers containing difference between patches around the original and moved points. Optional parameter; can be NULL ":"包含原始点和移动点周围补丁之间差异的双精度数组。可选参数；可以为 NULL\r\n","FontFile Name":"字体文件名\r\n","\r\n            Get the GpuMat from the input array\r\n            ":"\r\n            从输入数组中获取 GpuMat\r\n            \r\n","\r\n            Only for stereo: Fix intrinsic\r\n            ":"\r\n            仅适用于立体声：Fix intrinsic\r\n            \r\n","\r\n            Convert YUV (420sp) to Gray\r\n            ":"\r\n            将 YUV (420sp) 转换为灰色\r\n            \r\n","\r\n            (open-only) If non-zero, create new OpenCL context and bind it to current thread. The OpenCL context created with Video Acceleration context attached it (if not attached yet) for optimized GPU data copy between HW accelerated decoder and cv::UMat.\r\n            ":"\r\n            （仅打开）如果非零，则创建新的 OpenCL 上下文并将其绑定到当前线程。使用视频加速上下文创建的 OpenCL 上下文附加它（如果尚未附加）以优化 HW 加速解码器和 cv::UMat 之间的 GPU 数据复制。\r\n            \r\n","\r\n            Get the native device pointer\r\n            ":"\r\n            获取本机设备指针\r\n            \r\n","8-bit single-channel left image of CV_8UC1 type.":"CV_8UC1 类型的 8 位单通道左图像。\r\n","\r\n            Android focus distance near\r\n            ":"\r\n            Android对焦距离近\r\n            \r\n","\r\n            Distorts 2D points using fisheye model.\r\n            ":"\r\n            使用鱼眼模型扭曲二维点。\r\n            \r\n","\r\n            Auto trace\r\n            ":"\r\n            自动跟踪\r\n            \r\n","\r\n            Determines whether the point is inside contour, outside, or lies on an edge (or coinsides with a vertex). It returns positive, negative or zero value, correspondingly\r\n            ":"\r\n            确定该点是在轮廓内部、外部还是位于边缘上（或与顶点重合）。它相应地返回正值、负值或零值\r\n            \r\n","\r\n            cvInvert method\r\n            ":"\r\n            cvInvert 方法\r\n            \r\n","The first signature.":"第一个签名。\r\n","Radius of the basic function.":"基本函数的半径。\r\n","\r\n            Get the sub-sampled data in this storage\r\n            ":"\r\n            获取此存储中的子采样数据\r\n            \r\n","The thickness of the rectangle, any value less than or equal to 0 will result in a filled rectangle":"矩形的粗细，任何小于或等于 0 的值都会导致填充矩形\r\n","Number of fractional bits in the point coordinates.":"点坐标中的小数位数。\r\n","Pointer to the new error handler":"指向新错误处理程序的指针\r\n","The channel to get from the current image, zero based index":"从当前图像获取的通道，从零开始的索引\r\n","FAST threshold":"FAST阈值\r\n","The input 8-bit single-channel grayscale image":"输入的8位单通道灰度图像\r\n"," Multiply the current matrix with ":" 将当前矩阵乘以\r\n","Edge merge threshold. Increase to trade off accuracy for speed.":"边缘合并阈值。增加以牺牲速度的准确性。\r\n","\r\n            Floating-point number\r\n            ":"\r\n            浮点数\r\n            \r\n","Number of solutions":"解决方案数量\r\n","Corresponds to  in the formulas above. As it is enlarged, the smooth (blurred) images are treated more favorably than detailed (but maybe more noised) ones. Roughly speaking, as it becomes smaller, the result will be more blur but more sever outliers will be removed.":"对应于上面的公式。当它被放大时，平滑（模糊）的图像比详细（但可能有更多噪音）的图像更受欢迎。粗略地说，随着它变小，结果会更模糊，但会去除更多严重的异常值。\r\n","\r\n            The text\r\n            ":"\r\n            文本\r\n            \r\n","\r\n            P\r\n            ":"\r\n            P\r\n            \r\n","\r\n            Converts Cartesian coordinates to polar\r\n            ":"\r\n            将笛卡尔坐标转换为极坐标\r\n            \r\n","The source image depth type":"源图像深度类型\r\n","\r\n            Create a convolution kernel with the specific number of ":"\r\n            创建一个具有特定数量的卷积核\r\n","Second threshold for hysteresis procedure in Canny().":"Canny() 中滞后过程的第二个阈值。\r\n","\r\n            Compare the current image with ":"\r\n            将当前图像与\r\n","the thinkness of the line":"线条的思考\r\n","Compute the complement image":"计算补图\r\n","The range that contains the minimum and maximum values":"包含最小值和最大值的范围\r\n","\r\n            Minimum value\r\n            ":"\r\n            最小值\r\n            \r\n","The parent Umat":"父 Umat\r\n","Camera matrix of the distorted image. By default it is the same as cameraMatrix, but you may additionally scale and shift the result by using some different matrix":"失真图像的相机矩阵。默认情况下它与 cameraMatrix 相同，但您可以通过使用一些不同的矩阵另外缩放和移动结果\r\n","\r\n            The pointer to the dense optical flow object.\r\n            ":"\r\n            指向密集光流对象的指针。\r\n            \r\n","The source floating-point array":"源浮点数组\r\n","Indicating whether the angles are measured in radians (which is by default), or in degrees.":"指示角度是以弧度（默认情况下）还是以度为单位测量的。\r\n","Rise distance 0.8 means 10% ... 90% of the final signal strength":"上升距离 0.8 表示最终信号强度的 10% ... 90%\r\n","\r\n            Dict6X6_50\r\n            ":"\r\n            词典6X6_50\r\n            \r\n","Number of rows.":"行数。\r\n","\r\n            C\r\n            ":"\r\n            C\r\n            \r\n","\r\n            if true - rotates output frames of CvCapture considering video file's metadata  (applicable for FFmpeg back-end only) (https://github.com/opencv/opencv/issues/15499)\r\n            ":"\r\n            如果为 true - 考虑视频文件的元数据旋转 CvCapture 的输出帧（仅适用于 FFmpeg 后端）(https://github.com/opencv/opencv/issues/15499)\r\n            \r\n","\r\n            Convert YUV (YV12) to RGBA\r\n            ":"\r\n            将 YUV (YV12) 转换为 RGBA\r\n            \r\n","\r\n            Contrast Limited Adaptive Histogram Equalization\r\n            ":"\r\n            对比度受限自适应直方图均衡\r\n            \r\n","\r\n            Show a widget in the window\r\n            ":"\r\n            在窗口中显示一个小部件\r\n            \r\n","Buffer containing the content of the .caffemodel file":"包含 .caffemodel 文件内容的缓冲区\r\n","\r\n            Termination criteria of the procedure. EM algorithm stops either after a certain number of iterations (term_crit.num_iter), or when the parameters change too little (no more than term_crit.epsilon) from iteration to iteration\r\n            ":"\r\n            程序的终止标准。 EM 算法在一定次数的迭代 (term_crit.num_iter) 后停止，或者当参数在迭代之间变化太小（不超过 term_crit.epsilon）时停止\r\n            \r\n","The resulting mask":"由此产生的面具\r\n","Size in pixels of the template patch that is used to compute weights. Should be odd.":"用于计算权重的模板补丁的大小（以像素为单位）。应该是奇数。\r\n","\r\n            Mirror frame\r\n            ":"\r\n            镜框\r\n            \r\n","\r\n            Provide interfaces to the Open CV PhaseUnwrapping functions\r\n            ":"\r\n            为 Open CV PhaseUnwrapping 函数提供接口\r\n            \r\n","If true, it will not try to scale up the image to fit the frame":"如果为真，它不会尝试放大图像以适合框架\r\n","The matrix where subtraction take place":"减法发生的矩阵\r\n","\r\n            Calculates spatial and central moments up to the third order and writes them to moments. The moments may be used then to calculate gravity center of the shape, its area, main axises and various shape characeteristics including 7 Hu invariants.\r\n            ":"\r\n            计算高达三阶的空间和中心矩并将它们写入矩。然后可以使用力矩来计算形状的重心、面积、主轴和各种形状特征，包括 7 Hu 不变量。\r\n            \r\n","\r\n            The function initializes a SuperpixelSEEDS object for the input image.\r\n            ":"\r\n            该函数为输入图像初始化一个 SuperpixelSEEDS 对象。\r\n            \r\n","\r\n            YAML format\r\n            ":"\r\n            YAML格式\r\n            \r\n","The vectors of distortion coefficients for second camera, 4x1, 1x4, 5x1 or 1x5":"第二台摄像机的失真系数向量，4x1、1x4、5x1 或 1x5\r\n","\r\n             Performs a forward or inverse discrete Fourier transform (1D or 2D) of floating point matrix.\r\n             Param dft_size is the size of DFT transform.\r\n             \r\n             If the source matrix is not continous, then additional copy will be done,\r\n             so to avoid copying ensure the source matrix is continous one. If you want to use\r\n             preallocated output ensure it is continuous too, otherwise it will be reallocated.\r\n            \r\n             Being implemented via CUFFT real-to-complex transform result contains only non-redundant values\r\n             in CUFFT's format. Result as full complex matrix for such kind of transform cannot be retrieved.\r\n            \r\n             For complex-to-real transform it is assumed that the source matrix is packed in CUFFT's format.\r\n             ":"\r\n             执行浮点矩阵的正向或反向离散傅立叶变换（一维或二维）。\r\n             参数 dft_size 是 DFT 变换的大小。\r\n             \r\n             如果源矩阵不连续，则进行额外的复制，\r\n             所以为了避免复制确保源矩阵是连续的。如果你想使用\r\n             预分配的输出也确保它是连续的，否则它将被重新分配。\r\n            \r\n             通过 CUFFT 实现实数到复数的转换结果只包含非冗余值\r\n             以 CUFFT 的格式。无法检索此类变换的全复矩阵结果。\r\n            \r\n             对于复数到实数的变换，假定源矩阵以 CUFFT 格式打包。\r\n             \r\n","\r\n            Create a empty Image \r\n            ":"\r\n            创建一个空图像\r\n            \r\n"," and returns the comparison mask\r\n            ":" 并返回比较掩码\r\n            \r\n","Operation mask, 8-bit single channel array; specifies elements of destination array to be changed":"操作掩码，8位单通道数组；指定要更改的目标数组的元素\r\n","Hog clip":"猪夹\r\n","A Gpu mat to hold the result":"保存结果的 Gpu 垫\r\n","\r\n            The threshold on the squared distance between the pixel and the sample to decide whether a pixel is close to a data sample.\r\n            ":"\r\n            像素和样本之间的平方距离的阈值，用于决定像素是否接近数据样本。\r\n            \r\n","\r\n            Compute the sum of two GeodeticCoordinates\r\n            ":"\r\n            计算两个 GeodeticCoordinates 的总和\r\n            \r\n","Operation flags that may be zero or ZeroDisparity . If the flag is set, the function makes the principal points of each camera have the same pixel coordinates in the rectified views. And if the flag is not set, the function may still shift the images in the horizontal or vertical direction (depending on the orientation of epipolar lines) to maximize the useful image area.":"可能为零或 ZeroDisparity 的操作标志。如果设置了标志，则该函数使每个相机的主点在校正视图中具有相同的像素坐标。如果未设置该标志，该函数仍可能在水平或垂直方向（取决于对极线的方向）移动图像以最大化有用的图像区域。\r\n","\r\n            Create a thin plate spline shape transformer\r\n            ":"\r\n            创建薄板样条形状变换器\r\n            \r\n","\r\n            Latitude (phi) in radian\r\n            ":"\r\n            以弧度表示的纬度 (phi)\r\n            \r\n","\r\n            Convert YUV (YVYU) to BGRA\r\n            ":"\r\n            将 YUV (YVYU) 转换成 BGRA\r\n            \r\n","\r\n            Central Moment Mu11\r\n            ":"\r\n            中心矩 Mu11\r\n            \r\n","\r\n            Aligning image to put face on the standard position.\r\n            ":"\r\n            对齐图像以将面部放在标准位置。\r\n            \r\n","\r\n            UPC-EAN-EXTENSION\r\n            ":"\r\n            UPC-EAN-扩展\r\n            \r\n","\r\n            Get or Set the Retina parameters.\r\n            ":"\r\n            获取或设置 Retina 参数。\r\n            \r\n","\r\n            Same as DepthFloat16\r\n            ":"\r\n            与 DepthFloat16 相同\r\n            \r\n","\r\n            SVM kernel type\r\n            ":"\r\n            SVM 内核类型\r\n            \r\n","\r\n            Release the resource for this capture\r\n            ":"\r\n            释放这次捕获的资源\r\n            \r\n","list of marker ids in markerCorners.":"markerCorners 中的标记 ID 列表。\r\n","\r\n            The matrix is reduced to a single column\r\n            ":"\r\n            矩阵减少为单列\r\n            \r\n","\r\n            Exposure compensator which tries to remove exposure related artifacts by adjusting image intensities on each channel independently. \r\n            ":"\r\n            曝光补偿器，它试图通过独立调整每个通道上的图像强度来消除与曝光相关的伪影。\r\n            \r\n","\r\n            Check if the GPU module is targeted for the specific device version\r\n            ":"\r\n            检查 GPU 模块是否针对特定设备版本\r\n            \r\n","\r\n            Output buffer grid size is 1x1\r\n            ":"\r\n            输出缓冲区网格大小为 1x1\r\n            \r\n","256x1 matrix with inverse camera response function for each pixel value, it should have the same number of channels as images.":"256x1 矩阵，每个像素值具有逆相机响应函数，它应该具有与图像相同的通道数。\r\n","beta in: res = this * alpha + img2 * beta + gamma":"beta in: res = this * alpha + img2 * beta + gamma\r\n","Resulting singular value matrix (MxN or NxN) or vector (Nx1). ":"生成的奇异值矩阵（MxN 或 NxN）或向量 (Nx1)。\r\n","The IPosition3D array":"IPosition3D 数组\r\n","User data.":"用户数据。\r\n","\r\n            BRIEF Descriptor\r\n            ":"\r\n            简要说明\r\n            \r\n","Status code.":"状态码。\r\n","\r\n            Computes exponent of each matrix element (b = exp(a))\r\n            ":"\r\n            计算每个矩阵元素的指数 (b = exp(a))\r\n            \r\n","positive samples to use during tracking":"跟踪期间使用的正样本\r\n","\r\n            Dilates an image by using 3 by 3 rectangular structuring element.\r\n            ":"\r\n            使用 3 x 3 矩形结构元素扩展图像。\r\n            \r\n","The first point":"第一点\r\n","\r\n            Execute only second step of the algorithm\r\n            ":"\r\n            只执行算法的第二步\r\n            \r\n","\r\n            Possible activation functions\r\n            ":"\r\n            可能的激活函数\r\n            \r\n","\r\n            Converts an image from BGR color space to YUV color space.\r\n            ":"\r\n            将图像从 BGR 颜色空间转换为 YUV 颜色空间。\r\n            \r\n","\r\n            Expectation Maximization model\r\n            ":"\r\n            期望最大化模型\r\n            \r\n","\r\n            Create the standard vector of VectorOfDMatch \r\n            ":"\r\n            创建 VectorOfDMatch 的标准向量\r\n            \r\n","Standard vector of Matches between points.":"点之间匹配的标准向量。\r\n","Vector specifying which samples to use for training. It can be an integer vector (CV_32S) containing 0-based sample indices or byte vector (CV_8U) containing a mask of training samples.":"指定要用于训练的样本的向量。它可以是包含基于 0 的样本索引的整数向量 (CV_32S) 或包含训练样本掩码的字节向量 (CV_8U)。\r\n","\r\n            Interpolate base on this point and the other point with the given index\r\n            ":"\r\n            在此点和具有给定索引的另一点的基础上进行插值\r\n            \r\n","The matrix where the region is extracted from":"从中提取区域的矩阵\r\n","\r\n            A cross-shaped element.\r\n            ":"\r\n            十字形元素。\r\n            \r\n","if 0, signal the process to continue":"如果为 0，表示进程继续\r\n","\"Laplacian Zero-Crossing\" feature extractor is used by default (following to original article)":"默认使用“Laplacian Zero-Crossing”特征提取器（遵循原始文章）\r\n","true if every element of this matrix equals elements in ":"如果此矩阵的每个元素都等于中的元素，则为真\r\n"," The image that contains the absolute different value":" 包含绝对不同值的图像\r\n","\r\n            Output buffer grid size is 2x2\r\n            ":"\r\n            输出缓冲区网格大小为 2x2\r\n            \r\n","\r\n            Release all the unmanaged resource associated with MSDDetector\r\n            ":"\r\n            释放与 MSDDetector 关联的所有非托管资源\r\n            \r\n","\r\n            Boosting type\r\n            ":"\r\n            升压型\r\n            \r\n"," before multiplication":" 乘法前\r\n","\r\n            Get the equivalent opencv depth type for this image\r\n            ":"\r\n            获取此图像的等效 opencv 深度类型\r\n            \r\n","Output vector of lines. Each line is represented by a two-element vector. \r\n            The first element is the distance from the coordinate origin (top-left corner of the image). \r\n            The second element is the line rotation angle in radians.":"线的输出向量。每条线由一个二元向量表示。\r\n            第一个元素是距坐标原点（图像左上角）的距离。\r\n            第二个元素是以弧度为单位的线旋转角度。\r\n","The X component of the vector: rotation axis * sin(rotation angle / 2)":"向量的X分量：旋转轴*sin(旋转角度/2)\r\n","Type of the label array to build. If labelType==CCOMP then each connected component of zeros in src (as well as all the non-zero pixels closest to the connected component) will be assigned the same label. If labelType==PIXEL then each zero pixel (and all the non-zero pixels closest to it) gets its own label.":"要构建的标签数组的类型。如果 labelType==CCOMP 那么 src 中零的每个连通分量（以及最接近连通分量的所有非零像素）将被分配相同的标签。如果 labelType==PIXEL 那么每个零像素（以及所有最接近它的非零像素）都有自己的标签。\r\n","\r\n            The equivalent of cv::Mat, should only be used if you know what you are doing.\r\n            In most case you should use the Matrix class instead\r\n            ":"\r\n            等同于 cv::Mat，只有当你知道自己在做什么时才应该使用。\r\n            在大多数情况下，您应该改用 Matrix 类\r\n            \r\n","\r\n            Set a image used by switch* functions to initialize the class.\r\n            ":"\r\n            设置 switch* 函数使用的图像来初始化类。\r\n            \r\n","Diffusivity type.":"扩散型。\r\n","\r\n            Categorical\r\n            ":"\r\n            绝对的\r\n            \r\n","Filter sigma in the color space. A larger value of the parameter means that farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting in larger areas of semi-equal color.":"在颜色空间中过滤 sigma。较大的参数值意味着像素邻域内更远的颜色（参见 sigmaSpace）将混合在一起，从而产生更大的半等色区域。\r\n","\r\n            Performs generalized matrix multiplication:\r\n            dst = alpha*op(src1)*op(src2) + beta*op(src3), where op(X) is X or XT\r\n            ":"\r\n            执行广义矩阵乘法：\r\n            dst = alpha*op(src1)*op(src2) + beta*op(src3)，其中 op(X) 是 X 或 XT\r\n            \r\n","\r\n            Main interface for all disparity map filters.\r\n            ":"\r\n            所有视差图过滤器的主界面。\r\n            \r\n","\r\n            Run an exhaustive search to improve detection rate.\r\n            ":"\r\n            运行详尽搜索以提高检测率。\r\n            \r\n","Output vector of rotation vectors (see Rodrigues ) estimated for each pattern view. That is, each k-th rotation vector together with the corresponding k-th translation vector (see the next output parameter description) brings the calibration pattern from the model coordinate space (in which object points are specified) to the world coordinate space, that is, a real position of the calibration pattern in the k-th pattern view (k=0.. M -1).":"为每个模式视图估计的旋转向量的输出向量（参见 Rodrigues）。也就是说，每个第k个旋转向量连同相应的第k个平移向量（见下一个输出参数描述）将校准模式从模型坐标空间（其中指定了对象点）带到世界坐标空间，即是，第k个图案视图(k＝0..M -1)中校准图案的真实位置。\r\n","\r\n            Tangential distortion coefficients are set to zeros and do not change during the optimization\r\n            ":"\r\n            切向畸变系数设置为零，在优化过程中不会改变\r\n            \r\n","the number of bytes to be copied":"要复制的字节数\r\n","\r\n            float\r\n            ":"\r\n            漂浮\r\n            \r\n","The array of input arrays.":"输入数组的数组。\r\n","\r\n            Reduces GpuMat to a vector by treating the GpuMat rows/columns as a set of 1D vectors and performing the specified operation on the vectors until a single row/column is obtained. \r\n            ":"\r\n            通过将 GpuMat 行/列视为一组一维向量并对向量执行指定操作直到获得单个行/列，将 GpuMat 简化为向量。\r\n            \r\n","The specific diagonal elements of this matrix":"这个矩阵的具体对角线元素\r\n","\r\n            Calculates the superpixel segmentation on a given image with the initialized parameters in the SuperpixelSLIC object.\r\n            This function can be called again without the need of initializing the algorithm with createSuperpixelSLIC(). This save the computational cost of allocating memory for all the structures of the algorithm.\r\n            ":"\r\n            使用 SuperpixelSLIC 对象中的初始化参数计算给定图像的超像素分割。\r\n            无需使用 createSuperpixelSLIC() 初始化算法即可再次调用此函数。这节省了为算法的所有结构分配内存的计算成本。\r\n            \r\n","The vector of Platfom info":"平台信息向量\r\n","\r\n            Get or Set the specific channel of the current image.\r\n            For Get operation, a copy of the specific channel is returned.\r\n            For Set operation, the specific channel is copied to this image.\r\n            ":"\r\n            获取或设置当前图像的具体通道。\r\n            对于 Get 操作，返回特定通道的副本。\r\n            对于设置操作，特定通道被复制到该图像。\r\n            \r\n","The transformation result":"改造结果\r\n","Maximum number of iterations of refining algorithm (Levenberg-Marquardt). Passing 0 will disable refining, so the output matrix will be output of robust method.":"优化算法的最大迭代次数 (Levenberg-Marquardt)。传递 0 将禁用精炼，因此输出矩阵将是稳健方法的输出。\r\n","\r\n            Compress the data using the specific compression level\r\n            ":"\r\n            使用特定的压缩级别压缩数据\r\n            \r\n","The double value":"双重价值\r\n","The initial iterations":"初始迭代\r\n","\r\n            Create a HistogramPhaseUnwrapping instance\r\n            ":"\r\n            创建一个 HistogramPhaseUnwrapping 实例\r\n            \r\n","\r\n            Calculates the per-element bit-wise logical \"exclusive or\" of a matrix and a scalar.\r\n            ":"\r\n            计算矩阵和标量的每个元素按位逻辑“异或”。\r\n            \r\n","Convolution kernel (or rather a correlation kernel), a single-channel floating point matrix; if you want to apply different kernels to different channels, split the image into separate color planes using split and process them individually.":"卷积核（或者更确切地说是相关核），一个单通道浮点矩阵；如果要将不同的内核应用于不同的通道，请使用 split 将图像拆分为单独的颜色平面并单独处理它们。\r\n","\r\n            Automatic exposure/gain ROI Height\r\n            ":"\r\n            自动曝光/增益 ROI 高度\r\n            \r\n","\r\n            Returns true if video writer has been successfully initialized.\r\n            ":"\r\n            如果视频编写器已成功初始化，则返回 true。\r\n            \r\n","Path to output file with .dot extension":"带 .dot 扩展名的输出文件的路径\r\n","Destination back projection matrix of the sametype as the source matrices":"与源矩阵类型相同的目标反投影矩阵\r\n","The mat to be added":"要添加的垫子\r\n","The sqsum GpuMat, supports only CV32F source type.":"sqsum GpuMat，仅支持 CV32F 源类型。\r\n","\r\n            The horizontal size of the bounding box.\r\n            ":"\r\n            边界框的水平尺寸。\r\n            \r\n","\r\n            Number of neighbor rectangles in the group\r\n            ":"\r\n            组中相邻矩形的数量\r\n            \r\n","Input matrix of 8-bit elements.":"8 位元素的输入矩阵。\r\n","A string represent the filename of a trained model.":"字符串表示训练模型的文件名。\r\n","\r\n            The size of CvTermCriteria\r\n            ":"\r\n            CvTermCriteria 的大小\r\n            \r\n","bilateral filter sigma in coordinate space":"坐标空间中的双边滤波器西格玛\r\n","Source image. ":"源图像。\r\n","\r\n            Implements k-means algorithm that finds centers of cluster_count clusters and groups the input samples around the clusters. On output labels(i) contains a cluster index for sample stored in the i-th row of samples matrix\r\n            ":"\r\n            实现 k-means 算法，该算法找到 cluster_count 集群的中心并将输入样本分组在集群周围。在输出标签（i）上包含存储在样本矩阵第 i 行中的样本的聚类索引\r\n            \r\n","It returns false if the line segment is completely outside the rectangle and true otherwise.":"如果线段完全位于矩形之外，则返回 false，否则返回 true。\r\n","sensitivity to the edges":"对边缘敏感\r\n","\r\n            Approx frame sync\r\n            ":"\r\n            大约帧同步\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this InputArray\r\n            ":"\r\n            释放与此 InputArray 关联的所有非托管内存\r\n            \r\n","The array of points that define the convex polygon":"定义凸多边形的点数组\r\n","Output vector of three 2D points defining the vertices of the triangle. The depth of the OutputArray must be CV_32F.":"定义三角形顶点的三个二维点的输出向量。 OutputArray 的深度必须是 CV_32F。\r\n","\r\n            Wrapped KAZE detector\r\n            ":"\r\n            包裹式 KAZE 探测器\r\n            \r\n","Maximum relative error is ~7e-6. Currently, the function converts denormalized values to zeros on output.":"最大相对误差为 ~7e-6。目前，该函数在输出时将非规范化值转换为零。\r\n","Quantized levels per 'color' component. Power of two, typically 32, 64 or 128.":"每个“颜色”分量的量化级别。 2 的幂，通常为 32、64 或 128。\r\n","\r\n            n-class classification (n>=2), allows imperfect separation of classes with penalty multiplier C for outliers\r\n            ":"\r\n            n 类分类 (n>=2)，允许类的不完全分离，对于异常值使用惩罚乘数 C\r\n            \r\n"," The width of this capture":" 这次捕获的宽度\r\n","model file path for the super resolution model":"超分辨率模型的模型文件路径\r\n","\r\n            A square marker shape\r\n            ":"方形标记形状\r\n            \r\n","The descriptors from the given keypoints":"来自给定关键点的描述符\r\n","\r\n            Release all the unmanaged resource associated with AverageHash\r\n            ":"\r\n            释放与 AverageHash 关联的所有非托管资源\r\n            \r\n","The points to be inserted to this planar subdivision":"要插入到此平面细分中的点\r\n","Exposure ratio.":"曝光率。\r\n","Input 8-bit or 16-bit 1-channel image.":"输入 8 位或 16 位 1 通道图像。\r\n","Hog orientations":"养猪方向\r\n","\r\n            Class implementing PCT (position-color-texture) signature extraction as described in:\r\n            Martin Krulis, Jakub Lokoc, and Tomas Skopal. Efficient extraction of clustering-based feature signatures using GPU architectures. Multimedia Tools Appl., 75(13):8071–8103, 2016.\r\n            The algorithm is divided to a feature sampler and a clusterizer. Feature sampler produces samples at given set of coordinates. Clusterizer then produces clusters of these samples using k-means algorithm. Resulting set of clusters is the signature of the input image.\r\n            A signature is an array of SIGNATURE_DIMENSION-dimensional points.Used dimensions are: weight, x, y position; lab color, contrast, entropy.\r\n            ":"\r\n            实现 PCT（位置-颜色-纹理）签名提取的类，如下所述：\r\n            Martin Krulis、Jakub Lokoc 和 Tomas Skopal。使用 GPU 架构高效提取基于聚类的特征签名。多媒体工具应用，75(13):8071–8103, 2016。\r\n            该算法分为特征采样器和聚类器。特征采样器在给定的一组坐标处生成样本。 Clusterizer 然后使用 k-means 算法生成这些样本的集群。生成的簇集是输入图像的签名。\r\n            一个签名是一个SIGNATURE_DIMENSION维点的数组。使用的维度有：weight, x, y position；实验室颜色、对比度、熵。\r\n            \r\n","\r\n            Header is Null\r\n            ":"\r\n            标头为空\r\n            \r\n","\r\n            The flags for the neural network training function\r\n            ":"\r\n            神经网络训练函数的标志\r\n            \r\n","Sequence or array of the curve points":"曲线点的序列或数组\r\n","\r\n            pixel depth in bits: IPL_DEPTH_8U, IPL_DEPTH_8S, IPL_DEPTH_16U, IPL_DEPTH_16S, IPL_DEPTH_32S, IPL_DEPTH_32F and IPL_DEPTH_64F are supported \r\n            ":"\r\n            以位为单位的像素深度：支持 IPL_DEPTH_8U、IPL_DEPTH_8S、IPL_DEPTH_16U、IPL_DEPTH_16S、IPL_DEPTH_32S、IPL_DEPTH_32F 和 IPL_DEPTH_64F\r\n            \r\n","Thickness of lines used to render the text.":"用于呈现文本的线条粗细。\r\n","\r\n            Resize an image such that it fits in a given frame, keeping the aspect ratio.\r\n            ":"\r\n            调整图像大小，使其适合给定的框架，同时保持纵横比。\r\n            \r\n","\r\n            Releases image ROI. After that the whole image is considered selected.\r\n            ":"\r\n            释放图像 ROI。之后，整个图像被认为是选中的。\r\n            \r\n","\r\n            y-coordinate\r\n            ":"\r\n            y坐标\r\n            \r\n","Aperture size. It can be FILTER_SCHARR, 1, 3, 5, or 7.":"光圈大小。它可以是 FILTER_SCHARR、1、3、5 或 7。\r\n","\r\n            Release the opencl kernel\r\n            ":"\r\n            释放 opencl 内核\r\n            \r\n","\r\n            PCAFlow algorithm.\r\n            ":"\r\n            PCAFlow 算法。\r\n            \r\n","\r\n            Applying an appropriate non-linear transformation to the gradient field inside the selection and then integrating back with a Poisson solver, modifies locally the apparent illumination of an image.\r\n            ":"\r\n            对选区内的梯度场应用适当的非线性变换，然后用泊松求解器积分回来，局部修改图像的表观照明。\r\n            \r\n","The other line":"另一条线\r\n","\r\n            Symbol/character within a word.\r\n            ":"\r\n            单词中的符号/字符。\r\n            \r\n","First input matrix.":"第一个输入矩阵。\r\n","The CvMat header":"CvMat 标头\r\n","Upper bound for T-values.":"T 值的上限。\r\n","The training samples.":"训练样本。\r\n","\r\n            Weight of the color constancy term\r\n            ":"\r\n            颜色恒常性项的权重\r\n            \r\n","The second image":"第二张图片\r\n","\r\n            Create AKAZE using the specific values\r\n            ":"\r\n            使用特定值创建 AKAZE\r\n            \r\n"," The green value for this color ":" 这种颜色的绿色值\r\n","resulting contrast on logarithmic scale, i. e. log(max / min), where max and min are maximum and minimum luminance values of the resulting image.":"在对数刻度上产生的对比度，i。 e. log(max / min)，其中 max 和 min 是结果图像的最大和最小亮度值。\r\n","\r\n            If true, the algorithm detects shadows and marks them.\r\n            ":"\r\n            如果为真，算法会检测阴影并标记它们。\r\n            \r\n","\r\n            BTVL\r\n            ":"\r\n            BTVL\r\n            \r\n","\r\n            Positive saturation enhancement value. 1.0 preserves saturation, values greater than 1 increase saturation and values less than 1 decrease it.\r\n            ":"\r\n            正饱和增强值。 1.0 保留饱和度，大于 1 的值会增加饱和度，小于 1 的值会降低饱和度。\r\n            \r\n","\r\n            Native implementation to read files into Mat or Images.\r\n            ":"\r\n            将文件读入 Mat 或 Images 的本机实现。\r\n            \r\n","Input color image.":"输入彩色图像。\r\n","\r\n            SAUF algorithm for 8-way connectivity, SAUF algorithm for 4-way connectivity. The parallel implementation described is available for SAUF.\r\n            ":"\r\n            SAUF算法用于8路连接，SAUF算法用于4路连接。描述的并行实现可用于 SAUF。\r\n            \r\n","the destination to copy to":"复制到的目的地\r\n"," Used metric. CV_DIST_L1, CV_DIST_L2 , and CV_DIST_C stand for one of the standard metrics. CV_DIST_USER means that a pre-calculated cost matrix cost is used.":" 使用公制。 CV_DIST_L1、CV_DIST_L2 和 CV_DIST_C 代表标准指标之一。 CV_DIST_USER 表示使用预先计算好的成本矩阵成本。\r\n","\r\n            the vectors are stored as rows (i.e. all the components of a certain vector are stored continously)\r\n            ":"\r\n            向量存储为行（即某个向量的所有分量连续存储）\r\n            \r\n","\r\n            Textline order\r\n            ":"\r\n            文本行顺序\r\n            \r\n","Max number of boxes to detect.":"要检测的最大框数。\r\n","Null if the reading fails, otherwise, an array of Mat from the file":"如果读取失败则为空，否则为文件中的 Mat 数组\r\n","List of identifiers for each marker.":"每个标记的标识符列表。\r\n","The depth of the destination image":"目标图像的深度\r\n","\r\n            Feature type to be used in the tracking grayscale, colornames, compressed color-names\r\n            The modes available now:\r\n            -   \"GRAY\" -- Use grayscale values as the feature\r\n            -   \"CN\" -- Color-names feature\r\n            ":"\r\n            跟踪灰度、颜色名称、压缩颜色名称中使用的特征类型\r\n            现在可用的模式：\r\n            - \"GRAY\" -- 使用灰度值作为特征\r\n            - \"CN\" -- 颜色名称功能\r\n            \r\n","The zero-based column (x direction) of the pixel":"像素的从零开始的列（x方向）\r\n","Optional vector of type CV_8U and size <number_of_variables_in_samples> + <number_of_variables_in_responses>, containing types of each input and output variable.":"CV_8U 类型和大小的可选向量 <number_of_variables_in_samples> + <number_of_variables_in_responses>，包含每个输入和输出变量的类型。\r\n","\r\n            If set the difference between the current pixel and seed pixel is considered,\r\n            otherwise difference between neighbor pixels is considered (the range is floating).\r\n            ":"\r\n            如果设置当前像素和种子像素之间的差异被考虑，\r\n            否则考虑相邻像素之间的差异（范围是浮动的）。\r\n            \r\n","A matrix of the specific data depth with optional scaling.":"具有可选缩放比例的特定数据深度矩阵。\r\n","Back projection of object histogram ":"对象直方图的反投影\r\n","\r\n            Bounding box\r\n            ":"\r\n            边界框\r\n            \r\n","\r\n            Trains a descriptor matcher (for example, the flann index). In all methods to match, the method\r\n            train() is run every time before matching.Some descriptor matchers(for example, BruteForceMatcher)\r\n            have an empty implementation of this method.Other matchers really train their inner structures (for\r\n            example, FlannBasedMatcher trains flann::Index ).\r\n            ":"\r\n            训练描述符匹配器（例如，flann 索引）。在所有匹配的方法中，方法\r\n            train() 每次在匹配之前运行。一些描述符匹配器（例如，BruteForceMatcher）\r\n            有这个方法的空实现。其他匹配器真正训练它们的内部结构（对于\r\n            例如，FlannBasedMatcher 训练 flann::Index ）。\r\n            \r\n","The subtraction of one point from the other":"从一个点中减去另一个点\r\n","\r\n            The type of the input array\r\n            ":"\r\n            输入数组的类型\r\n            \r\n","Thickness of the ellipse arc":"椭圆弧的厚度\r\n","\r\n            Reload all settings on set.\r\n            ":"\r\n            重新加载现场的所有设置。\r\n            \r\n","\r\n            Convert YUV (420p) to RGB\r\n            ":"\r\n            将 YUV (420p) 转换为 RGB\r\n            \r\n","\r\n            Aligns images.\r\n            ":"\r\n            对齐图像。\r\n            \r\n","Motion gradient orientation image; calculated by the function cvCalcMotionGradient.":"运动梯度方向图像；由函数 cvCalcMotionGradient 计算。\r\n","delta":"三角洲\r\n","\r\n            Iterative\r\n            ":"\r\n            迭代\r\n            \r\n","Point coordinates in the original plane":"原平面中的点坐标\r\n","\r\n            Release the unmanaged memory associated with this WCloud\r\n            ":"\r\n            释放与此 WCloud 关联的非托管内存\r\n            \r\n","input image necessary for corner subpixel.":"角子像素所需的输入图像。\r\n","Vector of detected marker corners. For each marker, its four corners are provided, (e.g VectorOfVectorOfPointF ). For N detected markers, the dimensions of this array is Nx4. The order of the corners is clockwise.":"检测到的标记角的向量。对于每个标记，提供了它的四个角（例如 VectorOfVectorOfPointF ）。对于 N 个检测到的标记，此数组的维度为 Nx4。角的顺序是顺时针的。\r\n","Flag which indicates whether image will be cropped after resize or not":"指示图像在调整大小后是否会被裁剪的标志\r\n","\r\n            Chi-Square\r\n            ":"卡方\r\n            \r\n","Sufficient accuracy for radius (distance between the coordinate origin and the line),  0.01 would be a good default":"半径（坐标原点和直线之间的距离）的足够精度，0.01 是一个很好的默认值\r\n","The destination gpuMat":"目的地 gpuMat\r\n","An integer that represent a mat type":"表示垫类型的整数\r\n","Image header. ":"图片标题。\r\n","The number of rows in the window.":"窗口中的行数。\r\n","\r\n            (**open-only**) Hardware device index (select GPU if multiple available)\r\n            ":"\r\n            (**open-only**) 硬件设备索引（如果有多个可用，请选择 GPU）\r\n            \r\n","Output disparity image. It has the same size as src_disp. The type is CV_8UC4 in BGRA format (alpha = 255).":"输出视差图像。它的大小与 src_disp 相同。类型是 BGRA 格式的 CV_8UC4 (alpha = 255)。\r\n","\r\n            Explicitly destroys and cleans up all resources associated with the current device in the current process.\r\n            Any subsequent API call to this device will reinitialize the device.\r\n            ":"\r\n            显式销毁并清除当前进程中与当前设备关联的所有资源。\r\n            对该设备的任何后续 API 调用都将重新初始化该设备。\r\n            \r\n","\r\n            Get the Matrix, corresponding to a specified column span of the input array\r\n            ":"\r\n            获取输入数组的指定列跨度对应的矩阵\r\n            \r\n","\r\n            The implicit operator to convert MCvPoint3D32f to MCvPoint3D64f\r\n            ":"\r\n            将 MCvPoint3D32f 转换为 MCvPoint3D64f 的隐式运算符\r\n            \r\n","Vector of output rotation vectors (see Rodrigues ) that, together with tvecs, brings points from the model coordinate system to the camera coordinate system.":"输出旋转向量的向量（参见 Rodrigues ），与 tvecs 一起将点从模型坐标系带到相机坐标系。\r\n","\r\n            This is the default mode, the algorithm is single-pass, which means that you consider only 5 directions instead of 8\r\n            ":"\r\n            这是默认模式，算法是single-pass，也就是说你只考虑5个方向而不是8个\r\n            \r\n","\r\n            Performs Frequency Selective Reconstruction (FSR). Slower but better inpainting\r\n            ":"\r\n            执行频率选择性重建 (FSR)。更慢但更好的修复\r\n            \r\n","\r\n            Set default Color Correction Matrix\r\n            ":"\r\n            设置默认颜色校正矩阵\r\n            \r\n","The elementwise sum of the two matrices":"两个矩阵的元素和\r\n","\r\n            GOTURN is kind of trackers based on Convolutional Neural Networks (CNN). While taking all advantages of CNN trackers, GOTURN is much faster due to offline training without online fine-tuning nature. GOTURN tracker addresses the problem of single target tracking: given a bounding box label of an object in the first frame of the video, we track that object through the rest of the video. NOTE: Current method of GOTURN does not handle occlusions; however, it is fairly robust to viewpoint changes, lighting changes, and deformations. Inputs of GOTURN are two RGB patches representing Target and Search patches resized to 227x227. Outputs of GOTURN are predicted bounding box coordinates, relative to Search patch coordinate system, in format X1,Y1,X2,Y2.\r\n            ":"\r\n            GOTURN 是一种基于卷积神经网络 (CNN) 的跟踪器。在利用 CNN 跟踪器的所有优势的同时，由于没有在线微调性质的离线训练，GOTURN 的速度要快得多。 GOTURN 跟踪器解决了单目标跟踪的问题：给定视频第一帧中对象的边界框标签，我们通过视频的其余部分跟踪该对象。注意：GOTURN 的当前方法不处理遮挡；然而，它对视点变化、光照变化和变形相当稳健。 GOTURN 的输入是两个 RGB 补丁，代表调整为 227x227 的目标和搜索补丁。 GOTURN 的输出是相对于搜索补丁坐标系的预测边界框坐标，格式为 X1,Y1,X2,Y2。\r\n            \r\n","\r\n            It should be used only when CV_HAAR_FIND_BIGGEST_OBJECT is set and min_neighbors > 0. If the flag is set, the function does not look for candidates of a smaller size as soon as it has found the object (with enough neighbor candidates) at the current scale. Typically, when min_neighbors is fixed, the mode yields less accurate (a bit larger) object rectangle than the regular single-object mode (flags=CV_HAAR_FIND_BIGGEST_OBJECT), but it is much faster, up to an order of magnitude. A greater value of min_neighbors may be specified to improve the accuracy\r\n            ":"\r\n            仅当设置了 CV_HAAR_FIND_BIGGEST_OBJECT 且 min_neighbors > 0 时才应使用它。如果设置了该标志，则该函数不会在当前比例找到对象（具有足够的邻居候选对象）后立即寻找较小尺寸的候选对象。通常，当 min_neighbors 固定时，该模式产生的对象矩形不如常规单对象模式 (flags=CV_HAAR_FIND_BIGGEST_OBJECT) 准确（稍大），但速度快得多，可达一个数量级。可以指定更大的 min_neighbors 值以提高准确性\r\n            \r\n","Desired depth of the integral and the tilted integral images, CV_32S, CV_32F, or CV_64F.":"积分图像和倾斜积分图像的所需深度，CV_32S、CV_32F 或 CV_64F。\r\n","\r\n            Create DAISY descriptor extractor\r\n            ":"\r\n            创建 DAISY 描述符提取器\r\n            \r\n","\r\n            The device vendor name\r\n            ":"\r\n            设备供应商名称\r\n            \r\n","The pointer to the Feature2DAsync object":"指向 Feature2DAsync 对象的指针\r\n","\r\n            Performs forward or inverse transform of 1D or 2D floating-point array\r\n            ":"\r\n            执行一维或二维浮点数组的正向或反向变换\r\n            \r\n","\r\n            The types for MulSpectrums\r\n            ":"\r\n            MulSpectrum 的类型\r\n            \r\n","\r\n            Update the tracker, find the new most likely bounding box for the target.\r\n            ":"\r\n            更新跟踪器，为目标找到新的最有可能的边界框。\r\n            \r\n","The mask for the add operation":"添加操作的掩码\r\n","\r\n            When passing an object of this type the index constructed will consist of a set of randomized kd-trees which will be searched in parallel.\r\n            ":"\r\n            当传递这种类型的对象时，构建的索引将由一组随机的 kd 树组成，这些树将被并行搜索。\r\n            \r\n","\r\n            One step algorithm.\r\n            ":"\r\n            一步算法。\r\n            \r\n","Input vector with all the contours (vector of Point).":"具有所有轮廓的输入向量（点向量）。\r\n","\r\n            The size of the box\r\n            ":"\r\n            箱体尺寸\r\n            \r\n","\r\n            Lp distance function selector.       \r\n            ":"\r\n            Lp 距离函数选择器。\r\n            \r\n","This function can be called again for other images without the need of initializing the algorithm with createSuperpixelSEEDS(). This save the computational cost of allocating memory for all the structures of the algorithm.":"可以为其他图像再次调用此函数，而无需使用 createSuperpixelSEEDS() 初始化算法。这节省了为算法的所有结构分配内存的计算成本。\r\n","\r\n            Create an standard vector of VectorOfPoint with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfPoint 的标准向量\r\n            \r\n","The weighted sum of two matrices":"两个矩阵的加权和\r\n","\r\n            Complete Solution Classification for the Perspective-Three-Point Problem\r\n            X.S. Gao, X.-R. Hou, J. Tang, H.-F. Chang; \"Complete Solution Classification for the Perspective-Three-Point Problem\"\r\n            ":"\r\n            透视三点问题的完备解分类\r\n            X.S.高，X.-R。侯，J. 唐，H.-F。张; “透视三点问题的完全解决方案分类”\r\n            \r\n","Currently this parameter is ignored and only PickyICP is applied. Leave it as 1.":"目前此参数被忽略，仅应用 PickyICP。将其保留为 1。\r\n","\r\n            The y value of the 3d location\r\n            ":"\r\n            3d位置的y值\r\n            \r\n","Returns nonzero if the check succeeded, i.e. all elements are valid and within the range, and zero otherwise. In the latter case if CV_CHECK_QUIET flag is not set, the function raises runtime error.":"如果检查成功则返回非零，即所有元素都有效且在范围内，否则返回零。在后一种情况下，如果未设置 CV_CHECK_QUIET 标志，则该函数会引发运行时错误。\r\n","The streaming context":"流式上下文\r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are greater or equal compare to the scalar value.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否大于或等于标量值。\r\n            \r\n","The object representation as a result of the deserialization of the xml string":"作为 xml 字符串反序列化结果的对象表示\r\n","\r\n            Convert RGB color to BGRA color\r\n            ":"\r\n            将 RGB 颜色转换为 BGRA 颜色\r\n            \r\n","\r\n            Back\r\n            ":"\r\n            后退\r\n            \r\n","\r\n            The total number of pixels in the line\r\n            ":"\r\n            行中的像素总数\r\n            \r\n","name for layer which output is needed to get":"需要获取输出的层的名称\r\n","The IImage object to be refelected for methods marked with ExposableMethodAttribute":"为标有 ExposableMethodAttribute 的方法反射的 IImage 对象\r\n","\r\n            iOS device exposure\r\n            ":"\r\n            iOS设备曝光\r\n            \r\n","\r\n            Library to invoke XImgproc functions\r\n            ":"\r\n            调用 XImgproc 函数的库\r\n            \r\n","\r\n            Simple sequence\r\n            ":"\r\n            简单序列\r\n            \r\n","\r\n            Feature vectors are stored as cols\r\n            ":"\r\n            特征向量存储为 cols\r\n            \r\n","\r\n            Flags for Imwrite function\r\n            ":"\r\n            Imwrite 函数的标志\r\n            \r\n","\r\n            If set, always convert image to the single channel grayscale image and the image size reduced 1/8.\r\n            ":"\r\n            如果设置，总是将图像转换为单通道灰度图像，图像尺寸缩小 1/8。\r\n            \r\n","\r\n            Get a copy of the data values as an array\r\n            ":"\r\n            获取数据值的副本作为数组\r\n            \r\n","\r\n            Apply standard iterative refinement\r\n            ":"\r\n            应用标准迭代细化\r\n            \r\n","\r\n            cameraMatrix contains valid initial values of fx, fy, cx, cy that are optimized further. Otherwise, (cx, cy) is initially set to the image center ( imageSize is used), and focal distances are computed in a least-squares fashion.\r\n            ":"\r\n            cameraMatrix 包含进一步优化的 fx、fy、cx、cy 的有效初始值。否则，(cx, cy) 最初设置为图像中心（使用 imageSize），并以最小二乘法计算焦距。\r\n            \r\n","\r\n            This class represents high-level API for text recognition networks\r\n            ":"\r\n            此类代表文本识别网络的高级 API\r\n            \r\n","\r\n            Updates the predicted state from the measurement.\r\n            ":"\r\n            根据测量更新预测状态。\r\n            \r\n","\r\n            Convert YUV (YVYU) to BGR\r\n            ":"\r\n            YUV (YVYU) 转换成BGR\r\n            \r\n","\r\n            Convert the standard vector to an array of Triangle2DF\r\n            ":"\r\n            将标准向量转换为 Triangle2DF 数组\r\n            \r\n","The minimun size of the destination image":"目标图像的最小尺寸\r\n","A set of file names storing the trained detectors (models). Each file contains one model.":"一组文件名，用于存储经过训练的检测器（模型）。每个文件包含一个模型。\r\n","\r\n            memcpy function\r\n            ":"\r\n            存储函数\r\n            \r\n","An array of ERStat":"一组 ERStat\r\n"," \r\n              |-1  0  1|\r\n              |-2  0  2|\r\n              |-1  0  1|":" \r\n              |-1 0 1|\r\n              |-2 0 2|\r\n              |-1 0 1|\r\n"," \r\n            Update Running Average. ":" \r\n            更新运行平均值。\r\n","\r\n            Apply optimized iterative refinement based bilinear equation solutions\r\n            ":"\r\n            应用基于优化迭代细化的双线性方程解\r\n            \r\n","Type of distance":"距离类型\r\n","The SHA256 has for the file.":"SHA256 具有该文件。\r\n","The source 8-bit (8u), 16-bit (16u) or single-precision floating-point (32f) image":"源 8 位 (8u)、16 位 (16u) 或单精度浮点 (32f) 图像\r\n","\r\n            The equivalent of cv::GScalar\r\n            ":"\r\n            相当于 cv::GScalar\r\n            \r\n","The Matrix to be subtracted":"要减去的矩阵\r\n","The size of T in bytes":"T 的大小（以字节为单位）\r\n","\r\n             The Sobel operators combine Gaussian smoothing and differentiation so the result is more or less robust to the noise. Most often, the function is called with (xorder=1, yorder=0, aperture_size=3) or (xorder=0, yorder=1, aperture_size=3) to calculate first x- or y- image derivative. The first case corresponds to\r\n             ":"\r\n             Sobel 算子结合了高斯平滑和微分，因此结果或多或少对噪声具有鲁棒性。大多数情况下，调用函数时使用 (xorder=1, yorder=0, aperture_size=3) 或 (xorder=0, yorder=1, aperture_size=3) 来计算第一个 x- 或 y- 图像导数。第一种情况对应\r\n             \r\n","linear interpolation factor for adaptation":"适配的线性插值因子\r\n","\r\n            Returns header, corresponding to a specified rectangle of the input array. In other words, it allows the user to treat a rectangular part of input array as a stand-alone array. ROI is taken into account by the function so the sub-array of ROI is actually extracted.\r\n            ":"\r\n            返回标题，对应于输入数组的指定矩形。换句话说，它允许用户将输入数组的矩形部分视为独立数组。该函数考虑了 ROI，因此实际上提取了 ROI 的子数组。\r\n            \r\n","\r\n            Get or Set the data for this matrix\r\n            ":"\r\n            获取或设置此矩阵的数据\r\n            \r\n","\r\n            Create an instance of the FacemarkLBF model\r\n            ":"\r\n            创建 FacemarkLBF 模型的实例\r\n            \r\n","\r\n            Weight parameter for (u - v)^2, tightness parameter\r\n            ":"\r\n            (u - v)^2 的权重参数，紧度参数\r\n            \r\n","\r\n            Convert YUV (UYVY) to Gray\r\n            ":"\r\n            将 YUV (UYVY) 转换为灰色\r\n            \r\n","First threshold for the hysteresis procedure.":"滞后程序的第一个阈值。\r\n","\r\n            Calculates the superpixel segmentation on a given image with the initialized parameters in the SuperpixelLSC object.\r\n            This function can be called again without the need of initializing the algorithm with createSuperpixelLSC(). This save the computational cost of allocating memory for all the structures of the algorithm.\r\n            ":"\r\n            使用 SuperpixelLSC 对象中的初始化参数计算给定图像的超像素分割。\r\n            无需使用 createSuperpixelLSC() 初始化算法即可再次调用此函数。这节省了为算法的所有结构分配内存的计算成本。\r\n            \r\n","\r\n            Create video frame source from video file\r\n            ":"\r\n            从视频文件创建视频帧源\r\n            \r\n","\r\n            KL\r\n            ":"\r\n            吉隆坡\r\n            \r\n","The id of backend":"后端id\r\n","Index to the closest BoW centroid for each descriptors of image1.":"为 image1 的每个描述符指向最近的 BoW 质心的索引。\r\n","True means that target was located and false means that tracker cannot locate target in current frame. Note, that latter does not imply that tracker has failed, maybe target is indeed missing from the frame (say, out of sight)":"True 表示目标已定位，false 表示跟踪器无法在当前帧中定位目标。请注意，后者并不意味着跟踪器已失败，也许目标确实从框架中丢失（例如，看不见）\r\n","The objects detected, one array per channel":"检测到的物体，每个通道一个阵列\r\n","\r\n            Warps image to a new coordinate frame.\r\n            ":"\r\n            将图像扭曲到新的坐标系。\r\n            \r\n","\r\n            Create an standard vector of GpuMat of the specific size\r\n            ":"\r\n            创建特定大小的 GpuMat 标准向量\r\n            \r\n","The error status.":"错误状态。\r\n","A matrix header for the specified matrix column.":"指定矩阵列的矩阵标题。\r\n","Pointer to a CvArr":"指向 CvArr 的指针\r\n","\r\n            These functions try to compose the given images (or images stored internally from the other function calls) into the final pano under the assumption that the image transformations were estimated before.\r\n            ":"\r\n            这些函数尝试将给定的图像（或从其他函数调用内部存储的图像）组合成最终的全景图，假设之前估计了图像变换。\r\n            \r\n","\r\n            Create an empty standard vector of VectorOfRect\r\n            ":"\r\n            创建一个空的 VectorOfRect 标准向量\r\n            \r\n","\r\n            Horizontal sub-sampling of the image\r\n            ":"\r\n            图像的水平子采样\r\n            \r\n","Thresholding type. must be one of CV_THRESH_BINARY, CV_THRESH_BINARY_INV  ":"阈值类型。必须是 CV_THRESH_BINARY、CV_THRESH_BINARY_INV 之一\r\n","Output matrix of column filter coefficients.":"列滤波器系数的输出矩阵。\r\n","Output vector of distortion coefficients (k1,k2,p1,p2[,k3[,k4,k5,k6],[s1,s2,s3,s4]]) of 4, 5, 8 or 12 elements":"4、5、8 或 12 个元素的失真系数 (k1,k2,p1,p2[,k3[,k4,k5,k6],[s1,s2,s3,s4]]) 的输出向量\r\n","Output pyramid.":"输出金字塔。\r\n","\r\n            Start the grab process in a separate thread. Once started, use the ImageGrabbed event handler and RetrieveGrayFrame/RetrieveBgrFrame to obtain the images.\r\n            ":"\r\n            在单独的线程中启动抓取过程。启动后，使用 ImageGrabbed 事件处理程序和 RetrieveGrayFrame/RetrieveBgrFrame 获取图像。\r\n            \r\n","\r\n            Get the vertices of this convex polygon\r\n            ":"\r\n            获取这个凸多边形的顶点\r\n            \r\n","\r\n            Get if the cascade is old format\r\n            ":"\r\n            获取级联是否为旧格式\r\n            \r\n","\r\n            NSS\r\n            ":"\r\n            国家安全局\r\n            \r\n"," \r\n            Defines a Bgr565 (Blue Green Red) color\r\n            ":" \r\n            定义 Bgr565（蓝绿红）颜色\r\n            \r\n","\r\n            Convert the standard vector to an array of Rect\r\n            ":"\r\n            将标准向量转换为 Rect 数组\r\n            \r\n","\r\n            Create an empty standard vector of VectorOfInt\r\n            ":"\r\n            创建一个空的 VectorOfInt 标准向量\r\n            \r\n","\r\n            Dilate\r\n            ":"\r\n            膨胀\r\n            \r\n","\r\n            Initialize with mask\r\n            ":"\r\n            用掩码初始化\r\n            \r\n","\r\n            Finds rectangular regions in the given image that are likely to contain objects the cascade has been trained for and returns those regions as a sequence of rectangles. \r\n            The function scans the image several times at different scales. Each time it considers overlapping regions in the image. \r\n            It may also apply some heuristics to reduce number of analyzed regions, such as Canny prunning. \r\n            After it has proceeded and collected the candidate rectangles (regions that passed the classifier cascade), it groups them and returns a sequence of average rectangles for each large enough group. \r\n            ":"\r\n            在给定图像中查找可能包含级联训练对象的矩形区域，并将这些区域作为矩形序列返回。\r\n            该函数以不同的比例多次扫描图像。每次它考虑图像中的重叠区域。\r\n            它还可以应用一些启发式方法来减少分析区域的数量，例如 Canny 剪枝。\r\n            在它继续收集候选矩形（通过分类器级联的区域）之后，它将它们分组并为每个足够大的组返回一系列平均矩形。\r\n            \r\n","\r\n            Dict6X6_100\r\n            ":"\r\n            词典6X6_100\r\n            \r\n"," \r\n            An array of gray scale images where each element in the array represent a single color channel of the original image \r\n            ":" \r\n            一个灰度图像数组，其中数组中的每个元素代表原始图像的单个颜色通道\r\n            \r\n","Vector of vectors of the projections of the calibration pattern points, observed by the second camera.":"由第二台摄像机观察到的校准图案点投影向量的向量。\r\n","The eroded image.":"被侵蚀的形象。\r\n","\r\n            Horizontal Decimation - horizontal sub-sampling of the image - reduces the horizontal resolution of the image by the specified vertical decimation factor.\r\n            ":"\r\n            水平抽取 - 图像的水平子采样 - 通过指定的垂直抽取因子降低图像的水平分辨率。\r\n            \r\n","\r\n            Gelfand\r\n            ":"\r\n            格尔凡德\r\n            \r\n","\r\n            Construct a cross\r\n            ":"\r\n            构建一个十字架\r\n            \r\n","\r\n            Release all the unmanaged memory associated with this Facemark\r\n            ":"\r\n            释放与此 Facemark 关联的所有非托管内存\r\n            \r\n","\r\n            Dict7X7_50\r\n            ":"\r\n            词典7X7_50\r\n            \r\n","Tnput matrix.":"输入矩阵。\r\n","\r\n            Convert the source image to the current image, if the size are different, the current image will be a resized version of the srcImage. \r\n            ":"\r\n            将源图像转换为当前图像，如果大小不同，则当前图像将是 srcImage 的调整后版本。\r\n            \r\n","\r\n            Release all the unmanaged resource associated with TBMR\r\n            ":"\r\n            释放与 TBMR 关联的所有非托管资源\r\n            \r\n","\r\n            Focus\r\n            ":"\r\n            重点\r\n            \r\n","A CudaImage of the new size":"新尺寸的 CudaImage\r\n","\r\n            LBGM (alias FP-Boost) is the floating point extension where each dimension is computed as a linear combination of the weak learner responses.\r\n            ":"\r\n            LBGM（别名 FP-Boost）是浮点扩展，其中每个维度都被计算为弱学习者响应的线性组合。\r\n            \r\n","\r\n            Convert BGR555 color to BGRA color\r\n            ":"\r\n            将 BGR555 颜色转换为 BGRA 颜色\r\n            \r\n","\r\n            Indicates if the device has the specific feature\r\n            ":"\r\n            指示设备是否具有特定功能\r\n            \r\n","\r\n            Converts an image from NV12 (YUV420p) color space to gray-scaled.\r\n            ":"\r\n            将图像从 NV12 (YUV420p) 色彩空间转换为灰度。\r\n            \r\n","\r\n            Computes norm of the difference between two GpuMats\r\n            ":"\r\n            计算两个 GpuMat 之间差异的范数\r\n            \r\n","\r\n            Implementation of the camera parameters refinement algorithm which minimizes sum of the reprojection\r\n            error squares.\r\n            It can estimate focal length, aspect ratio, principal point.\r\n            ":"\r\n            最小化重投影总和的相机参数细化算法的实现\r\n            误差方块。\r\n            它可以估计焦距、纵横比、主点。\r\n            \r\n","\r\n            Bit exact bilinear interpolation\r\n            ":"\r\n            位精确双线性插值\r\n            \r\n","\r\n            Convert the standard vector to arrays of arrays of Rectangle\r\n            ":"\r\n            将标准向量转换为矩形数组的数组\r\n            \r\n"," The thickness of the line segment ":" 线段的粗细\r\n","The motion filter":"运动过滤器\r\n","The source image. Has to be GpuMat<Byte>. If stream is used, the GpuMat has to be either single channel or 4 channels.":"源图像。必须是 GpuMat<Byte>。如果使用流，GpuMat 必须是单通道或 4 通道。\r\n"," The threshhold to find initial segments of strong edges":" 找到强边初始段的阈值\r\n","path to the .caffemodel file with learned network.":"具有学习网络的 .caffemodel 文件的路径。\r\n","Aperture size ":"光圈大小\r\n","\r\n             Finds the minimal circumscribed circle for 2D point set using iterative algorithm. It returns nonzero if the resultant circle contains all the input points and zero otherwise (i.e. algorithm failed)\r\n             ":"\r\n             使用迭代算法找到 2D 点集的最小外接圆。如果结果圆包含所有输入点，则返回非零，否则返回零（即算法失败）\r\n             \r\n","\r\n            Create an standard vector of VectorOfMat with the initial values\r\n            ":"\r\n            使用初始值创建 VectorOfMat 的标准向量\r\n            \r\n","\r\n            AGAST_7_12d\r\n            ":"\r\n            AGAST_7_12d\r\n            \r\n","\r\n            Adaptive logarithmic mapping is a fast global tonemapping algorithm that scales the image in logarithmic domain.\r\n            Since it's a global operator the same function is applied to all the pixels, it is controlled by the bias parameter.\r\n            ":"\r\n            自适应对数映射是一种快速的全局色调映射算法，可在对数域中缩放图像。\r\n            由于它是一个全局运算符，相同的函数应用于所有像素，它由偏置参数控制。\r\n            \r\n","\r\n            Calculates rotation matrix\r\n            ":"\r\n            计算旋转矩阵\r\n            \r\n"," Perform an elementwise XOR operation with another image and return the result":" 与另一个图像执行逐元素异或运算并返回结果\r\n","\r\n            Wait for the completion\r\n            ":"\r\n            等待完成\r\n            \r\n","operation flags":"操作标志\r\n","Fish eye calibration flags":"鱼眼校准标志\r\n","\r\n            Create a Pix object by coping data from Mat\r\n            ":"\r\n            通过复制来自 Mat 的数据创建一个 Pix 对象\r\n            \r\n","\r\n            This class is used to find the path (contour) between two points which can be used for image segmentation.\r\n            ":"\r\n            此类用于查找可用于图像分割的两点之间的路径（轮廓）。\r\n            \r\n","\r\n            Merges two byte vector into one\r\n            ":"\r\n            将两个字节向量合并为一个\r\n            \r\n","\r\n            Utilities class\r\n            ":"\r\n            公用事业类\r\n            \r\n","\r\n            Output data format.\r\n            ":"\r\n            输出数据格式。\r\n            \r\n","\r\n            This 3D Widget defines a circle.\r\n            ":"\r\n            这个 3D Widget 定义了一个圆。\r\n            \r\n","\r\n            Myraid\r\n            ":"\r\n            Myraid\r\n            \r\n","\r\n            MPEG1\r\n            ":"\r\n            MPEG1\r\n            \r\n","\r\n            Returns list of all built-in backends\r\n            ":"返回所有内置后端的列表\r\n            \r\n","\r\n            Convert Lab color to sRGB color\r\n            ":"\r\n            将 Lab 颜色转换为 sRGB 颜色\r\n            \r\n","\r\n            Temperature\r\n            ":"温度\r\n            \r\n","String to print":"要打印的字符串\r\n","\r\n            Rotate the Affine3 matrix by a Rodrigues vector\r\n            ":"\r\n            通过 Rodrigues 向量旋转 Affine3 矩阵\r\n            \r\n","Increase step for T-values.":"增加 T 值的步长。\r\n","Isotropic scale factor":"各向同性比例因子\r\n","First contour or grayscale image":"第一个轮廓或灰度图像\r\n","\r\n            Flip both vertically and horizontally\r\n            ":"\r\n            垂直和水平翻转\r\n            \r\n","\r\n            Performs image denoising using the Block-Matching and 3D-filtering algorithm with several computational optimizations. Noise expected to be a gaussian white noise.\r\n            ":"\r\n            使用具有多个计算优化的块匹配和 3D 过滤算法执行图像去噪。噪声预计为高斯白噪声。\r\n            \r\n","Operation flags":"操作标志\r\n","\r\n            The exception handler\r\n            ":"\r\n            异常处理程序\r\n            \r\n","\r\n            transpose src2\r\n            ":"\r\n            转置 src2\r\n            \r\n","Prune the area have similar size to its children":"修剪该区域与其子区域大小相似\r\n","\r\n            There is a partial intersection\r\n            ":"\r\n            有部分交集\r\n            \r\n","\r\n            Computes an optimal limited affine transformation with 4 degrees of freedom between two 2D point sets.\r\n            ":"\r\n            计算两个 2D 点集之间具有 4 个自由度的最佳有限仿射变换。\r\n            \r\n","Input single-channel array.":"输入单通道数组。\r\n","\r\n            This class generates sinusoidal patterns that can be used with FTP, PSP and FAPS.\r\n            ":"\r\n            此类生成可用于 FTP、PSP 和 FAPS 的正弦模式。\r\n            \r\n","\r\n            PvAPI, Prosilica GigE SDK\r\n            ":"\r\n            PvAPI、Prosilica GigE SDK\r\n            \r\n","\r\n            Horizontal offset from the origin to the area of interest (in pixels).\r\n            ":"\r\n            从原点到感兴趣区域的水平偏移（以像素为单位）。\r\n            \r\n","The squared sum of matrix elements.":"矩阵元素的平方和。\r\n","\r\n            Remove keypoints from some image by mask for pixels of this image.\r\n            ":"\r\n            通过此图像像素的掩码从某些图像中删除关键点。\r\n            \r\n","search region parameters to use in a OnlineBoosting algorithm":"在 OnlineBoosting 算法中使用的搜索区域参数\r\n","0 based index of the channel to be extracted":"要提取的通道的基于 0 的索引\r\n","Index to the closest BoW centroid for each descriptors of image2.":"为 image2 的每个描述符指向最近的 BoW 质心的索引。\r\n","The line color":"线条颜色\r\n","\r\n            Create a new Image Map defined by the Rectangle area. The center (0.0, 0.0) of this map is \r\n            defined by the center of the rectangle. The initial value of the map is 0.0\r\n            ":"\r\n            创建一个由矩形区域定义的新图像映射。这张地图的中心 (0.0, 0.0) 是\r\n            由矩形的中心定义。地图的初始值为0.0\r\n            \r\n","\r\n            If or not the regions is a local maxima of the probability\r\n            ":"\r\n            如果这些区域是概率的局部最大值\r\n            \r\n","color of marker borders. Rest of colors (text color and first corner color) are calculated based on this one.":"标记边框的颜色。其余颜色（文本颜色和第一个角颜色）是基于此计算的。\r\n","\r\n            return the full range.\r\n            ":"\r\n            返回整个范围。\r\n            \r\n","The bytes that is a concatenation of a and b":"由 a 和 b 串联而成的字节\r\n","See Ximgproc.EdgeAwareInterpolator() K value.":"参见 Ximgproc.EdgeAwareInterpolator() K 值。\r\n","\r\n            Defines a transformation that consists on a simple displacement\r\n            ":"\r\n            定义包含简单位移的变换\r\n            \r\n","Number of times erosion and dilation are applied.":"应用腐蚀和膨胀的次数。\r\n","\r\n            The method removes one or more rows from the bottom of the matrix\r\n            ":"\r\n            该方法从矩阵的底部删除一行或多行\r\n            \r\n","The maximum x,y,z values":"最大 x、y、z 值\r\n","\r\n            The string that this QR code represents\r\n            ":"\r\n            这个二维码代表的字符串\r\n            \r\n","\r\n            Border is filled with the fixed value, passed as last parameter of the function\r\n            ":"\r\n            边框填充固定值，作为函数的最后一个参数传递\r\n            \r\n","\r\n            Used to iterate through sequences and mappings.\r\n            ":"\r\n            用于遍历序列和映射。\r\n            \r\n","\r\n            An abstract class that wrap around a disposable object\r\n            ":"\r\n            包裹一次性对象的抽象类\r\n            \r\n","Hash value one":"哈希值一\r\n","\r\n            Logarithmic polynomial fitting channels respectively; Need assign a value to deg simultaneously\r\n            ":"\r\n            对数多项式分别拟合通道；需要同时给deg赋值\r\n            \r\n","\r\n            True if the native binary is built with DepthAI support.\r\n            ":"\r\n            如果本机二进制文件是使用 DepthAI 支持构建的，则为真。\r\n            \r\n","\r\n            Draws a simple or thick elliptic arc or fills an ellipse sector. The arc is clipped by ROI rectangle. A piecewise-linear approximation is used for antialiased arcs and thick arcs. All the angles are given in degrees.\r\n            ":"\r\n            绘制简单或粗椭圆弧或填充椭圆扇区。弧被 ROI 矩形裁剪。分段线性近似用于抗锯齿弧和粗弧。所有角度都以度为单位给出。\r\n            \r\n","\r\n            Get the Umat header for the specific roi of the parent\r\n            ":"\r\n            获取父级特定 roi 的 Umat 标头\r\n            \r\n","\tInput vector of distortion coefficients (k1,k2,k3,k4).":"失真系数的输入向量 (k1,k2,k3,k4)。\r\n","The third source array (shift). Can be null, if there is no shift.":"第三源数组（shift）。如果没有班次，则可以为空。\r\n","\r\n            Create a FileNodeIterator from a specific node.\r\n            ":"\r\n            从特定节点创建 FileNodeIterator。\r\n            \r\n","Pointer to MCvRNG random number generator. Use 0 if not sure":"指向 MCvRNG 随机数生成器的指针。如果不确定，请使用 0\r\n","Type of descriptor to use":"要使用的描述符类型\r\n","\r\n            Get or Set the center of the CChecker\r\n            ":"获取或设置 CChecker 的中心\r\n            \r\n","The matrix to be added to the current matrix":"要添加到当前矩阵的矩阵\r\n","Optional delta added to the scaled values.":"添加到缩放值的可选增量。\r\n","\r\n            Pan\r\n            ":"\r\n            平底锅\r\n            \r\n","Center of the circle":"圆心\r\n","\r\n            Warp Rectify\r\n            ":"\r\n            扭曲矫正\r\n            \r\n","\r\n            Calculates the covariance matrix of a set of vectors.\r\n            ":"\r\n            计算一组向量的协方差矩阵。\r\n            \r\n","\r\n            Use QR instead of SVD decomposition for solving. Faster but potentially less precise\r\n            ":"\r\n            使用 QR 而不是 SVD 分解来求解。更快但可能不太精确\r\n            \r\n","\r\n            This function receives the detected markers and returns their pose estimation respect to the camera individually. So for each marker, one rotation and translation vector is returned. The returned transformation is the one that transforms points from each marker coordinate system to the camera coordinate system. The marker corrdinate system is centered on the middle of the marker, with the Z axis perpendicular to the marker plane. The coordinates of the four corners of the marker in its own coordinate system are: (-markerLength/2, markerLength/2, 0), (markerLength/2, markerLength/2, 0), (markerLength/2, -markerLength/2, 0), (-markerLength/2, -markerLength/2, 0)\r\n            ":"\r\n            该函数接收检测到的标记，并分别返回它们对相机的姿态估计。因此对于每个标记，返回一个旋转和平移向量。返回的转换是将点从每个标记坐标系转换到相机坐标系的转换。标记坐标系以标记的中间为中心，Z 轴垂直于标记平面。 marker的四个角在自身坐标系中的坐标为：(-markerLength/2, markerLength/2, 0), (markerLength/2, markerLength/2, 0), (markerLength/2, -markerLength/2 , 0), (-markerLength/2, -markerLength/2, 0)\r\n            \r\n","\r\n            Update weights\r\n            ":"\r\n            更新权重\r\n            \r\n","Background ratio":"背景比\r\n","Quadrangle vertices found by detect() method (or some other algorithm).":"通过 detect() 方法（或其他算法）找到的四边形顶点。\r\n","\r\n            Entry points to the Open CV Dnn module\r\n            ":"\r\n            Open CV Dnn 模块的入口点\r\n            \r\n"," \r\n            Indicates if the region of interest has been set\r\n            ":" \r\n            表示是否设置了感兴趣区域\r\n            \r\n","\r\n            Set the background color\r\n            ":"\r\n            设置背景颜色\r\n            \r\n","\r\n            Run the LSTM recognizer, but allow fallback to Tesseract when things get difficult.\r\n            ":"\r\n            运行 LSTM 识别器，但当事情变得困难时允许回退到 Tesseract。\r\n            \r\n","The upper values stored in an image of same type & size as ":"上限值存储在与以下类型和大小相同的图像中\r\n","Parameter used for the RANSAC or LMedS methods only. It specifies a desirable level of confidence (probability) that the estimated matrix is correct.":"仅用于 RANSAC 或 LMedS 方法的参数。它指定了估计矩阵正确的理想置信度（概率）水平。\r\n","\r\n            Applies horizontal concatenation to given matrices.\r\n            ":"\r\n            将水平串联应用于给定矩阵。\r\n            \r\n","Normalization type ( NORM_MINMAX , NORM_L2 , NORM_L1 or NORM_INF ).":"规范化类型（ NORM_MINMAX 、 NORM_L2 、 NORM_L1 或 NORM_INF ）。\r\n","Array of N points from the first image. The point coordinates should be floating-point (single or double precision).":"来自第一个图像的 N 个点的数组。点坐标应该是浮点数（单精度或双精度）。\r\n","Rate of allowed erroneous bits respect to the error correction capability of the used dictionary. -1 ignores the error correction step. (default 3)":"允许错误位的比率与所用字典的纠错能力有关。 -1 忽略纠错步骤。 （默认 3）\r\n","\r\n            Similar to cvCvtScale but it stores absolute values of the conversion results:\r\n            dst(I)=abs(src(I)*scale + (shift,shift,...))\r\n            The function supports only destination arrays of 8u (8-bit unsigned integers) type, for other types the function can be emulated by combination of cvConvertScale and cvAbs functions.\r\n            ":"\r\n            类似于 cvCvtScale 但它存储转换结果的绝对值：\r\n            dst(I)=abs(src(I)*scale + (shift,shift,...))\r\n            该函数仅支持 8u（8 位无符号整数）类型的目标数组，对于其他类型，该函数可以通过 cvConvertScale 和 cvAbs 函数的组合来模拟。\r\n            \r\n","\r\n            Wrapped CvParamGrid structure used by SVM\r\n            ":"\r\n            SVM 使用的包装 CvParamGrid 结构\r\n            \r\n","The number of disparities. Must be multiple of 8. Use 64 for default ":"差距的数量。必须是8的倍数。默认使用64\r\n","Output 3D affine transformation matrix.":"输出 3D 仿射变换矩阵。\r\n","gamma in: res = this * alpha + img2 * beta + gamma":"伽玛输入：res = this * alpha + img2 * beta + gamma\r\n","\r\n            Trigger\r\n            ":"\r\n            扳机\r\n            \r\n","\r\n             Synonym for Bhattacharyya\r\n            ":"\r\n             Bhattacharyya 的同义词\r\n            \r\n","\r\n            Reset the pointers\r\n            ":"\r\n            重置指针\r\n            \r\n","\r\n            Rotates an image around the origin (0,0) and then shifts it.\r\n            ":"\r\n            围绕原点 (0,0) 旋转图像，然后移动它。\r\n            \r\n","The array of decoded string.":"解码后的字符串数组。\r\n","Structuring element used for erosion. If it is IntPtr.Zero, a 3x3 rectangular structuring element is used.":"用于侵蚀的结构元素。如果它是 IntPtr.Zero，则使用 3x3 矩形结构元素。\r\n","\r\n            PM G1\r\n            ":"\r\n            PM G1\r\n            \r\n","Left singular vectors":"左奇异向量\r\n","\r\n            Create a shape context distance extractor\r\n            ":"\r\n            创建形状上下文距离提取器\r\n            \r\n","If true, iterate each block level twice for higher accuracy.":"如果为真，则将每个块级别迭代两次以获得更高的准确性。\r\n","\r\n            Computes natural logarithm of absolute value of each matrix element: b = log(abs(a))\r\n            ":"\r\n            计算每个矩阵元素的绝对值的自然对数：b = log(abs(a))\r\n            \r\n","\r\n            AdaptiveThreshold window size step\r\n            ":"\r\n            AdaptiveThreshold 窗口大小步长\r\n            \r\n","optional depth of the output image.":"输出图像的可选深度。\r\n","\r\n              Simple euclidean distance \r\n            ":"\r\n              简单欧式距离\r\n            \r\n","Structuring element used for erosion;":"用于侵蚀的结构元素；\r\n","Parameter specifying the approximation accuracy. This is the maximum distance between the original curve and its approximation.":"指定近似精度的参数。这是原始曲线与其近似曲线之间的最大距离。\r\n","\r\n            Background Subtraction using Local SVD Binary Pattern.\r\n            ":"\r\n            使用本地 SVD 二进制模式的背景减法。\r\n            \r\n","Source array (single-channel, 8-bit of 32-bit floating point). ":"源数组（单通道，32 位浮点数的 8 位）。\r\n","\r\n            Clear eeprom\r\n            ":"\r\n            清除eeprom\r\n            \r\n","Coefficients for filtering each row.":"过滤每行的系数。\r\n","Method for solving a PnP problem ":"解决 PnP 问题的方法\r\n","\r\n            Get all the text in the image\r\n            ":"\r\n            获取图片中的所有文字\r\n            \r\n","contains the imgPoints of those squares whose inner code has not a correct codification. Useful for debugging purposes.":"包含那些内部代码没有正确编码的方块的 imgPoints。用于调试目的。\r\n","\r\n            Base class for text detection networks.\r\n            ":"\r\n            文本检测网络的基类。\r\n            \r\n"," image and the other image\r\n            ":" 图像和另一个图像\r\n            \r\n","Output image with compensated fisheye lens distortion.":"输出具有补偿鱼眼镜头失真的图像。\r\n","\r\n            The size of CvMatND\r\n            ":"\r\n            CvMatND 的大小\r\n            \r\n","A threshold used in non maximum suppression. The default value 0 means we will not perform non-maximum supression.":"用于非最大抑制的阈值。默认值 0 意味着我们不会执行非最大抑制。\r\n","\r\n            Release all the unmanaged memory associated with this OclDevice\r\n            ":"\r\n            释放与此 OclDevice 关联的所有非托管内存\r\n            \r\n"," Elementwise add ":" 按元素添加\r\n","Search region parameters to use in a OnlineBoosting algorithm":"在 OnlineBoosting 算法中使用的搜索区域参数\r\n","Use the input rotation and translation parameters as a guess":"使用输入的旋转和平移参数作为猜测\r\n","\r\n            Parameter C of a SVM optimization problem\r\n            ":"\r\n            SVM 优化问题的参数 C\r\n            \r\n","The level at which the image is given. If 1, that means we will also look at the image.":"给出图像的级别。如果为 1，则意味着我们还将查看图像。\r\n","Per-element bit-wise logical disjunction of two matrices of the same size.":"两个相同大小的矩阵的每个元素按位逻辑或。\r\n","Path to the model definition file.":"模型定义文件的路径。\r\n","Converted format for output":"转换后的输出格式\r\n","\r\n            Get or set the intensity of the Y color channel\r\n            ":"\r\n            获取或设置 Y 颜色通道的强度\r\n            \r\n","\r\n            Same to cv::VideoCapture >gt; cv::Mat function\r\n            ":"\r\n            与 cv::VideoCapture >gt; 相同简历::垫功能\r\n            \r\n","Displacement part of the affine transformation":"仿射变换的位移部分\r\n","\r\n            Get the pointer to the widget3D object\r\n            ":"\r\n            获取指向 widget3D 对象的指针\r\n            \r\n","\r\n            Base Cuda filter class\r\n            ":"\r\n            基础 Cuda 过滤器类\r\n            \r\n","saturation enhancement value.":"饱和度增强值。\r\n","The Signature Quadratic Form Distance of two signatures":"两个签名的签名二次型距离\r\n","gaussian kernel bandwidth":"高斯核带宽\r\n","This should be only a header to the image. When the image is disposed, the cvReleaseImageHeader will be called on the pointer.":"这应该只是图像的标题。处理图像时，将在指针上调用 cvReleaseImageHeader。\r\n","\r\n            Create an empty standard vector of VectorOfPointF\r\n            ":"\r\n            创建 VectorOfPointF 的空标准向量\r\n            \r\n","The circles detected":"检测到的圈子\r\n","The source file name where error is encountered":"遇到错误的源文件名\r\n","\r\n            Release the matrix and all the memory associate with it\r\n            ":"\r\n            释放矩阵和所有与之关联的内存\r\n            \r\n"," Perform Gaussian Smoothing in the current image and return the result ":" 对当前图像进行高斯平滑并返回结果\r\n","\r\n            Convert a CvArr to a GpuMat\r\n            ":"\r\n            将 CvArr 转换为 GpuMat\r\n            \r\n","Type of a morphological operation":"形态学操作的类型\r\n","the specific row of the matrix":"矩阵的特定行\r\n","\r\n            Convert YUV (420p) to RGBA\r\n            ":"\r\n            将 YUV (420p) 转换为 RGBA\r\n            \r\n","\r\n            Release the random tree and all memory associate with it\r\n            ":"\r\n            释放随机树及其关联的所有内存\r\n            \r\n","For more details about this implementation, please see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.476.5736&rep=rep1&type=pdf ":"有关此实现的更多详细信息，请参阅 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.476.5736&rep=rep1&type=pdf\r\n","The names of the channels":"频道名称\r\n","\r\n            Out\r\n            ":"\r\n            出去\r\n            \r\n","\r\n            Usb chunk KiB\r\n            ":"\r\n            USB 块 KiB\r\n            \r\n","clamp descriptors to 255 and convert to uchar CV_8UC1":"将描述符固定为 255 并转换为 uchar CV_8UC1\r\n","\r\n            Calculate square root of each source array element. in the case of multichannel\r\n            arrays each channel is processed independently. The function accuracy is approximately\r\n            the same as of the built-in std::sqrt.\r\n            ":"\r\n            计算每个源数组元素的平方根。在多通道的情况下\r\n            阵列每个通道独立处理。函数精度约为\r\n            与内置 std::sqrt 相同。\r\n            \r\n","Cross-product of two 3-element vectors.":"两个三元素向量的叉积。\r\n","\r\n            Cosine distance\r\n            ":"\r\n            余弦距离\r\n            \r\n","\r\n            A color type\r\n            ":"\r\n            颜色类型\r\n            \r\n","The diameter of each pixel neighborhood, that is used during filtering.":"每个像素邻域的直径，在过滤期间使用。\r\n","\r\n            Convert YUV (Y422) to Gray\r\n            ":"\r\n            将 YUV (Y422) 转换为灰色\r\n            \r\n","\r\n            LocalAdaptintegration_tau. Use 0.0 for default\r\n            ":"\r\n            LocalAdaptintegration_tau。默认使用 0.0\r\n            \r\n","\r\n            The user cannot resize the window, the size is constrainted by the image displayed\r\n            ":"\r\n            用户无法调整窗口大小，大小受显示图像的限制\r\n            \r\n","Parameter in the original article, it's similar to the sigma in the coordinate space into bilateralFilter.":"原文中的参数，类似于将坐标空间中的sigma转化为bilateralFilter。\r\n","\r\n            Defaults to CV_8U\r\n            ":"\r\n            默认为 CV_8U\r\n            \r\n","Optional output array for confidences.":"用于置信度的可选输出数组。\r\n","Output vector of 2D points containing the calculated new positions of input features in the second image.":"二维点的输出向量，包含计算出的第二幅图像中输入特征的新位置。\r\n","The default new camera matrix.":"默认的新相机矩阵。\r\n","\r\n            Finds edges in an image using the Canny algorithm.\r\n            ":"\r\n            使用 Canny 算法查找图像中的边缘。\r\n            \r\n","\r\n            The 1st distortion coefficient (k1) is fixed to 0 or to the initial passed value if CV_CALIB_USE_INTRINSIC_GUESS is passed\r\n            ":"\r\n            如果传递了 CV_CALIB_USE_INTRINSIC_GUESS，则第一个失真系数 (k1) 固定为 0 或初始传递值\r\n            \r\n","Output vector of Mat where computed channels are stored.":"存储计算通道的 Mat 的输出向量。\r\n","The code to generate this MCvScalar from specific language":"从特定语言生成此 MCvScalar 的代码\r\n","\r\n            The device OpenCL C version\r\n            ":"\r\n            设备 OpenCL C 版本\r\n            \r\n","The DNN network":"DNN 网络\r\n","Second method-specific parameter. In case of CV_HOUGH_GRADIENT , it is the accumulator threshold for the circle centers at the detection stage. The smaller it is, the more false circles may be detected. Circles, corresponding to the larger accumulator values, will be returned first.":"第二个特定于方法的参数。在 CV_HOUGH_GRADIENT 的情况下，它是检测阶段圆心的累加器阈值。它越小，可能检测到的错误圆圈就越多。对应于较大累加器值的圆将首先返回。\r\n","Border value":"边界值\r\n","\r\n            Wrapped class of the C++ standard vector of VectorOfPoint3D32F.\r\n            ":"\r\n            VectorOfPoint3D32F 的 C++ 标准向量的包装类。\r\n            \r\n","The list of pixels which contains optimal path between the source and the target points of the image. Type is CV_32SC2 (compatible with VectorOfPoint)":"包含图像源点和目标点之间的最佳路径的像素列表。类型为 CV_32SC2（与 VectorOfPoint 兼容）\r\n","Center of the cone base.":"锥底的中心。\r\n","The other quaternions to interpolate with":"其他四元数插值\r\n","\r\n            Opencv's calling convention\r\n            ":"\r\n            Opencv的调用约定\r\n            \r\n","\r\n            Set the values of the rotation matrix\r\n            ":"\r\n            设置旋转矩阵的值\r\n            \r\n","The images used in the training.":"训练中使用的图像。\r\n","\r\n            Convert BGR to HLS\r\n            ":"\r\n            将 BGR 转换为 HLS\r\n            \r\n","\r\n            Create a GScalar from a scalar value.\r\n            ":"\r\n            从标量值创建 GScalar。\r\n            \r\n","\r\n            The Cuda device information\r\n            ":"\r\n            Cuda设备信息\r\n            \r\n","\r\n            Pointer to the cv::structured_light::StructuredLightPattern object\r\n            ":"\r\n            指向 cv::structured_light::StructuredLightPattern 对象的指针\r\n            \r\n","\r\n            Release all the unmanaged resource associated with ColorMomentHash\r\n            ":"\r\n            释放与 ColorMomentHash 关联的所有非托管资源\r\n            \r\n","the number of intermediate scales per octave":"每个八度音阶的中间音阶数\r\n","The point to subtract from":"要减去的点\r\n","\r\n            Intelperc Generators Mask\r\n            ":"\r\n            Intelperc 生成器掩码\r\n            \r\n","\r\n            The method trains the SVM model automatically by choosing the optimal parameters C, gamma, p, nu, coef0, degree from CvSVMParams. By the optimality one mean that the cross-validation estimate of the test set error is minimal. \r\n            ":"\r\n            该方法通过从 CvSVMParams 中选择最优参数 C、gamma、p、nu、coef0、degree 来自动训练 SVM 模型。最优性意味着测试集误差的交叉验证估计是最小的。\r\n            \r\n","\r\n            Maximum number of output lines\r\n            ":"\r\n            最大输出行数\r\n            \r\n","the specific column of the matrix":"矩阵的特定列\r\n","\r\n            Buffer allocation policy is platform and usage specific \r\n            It is not equal to: AllocateHostMemory | AllocateDeviceMemory\r\n            ":"\r\n            缓冲区分配策略是特定于平台和用途的\r\n            它不等于：AllocateHostMemory |分配设备内存\r\n            \r\n","\r\n            Normalize the image using cvNormalizeHist before applying fixed or adaptive thresholding.\r\n            ":"\r\n            在应用固定或自适应阈值之前，使用 cvNormalizeHist 规范化图像。\r\n            \r\n","Pattern scale":"图案比例\r\n","\r\n            Selective search segmentation algorithm The class implements the algorithm described in:\r\n            Jasper RR Uijlings, Koen EA van de Sande, Theo Gevers, and Arnold WM Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154–171, 2013.\r\n            ":"\r\n            Selective search segmentation algorithm 该类实现了以下描述的算法：\r\n            Jasper RR Uijlings、Koen EA van de Sande、Theo Gevers 和 Arnold WM Smeulders。选择性搜索对象识别。国际计算机视觉杂志，104(2):154–171, 2013。\r\n            \r\n","\r\n            Number of stripes for parallel encoding. -1 for auto detection.\r\n            ":"\r\n            并行编码的条带数。 -1 用于自动检测。\r\n            \r\n","\r\n            Applies the rolling guidance filter to an image\r\n            ":"\r\n            将滚动引导滤镜应用于图像\r\n            \r\n","The result of the morphological operation":"形态学运算结果\r\n","\r\n            Calculate and return available interface bandwidth(int Megabits)\r\n            ":"计算并返回可用接口带宽(int Megabits)\r\n            \r\n","8-bit, single-channel, grayscale input image.":"8 位、单通道、灰度输入图像。\r\n","The assigned value ":"赋值\r\n","Float multiplier for G channel.":"G通道的浮动乘数。\r\n","A regular image":"常规图像\r\n","m-by-n+1 matrix, whose rightmost column corresponds to b in formulation above and the remaining to A. It should containt 32- or 64-bit floating point numbers.":"m×n+1 矩阵，其最右边的列对应于上面公式中的 b，其余列对应于 A。它应该包含 32 位或 64 位浮点数。\r\n","\r\n            Denorm\r\n            ":"\r\n            规范\r\n            \r\n","Array of vector angles; it has the same size and same type as x.":"矢量角度数组；它与 x 具有相同的大小和相同的类型。\r\n","It is created if it does not have the same size and type with src1.":"如果它的大小和类型与 src1 不同，则会创建它。\r\n","\r\n            If set, always convert image to the 3 channel BGR color image and the image size reduced 1/2.\r\n            ":"\r\n            如果设置，则始终将图像转换为 3 通道 BGR 彩色图像并且图像尺寸减小 1/2。\r\n            \r\n","If true, cube is represented as wireframe.":"如果为真，则立方体表示为线框。\r\n","The first output map.":"第一张输出图。\r\n","\r\n            The weight of the appearance cost in the final distance value.\r\n            ":"\r\n            外观代价在最终距离值中的权重。\r\n            \r\n","\r\n            Hershey plain\r\n            ":"\r\n            好时平原\r\n            \r\n","wscale":"wscale\r\n","\r\n            Detects lines.\r\n            ":"\r\n            检测线。\r\n            \r\n","\r\n            Iris\r\n            ":"\r\n            鸢尾花\r\n            \r\n","The initial values":"初始值\r\n","\r\n            Extension methods for IDenseOpticalFlow\r\n            ":"\r\n            IDenseOpticalFlow 的扩展方法\r\n            \r\n","\r\n            Get the height of the mat.\r\n            ":"\r\n            获取垫子的高度。\r\n            \r\n"," The result of elementwise adding img2 to the current image":" 对当前图像逐元素添加img2的结果\r\n","stream indexes with grabbed frames (ready to use .retrieve() to fetch actual frame)":"带有抓取帧的流索引（准备使用 .retrieve() 来获取实际帧）\r\n","The array of corresponding image points, 2xN or Nx2, where N is the number of points in the view":"对应图像点的数组，2xN 或 Nx2，其中 N 是视图中的点数\r\n","\r\n            Creates a horizontal 1D box filter.\r\n            ":"\r\n            创建水平一维盒式过滤器。\r\n            \r\n","An empty input array":"一个空的输入数组\r\n","\r\n            Refine the corners using subpix\r\n            ":"\r\n            使用 subpix 细化角\r\n            \r\n","\r\n            correlation threshold\r\n            ":"\r\n            相关阈值\r\n            \r\n","\r\n            Convert Lab color to BGR color\r\n            ":"\r\n            将 Lab 颜色转换为 BGR 颜色\r\n            \r\n","input image: 8-bit unsigned 1-channel image":"输入图像：8 位无符号 1 通道图像\r\n","\r\n            Erodes the source image using the specified structuring element that determines the shape of a pixel neighborhood over which the minimum is taken:\r\n            dst=erode(src,element):  dst(x,y)=min((x',y') in element)) src(x+x',y+y')\r\n            The function supports the in-place mode. Erosion can be applied several (iterations) times. In case of color image each channel is processed independently.\r\n            ":"\r\n            使用指定的结构化元素腐蚀源图像，该结构化元素确定采用最小值的像素邻域的形状：\r\n            dst=erode(src,element): dst(x,y)=min((x',y') in element)) src(x+x',y+y')\r\n            该函数支持就地模式。侵蚀可以应用多次（迭代）次。在彩色图像的情况下，每个通道都是独立处理的。\r\n            \r\n","The left Channel of a stereo image pair.":"立体图像对的左通道。\r\n","Border type. Use REFLECT101 as default.":"边框类型。默认使用 REFLECT101。\r\n","\r\n            Structural similarity algorithm\r\n            ":"\r\n            结构相似度算法\r\n            \r\n","\r\n            Pose estimation for a board of markers.\r\n            ":"\r\n            标记板的姿势估计。\r\n            \r\n","\r\n            Camera sensor board temperature\r\n            ":"\r\n            摄像头传感器板温度\r\n            \r\n","Order of the derivative x.":"导数 x 的阶数。\r\n","The float from the node.":"来自节点的浮动。\r\n","\r\n            Parameter degree of a kernel function\r\n            ":"\r\n            核函数的参数度\r\n            \r\n","First method-specific parameter. In case of CV_HOUGH_GRADIENT , it is the higher threshold of the two passed to the Canny() edge detector (the lower one is twice smaller).":"第一个特定于方法的参数。在 CV_HOUGH_GRADIENT 的情况下，它是传递给 Canny() 边缘检测器的两个阈值中的较高阈值（较低的阈值小两倍）。\r\n","The image to be inverted":"要反转的图像\r\n","An array of Point":"点数组\r\n","\r\n            Detect ChArUco Diamond markers\r\n            ":"\r\n            检测 ChArUco 钻石标记\r\n            \r\n","\r\n            Get the pointer to cv::_OutputArray\r\n            ":"\r\n            获取指向 cv::_OutputArray 的指针\r\n            \r\n"," The color of the triangle ":" 三角形的颜色\r\n","\r\n            Estimate the number of elements in this storage as the size of the storage divided by the size of the elements\r\n            ":"\r\n            估计此存储中的元素数为存储大小除以元素大小\r\n            \r\n","\r\n            Creates BEBLID (Boosted Efficient Binary Local Image Descriptor).\r\n            ":"\r\n            创建 BEBLID（提升高效二进制本地图像描述符）。\r\n            \r\n","saturation enhancement value. ":"饱和度增强值。\r\n","\r\n            (open-only) Timeout in milliseconds for reading from a video capture (applicable for FFmpeg back-end only)\r\n            ":"\r\n            （仅打开）从视频捕获中读取的超时时间（以毫秒为单位）（仅适用于 FFmpeg 后端）\r\n            \r\n","\r\n            SVMSGD type.\r\n            ASGD is often the preferable choice.\r\n            ":"\r\n            SVMSGD 类型。\r\n            ASGD 通常是更可取的选择。\r\n            \r\n","\r\n            Convert the image to log polar, simulating the human foveal vision\r\n            ":"\r\n            将图像转换为对数极坐标，模拟人类中央凹视觉\r\n            \r\n","\r\n            Class for computing stereo correspondence using the block matching algorithm, introduced and contributed to OpenCV by K. Konolige.\r\n            ":"\r\n            使用块匹配算法计​​算立体对应的类，由 K. Konolige 介绍并贡献给 OpenCV。\r\n            \r\n","The destination GpuMat":"目的地 GpuMat\r\n","The type of the second value":"第二个值的类型\r\n","\r\n            cvCalcCovarMatrix method types\r\n            ":"\r\n            cvCalcCovarMatrix 方法类型\r\n            \r\n","The indexes of the interpolate result":"插值结果的指标\r\n","\r\n            step\r\n            ":"\r\n            步\r\n            \r\n","Parameter indicating a contour to draw. If it is negative, all the contours are drawn.":"指示要绘制的轮廓的参数。如果为负，则绘制所有轮廓。\r\n","The 8-bit 3-channel image to be segmented":"待分割的8位3通道图像\r\n","If true and the problem is 2-class classification then the method creates more balanced cross-validation subsets that is proportions between classes in subsets are close to such proportion in the whole train dataset.":"如果为真且问题是 2 类分类，则该方法会创建更平衡的交叉验证子集，即子集中类之间的比例接近整个训练数据集中的此类比例。\r\n","Returns 0 on success.":"成功返回 0。\r\n","\r\n            Implementation of the different yet better algorithm which is called GSOC, as it was implemented during GSOC and was not originated from any paper.\r\n            ":"\r\n            称为 GSOC 的不同但更好的算法的实现，因为它是在 GSOC 期间实现的，并非源自任何论文。\r\n            \r\n","\r\n            Calculates the first order image derivative in both x and y using a Sobel operator. Equivalent to calling:\r\n            Sobel(src, dx, CV_16SC1, 1, 0, 3 );\r\n            Sobel(src, dy, CV_16SC1, 0, 1, 3 );\r\n            ":"\r\n            使用 Sobel 运算符计算 x 和 y 中的一阶图像导数。相当于调用：\r\n            索贝尔 (src, dx, CV_16SC1, 1, 0, 3 );\r\n            索贝尔 (src, dy, CV_16SC1, 0, 1, 3 );\r\n            \r\n","vector of input matrices to be concatenated vertically.":"要垂直连接的输入矩阵向量。\r\n","Draw a line segment using the specific color and thickness ":"使用特定颜色和粗细绘制线段\r\n","\r\n            Release the stereo state and all the memory associate with it\r\n            ":"\r\n            释放立体状态和所有与之关联的内存\r\n            \r\n","\r\n            Release all memory associated with this ShapeDistanceExtractor\r\n            ":"\r\n            释放与此 ShapeDistanceExtractor 关联的所有内存\r\n            \r\n","\r\n            Config\r\n            ":"\r\n            配置\r\n            \r\n","Input camera matrix A=[[fx,0,0],[0,fy,0][cx,cy,1]].":"输入相机矩阵 A=[[fx,0,0],[0,fy,0][cx,cy,1]]。\r\n","\r\n            Create a cascade classifier\r\n            ":"\r\n            创建级联分类器\r\n            \r\n","The joint matrix of corresponding image points in the views from the 1st camera, 2xN or Nx2, where N is the total number of points in all views":"第一个摄像机的视图中相应图像点的联合矩阵，2xN 或 Nx2，其中 N 是所有视图中点的总数\r\n","The keypoints to be drawn":"要绘制的关键点\r\n","\r\n            Removes a widget from the window.\r\n            ":"\r\n            从窗口中删除一个小部件。\r\n            \r\n","\r\n            RPROP: Decrease factor\r\n            ":"\r\n            RPROP：减少因子\r\n            \r\n","Face index to select a font faces in a single file.":"用于在单个文件中选择字体的面索引。\r\n","\r\n            The size of PointF\r\n            ":"\r\n            PointF 的大小\r\n            \r\n","\r\n            Convert the standard vector to an array of TesseractResult\r\n            ":"\r\n            将标准向量转换为 TesseractResult 数组\r\n            \r\n","If true, then the iteration is always done from the left-most point to the right most, not to depend on the ordering of pt1 and pt2 parameters":"如果为真，则迭代总是从最左边的点到最右边的点进行，而不依赖于 pt1 和 pt2 参数的顺序\r\n","True if success":"如果成功则为真\r\n","\r\n            Homography based rotation estimator.\r\n            ":"\r\n            基于单应性的旋转估计器。\r\n            \r\n","\r\n            Release all the unmanaged resource associated with BRIEF\r\n            ":"\r\n            释放与 BRIEF 关联的所有非托管资源\r\n            \r\n","Nms scale radius":"Nms 刻度半径\r\n","Get the input output array":"获取输入输出数组\r\n","\r\n            Acquisition transport buffer size in bytes\r\n            ":"\r\n            以字节为单位的采集传输缓冲区大小\r\n            \r\n","\r\n            Empty node\r\n            ":"\r\n            空节点\r\n            \r\n","The mask for subtraction":"减法掩码\r\n","\r\n            soft float\r\n            ":"\r\n            软漂浮\r\n            \r\n","\r\n            Calculates the absolute infinite norm of a matrix.\r\n            ":"\r\n            计算矩阵的绝对无限范数。\r\n            \r\n","The pointer to the ImgHashBase object":"指向 ImgHashBase 对象的指针\r\n","Maximum disparity minus minimum disparity. The value is always greater than zero. In the current implementation, this parameter must be divisible by 16.":"最大视差减去最小视差。该值始终大于零。在当前实现中，此参数必须能被 16 整除。\r\n","True if the GPU module is targeted for equal or greater device version.":"如果 GPU 模块针对相同或更高版本的设备，则为真。\r\n","\r\n            BGM_BILINEAR refers to same BGM but use different type of gradient binning. In the BGM_BILINEAR that use ASSIGN_BILINEAR binning type the gradient is assigned to the two neighbouring bins.\r\n            ":"\r\n            BGM_BILINEAR 指的是相同的 BGM 但使用不同类型的梯度合并。在使用 ASSIGN_BILINEAR binning 类型的 BGM_BILINEAR 中，梯度被分配给两个相邻的 bin。\r\n            \r\n","\r\n            Brox optical flow\r\n            ":"Brox光流\r\n            \r\n","Optional flag to specify if the second spectrum needs to be conjugated before the multiplication.":"可选标志，用于指定第二个光谱是否需要在乘法之前进行共轭。\r\n","Input/output second camera matrix. The parameter is similar to ":"输入/输出第二个相机矩阵。该参数类似于\r\n","\r\n            Runs the Harris edge detector on image. Similarly to cvCornerMinEigenVal and cvCornerEigenValsAndVecs, for each pixel it calculates 2x2 gradient covariation matrix M over block_size x block_size neighborhood. Then, it stores\r\n            det(M) - k*trace(M)^2\r\n            to the destination image. Corners in the image can be found as local maxima of the destination image.\r\n            ":"\r\n            在图像上运行 Harris 边缘检测器。类似于 cvCornerMinEigenVal 和 cvCornerEigenValsAndVecs，对于每个像素，它计算 block_size x block_size 邻域上的 2x2 梯度协方差矩阵 M。然后，它存储\r\n            det(M) - k*trace(M)^2\r\n            到目标图像。图像中的角可以作为目标图像的局部最大值找到。\r\n            \r\n","The width of the returned image.":"返回图像的宽度。\r\n","A random point cloud around the ellipse":"椭圆周围的随机点云\r\n","The source GpuMat. Supports CV_8UC1, CV_8UC3 source types. ":"来源 GpuMat。支持 CV_8UC1、CV_8UC3 源类型。\r\n","\r\n            Central Moment Mu20\r\n            ":"\r\n            中心矩 Mu20\r\n            \r\n","The starting row for the tile":"磁贴的起始行\r\n","\r\n            Save the algorithm to file\r\n            ":"\r\n            将算法保存到文件\r\n            \r\n","Source 8-bit single-channel (binary) image.":"源 8 位单通道（二进制）图像。\r\n","The normalized image":"归一化图像\r\n","\r\n            A FrameSource that can be used by the Video Stabilizer\r\n            ":"\r\n            可由视频稳定器使用的 FrameSource\r\n            \r\n","\r\n            The size of CvPoint\r\n            ":"\r\n            CvPoint 的大小\r\n            \r\n","\r\n            Dense sequence subtypes \r\n            ":"\r\n            密集序列亚型\r\n            \r\n","List of the channels used to compute the histogram. ":"用于计算直方图的通道列表。\r\n","\r\n            For stereo rectification: Zero disparity\r\n            ":"\r\n            对于立体校正：零视差\r\n            \r\n","\r\n            R(x,y)=sumx',y'[T(x',y') I(x+x',y+y')]\r\n            ":"\r\n            R(x,y)=sumx',y'[T(x',y') I(x+x',y+y')]\r\n            \r\n","The step (row stride in bytes)":"步骤（以字节为单位的行步幅）\r\n","The rectangle area of the motion":"运动的矩形区域\r\n","\r\n            Fast perf level results in high performance and low quality\r\n            ":"\r\n            快速性能水平导致高性能和低质量\r\n            \r\n","0-based maximal pyramid level number.":"从 0 开始的最大金字塔层数。\r\n","\r\n            Get the pointer to the Feature2DAsync object\r\n            ":"\r\n            获取指向 Feature2DAsync 对象的指针\r\n            \r\n","\r\n            Get the pointer to the native SeamFinder object.\r\n            ":"\r\n            获取指向本机 SeamFinder 对象的指针。\r\n            \r\n","\r\n            Return the header, corresponding to a specified row span of the input array\r\n            ":"\r\n            返回标题，对应于输入数组的指定行跨度\r\n            \r\n","CUDA stream.":"CUDA 流。\r\n","\r\n            The detection result\r\n            ":"\r\n            检测结果\r\n            \r\n","Win size, use (3, 3) for default":"Win 大小，默认使用 (3, 3)\r\n","\r\n            Sorts each matrix row or each matrix column in the\r\n            ascending or descending order.So you should pass two operation flags to\r\n            get desired behaviour. Instead of reordering the elements themselves, it\r\n            stores the indices of sorted elements in the output array.\r\n            ":"\r\n            对矩阵中的每个矩阵行或每个矩阵列进行排序\r\n            升序或降序。所以你应该将两个操作标志传递给\r\n            获得所需的行为。它不是重新排序元素本身，而是\r\n            将已排序元素的索引存储在输出数组中。\r\n            \r\n","\r\n            A FAST detector using Cuda\r\n            ":"\r\n            使用 Cuda 的 FAST 检测器\r\n            \r\n","minRegionSizeII":"minRegionSizeII\r\n","\r\n            Crops a 2D matrix.\r\n            ":"\r\n            裁剪二维矩阵。\r\n            \r\n","\r\n            Check whether a word is valid according to Tesseract's language model\r\n            ":"\r\n            根据Tesseract的语言模型检查一个词是否有效\r\n            \r\n","number of channels in the destination image; if the parameter is 0, the number of the channels is derived automatically from src and code .":"目标图像中的通道数；如果参数为 0，则通道数自动从 src 和 code 导出。\r\n","\r\n            Rotation Invariant\r\n            ":"\r\n            旋转不变\r\n            \r\n","\r\n            Make a clone of the current Mat\r\n            ":"\r\n            克隆当前的 Mat\r\n            \r\n","Input image: 8-bit unsigned 3-channel":"输入图像：8 位无符号 3 通道\r\n","The CudaImage to search in":"要搜索的 CudaImage\r\n","\r\n            Set general purpose output mode\r\n            ":"设置通用输出模式\r\n            \r\n","\r\n            Set the bundle adjuster for this stitcher\r\n            ":"\r\n            为此订书机设置捆绑调节器\r\n            \r\n","\r\n            Create an standard vector of Triangle2DF with the initial values\r\n            ":"\r\n            使用初始值创建 Triangle2DF 的标准向量\r\n            \r\n","\r\n            The default exception to be thrown when error encounter in Open CV \r\n            ":"\r\n            在 Open CV 中遇到错误时抛出的默认异常\r\n            \r\n","Detected objects boundaries.":"检测到的对象边界。\r\n","\r\n            Convert RGB color to YUV\r\n            ":"\r\n            将 RGB 颜色转换为 YUV\r\n            \r\n","\r\n            Computes a cross-product of two 3-element vectors.\r\n            ":"\r\n            计算两个三元素向量的叉积。\r\n            \r\n","\r\n            Release all the memory associated with this InputOutputArray\r\n            ":"\r\n            释放与此 InputOutputArray 关联的所有内存\r\n            \r\n","\r\n            Filter by color\r\n            ":"\r\n            按颜色筛选\r\n            \r\n","The moment":"此时此刻\r\n","\r\n            Get or set the registration resolution\r\n            ":"\r\n            获取或设置注册分辨率\r\n            \r\n","The code to generate the object from the specific language":"从特定语言生成对象的代码\r\n","\r\n            position of second kneepoint (in % of XI_PRM_EXPOSURE)\r\n            ":"\r\n            第二个拐点的位置（以 XI_PRM_EXPOSURE 的百分比表示）\r\n            \r\n","Use RGB":"使用RGB\r\n","\r\n            Convert RGB to YUV_I420\r\n            ":"\r\n            将 RGB 转换为 YUV_I420\r\n            \r\n","Specify cost of gradient magnitude function (default: 0.14f)":"指定梯度幅度函数的成本（默认值：0.14f）\r\n","The current frame":"当前帧\r\n","\r\n            Old fashion way\r\n            ":"\r\n            旧时尚方式\r\n            \r\n","\r\n            Mapper for affine motion\r\n            ":"\r\n            仿射运动映射器\r\n            \r\n","The pointer to the tonemap object":"指向色调映射对象的指针\r\n"," The result of element wise subtracting img2 from ":" 从元素中减去 img2 的结果\r\n","\r\n            If it is on, then this check is performed before the main algorithm and if a chessboard is not found, the function returns 0 instead of wasting 0.3-1s on doing the full search.\r\n            ":"\r\n            如果打开，则在主算法之前执行此检查，如果未找到棋盘，则该函数返回 0 而不是浪费 0.3-1 秒进行完整搜索。\r\n            \r\n","\r\n            class id\r\n            ":"\r\n            班级号\r\n            \r\n","Optional depth type for the returned array":"返回数组的可选深度类型\r\n","\r\n            Regression; nu is used instead of p.\r\n            ":"\r\n            回归；使用 nu 代替 p。\r\n            \r\n"," Draw a convex polygon using the specific color and thickness ":" 使用特定颜色和厚度绘制凸多边形\r\n","path to the .weights file with learned network.":"具有学习网络的 .weights 文件的路径。\r\n","\r\n            Seed point\r\n            ":"\r\n            种子点\r\n            \r\n","The second 1D source vector":"第二个一维源向量\r\n","Th saliency":"显着性\r\n","The Gemm operation type":"Gemm 操作类型\r\n","\r\n            Norm mask\r\n            ":"\r\n            规范掩码\r\n            \r\n","\r\n            Creates a MIL Tracker\r\n            ":"\r\n            创建 MIL 跟踪器\r\n            \r\n","The interpolation type. Supports INTER_NEAREST, INTER_LINEAR.":"插值类型。支持 INTER_NEAREST、INTER_LINEAR。\r\n","\r\n            Shifts a matrix to the right (c = a >> scalar)\r\n            ":"\r\n            将矩阵右移（c = a >> 标量）\r\n            \r\n","Second rectangle ":"第二个矩形\r\n","\r\n            Central Normalized Moment Nu30\r\n            ":"\r\n            中心归一化力矩 Nu30\r\n            \r\n","\r\n            Release the unmanaged memory associated with this Flann based matcher.\r\n            ":"\r\n            释放与这个基于 Flann 的匹配器关联的非托管内存。\r\n            \r\n","\r\n            Max size\r\n            ":"\r\n            最大尺寸\r\n            \r\n","\r\n            Get reshaped matrix which also share the same data with the current matrix\r\n            ":"\r\n            获取与当前矩阵共享相同数据的重塑矩阵\r\n            \r\n","\r\n            Atop\r\n            ":"\r\n            在顶上\r\n            \r\n","Mask input matrix.":"屏蔽输入矩阵。\r\n","\r\n            Given the input frame, create input blob, run net and return recognition result.\r\n            ":"\r\n            给定输入帧，创建输入 blob，运行网络并返回识别结果。\r\n            \r\n","If true, use initial flow.":"如果为真，则使用初始流。\r\n","If true, will try to use GPU":"如果为真，将尝试使用 GPU\r\n","Output matrix of row filter coefficients.":"行滤波器系数的输出矩阵。\r\n","Coordinates of the 3 corresponding triangle vertices in the destination image. If the array contains more than 3 points, only the first 3 will be used":"目标图像中 3 个对应三角形顶点的坐标。如果数组包含超过 3 个点，则只使用前 3 个\r\n","The terminal cost":"终端成本\r\n","The optional name of the node to read (if empty, the first top-level node will be used)":"要读取的节点的可选名称（如果为空，将使用第一个顶级节点）\r\n","\r\n            The backend\r\n            ":"\r\n            后端\r\n            \r\n","\r\n            OutputArrayOfArrays\r\n            ":"\r\n            OutputArrayOfArrays\r\n            \r\n","The row border type.":"行边框类型。\r\n","The other vector, from which the values will be pushed to the current vector":"另一个向量，值将从中推送到当前向量\r\n","\r\n             Makes multi-channel array out of several single-channel arrays\r\n             ":"\r\n             从几个单通道阵列中创建多通道阵列\r\n             \r\n","\r\n            The simulated annealing algorithm.\r\n            ":"\r\n            模拟退火算法。\r\n            \r\n","\r\n            The VGG descriptor type\r\n            ":"\r\n            VGG 描述符类型\r\n            \r\n","\r\n            The type of Marker for drawing\r\n            ":"\r\n            绘图标记的类型\r\n            \r\n","\r\n            The pointer to the ImgHashBase object\r\n            ":"\r\n            指向 ImgHashBase 对象的指针\r\n            \r\n","Weight of the first array elements.":"第一个数组元素的权重。\r\n","\r\n            Attempts to determine whether the input image is a view of the chessboard pattern and locate internal chessboard corners\r\n            ":"\r\n            尝试确定输入图像是否是棋盘图案的视图并定位内部棋盘角\r\n            \r\n","0-based index of the last (the smallest) pyramid layer. It must be non-negative.":"最后（最小）金字塔层的从 0 开始的索引。它必须是非负的。\r\n","\r\n            Returns the specified VideoWriter property.\r\n            ":"\r\n            返回指定的 VideoWriter 属性。\r\n            \r\n","See also: Christian Beecks, Merih Seran Uysal, Thomas Seidl. Signature quadratic form distance. In Proceedings of the ACM International Conference on Image and Video Retrieval, pages 438-445. ACM, 2010.":"另见：Christian Beecks、Merih Seran Uysal、Thomas Seidl。签名二次形式距离。在 ACM 国际图像和视频检索会议记录中，第 438-445 页。美国计算机学会，2010 年。\r\n","\r\n            Maximum number of detection window increases\r\n            ":"\r\n            最大检测窗口数增加\r\n            \r\n","\r\n            Response of the keypoint\r\n            ":"\r\n            关键点的响应\r\n            \r\n","The pixel extrapolation method.":"像素外推法。\r\n","The destination GpuMat. Supports only floating-point type":"目的地 GpuMat。仅支持浮点类型\r\n","\r\n            The function releases the sparse array and clears the array pointer upon exit.\r\n            ":"\r\n            该函数释放稀疏数组并在退出时清除数组指针。\r\n            \r\n","\r\n            Adds the input ":"添加输入\r\n","The row range.":"行范围。\r\n","The major version of the compute capability":"计算能力的主要版本\r\n","\r\n            Performs stereo calibration.\r\n            ":"\r\n            执行立体校准。\r\n            \r\n","\r\n            WeChat QRCode includes two CNN-based models: A object detection model and a super resolution model. Object detection model is applied to detect QRCode with the bounding box. super resolution model is applied to zoom in QRCode when it is small.\r\n            ":"\r\n            微信二维码包括两个基于 CNN 的模型：对象检测模型和超分辨率模型。应用对象检测模型来检测带有边界框的 QRCode。 QRCode小的时候应用超分辨率模型放大QRCode。\r\n            \r\n","Adaptation rate for nms threshold.":"nms 阈值的适应率。\r\n","\r\n            Create a rotation vector using the specific values\r\n            ":"\r\n            使用特定值创建旋转向量\r\n            \r\n","Train set of descriptors. This set is not added to the train descriptors collection stored in the class object.":"训练描述符集。该集合不会添加到存储在类对象中的列车描述符集合中。\r\n","\r\n            Calculates absolute difference between matrix elements and given scalar value\r\n            ":"\r\n            计算矩阵元素与给定标量值之间的绝对差\r\n            \r\n","Second ending point of the line segment. It is modified by the function.":"线段的第二个终点。它由函数修改。\r\n"," Threshold for the distance between features and SVM classifying plane. Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient). But if the free coefficient is omitted (which is allowed), you can specify it manually here.":" 特征与 SVM 分类平面之间距离的阈值。通常它是 0，应该在检测器系数中指定（作为最后一个自由系数）。但如果省略了自由系数（这是允许的），您可以在此处手动指定。\r\n","By default edge responses for horizontal lines are calculated":"默认情况下计算水平线的边缘响应\r\n","The type of the first value":"第一个值的类型\r\n","\r\n            One of cv::ImwritePNGFlags, default is IMWRITE_PNG_STRATEGY_DEFAULT.\r\n            ":"\r\n            cv::ImwritePNGFlags 之一，默认为 IMWRITE_PNG_STRATEGY_DEFAULT。\r\n            \r\n","\r\n            Set the native device pointer\r\n            ":"\r\n            设置本机设备指针\r\n            \r\n","\r\n            Draw a ChArUco Diamond marker\r\n            ":"\r\n            画一个 ChArUco 钻石标记\r\n            \r\n","\r\n            Bad model or chseq\r\n            ":"\r\n            错误的模型或 chseq\r\n            \r\n","\r\n            Indicates if the kernel is empty\r\n            ":"\r\n            指示内核是否为空\r\n            \r\n","\r\n            opengl support.\r\n            ":"\r\n            支持。\r\n            \r\n","\r\n            iOS device torch\r\n            ":"\r\n            iOS 设备手电筒\r\n            \r\n","x-coordinate":"x坐标\r\n","\r\n            Create a matrix of the specific size\r\n            ":"\r\n            创建特定大小的矩阵\r\n            \r\n","\r\n            Create an empty standard vector of DMatch\r\n            ":"\r\n            创建 DMatch 的空标准向量\r\n            \r\n","\r\n            Debug message. Disabled in the \"Release\" build.\r\n            ":"\r\n            调试消息。在“发布”版本中禁用。\r\n            \r\n","\r\n            Computes disparity map for the specified stereo pair\r\n            ":"\r\n            计算指定立体对的视差图\r\n            \r\n","\r\n            Set the current Gpu Device\r\n            ":"\r\n            设置当前的 Gpu 设备\r\n            \r\n","The output of the algorithm that indicates the text regions":"指示文本区域的算法的输出\r\n","The amount of time to step forward by on each iteration (normally, it's between 0 and 1).":"每次迭代前进的时间量（通常在 0 到 1 之间）。\r\n","positive value for gamma correction. Gamma value of 1.0 implies no correction, gamma equal to 2.2f is suitable for most displays. Generally gamma > 1 brightens the image and gamma < 1 darkens it.":"伽马校正的正值。 Gamma 值为 1.0 意味着没有校正，Gamma 等于 2.2f 适用于大多数显示器。通常 gamma > 1 会使图像变亮，而 gamma < 1 会使图像变暗。\r\n","\r\n            Returns the segmentation labeling of the image.\r\n            Each label represents a superpixel, and each pixel is assigned to one superpixel label.\r\n            ":"\r\n            返回图像的分割标签。\r\n            每个标签代表一个超像素，每个像素都分配给一个超像素标签。\r\n            \r\n","\r\n            Implementation of the camera parameters refinement algorithm which minimizes sum of the distances between the rays passing through the camera center and a feature.\r\n            ":"\r\n            相机参数细化算法的实现，该算法最小化通过相机中心的光线与特征之间的距离之和。\r\n            \r\n","\r\n            Defines a transformation that consists on a projective transformation\r\n            ":"\r\n            定义包含投影变换的变换\r\n            \r\n","The distance type":"距离型\r\n","\r\n            Base class for circles detector algorithm.\r\n            ":"\r\n            圆检测器算法的基类。\r\n            \r\n","\r\n            Convert arrays of points to matrix\r\n            ":"\r\n            将点数组转换为矩阵\r\n            \r\n","Vector of vectors of the projections of board marker corner points.":"板标记角点投影向量的向量。\r\n","\r\n            Inferno\r\n            ":"\r\n            地狱火\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of Point.\r\n            ":"\r\n            Point 的 C++ 标准向量的包装类。\r\n            \r\n","Specifies minimum point of the bounding box.":"指定边界框的最小点。\r\n","\r\n            Convert Bayer BGGR to BGR (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 Bayer BGGR 转换为 BGR（边缘感知去马赛克）\r\n            \r\n","\r\n            The kind of sequence available\r\n            ":"\r\n            可用的序列类型\r\n            \r\n","Array of object points in the object coordinate space, Nx3 1-channel or 1xN/Nx1 3-channel, where N is the number of points. VectorOfPoint3f can also be passed here.":"对象坐标空间中的对象点数组，Nx3 1 通道或 1xN/Nx1 3 通道，其中 N 是点数。这里也可以传VectorOfPoint3f。\r\n","\r\n            If the image has only one channel, apply the action directly on the IntPtr of this image and ":"\r\n            如果图像只有一个通道，则直接在该图像的 IntPtr 上应用操作，并且\r\n","\r\n            Release the TBB task scheduler\r\n            ":"\r\n            发布 TBB 任务调度器\r\n            \r\n","Pointer to the opencl device":"指向 opencl 设备的指针\r\n","Image width":"图片宽度\r\n","\r\n            Parameters for GFT algorithm.\r\n            ":"\r\n            GFT 算法的参数。\r\n            \r\n","Use segmentation":"使用细分\r\n","The accumulator threshold for the circle centers at the detection stage. The smaller it is, the more false circles may be detected.":"检测阶段圆心的累加器阈值。它越小，可能检测到的错误圆圈就越多。\r\n","\r\n            distance between elements in bytes for this dimension\r\n            ":"\r\n            此维度的元素之间的距离（以字节为单位）\r\n            \r\n","Scalar added to each sum.":"添加到每个总和的标量。\r\n","The pointer to the existing inputOutputArray":"指向现有 inputOutputArray 的指针\r\n","type of descriptor to use":"要使用的描述符类型\r\n","\r\n            Synonym for Str\r\n            ":"\r\n            Str 的同义词\r\n            \r\n","The type of element in the matrix":"矩阵中元素的类型\r\n","\r\n            Parameters for the FacemarkAAM model\r\n            ":"\r\n            FacemarkAAM 模型的参数\r\n            \r\n","The function returns the compactness measure. The best (minimum) value is chosen and the corresponding labels and the compactness value are returned by the function. ":"该函数返回紧凑度度量。选择最佳（最小）值，并由函数返回相应的标签和紧凑度值。\r\n","\r\n            For PAM, sets the TUPLETYPE field to the corresponding string value that is defined for the format\r\n            ":"对于 PAM，将 TUPLETYPE 字段设置为为格式定义的相应字符串值\r\n            \r\n","\r\n            Pointer to the native Blender object.\r\n            ":"\r\n            指向原生 Blender 对象的指针。\r\n            \r\n","\r\n            MinMax, flag\r\n            ":"\r\n            最小最大值，标志\r\n            \r\n","\r\n            Calculates the product of src and its transposition.\r\n            The function evaluates dst=scale(src-delta)*(src-delta)^T if order=0, and dst=scale(src-delta)^T*(src-delta) otherwise.\r\n            ":"\r\n            计算 src 及其转置的乘积。\r\n            如果 order=0，函数计算 dst=scale(src-delta)*(src-delta)^T，否则计算 dst=scale(src-delta)^T*(src-delta)。\r\n            \r\n","\r\n            Use a Gaussian winsize x winsizefilter instead of box\r\n            filter of the same size for optical flow estimation. Usually, this option gives more accurate\r\n            flow than with a box filter, at the cost of lower speed (and normally winsize for a\r\n            Gaussian window should be set to a larger value to achieve the same level of robustness)\r\n            ":"\r\n            使用高斯 winsize x winsizefilter 而不是框\r\n            相同尺寸的滤波器用于光流估计。通常，此选项提供更准确的\r\n            与箱式过滤器相比，流量较低，但速度较低（通常 winsize 对于\r\n            高斯窗口应设置为更大的值以达到相同的鲁棒性水平）\r\n            \r\n","Number of pixel level iterations. Higher number improves the result.":"像素级迭代次数。较高的数字会改善结果。\r\n","Stat model update parameter. 0.002f ~ 1K frame(~45sec), 0.005 ~ 18sec (if 25fps and absolutely static BG)":"Stat 模型更新参数。 0.002f ~ 1K frame(~45sec), 0.005 ~ 18sec (if 25fps and absolutely static BG)\r\n","Source 8-bit or floating-point, 1-channel or 3-channel image.":"源 8 位或浮点数、1 通道或 3 通道图像。\r\n","\r\n            Default type\r\n            ":"\r\n            默认类型\r\n            \r\n","\r\n            Get the class names\r\n            ":"\r\n            获取类名\r\n            \r\n","\r\n            Write an attribute inside the root group.\r\n            ":"\r\n            在根组内写一个属性。\r\n            \r\n","Surface format of input frames. BGR or gray frames will be converted to YV12 format before encoding, frames with other formats will be used as is.":"输入帧的表面格式。 BGR或灰度帧在编码前会转为YV12格式，其他格式的帧将原样使用。\r\n"," The intensity of the gray color ":" 灰色的强度\r\n","Block stride. Must be a multiple of cell size. Use (8,8) for default.":"阻止步幅。必须是像元大小的倍数。默认使用 (8,8)。\r\n","\r\n            Warper that maps an image onto the z = 1 plane.\r\n            ":"\r\n            将图像映射到 z = 1 平面的变形器。\r\n            \r\n","\r\n            Convert sRGB color to Luv color\r\n            ":"\r\n            将 sRGB 颜色转换为 Luv 颜色\r\n            \r\n","\r\n            The maximum memory allocation size\r\n            ":"\r\n            最大内存分配大小\r\n            \r\n","Input floating-point array of magnitudes of 2D vectors; it can be an empty matrix (=Mat()), in this case, the function assumes that all the magnitudes are =1; if it is not empty, it must have the same size and type as angle":"输入二维向量大小的浮点数组；它可以是一个空矩阵（=Mat()），在这种情况下，该函数假定所有量级都=1；如果它不为空，它必须与角度具有相同的大小和类型\r\n","Vector of vectors of board marker points in the board coordinate space.":"棋盘坐标空间中棋盘标记点向量的向量。\r\n","First input CV_8UC1 matrix to be merged.":"首先输入要合并的 CV_8UC1 矩阵。\r\n","\r\n            IGpu\r\n            ":"\r\n            IGpu\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of Point3D32F.\r\n            ":"\r\n            Point3D32F 的 C++ 标准向量的包装类。\r\n            \r\n","\r\n            Computes square root of each pixel in an image\r\n            ":"\r\n            计算图像中每个像素的平方根\r\n            \r\n","\r\n            Get the corresponding opencv depth type\r\n            ":"\r\n            获取对应的opencv深度类型\r\n            \r\n","\r\n            Get or Set the equivalent MCvScalar value\r\n            ":"\r\n            获取或设置等效的 MCvScalar 值\r\n            \r\n","\r\n            OpenNI2 (for Kinect)\r\n            ":"\r\n            OpenNI2（用于 Kinect）\r\n            \r\n","4-dimensional output array with NCHW dimensions order.":"具有 NCHW 维度顺序的 4 维输出数组。\r\n","\r\n            The display color\r\n            ":"\r\n            显示颜色\r\n            \r\n","Input multi-channel array":"输入多通道阵列\r\n","\r\n            Calculates per-element bit-wise inversion of the input matrix\r\n            ":"\r\n            计算输入矩阵的每个元素的逐位求逆\r\n            \r\n","\r\n            Need Plot Line\r\n            ":"\r\n            需要剧情线\r\n            \r\n","input video streams":"输入视频流\r\n","\r\n            Make a HTML-formatted string with hOCR markup from the internal data structures.\r\n            ":"\r\n            使用来自内部数据结构的 hOCR 标记制作 HTML 格式的字符串。\r\n            \r\n","\r\n            Release the memory associated with this neural network\r\n            ":"\r\n            释放与此神经网络关联的内存\r\n            \r\n","\r\n            Calculates the back projection of a histogram.\r\n            ":"\r\n            计算直方图的反投影。\r\n            \r\n","The center of the kernel":"内核的中心\r\n","\r\n            Concate the current matrix with another matrix vertically. If this matrix is n1 x m and ":"\r\n            将当前矩阵与另一个矩阵垂直连接。如果这个矩阵是 n1 x m 并且\r\n","Output 8-bit 3-channel image.":"输出 8 位 3 通道图像。\r\n","The first source image":"第一张源图\r\n","\r\n            Calculates x and y coordinates of 2D vectors from their magnitude and angle.\r\n            ":"\r\n            根据二维向量的大小和角度计算其 x 和 y 坐标。\r\n            \r\n","\r\n            This function allows the correct initialization of all data structures that will be used by the algorithm.\r\n            ":"\r\n            此函数允许正确初始化算法将使用的所有数据结构。\r\n            \r\n","\r\n            Constructs a WCylinder.\r\n            ":"\r\n            构造一个 WCylinder。\r\n            \r\n","\r\n            Calculates natural logarithm of absolute value of every element of input array\r\n            ":"\r\n            计算输入数组每个元素的绝对值的自然对数\r\n            \r\n","\r\n            Cuda backend\r\n            ":"\r\n            Cuda后端\r\n            \r\n","Reading of this value means that special H/W accelerated handling is not added or not detected by OpenCV.":"读取此值意味着 OpenCV 未添加或未检测到特殊的 H/W 加速处理。\r\n","\r\n            Uses initial estimations, stored in nextPts; if the flag is not set, then prevPts is copied to nextPts and is considered the initial estimate.\r\n            ":"\r\n            使用存储在 nextPts 中的初始估计；如果未设置标志，则将 prevPts 复制到 nextPts 并视为初始估计。\r\n            \r\n","\r\n            Assigns user data to the array header.\r\n            ":"\r\n            将用户数据分配给数组头。\r\n            \r\n","Parameter used for SolvePnpMethod.Iterative. If true, the function uses the provided rvec and tvec values as initial approximations of the rotation and translation vectors, respectively, and further optimizes them.":"用于 SolvePnpMethod.Iterative 的参数。如果为真，则函数使用提供的 rvec 和 tvec 值分别作为旋转和平移向量的初始近似值，并进一步优化它们。\r\n","If true merge similar words":"如果为真合并相似词\r\n","Number of pixel locations to use":"要使用的像素位置数\r\n","\r\n            Built-in OpenCV MotionJPEG codec\r\n            ":"\r\n            内置 OpenCV MotionJPEG 编解码器\r\n            \r\n","H/W acceleration may require special configuration of used environment. Results in encoding scenario may differ between software and hardware accelerated encoders.":"硬件加速可能需要使用环境的特殊配置。软件和硬件加速编码器在编码场景中的结果可能不同。\r\n","\r\n            Return the list of the rectangles' objectness value. \r\n            ":"\r\n            返回矩形的对象值列表。\r\n            \r\n","\r\n            Create a mapper for affine motion\r\n            ":"\r\n            为仿射运动创建映射器\r\n            \r\n","The zero-based row (y direction) of the pixel ":"像素的从零开始的行（y方向）\r\n","Allows to specify API backends to use. Use 0 if you don't have any preference.":"允许指定要使用的 API 后端。如果您没有任何偏好，请使用 0。\r\n","\r\n            Minimum graph cut-based seam estimator.\r\n            ":"\r\n            基于最小图切割的接缝估计器。\r\n            \r\n","\r\n            A generic version of the DataLogger\r\n            ":"\r\n            DataLogger 的通用版本\r\n            \r\n","The quaternions to be compared":"要比较的四元数\r\n","\r\n            Hole\r\n            ":"\r\n            洞\r\n            \r\n","\r\n            Define the Keypoint draw type\r\n            ":"\r\n            定义关键点绘图类型\r\n            \r\n","Only for radius search, require neighbors sorted by distance ":"仅用于半径搜索，要求邻居按距离排序\r\n","\r\n            Central Normalized Moment Nu02\r\n            ":"\r\n            中心标准化矩 Nu02\r\n            \r\n","\r\n            Release the unmanaged memory associated with this object.\r\n            ":"\r\n            释放与此对象关联的非托管内存。\r\n            \r\n","Output image with the same size and type as src":"输出与 src 大小和类型相同的图像\r\n","the other 3D point":"另一个 3D 点\r\n","\r\n            This type is very similar to InputArray except that it is used for output function parameters.\r\n            ":"\r\n            此类型与 InputArray 非常相似，只是它用于输出函数参数。\r\n            \r\n","result CV_32F image with same number of channel than op.":"结果 CV_32F 图像，通道数与 op 相同。\r\n","Depth data of the destination frame (CV_32FC1, in meters)":"目标帧的深度数据（CV_32FC1，以米为单位）\r\n","Correspondence-position per line in line-bundle-space":"行束空间中每行的对应位置\r\n","\r\n            Segment an image and store output in dst.\r\n            ":"\r\n            分割图像并将输出存储在 dst 中。\r\n            \r\n","The blurriness measure":"模糊度测量\r\n","The border type.":"边框类型。\r\n","\r\n            Constructs default cone oriented along x-axis with center of its base located at origin.\r\n            ":"\r\n            构造沿 x 轴定向的默认圆锥体，其底部的中心位于原点。\r\n            \r\n","Source image depth.":"源图像深度。\r\n","Compute the complement Mat":"计算补码 Mat\r\n","\r\n            Converts a matrix to another data depth with optional scaling.\r\n            ":"\r\n            使用可选缩放将矩阵转换为另一个数据深度。\r\n            \r\n","The dest color type. Must be a type inherited from IColor":"最好的颜色类型。必须是继承自 IColor 的类型\r\n","Input Mat for unary computation":"一元计算的输入矩阵\r\n","\r\n            Pointer to the native ExposureCompensator object.\r\n            ":"\r\n            指向本机 ExposureCompensator 对象的指针。\r\n            \r\n","\r\n            Get the number of channels for this image\r\n            ":"\r\n            获取此图像的通道数\r\n            \r\n","An image expected to be a CV_U8C3 of any size":"预期为任意大小的 CV_U8C3 的图像\r\n","\r\n            convert a series of points to LineSegment2D\r\n            ":"\r\n            将一系列点转换为 LineSegment2D\r\n            \r\n","Specifies maximum number of iterations and/or accuracy (distance the centers move by between the subsequent iterations)":"指定最大迭代次数和/或精度（中心在后续迭代之间移动的距离）\r\n","The predicted state. ":"预测的状态。\r\n","Source image (3- or 4-channel 8 bit).":"源图像（3 或 4 通道 8 位）。\r\n","\r\n            Returns Gaussian filter coefficients.\r\n            ":"\r\n            返回高斯滤波器系数。\r\n            \r\n","\r\n            Create an empty standard vector of PointF\r\n            ":"\r\n            创建 PointF 的空标准向量\r\n            \r\n","\r\n            Bad memory block\r\n            ":"\r\n            坏内存块\r\n            \r\n","\r\n            Grab a frame\r\n            ":"\r\n            抓取一个框架\r\n            \r\n","\r\n            Intelperc Depth Generator\r\n            ":"\r\n            Intelperc 深度发生器\r\n            \r\n","The exposure compensator":"曝光补偿器\r\n","\r\n            Create KAZE using the specific values\r\n            ":"\r\n            使用特定值创建 KAZE\r\n            \r\n","Set of colors. It has to be of the same size with cloud.":"一组颜色。它必须与云大小相同。\r\n","The size of the box":"箱体尺寸\r\n","Output 3x4 projection matrix in the new (rectified) coordinate systems for the first camera.":"在第一台摄像机的新（校正）坐标系中输出 3x4 投影矩阵。\r\n","\r\n            Check if the GPU module is targeted for equal or greater BIN version\r\n            ":"\r\n            检查 GPU 模块是否针对相同或更高的 BIN 版本\r\n            \r\n","\r\n            RGB setting\r\n            ":"\r\n            RGB设置\r\n            \r\n","For more details about this filter see: Hojin Cho, Hyunjoon Lee, Henry Kang, and Seungyong Lee. Bilateral texture filtering. ACM Transactions on Graphics, 33(4):128:1–128:8, July 2014.":"有关此过滤器的更多详细信息，请参阅：Hojin Cho、Hyunjoon Lee、Henry Kang 和 Seungyong Lee。双边纹理过滤。 ACM 图形交易，33(4):128:1–128:8，2014 年 7 月。\r\n","\r\n            Create a new device\r\n            ":"\r\n            创建新设备\r\n            \r\n","\r\n            An CudaImage is very similar to the Emgu.CV.Image except that it is being used for GPU processing\r\n            ":"\r\n            CudaImage 与 Emgu.CV.Image 非常相似，只是它用于 GPU 处理\r\n            \r\n","\r\n            Sets a translational motion model; warpMatrix is 2x3 with the first 2x2 part being the unity matrix and the rest two parameters being estimated.\r\n            ":"\r\n            设置平移运动模型； warpMatrix 是 2x3，第一个 2x2 部分是单位矩阵，其余两个参数被估计。\r\n            \r\n","\r\n            Computes element-wise absolute difference of two GpuMats (c = abs(a - b)).\r\n            ":"\r\n            计算两个 GpuMat 的逐元素绝对差 (c = abs(a - b))。\r\n            \r\n","New input size.":"新的输入尺寸。\r\n"," Perform an elementwise OR operation with another image, using a mask, and return the result":" 使用掩码对另一幅图像执行逐元素或运算，并返回结果\r\n","\r\n            Cool\r\n            ":"\r\n            凉爽的\r\n            \r\n","Pointer to IplImage structure used as a temporary buffer.":"指向用作临时缓冲区的 IplImage 结构的指针。\r\n","\r\n            Convert sBGR color to Luv color\r\n            ":"\r\n            将 sBGR 颜色转换为 Luv 颜色\r\n            \r\n","The convex hull of the points":"点的凸包\r\n","The quality base object":"质量基础对象\r\n","Color of the cylinder.":"圆柱体的颜色。\r\n","\r\n            Gpu\r\n            ":"\r\n            显卡\r\n            \r\n"," Elementwise add another matrix with the current matrix ":" Elementwise 添加另一个矩阵与当前矩阵\r\n","Anchor point. The default value (-1) means that the anchor is at the kernel center.":"锚点。默认值 (-1) 表示锚点位于内核中心。\r\n","\r\n            Create a PHash object\r\n            ":"\r\n            创建一个 PHash 对象\r\n            \r\n","The structure that will hold the Open CV structure sizes":"将保存 Open CV 结构大小的结构\r\n","The RLOF optical flow parameters":"RLOF光流参数\r\n","Upper non-inclusive boundary of the returned random number.":"返回的随机数的上非包含边界。\r\n","\r\n              distance = |x1-x2| + |y1-y2| \r\n            ":"\r\n              距离 = |x1-x2| + |y1-y2|\r\n            \r\n","Image where the search is running. It should be 8-bit or 32-bit floating-point":"运行搜索的图像。它应该是8位或32位浮点数\r\n","\r\n            If set, the image is read in any possible color format.\r\n            ":"\r\n            如果设置，图像将以任何可能的颜色格式读取。\r\n            \r\n","The motion channel of the retina.":"视网膜的运动通道。\r\n","\r\n            Returns true if the node has a name\r\n            ":"如果节点有名称则返回真\r\n            \r\n","Specifies maximum point of the bounding box.":"指定边界框的最大点。\r\n","How many random points are used to produce each cell of the descriptor (2, 3, 4 ...).":"有多少随机点用于生成描述符的每个单元格（2、3、4 ...）。\r\n","Each array member specifies the chunking size to be used for block I/O, by default null means none at all.":"每个数组成员指定用于块 I/O 的分块大小，默认情况下 null 表示完全没有。\r\n","\r\n            Create a Bgr565 color using the System.Drawing.Color\r\n            ":"\r\n            使用 System.Drawing.Color 创建 Bgr565 颜色\r\n            \r\n","\r\n            Convert BGRA color to BGR color\r\n            ":"\r\n            将 BGRA 颜色转换为 BGR 颜色\r\n            \r\n","\r\n            Create a MSD (Maximal Self-Dissimilarity) keypoint detector.\r\n            ":"\r\n            创建一个 MSD（最大自相异度）关键点检测器。\r\n            \r\n","translation vector":"翻译向量\r\n","\r\n            Create a multiBandBlender\r\n            ":"\r\n            创建一个 multiBandBlender\r\n            \r\n","\r\n            AdaptiveThreshold constant\r\n            ":"\r\n            AdaptiveThreshold 常量\r\n            \r\n","\r\n            Image generator output mode\r\n            ":"\r\n            图像发生器输出方式\r\n            \r\n","The vertices of this triangle":"这个三角形的顶点\r\n","\r\n            Affine transformation based estimator.\r\n            ":"\r\n            基于仿射变换的估计器。\r\n            \r\n","\r\n            increments from adaptiveThreshWinSizeMin to adaptiveThreshWinSizeMax during the thresholding (default 10).\r\n            ":"\r\n            在阈值处理期间从 adaptiveThreshWinSizeMin 递增到 adaptiveThreshWinSizeMax（默认为 10）。\r\n            \r\n","\r\n            Global Atomic\r\n            ":"\r\n            全球原子\r\n            \r\n","Number of clusters to split the set by.":"拆分集合所依据的簇数。\r\n","The vector of distortion coefficients, 4x1 or 1x4 [k1, k2, p1, p2]. If it is IntPtr.Zero, all distortion coefficients are considered 0's":"失真系数的向量，4x1 或 1x4 [k1, k2, p1, p2]。如果是IntPtr.Zero，所有的失真系数都被认为是0的\r\n","Input data to compute the wrapped phase map.":"输入数据以计算包裹的相图。\r\n","Desired depth of the destination image":"目标图像的所需深度\r\n","The source GpuMat":"来源GpuMat\r\n","Initial weights of mixture components. It should be a one-channel floating-point matrix with 1 x nclusters or nclusters x 1 size.":"混合成分的初始权重。它应该是具有 1 x nclusters 或 nclusters x 1 大小的单通道浮点矩阵。\r\n","\r\n            disparity gradient threshold\r\n            ":"\r\n            视差梯度阈值\r\n            \r\n","\r\n            Performs the per-element comparison of of a matrix and a scalar, checking if elements from first matrix are not equal to elements in second.\r\n            ":"\r\n            执行矩阵和标量的每个元素比较，检查第一个矩阵中的元素是否不等于第二个中的元素。\r\n            \r\n","\r\n            Image hash based on Radon transform\r\n            ":"\r\n            基于 Radon 变换的图像哈希\r\n            \r\n","\r\n            Grayscale Logarithmic polynomial fitting;  Need assign a value to deg and dst_whites simultaneously\r\n            ":"\r\n            灰度对数多项式拟合；需要同时给deg和dst_whites赋值\r\n            \r\n","\r\n            Termination criteria of the training algorithm\r\n            ":"\r\n            训练算法的终止标准\r\n            \r\n","\r\n            (simple blur) - summation over a pixel param1 x param2 neighborhood with subsequent scaling by 1/(param1 x param2). \r\n            ":"\r\n            （简单模糊）- 在像素 param1 x param2 邻域上求和，随后按 1/(param1 x param2) 缩放。\r\n            \r\n","\r\n            A generic EventArgs\r\n            ":"\r\n            一个通用的 EventArgs\r\n            \r\n","Specifies if (true) color is processed of not (false) to then processing gray level image":"指定是否处理（真）颜色或不（假）处理灰度图像\r\n","destination image - 32-bit 3-channel Mat with values in [0, 1] range":"目标图像 - 值在 [0, 1] 范围内的 32 位 3 通道垫\r\n","\r\n            Release all the unmanaged memory associated with this WBDetector.\r\n            ":"\r\n            释放与此 WBDetector 关联的所有非托管内存。\r\n            \r\n"," The result of the OR operation":" OR 运算的结果\r\n","\r\n            Performs object detection with a multi-scale window.\r\n            ":"\r\n            使用多尺度窗口执行对象检测。\r\n            \r\n","\r\n              (x,y) \r\n            ":"\r\n              (x,y)\r\n            \r\n","\r\n            The motion mask. \r\n            Do not dispose this image.\r\n            ":"\r\n            运动遮罩。\r\n            不要处理此图像。\r\n            \r\n","\r\n            Class implementing VGG (Oxford Visual Geometry Group) descriptor trained end to end using \"Descriptor Learning Using Convex Optimisation\" (DLCO) aparatus\r\n            ":"\r\n            实现 VGG（牛津视觉几何组）描述符的类使用“使用凸优化的描述符学习”（DLCO）设备端到端地训练\r\n            \r\n","True if the GPU module is targeted for the specific BIN version.":"如果 GPU 模块针对特定 BIN 版本，则为真。\r\n","The approximate size of a box that contains the specified text":"包含指定文本的框的近似大小\r\n","\r\n            Create a convolution kernel using the specific floating point matrix\r\n            ":"\r\n            使用特定的浮点矩阵创建卷积核\r\n            \r\n","Disparity map of the left view, 1 channel, CV_16S type. Implicitly assumes that disparity values are scaled by 16 (one-pixel disparity corresponds to the value of 16 in the disparity map). Disparity map can have any resolution, it will be automatically resized to fit left_view resolution.":"左视图视差图，1通道，CV_16S型。隐式假设视差值按 16 缩放（一个像素视差对应视差图中的值 16）。视差图可以有任何分辨率，它会自动调整大小以适应 left_view 分辨率。\r\n","\r\n            The size of CvSize\r\n            ":"\r\n            CvSize 的大小\r\n            \r\n","\r\n            Block Mean Hash mode\r\n            ":"\r\n            块均值哈希模式\r\n            \r\n","\r\n            H264_SVC\r\n            ":"\r\n            H264_SVC\r\n            \r\n","the hash code":"哈希码\r\n","The points to be rotated":"要旋转的点\r\n","\r\n            The MCvScalar representation of the color intensity\r\n            ":"\r\n            颜色强度的 MCvScalar 表示\r\n            \r\n","\r\n            Hint buffer grid size is 2x2.\r\n            ":"\r\n            提示缓冲区网格大小为 2x2。\r\n            \r\n","The factor applied to modulate the meanLuminance information (default is 1, see reference paper)":"用于调制平均亮度信息的因子（默认为 1，参见参考文献）\r\n","The minimum x,y,z values":"最小 x、y、z 值\r\n","How many positives the sample must get before it will be considered as a possible replacement.":"在将其视为可能的替代品之前，样品必须获得多少阳性结果。\r\n","Standard deviation of the gaussian envelope.":"高斯包络的标准差。\r\n","\r\n            Numeric\r\n            ":"\r\n            数字\r\n            \r\n","\r\n            Create a triangle using the specific vertices\r\n            ":"\r\n            使用特定顶点创建三角形\r\n            \r\n","\r\n            The blue color\r\n            ":"\r\n            蓝色\r\n            \r\n","\r\n            Create a file download manager\r\n            ":"\r\n            创建文件下载管理器\r\n            \r\n","\r\n            The three modes for filtering 2D signals in the article.\r\n            ":"\r\n            文章中用于过滤 2D 信号的三种模式。\r\n            \r\n","\r\n            Returns the result of each individual tree in the forest.\r\n            In case the model is a regression problem, the method will return each of the trees'\r\n            results for each of the sample cases.If the model is a classifier, it will return\r\n            a Mat with samples + 1 rows, where the first row gives the class number and the\r\n            following rows return the votes each class had for each sample.\r\n            ":"\r\n            返回森林中每棵树的结果。\r\n            如果模型是回归问题，该方法将返回每棵树的\r\n            每个样本案例的结果。如果模型是分类器，它将返回\r\n            带有样本 + 1 行的垫子，其中第一行给出类号和\r\n            以下行返回每个班级对每个样本的投票。\r\n            \r\n","\r\n            Wrapped class of the C++ standard vector of GpuMat.\r\n            ":"\r\n            GpuMat 的 C++ 标准向量的包装类。\r\n            \r\n","Minimum size":"最小尺寸\r\n","\r\n            The base class for algorithms that align images of the same scene with different exposures\r\n            ":"\r\n            将同一场景的图像与不同曝光对齐的算法的基类\r\n            \r\n","Desired depth of the integral image of squared pixel values, CV_32F or CV_64F.":"平方像素值 CV_32F 或 CV_64F 的积分图像的所需深度。\r\n","Result of the dilation":"扩张的结果\r\n","\r\n            Automatic bandwidth calculation,\r\n            ":"\r\n            自动带宽计算，\r\n            \r\n","\r\n            Add a file to download\r\n            ":"\r\n            添加要下载的文件\r\n            \r\n","The multiplication scale":"乘法尺度\r\n","\r\n            SeparableLinearFilter\r\n            ":"\r\n            可分离线性滤波器\r\n            \r\n","Size of distance transform mask; can be 3 or 5.\r\n            In case of CV_DIST_L1 or CV_DIST_C the parameter is forced to 3, because 3x3 mask gives the same result as 5x5 yet it is faster.":"距离变换掩码的大小；可以是 3 或 5。\r\n            在 CV_DIST_L1 或 CV_DIST_C 的情况下，参数被强制为 3，因为 3x3 掩码给出与 5x5 相同的结果但它更快。\r\n","Arrays of data":"数据数组\r\n","block height":"区块高度\r\n","Search radius (used to restrict the ROI)":"搜索半径（用于限制ROI）\r\n","\r\n            number of rows\r\n            ":"\r\n            行数\r\n            \r\n","Optional vector of distortion coefficients (k1,k2,p1,p2[,k3[,k4,k5,k6],[s1,s2,s3,s4]]) of 4, 5, 8 or 12 elements":"4、5、8 或 12 个元素的可选失真系数向量 (k1,k2,p1,p2[,k3[,k4,k5,k6],[s1,s2,s3,s4]])\r\n","\r\n            image width in pixels \r\n            ":"\r\n            以像素为单位的图像宽度\r\n            \r\n","The pattern images acquired by the camera, stored in a grayscale VectorOfMat.":"相机获取的图案图像，存储在灰度 VectorOfMat 中。\r\n","The destination estimated covariance matrix. Output matrix will be size (windowRows*windowCols, windowRows*windowCols).":"目的地估计的协方差矩阵。输出矩阵的大小为 (windowRows*windowCols, windowRows*windowCols)。\r\n","\r\n            The detect result\r\n            ":"\r\n            检测结果\r\n            \r\n","\r\n            Override eeprom\r\n            ":"\r\n            覆盖eeprom\r\n            \r\n","Input array. Must have a single channel":"输入数组。必须有一个单一的渠道\r\n","\r\n            Bad depth\r\n            ":"\r\n            深度不好\r\n            \r\n","\r\n            Create the Contrast Limited Adaptive Histogram Equalization\r\n            ":"\r\n            创建对比度受限自适应直方图均衡\r\n            \r\n","Destination back projection array that is a single-channel array of the same size and depth as images[0] .":"目标反投影数组，它是与 images[0] 具有相同大小和深度的单通道数组。\r\n","The destination array, should be the same type as the source":"目标数组，应与源数组类型相同\r\n","Circumscribed box for the object, contains object size and orientation":"对象的外接框，包含对象大小和方向\r\n","New number of columns.":"新的列数。\r\n","The linear interpolated quaternions":"线性插值四元数\r\n","\r\n            Pointer to the DenseOpticalFlow object\r\n            ":"\r\n            指向 DenseOpticalFlow 对象的指针\r\n            \r\n","The local size":"局部尺寸\r\n","Size of video frames.":"视频帧的大小。\r\n","\r\n            StdVectorMat\r\n            ":"\r\n            标准矢量垫\r\n            \r\n","The data will be read in trunk of this size internally. Can be use to seed up the file read. A good number will be 4096":"内部将在这种大小的主干中读取数据。可用于为读取的文件设置种子。一个好的数字将是 4096\r\n","\r\n            Finds the k best matches for each descriptor from a query set (asynchronous version).\r\n            ":"\r\n            从查询集中（异步版本）为每个描述符找到 k 个最佳匹配项。\r\n            \r\n","\r\n            The dispose function that implements IDisposable interface\r\n            ":"\r\n            实现 IDisposable 接口的 dispose 函数\r\n            \r\n","Input floating-point CV_32FC1 matrix (1xN) of magnitudes of 2D vectors":"二维向量大小的输入浮点 CV_32FC1 矩阵 (1xN)\r\n","the index of the column to be reterived":"要检索的列的索引\r\n","\r\n            Sparse sequence (or set) subtypes \r\n            ":"\r\n            稀疏序列（或集合）子类型\r\n            \r\n","\r\n            Get the number of descriptors\r\n            ":"\r\n            获取描述符的数量\r\n            \r\n","Depth of output blob. Choose CV_32F or CV_8U.":"输出 blob 的深度。选择 CV_32F 或 CV_8U。\r\n","\r\n            Release the unmanaged resource associated with this class\r\n            ":"\r\n            释放与此类关联的非托管资源\r\n            \r\n","\r\n            Release the unmanaged memory associated with this tracker\r\n            ":"\r\n            释放与此跟踪器关联的非托管内存\r\n            \r\n","\r\n            Find the approximate nearest position in 3D\r\n            ":"\r\n            在 3D 中找到近似最近的位置\r\n            \r\n","True if the GPU module is targeted for equal or greater BIN version.":"如果 GPU 模块的目标是相同或更高的 BIN 版本，则为真。\r\n","\r\n            Exposure compensator which tries to remove exposure related artifacts by adjusting image block intensities\r\n            ":"\r\n            曝光补偿器，它试图通过调整图像块强度来消除与曝光相关的伪影\r\n            \r\n","Buffer to store detected objects (rectangles).":"用于存储检测到的对象（矩形）的缓冲区。\r\n","\r\n            Initialize with one of predefined kernels\r\n            ":"\r\n            使用预定义内核之一进行初始化\r\n            \r\n","Stream for the asynchronous version.":"异步版本的流。\r\n","The mat to be subtracted from.":"要从中减去的垫子。\r\n","\r\n            Creates TonemapDrago object.\r\n            ":"\r\n            创建 TonemapDrago 对象。\r\n            \r\n","Projector's width.":"投影仪的宽度。\r\n","\r\n            Create a Dictionary using predefined values\r\n            ":"\r\n            使用预定义值创建字典\r\n            \r\n","\r\n            Premul\r\n            ":"\r\n            前乳\r\n            \r\n","\r\n            Acquisition buffer size in buffer_size_unit. Default bytes.\r\n            ":"\r\n            buffer_size_unit 中的采集缓冲区大小。默认字节。\r\n            \r\n","\r\n            Returns color filter array type of RAW data.\r\n            ":"\r\n            返回 RAW 数据的滤色器数组类型。\r\n            \r\n","\r\n            A description of the error\r\n            ":"\r\n            错误描述\r\n            \r\n","\r\n            Constructs repositioned planar cone.\r\n            ":"\r\n            构造重新定位的平面锥体。\r\n            \r\n","\r\n            Interpolate position of ChArUco board corners\r\n            ":"\r\n            ChArUco 板角的插值位置\r\n            \r\n","\r\n            Performs forward or inverse transform of 1D or 2D floating-point array\r\n            In case of real (single-channel) data, the packed format, borrowed from IPL, is used to to represent a result of forward Fourier transform or input for inverse Fourier transform\r\n            ":"\r\n            执行一维或二维浮点数组的正向或反向变换\r\n            在真实（单通道）数据的情况下，从 IPL 借用的打包格式用于表示正向傅立叶变换的结果或反向傅立叶变换的输入\r\n            \r\n","\tAmount of time in milliseconds for the event loop to keep running.":"事件循环保持运行的时间量（以毫秒为单位）。\r\n","\r\n            OpenNI map generators\r\n            ":"\r\n            OpenNI 地图生成器\r\n            \r\n","\r\n            Create a new gain compensator\r\n            ":"\r\n            创建一个新的增益补偿器\r\n            \r\n","\r\n            Parameter specifying how many neighbors each candidate rectangle should have to retain it\r\n            ":"\r\n            指定每个候选矩形应该保留多少个邻居的参数\r\n            \r\n","Number of channels in the destination image. If the parameter is 0, the number of the channels is derived automatically from src and the code .":"目标图像中的通道数。如果参数为 0，通道数自动从 src 和 code 导出。\r\n","The image to be added":"要添加的图像\r\n","\r\n            Vertical offset from the origin to the area of interest (in pixels).\r\n            ":"\r\n            从原点到感兴趣区域的垂直偏移（以像素为单位）。\r\n            \r\n","The display color for each channel":"每个通道的显示颜色\r\n","\r\n            Convert RGBA color to BGRA color\r\n            ":"\r\n            将 RGBA 颜色转换为 BGRA 颜色\r\n            \r\n","\r\n            Get general purpose level\r\n            ":"\r\n            获得通用级别\r\n            \r\n","\r\n            Performs up-sampling step of Gaussian pyramid decomposition. \r\n            First it up-samples ":"\r\n            执行高斯金字塔分解的上采样步骤。\r\n            首先它向上采样\r\n","Destination spectrum.":"目标频谱。\r\n","\r\n            If CVFolds greater than 1 then algorithms prunes the built decision tree using K-fold\r\n            ":"\r\n            如果 CVFolds 大于 1，则算法使用 K-fold 修剪构建的决策树\r\n            \r\n","\r\n            The number of bounding boxes to preserve from top rank based on score\r\n            ":"\r\n            根据分数从最高排名保留的边界框数量\r\n            \r\n","\r\n            Intelperc Depth Saturation Value\r\n            ":"\r\n            Intelperc 深度饱和值\r\n            \r\n","The second output map.":"第二张输出图。\r\n","Initial search window":"初始搜索窗口\r\n"," \r\n            Perform an binary OR operation with some scalar\r\n            ":" \r\n            用一些标量执行二元或运算\r\n            \r\n","Block matching threshold for the second step of BM3D (Wiener filtering), i.e. maximum distance for which two blocks are considered similar. Value expressed in euclidean distance.":"BM3D（维纳滤波）第二步的块匹配阈值，即两个块被认为相似的最大距离。以欧氏距离表示的值。\r\n","Kaiser alpha":"凯撒阿尔法\r\n","\r\n            Create index for 3D points\r\n            ":"\r\n            为 3D 点创建索引\r\n            \r\n","\r\n            Cuda compute 1.3\r\n            ":"\r\n            Cuda 计算 1.3\r\n            \r\n","interpolated chessboard corners":"内插棋盘角\r\n"," Sometimes the background image can be very blurry, as it contain the average background statistics.":" 有时背景图像可能非常模糊，因为它包含平均背景统计信息。\r\n","\r\n            Converts polar coordinates to Cartesian\r\n            ":"\r\n            将极坐标转换为笛卡尔坐标\r\n            \r\n","\r\n            Release the unmanaged resource associated with this ChArUco board\r\n            ":"\r\n            释放与此 ChArUco 板关联的非托管资源\r\n            \r\n","\r\n            Compare two images, returns true if the each of the pixels are equal, false otherwise\r\n            ":"\r\n            比较两个图像，如果每个像素相等则返回 true，否则返回 false\r\n            \r\n","\r\n            Point falls onto the edge\r\n            ":"\r\n            点落在边缘\r\n            \r\n","The size of the frame":"相框尺寸\r\n","Prototxt file path for the super resolution model":"超分辨率模型的 Prototxt 文件路径\r\n","A point on the line.":"线上的一个点。\r\n","Determines the size of the axes.":"确定轴的大小。\r\n","Number of iterations. Higher number improves the result.":"迭代次数。较高的数字会改善结果。\r\n","\r\n            Creates 4-dimensional blob from series of images. Optionally resizes and crops images from center, subtract mean values, scales values by scale factor, swap Blue and Red channels.\r\n            ":"\r\n            从一系列图像创建 4 维 blob。可选地从中心调整大小和裁剪图像，减去平均值，按比例因子缩放值，交换蓝色和红色通道。\r\n            \r\n","The matrix plus the value":"矩阵加上值\r\n"," The standard deviation of the Gaussian kernel in the vertical dimension":" 高斯核在垂直维度的标准差\r\n","\r\n            Get the data as OutputArray\r\n            ":"\r\n            获取数据作为 OutputArray\r\n            \r\n","rotation around z-axis (yaw) in radian":"以弧度为单位绕 z 轴旋转（偏航）\r\n","Number of fractional bits in the point coordinates":"点坐标中的小数位数\r\n"," \r\n            Compute the element of a new image based on the value as well as the x and y positions of each pixel on the image\r\n            ":" \r\n            根据值以及图像上每个像素的 x 和 y 位置计算新图像的元素\r\n            \r\n","\r\n            Creates video reader.\r\n            ":"\r\n            创建视频阅读器。\r\n            \r\n","true if the saliency map is computed, false otherwise":"如果计算了显着图，则为 true，否则为 false\r\n","\r\n            Confidence Threshold\r\n            ":"\r\n            置信阈值\r\n            \r\n","\r\n            Back trace\r\n            ":"\r\n            回溯\r\n            \r\n","\r\n            Convert BGR565 color to BGR color\r\n            ":"\r\n            将 BGR565 颜色转换为 BGR 颜色\r\n            \r\n","Destination array of the same size and same type as the source":"与源相同大小和相同类型的目标数组\r\n","Optional depth type of the output array":"输出数组的可选深度类型\r\n","\r\n            Convert BGR565 color to BGRA color\r\n            ":"\r\n            将 BGR565 颜色转换为 BGRA 颜色\r\n            \r\n","Container where data reads will be returned.":"将返回数据读取的容器。\r\n","\r\n            Set the warper creator for this stitcher.\r\n            ":"\r\n            为这个缝合器设置 warper creator。\r\n            \r\n","The line number in the souce where error is encountered":"souce中遇到错误的行号\r\n","\r\n            Uniform\r\n            ":"制服\r\n            \r\n","The value of the border.":"边界值。\r\n","Width of the marker borders.":"标记边框的宽度。\r\n","\r\n            Pointer to the native SeamFinder object.\r\n            ":"\r\n            指向本机 SeamFinder 对象的指针。\r\n            \r\n","The coordinates detected are approximate, and to determine their position more accurately, the user may use the function cvFindCornerSubPix":"检测到的坐标是近似的，为了更准确地确定它们的位置，用户可以使用函数 cvFindCornerSubPix\r\n","Number of histogram bins":"直方图箱数\r\n","\r\n            OpenCL\r\n            ":"\r\n            OpenCL\r\n            \r\n","If true, it will enforce \"C\" locale during the initialization.":"如果为真，它将在初始化期间强制执行“C”语言环境。\r\n","Encoding of the file. Note that UTF-16 XML encoding is not supported currently and\r\n            you should use 8-bit encoding instead of it.":"文件的编码。请注意，目前不支持 UTF-16 XML 编码，并且\r\n            你应该使用 8 位编码而不是它。\r\n","\r\n            for LMedS algorithm. N >= 8\r\n            ":"\r\n            对于 LMedS 算法。 N >= 8\r\n            \r\n","\r\n            Erodes an image by using a specific structuring element\r\n            ":"\r\n            使用特定的结构元素侵蚀图像\r\n            \r\n","\r\n            The function calculates the ellipse that fits a set of 2D points. The Direct least square (Direct) method by [58] is used.\r\n            ":"\r\n            该函数计算适合一组二维点的椭圆。使用[58]的直接最小二乘法（Direct）。\r\n            \r\n","\r\n            Returns true if the Algorithm is empty. e.g. in the very beginning or after unsuccessful read.\r\n            ":"\r\n            如果算法为空，则返回真。例如在一开始或阅读失败后。\r\n            \r\n","The sparse optical flow":"稀疏光流\r\n","Maximum number of output circles.":"最大输出圈数。\r\n","Ellipse color":"椭圆颜色\r\n","\r\n            Get the pointer to the Widget obj\r\n            ":"\r\n            获取指向 Widget obj 的指针\r\n            \r\n","\r\n            Create a default EM model\r\n            ":"\r\n            创建默认 EM 模型\r\n            \r\n","\r\n            Returns 1 for color cameras.\r\n            ":"\r\n            对于彩色相机返回 1。\r\n            \r\n","The read mode":"阅读模式\r\n","Assigned scalar converted to the actual array type.":"分配的标量转换为实际数组类型。\r\n","The weight for ":"重量为\r\n","New title.":"新标题。\r\n","\r\n            Get the corresponding depth type\r\n            ":"\r\n            获取对应的深度类型\r\n            \r\n","Optional writer properties. e.g. new Tuple<VideoWriter.WriterProperty>(VideoWriter.WriterProperty.HwAcceleration, (int) VideoAccelerationType.Any)":"可选的编写器属性。例如新元组<VideoWriter.WriterProperty>(VideoWriter.WriterProperty.HwAcceleration, (int) VideoAccelerationType.Any)\r\n","Input array":"输入数组\r\n","True if two boxes are equal":"如果两个框相等则为真\r\n","\r\n            Color Correction Matrix element [1][2]\r\n            ":"\r\n            颜色校正矩阵元素 [1][2]\r\n            \r\n","Anchor position with the kernel. Negative values mean that the anchor is at the kernel center.":"与内核的锚定位置。负值表示锚点位于内核中心。\r\n","\r\n            One of the rectangle is fully enclosed in the other\r\n            ":"\r\n            其中一个矩形完全包围在另一个矩形中\r\n            \r\n","Threshold on difference between intensity of center pixel and pixels on circle around\r\n            this pixel. Use 10 for default.":"中心像素强度与周围像素强度差异的阈值\r\n            这个像素。默认使用 10。\r\n","The depth type of ":"的深度类型\r\n","\r\n            Execute a computation with arbitrary number of inputs/outputs (with compilation on-the-fly).\r\n            ":"\r\n            使用任意数量的输入/输出执行计算（即时编译）。\r\n            \r\n","Range from 0 to 100.":"范围从 0 到 100。\r\n","z-coordinate":"z坐标\r\n","\r\n            Class implementing BoostDesc (Learning Image Descriptors with Boosting).\r\n            ":"\r\n            实现 BoostDesc 的类（使用提升学习图像描述符）。\r\n            \r\n","\r\n            Convert YUV (VYUY) to BGRA\r\n            ":"\r\n            将 YUV (VYUY) 转换成 BGRA\r\n            \r\n","The color for the match correspondence lines":"匹配对应线的颜色\r\n","Aperture parameter for Sobel operator, use 3 for default":"Sobel算子的孔径参数，默认为3\r\n","The descriptor vector":"描述符向量\r\n","\r\n            Execute a binary computation (with compilation on the fly)\r\n            ":"\r\n            执行二进制计算（即时编译）\r\n            \r\n","\r\n            Create a GpuMat of the specified size. The allocated data is continuous within this GpuMat.\r\n            ":"\r\n            创建指定大小的 GpuMat。分配的数据在这个 GpuMat 中是连续的。\r\n            \r\n","Fast threshold":"快门槛\r\n","Specify keypoints data list to be written.":"指定要写入的关键点数据列表。\r\n","\r\n            Get the histograms\r\n            ":"\r\n            获取直方图\r\n            \r\n","\r\n            Create a convolution kernel using the specific matrix and center\r\n            ":"\r\n            使用特定矩阵和中心创建卷积核\r\n            \r\n","\r\n            Summer\r\n            ":"\r\n            夏天\r\n            \r\n","\r\n            The recognized text\r\n            ":"\r\n            识别的文本\r\n            \r\n","\r\n            Polynomial fitting channels respectively; Need assign a value to deg simultaneously\r\n            ":"\r\n            多项式分别拟合通道；需要同时给deg赋值\r\n            \r\n","\r\n            Creates a vertical or horizontal Scharr operator.\r\n            ":"\r\n            创建垂直或水平 Scharr 运算符。\r\n            \r\n","The result of a - b":"a - b 的结果\r\n","\r\n            Switch to Laplacian Zero-Crossing edge feature extractor and specify its parameters. This feature extractor is used by default according to article. Implementation has additional filtering for regions with low-amplitude noise. This filtering is enabled through parameter of minimal gradient amplitude (use some small value 4, 8, 16).\r\n            ":"\r\n            切换到拉普拉斯零交叉边缘特征提取器并指定其参数。根据文章，默认使用此特征提取器。实现对具有低幅度噪声的区域进行了额外的过滤。此过滤是通过最小梯度振幅参数启用的（使用一些小值 4、8、16）。\r\n            \r\n","The preferred DNN target":"首选 DNN 目标\r\n","second input image of the same size and the same type as ":"相同大小和相同类型的第二个输入图像\r\n","\r\n            White balance blue coefficient\r\n            ":"\r\n            白平衡蓝色系数\r\n            \r\n"," Returns the transpose of this matrix":" 返回此矩阵的转置\r\n","\r\n            Exposure compensator which tries to remove exposure related artifacts by adjusting image intensities\r\n            ":"\r\n            曝光补偿器，它试图通过调整图像强度来消除与曝光相关的伪影\r\n            \r\n","\r\n            iOS device focus\r\n            ":"\r\n            iOS 设备焦点\r\n            \r\n","\r\n            (|I1-I2|+sigma)^-1\r\n            ":"\r\n            (|I1-I2|+西格玛)^-1\r\n            \r\n","\r\n            Descriptors are normalized for L2 norm equal to 1.0\r\n            ":"\r\n            描述符针对等于 1.0 的 L2 范数进行归一化\r\n            \r\n","\r\n            This class wraps the functional calls to the OpenCV Text modules\r\n            ":"\r\n            此类包装了对 OpenCV 文本模块的功能调用\r\n            \r\n","\r\n            Find corresponding image locations by searching for a maximal sobel edge along the search line (a single row in the bundle)\r\n            ":"\r\n            通过沿搜索线（束中的单行）搜索最大索贝尔边缘来找到相应的图像位置\r\n            \r\n","\r\n            The line number in the souce where error is encountered\r\n            ":"\r\n            souce中遇到错误的行号\r\n            \r\n","\r\n            Calculates a contour perimeter or a curve length\r\n            ":"\r\n            计算轮廓周长或曲线长度\r\n            \r\n","Clip Limit, use 40 for default":"Clip Limit，默认使用40\r\n","A set of corresponding confidences.":"一组相应的置信度。\r\n","Method for computing a fundamental matrix. RANSAC for the RANSAC algorithm. LMEDS for the LMedS algorithm":"计算基本矩阵的方法。 RANSAC为RANSAC算法。 LMedS 算法的 LMEDS\r\n","Image is divided by dynRatio before histogram processing":"图像在直方图处理之前除以 dynRatio\r\n","Accumulation flag. If it is set, the histogram is not cleared in the beginning when it is allocated. This feature enables you to compute a single histogram from several sets of arrays, or to update the histogram in time.":"累积标志。如果设置，直方图在分配时不会在开始时被清除。此功能使您能够从多组数组计算单个直方图，或及时更新直方图。\r\n","Convex hull obtained using ConvexHull that should contain pointers or indices to the contour points, not the hull points themselves, i.e. return_points parameter in cvConvexHull2 should be 0":"使用 ConvexHull 获得的凸包应包含指向轮廓点的指针或索引，而不是包点本身，即 cvConvexHull2 中的 return_points 参数应为 0\r\n","New number of rows. new_rows = 0 means that number of rows remains unchanged unless it needs to be changed according to new_cn value. destination array to be changed":"新的行数。 new_rows = 0 表示行数保持不变，除非需要根据new_cn值改变。要更改的目标数组\r\n","rotation vector of the coordinate system that will be drawn.":"将绘制的坐标系的旋转矢量。\r\n","The normalized point":"归一化点\r\n","Number of frames used to initialize the background models.":"用于初始化背景模型的帧数。\r\n","\r\n            NN Engine\r\n            ":"\r\n            神经网络引擎\r\n            \r\n","Array of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel, where N is the number of points. VectorOfPoint2f can also be passed here.":"相应图像点的数组，Nx2 1 通道或 1xN/Nx1 2 通道，其中 N 是点数。这里也可以传VectorOfPoint2f。\r\n","\r\n            Given an input bgr or grayscale image, apply autoscaling on domain [0, 255] to increase the contrast of the input image and return the resulting image.\r\n            ":"\r\n            给定输入 bgr 或灰度图像，在域 [0, 255] 上应用自动缩放以增加输入图像的对比度并返回结果图像。\r\n            \r\n","\r\n            A raw data storage\r\n            ":"\r\n            原始数据存储\r\n            \r\n","\r\n            Detect all the characters in the image.\r\n            ":"\r\n            检测图像中的所有字符。\r\n            \r\n","\r\n            A simple Hausdorff distance measure between shapes defined by contours, according to the paper “Comparing Images using the Hausdorff distance.” by D.P. Huttenlocher, G.A. Klanderman, and W.J. Rucklidge. (PAMI 1993).\r\n            ":"\r\n            根据论文“使用 Hausdorff 距离比较图像”，由轮廓定义的形状之间的简单 Hausdorff 距离度量。由 D.P. G.A.哈滕洛彻克兰德曼和 W.J.拉克利奇。 (PAMI 1993)。\r\n            \r\n","\r\n            What Gaussian blur should be applied to the segmented image (used for quad detection?)\r\n            Parameter is the standard deviation in pixels.Very noisy images benefit from non-zero values(e.g. 0.8).\r\n            ":"\r\n            应该对分割图像应用什么高斯模糊（用于四边形检测？）\r\n            参数是以像素为单位的标准偏差。非常嘈杂的图像受益于非零值（例如 0.8）。\r\n            \r\n","\r\n            Convert Bayer GRBG to BGRA \r\n            ":"\r\n            将拜耳 GRBG 转换为 BGRA\r\n            \r\n","Size of the image":"图片大小\r\n","\r\n            Spatial Moment M12\r\n            ":"\r\n            空间矩M12\r\n            \r\n","\r\n            Variable type\r\n            ":"\r\n            变量类型\r\n            \r\n","Source GpuMat":"来源 GpuMat\r\n","\r\n            Bad function\r\n            ":"\r\n            坏功能\r\n            \r\n","\r\n            Create a empty OclProgram object\r\n            ":"创建一个空的 OclProgram 对象\r\n            \r\n","\r\n            Descriptors are normalized for L2 norm equal to 1.0 but no individual one is bigger than 0.154 as in SIFT\r\n            ":"\r\n            描述符针对等于 1.0 的 L2 范数进行归一化，但没有一个像 SIFT 中那样大于 0.154\r\n            \r\n","\r\n            The size of CvRect\r\n            ":"\r\n            CvRect 的大小\r\n            \r\n","The optional output \"class label\" (indices of the most probable mixture component for each sample). It has nsamples x 1 size and CV_32SC1 type.":"可选输出“类别标签”（每个样本最可能的混合物成分的索引）。它有 nsamples x 1 大小和 CV_32SC1 类型。\r\n","\r\n            Computes average hash value of the input image.\r\n            ":"\r\n            计算输入图像的平均哈希值。\r\n            \r\n","\r\n            Brightness of the image (only for those cameras that support).\r\n            ":"\r\n            图像的亮度（仅适用于支持的相机）。\r\n            \r\n","Singular values":"奇异值\r\n","the first byte vector to be merged":"要合并的第一个字节向量\r\n","A transformation.":"一个转变。\r\n","Vector of input Mat objects to process by the computation.":"要由计算处理的输入 Mat 对象的向量。\r\n","Input/Output rotation vector (see Rodrigues ) that, together with tvec, brings points from the model coordinate system to the camera coordinate system. Input values are used as an initial solution.":"输入/输出旋转矢量（参见 Rodrigues ），与 tvec 一起将点从模型坐标系带到相机坐标系。输入值用作初始解决方案。\r\n","\r\n            Normalizes the norm or value range of an array.\r\n            ":"\r\n            规范化数组的范数或值范围。\r\n            \r\n","The optional output matrix that contains a likelihood logarithm value for each sample. It has nsamples x 1 size and CV_64FC1 type.":"包含每个样本的似然对数值的可选输出矩阵。它有 nsamples x 1 大小和 CV_64FC1 类型。\r\n","\r\n            Create a umat header for the specific ROI\r\n            ":"\r\n            为特定的 ROI 创建一个 umat 标头\r\n            \r\n","\r\n            Infinitesimal Plane-Based Pose Estimation. Object points must be coplanar.\r\n            ":"\r\n            基于无穷小平面的姿态估计。物点必须共面。\r\n            \r\n","\r\n            The storage is open for writing\r\n            ":"\r\n            存储打开以供写入\r\n            \r\n","Type of the line:\r\n            8 (or 0) - 8-connected line.\r\n            4 - 4-connected line.\r\n            CV_AA - antialiased line. \r\n            ":"线路类型：\r\n            8（或 0）- 8 连接线。\r\n            4 - 4 连线。\r\n            CV_AA - 抗锯齿线。\r\n            \r\n","256x1 matrix with inverse camera response function":"具有逆相机响应功能的 256x1 矩阵\r\n","\r\n            Creates a CNT Background Subtractor.\r\n            ":"\r\n            创建 CNT 背景减法器。\r\n            \r\n","Aperture size. It should be odd and positive.":"光圈大小。它应该是奇怪的和积极的。\r\n","Specify the hdf5 dataset label. Existing dataset label will cause an error.":"指定 hdf5 数据集标签。现有数据集标签将导致错误。\r\n","The source CudaImage.":"源CudaImage。\r\n","Block matching threshold for the first step of BM3D (hard thresholding), i.e. maximum distance for which two blocks are considered similar. Value expressed in euclidean distance.":"BM3D第一步的块匹配阈值（硬阈值），即两个块被认为相似的最大距离。以欧氏距离表示的值。\r\n"," tokens in each search step, ":" 每个搜索步骤中的标记，\r\n","\r\n            Base interface for MotionSaliency algorithms\r\n            ":"\r\n            MotionSaliency 算法的基础接口\r\n            \r\n"," Elementwise subtract a color from the current image":" Elementwise 从当前图像中减去一种颜色\r\n","\r\n            Calculates fundamental matrix given a set of corresponding points\r\n            ":"\r\n            给定一组对应点计算基本矩阵\r\n            \r\n","\r\n            Back-propagation algorithm\r\n            ":"\r\n            反向传播算法\r\n            \r\n","The checker which will be drawn by this object.":"将由此对象绘制的检查器。\r\n"," Create a circle with the specific center and radius ":" 创建一个具有特定圆心和半径的圆\r\n","The output foreground mask as an 8-bit binary image.":"作为 8 位二进制图像的输出前景掩码。\r\n","Ratio of search lines that could be extracted and matched":"可以提取和匹配的搜索行的比例\r\n","\r\n            detection score\r\n            ":"\r\n            检测分数\r\n            \r\n","System-specific locale identifier. Can be \"\" for the user-preferred locale or \"C\" for the minimal locale":"系统特定的语言环境标识符。可以是用户首选语言环境的“”或最小语言环境的“C”\r\n","\r\n            Delta\r\n            ":"\r\n            三角洲\r\n            \r\n","marker side length (same unit than squareLength)":"标记边长（与 squareLength 单位相同）\r\n","\r\n            Get a subimage which image data is shared with the current image.\r\n            ":"获取与当前图像共享图像数据的子图像。\r\n            \r\n","Interpolation method. Only INTER_NEAREST, INTER_LINEAR, and INTER_CUBIC are supported.":"插值法。仅支持 INTER_NEAREST、INTER_LINEAR 和 INTER_CUBIC。\r\n","\r\n            Discriminative Correlation Filter Tracker with Channel and Spatial Reliability\r\n            ":"\r\n            具有通道和空间可靠性的判别相关滤波器跟踪器\r\n            \r\n","\r\n            The local memory size\r\n            ":"\r\n            本地内存大小\r\n            \r\n","\r\n            Create an empty standard vector of Size\r\n            ":"\r\n            创建大小为空的标准向量\r\n            \r\n","\r\n             Error codes\r\n             ":"\r\n             错误代码\r\n             \r\n","\r\n            Detect keypoints in an image and compute the descriptors on the image from the keypoint locations.\r\n            ":"\r\n            检测图像中的关键点并从关键点位置计算图像上的描述符。\r\n            \r\n","\r\n            Handle exception\r\n            ":"\r\n            处理异常\r\n            \r\n","\r\n            Shadow value is the value used to mark shadows in the foreground mask. Default value is 127. Value 0 in the mask always means background, 255 means foreground.\r\n            ":"\r\n            阴影值是用于在前景蒙版中标记阴影的值。默认值为 127。掩码中的值 0 始终表示背景，255 表示前景。\r\n            \r\n","\r\n            The Cascade Classifier\r\n            ":"\r\n            级联分类器\r\n            \r\n","features":"特征\r\n","\r\n            Thinning technique of Zhang-Suen\r\n            ":"\r\n            张苏恩的间苗技术\r\n            \r\n","\r\n            Log some data\r\n            ":"\r\n            记录一些数据\r\n            \r\n","Optional mean value; if the matrix is empty, the mean is computed from the data.":"可选平均值；如果矩阵为空，则根据数据计算平均值。\r\n","The anchor of the kernel that indicates the relative position of a filtered point within the kernel. The anchor shoud lie within the kernel. The special default value (-1,-1) means that it is at the kernel center":"内核的锚点，指示内核中过滤点的相对位置。锚点应该位于内核中。特殊的默认值(-1,-1)表示在内核中心\r\n","\r\n            simulate the behavior of pre-attentive visual search\r\n            ":"\r\n            模拟前注意视觉搜索的行为\r\n            \r\n","The rectification transformation in object space (3x3 matrix). R1 or R2, computed by cvStereoRectify can be passed here. If the parameter is IntPtr.Zero, the identity matrix is used":"对象空间（3x3 矩阵）中的整流变换。由 cvStereoRectify 计算的 R1 或 R2 可以传递到这里。如果参数为 IntPtr.Zero，则使用单位矩阵\r\n","Minimum number (minus 1) of neighbor rectangles that makes up an object. All the groups of a smaller number of rectangles than min_neighbors-1 are rejected. If min_neighbors is 0, the function does not any grouping at all and returns all the detected candidate rectangles, which may be useful if the user wants to apply a customized grouping procedure. Use 3 for default.":"构成对象的相邻矩形的最小数量（负 1）。所有比 min_neighbors-1 更少的矩形组都被拒绝。如果 min_neighbors 为 0，则该函数根本不进行任何分组并返回所有检测到的候选矩形，如果用户想要应用自定义分组过程，这可能很有用。默认使用 3。\r\n","Input three-channel image in the BGR color space (either CV_8UC3 or CV_16UC3)":"在 BGR 颜色空间中输入三通道图像（CV_8UC3 或 CV_16UC3）\r\n","\r\n            Convert BayerRG to GRAY\r\n            ":"\r\n            将 BayerRG 转换为 GREY\r\n            \r\n","\r\n            Start camera cooling.\r\n            ":"\r\n            开始相机冷却。\r\n            \r\n","\r\n            The grouping method\r\n            ":"\r\n            分组方法\r\n            \r\n","\r\n            Detects objects of different sizes in the input image.\r\n            ":"\r\n            检测输入图像中不同大小的对象。\r\n            \r\n","\r\n            Graph Based Segmentation Algorithm. The class implements the algorithm described in Pedro F Felzenszwalb and Daniel P Huttenlocher. Efficient graph-based image segmentation. volume 59, pages 167 - 181. Springer, 2004.\r\n            ":"\r\n            基于图的分割算法。该类实现了 Pedro F Felzenszwalb 和 Daniel P Huttenlocher 中描述的算法。高效的基于图形的图像分割。第 59 卷，第 167 - 181 页。Springer，2004 年。\r\n            \r\n","\r\n            Converts an image from RGB color space to I420 color space.\r\n            ":"\r\n            将图像从 RGB 颜色空间转换为 I420 颜色空间。\r\n            \r\n","\r\n            Convert YUV (iYUV) to RGB\r\n            ":"\r\n            将 YUV (iYUV) 转换为 RGB\r\n            \r\n","The normals":"法线\r\n","The flag indicating whether the functions quietly return false when the array elements are\r\n            out of range, or they throw an exception":"指示函数是否在数组元素被删除时安静地返回 false 的标志\r\n            超出范围，或者他们抛出异常\r\n",", can be ":"， 可\r\n","Must be > 0 ":"必须 > 0\r\n","Arrays of arrays of the MCvERStat":"MCvERStat 的数组数组\r\n","\r\n            Copies each plane of a multi-channel GpuMat to a dedicated GpuMat\r\n            ":"\r\n            将多通道 GpuMat 的每个平面复制到专用 GpuMat\r\n            \r\n","Pointer to some unmanaged data":"指向一些非托管数据的指针\r\n","Range-level thresholding to a single- or multiple-channel matrix. It sets output pixel value to OxFF if the corresponding pixel value of input matrix is in specified range,or 0 otherwise.":"单通道或多通道矩阵的范围级阈值。如果输入矩阵的相应像素值在指定范围内，则将输出像素值设置为 OxFF，否则为 0。\r\n","The detected line segments":"检测到的线段\r\n","\r\n            Indicates whether the polylines must be drawn closed. \r\n            If !=0, the function draws the line from the last vertex of every contour to the first vertex.\r\n            ":"\r\n            指示是否必须绘制闭合的多段线。\r\n            如果 !=0，函数绘制从每个轮廓的最后一个顶点到第一个顶点的线。\r\n            \r\n","contrast scale factor. HVS response is multiplied by this parameter, thus compressing dynamic range. Values from 0.6 to 0.9 produce best results.":"对比度比例因子。 HVS 响应乘以该参数，从而压缩动态范围。 0.6 到 0.9 之间的值会产生最佳结果。\r\n","\r\n            Base interface for Saliency algorithms\r\n            ":"\r\n            显着性算法的基本接口\r\n            \r\n","The path to the requested model":"请求模型的路径\r\n","Flag to enable the use of normalized channel data types":"启用规范化通道数据类型的标志\r\n","\r\n            A user-defined element.\r\n            ":"\r\n            用户定义的元素。\r\n            \r\n","Font type.":"字体类型。\r\n","Bitwise conjunction of a matrix and a scalar":"矩阵和标量的按位结合\r\n","\r\n            The corresponding error string for the Status code\r\n            ":"\r\n            状态码对应的错误字符串\r\n            \r\n","Optional scale factor for the computed derivative values":"计算导数值的可选比例因子\r\n","Look-up table of 256 elements; should have the same depth as the destination array. In case of multi-channel source and destination arrays, the table should either have a single-channel (in this case the same table is used for all channels), or the same number of channels as the source/destination array":"256个元素的查找表；应该与目标数组具有相同的深度。在多通道源和目标数组的情况下，该表应该有一个单通道（在这种情况下，同一个表用于所有通道），或者与源/目标数组相同数量的通道\r\n","\r\n            Apply Canny Edge Detector follows by Probabilistic Hough transform to find line segments in the image\r\n            ":"\r\n            应用 Canny 边缘检测器，然后通过概率霍夫变换来查找图像中的线段\r\n            \r\n","\r\n            Get the frame meta data\r\n            ":"\r\n            获取框架元数据\r\n            \r\n","The image with the keypoints drawn":"绘制了关键点的图像\r\n","\r\n            Create text detection model from network represented in one of the supported formats.\r\n            ":"\r\n            从以一种受支持的格式表示的网络创建文本检测模型。\r\n            \r\n","Frame rate per second":"每秒帧率\r\n","\r\n            Grayscale\r\n            ":"\r\n            灰阶\r\n            \r\n","\r\n            Get the GpuMat size:\r\n            width == number of columns, height == number of rows\r\n            ":"\r\n            获取 GpuMat 大小：\r\n            宽度==列数，高度==行数\r\n            \r\n","\r\n            The 5th distortion coefficient (k5) is fixed to 0 or to the initial passed value if CV_CALIB_USE_INTRINSIC_GUESS is passed\r\n            ":"\r\n            如果传递 CV_CALIB_USE_INTRINSIC_GUESS，则第 5 个失真系数 (k5) 固定为 0 或初始传递值\r\n            \r\n","\r\n            Computes a dot-product of two vectors.\r\n            ":"\r\n            计算两个向量的点积。\r\n            \r\n","\r\n            Lens current focus movement value to be used by XI_PRM_LENS_FOCUS_MOVE in motor steps.\r\n            ":"\r\n            XI_PRM_LENS_FOCUS_MOVE 在电机步进中使用的镜头当前焦点移动值。\r\n            \r\n","\r\n            GPU feature\r\n            ":"\r\n            显卡功能\r\n            \r\n","\r\n            VP9\r\n            ":"\r\n            VP9\r\n            \r\n","\r\n            Indicates if the linker is available\r\n            ":"\r\n            指示链接器是否可用\r\n            \r\n","The color of points in BGR format ":"BGR 格式的点的颜色\r\n","\r\n            Convert BayerBG to RGB (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 BayerBG 转换为 RGB（边缘感知去马赛克）\r\n            \r\n","The maximum number of results":"最大结果数\r\n","\r\n            A geodetic coordinate that is defined by its latitude, longitude and altitude\r\n            ":"\r\n            由纬度、经度和高度定义的大地坐标\r\n            \r\n","\r\n            The function imreadmulti loads a multi-page image from the specified file into a vector of Mat objects.\r\n            ":"\r\n            函数 imreadmulti 将指定文件中的多页图像加载到 Mat 对象的向量中。\r\n            \r\n","\r\n            BayerGR2BGR_MHT\r\n            ":"\r\n            拜耳GR2BGR_MHT\r\n            \r\n","Scale factor along the vertical axis;":"沿垂直轴的比例因子；\r\n"," Draw a Ellipse of the specific color and thickness ":" 绘制一个特定颜色和粗细的椭圆\r\n","The color type of the image to be written":"要写入的图像的颜色类型\r\n","\r\n            Transforms source image using the specified matrix\r\n            ":"\r\n            使用指定的矩阵转换源图像\r\n            \r\n","A polyline defined by its point":"由其点定义的折线\r\n","The number of channels of this image":"此图像的通道数\r\n","\r\n            Most of OpenCV functions support 1,2,3 or 4 channels \r\n            ":"\r\n            大多数 OpenCV 函数支持 1、2、3 或 4 通道\r\n            \r\n","\r\n            RPROP: Initial value Delta_0 of update-values Delta_{ij}\r\n            ":"\r\n            RPROP：更新值Delta_{ij}的初始值Delta_0\r\n            \r\n","\r\n            Get the detections from the NNet packet\r\n            ":"\r\n            从 NNet 数据包中获取检测结果\r\n            \r\n","\r\n            Creates TonemapMantiuk object\r\n            ":"\r\n            创建 TonemapMantiuk 对象\r\n            \r\n","The file storage to create the classifier from":"从中创建分类器的文件存储\r\n","\r\n            Create an Extremal Region Filter for the 1st stage classifier of N&M algorithm\r\n            ":"\r\n            为 N&M 算法的第一阶段分类器创建一个极值区域过滤器\r\n            \r\n","The first image to apply bitwise OR operation":"第一个应用按位或运算的图像\r\n","\r\n            Input callback\r\n            ":"\r\n            输入回调\r\n            \r\n","\r\n            Ccm type\r\n            ":"\r\n            CCM型\r\n            \r\n","Consider the four posible corner orders in the rejectedCorners array. If it set to false, only the provided corner order is considered (default true).":"考虑 rejectedCorners 数组中的四个可能的角订单。如果设置为 false，则仅考虑提供的角顺序（默认为 true）。\r\n","\r\n            Create a new affine bundler adjuster\r\n            ":"\r\n            创建一个新的仿射捆绑器调整器\r\n            \r\n","\r\n            Create a stereoBM object\r\n            ":"\r\n            创建一个 stereoBM 对象\r\n            \r\n","\r\n            Dict4X4_1000\r\n            ":"\r\n            Dict4X4_1000\r\n            \r\n","The camera matrices [fx_k 0 cx_k; 0 fy_k cy_k; 0 0 1]":"相机矩阵 [fx_k 0 cx_k; 0 fy_k cy_k； 0 0 1]\r\n","if draw the image in the returned Mat. if this parameter is false, then the content of the returned Mat is a matrix of index, describing the region each pixel belongs to. And it's data type is CV_16U. If this parameter is true, then the returned Mat is a segmented picture, and color of each region is the average color of all pixels in that region. And it's data type is the same as the input image":"如果在返回的 Mat 中绘制图像。如果该参数为false，则返回的Mat内容为索引矩阵，描述每个像素所属的区域。它的数据类型是 CV_16U。如果该参数为真，则返回的Mat为分割后的图片，每个区域的颜色为该区域所有像素的平均颜色。并且它的数据类型与输入图像相同\r\n","\r\n            Spaghetti algorithm for 8-way connectivity, Spaghetti4C algorithm for 4-way connectivity. The parallel implementation described is available for both Spaghetti and Spaghetti4C.\r\n            ":"\r\n            8 路连接的 Spaghetti 算法，4 路连接的 Spaghetti4C 算法。描述的并行实现可用于 Spaghetti 和 Spaghetti4C。\r\n            \r\n","number of rows (CvSize::height) and number of columns (CvSize::width) of the input matrix or image. In case of image the size of ROI is returned.":"输入矩阵或图像的行数 (CvSize::height) 和列数 (CvSize::width)。在图像的情况下，返回 ROI 的大小。\r\n","\r\n            The options for generic parameters\r\n            ":"\r\n            通用参数的选项\r\n            \r\n","The second coordinate to be added":"要添加的第二个坐标\r\n","The names of opencv modules. e.g. \"opencv_core.dll\" on windows.":"opencv 模块的名称。例如Windows 上的“opencv_core.dll”。\r\n","Default number of sublevels per scale level":"每个比例级别的默认子级别数\r\n","If != 0, the function estimates distance from the point to the nearest contour edge":"如果 != 0，函数估计点到最近轮廓边缘的距离\r\n","\r\n            Get the equivalent of CV_WHOLE_SEQ\r\n            ":"\r\n            得到 CV_WHOLE_SEQ 的等价物\r\n            \r\n","Flag which indicates that swap first and last channels.":"指示交换第一个和最后一个通道的标志。\r\n","\r\n            Implement this interface if the object can output code to generate it self.\r\n            ":"\r\n            如果对象可以输出代码以自行生成它，则实现此接口。\r\n            \r\n","\r\n            Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently).\r\n            ":"\r\n            立体相机的校正标志（注意：目前仅 DC1394 v 2.x 后端支持）。\r\n            \r\n","Output parameter set by the function to the minimum bounding rectangle of the repainted domain.":"函数设置的输出参数为重绘域的最小边界矩形。\r\n","\r\n            Mode of color management system.\r\n            ":"\r\n            色彩管理系统模式。\r\n            \r\n","Type of the line segments, see cvLine description":"线段的类型，参见 cvLine 描述\r\n"," \r\n            Compute the complement image\r\n            ":" \r\n            计算补图\r\n            \r\n","The source matrix in the RHS":"RHS 中的源矩阵\r\n","Second frame, at time t + dt .":"第二帧，时间 t + dt 。\r\n","A clone of the Matrix":"矩阵的克隆\r\n","Optional delta value that is added to the results prior to storing them in ":"在将结果存储在之前添加到结果中的可选增量值\r\n"," The center of this circle ":" 这个圆的中心\r\n","Number of bins between 0 and \"histThresh\". Default value is 10.":"0 和“histThresh”之间的箱数。默认值为 10。\r\n","The prediction label":"预测标签\r\n","\r\n            Release all unmanaged resources associated with this blender\r\n            ":"\r\n            释放与此搅拌机关联的所有非托管资源\r\n            \r\n","The lower values stored in an image of same type & size as ":"较低的值存储在与以下类型和大小相同的图像中\r\n","\r\n            Set every pixel of the image to the specific color \r\n            ":"\r\n            将图像的每个像素设置为特定颜色\r\n            \r\n","\r\n            Convert YUV420sp to RGBA\r\n            ":"\r\n            将 YUV420sp 转换为 RGBA\r\n            \r\n","The matrix to be substracted":"要减去的矩阵\r\n","\r\n            Flag used for cvDFT\r\n            ":"\r\n            用于 cvDFT 的标志\r\n            \r\n"," \r\n            Performs a convolution using the specific ":" \r\n            使用特定的执行卷积\r\n","\r\n            Save the algorithm to a string\r\n            ":"\r\n            将算法保存为字符串\r\n            \r\n","The average color of the image":"图像的平均颜色\r\n"," times bigger":" 大倍\r\n","\r\n            Treat the image as a single character.\r\n            ":"\r\n            将图像视为单个字符。\r\n            \r\n","\r\n            Convert Bayer BG to BGRA \r\n            ":"\r\n            将 Bayer BG 转换为 BGRA\r\n            \r\n","\r\n            The SGBM mode\r\n            ":"\r\n            SGBM模式\r\n            \r\n","Segmentation threshold; recommended to be equal to the interval between motion history \"steps\" or greater":"分割阈值；建议等于运动历史“步骤”之间的间隔或更大\r\n","The sigma parameter, used to smooth image":"sigma 参数，用于平滑图像\r\n","\r\n            Smartek Giganetix Ethernet Vision: frame sens width\r\n            ":"Smartek Giganetix Ethernet Vision：帧传感宽度\r\n            \r\n","\r\n            AVFoundation framework for iOS (OS X Lion will have the same API)\r\n            ":"\r\n            适用于 iOS 的 AVFoundation 框架（OS X Lion 将具有相同的 API）\r\n            \r\n","\r\n            Computes Signature Quadratic Form Distance of two signatures.\r\n            ":"\r\n            计算两个签名的签名二次型距离。\r\n            \r\n","  \r\n            pointer to element of other sequence \r\n            ":"  \r\n            指向其他序列元素的指针\r\n            \r\n","\r\n            Flood fill type\r\n            ":"\r\n            洪水填充类型\r\n            \r\n","\r\n            The function calculates the ellipse that fits a set of 2D points. The Approximate Mean Square (AMS) is used.\r\n            ":"\r\n            该函数计算适合一组二维点的椭圆。使用近似均方 (AMS)。\r\n            \r\n","Histogram Lr":"直方图\r\n","The maximum number of robust method iterations.":"稳健方法迭代的最大次数。\r\n","\r\n            Use next point list as initial values. A good initialization can improve the algorithm accuracy and reduce the runtime by a faster convergence of the iteration refinement\r\n            ":"\r\n            使用下一个点列表作为初始值。良好的初始化可以提高算法的准确性，并通过迭代细化的更快收敛来减少运行时间\r\n            \r\n","\r\n            The following patents have been issued for methods embodied in this software: \"Recognition and pose determination of 3D objects in 3D scenes using geometric point pair descriptors and the generalized Hough Transform\", Bertram Heinrich Drost, Markus Ulrich, EP Patent 2385483 (Nov. 21, 2012), assignee: MVTec Software GmbH, 81675 Muenchen (Germany); \"Recognition and pose determination of 3D objects in 3D scenes\", Bertram Heinrich Drost, Markus Ulrich, US Patent 8830229 (Sept. 9, 2014), assignee: MVTec Software GmbH, 81675 Muenchen (Germany). Further patents are pending. For further details, contact MVTec Software GmbH (info@mvtec.com).\r\n            Note that restrictions imposed by these patents(and possibly others) exist independently of and may be in conflict with the freedoms granted in this license, which refers to copyright of the program, not patents for any methods that it implements.Both copyright and patent law must be obeyed to legally use and redistribute this program and it is not the purpose of this license to induce you to infringe any patents or other property right claims or to contest validity of any such claims.If you redistribute or use the program, then this license merely protects you from committing copyright infringement. It does not protect you from committing patent infringement.So, before you do anything with this program, make sure that you have permission to do so not merely in terms of copyright, but also in terms of patent law.\r\n            Please note that this license is not to be understood as a guarantee either.If you use the program according to this license, but in conflict with patent law, it does not mean that the licensor will refund you for any losses that you incur if you are sued for your patent infringement.\r\n            ":"\r\n            该软件中体现的方法已获得以下专利：“使用几何点对描述符和广义霍夫变换识别和确定 3D 场景中的 3D 对象”，Bertram Heinrich Drost、Markus Ulrich，EP 专利 2385483（11 月 21 日） , 2012), 受让人: MVTec Software GmbH, 81675 Muenchen (Germany); “3D 场景中 3D 对象的识别和姿势确定”，Bertram Heinrich Drost、Markus Ulrich，美国专利 8830229（2014 年 9 月 9 日），受让人：MVTec Software GmbH，81675 Muenchen（德国）。更多专利正在申请中。有关详细信息，请联系 MVTec Software GmbH (info@mvtec.com)。\r\n            请注意，这些专利（可能还有其他专利）施加的限制独立于本许可中授予的自由，并且可能与本许可中授予的自由相冲突，后者指的是程序的版权，而不是其实现的任何方法的专利。版权法和专利法必须遵守合法使用和重新分发此程序的规定，本许可的目的不是诱导您侵犯任何专利或其他财产权索赔或质疑任何此类索赔的有效性。如果您重新分发或使用该程序，则此许可仅保护您免于侵犯版权。它不能保护您免于侵犯专利权。因此，在您使用该程序进行任何操作之前，请确保您不仅在版权方面而且在专利法方面都获得了许可。\r\n            请注意，本许可也不应被理解为保证。如果您根据本许可使用该程序，但与专利法相冲突，这并不意味着许可方将退还您因您所遭受的任何损失因您的专利侵权而被起诉。\r\n            \r\n","The maximum number of channels":"最大通道数\r\n","\r\n            Category\r\n            ":"\r\n            类别\r\n            \r\n","Number of iterations, use 1 as default":"迭代次数，默认为1\r\n","\r\n            Checks that every element is neither NaN nor Infinity\r\n            ":"\r\n            检查每个元素既不是 NaN 也不是 Infinity\r\n            \r\n","\r\n            Draw the matched keypoints between the model image and the observed image.\r\n            ":"\r\n            绘制模型图像和观察图像之间的匹配关键点。\r\n            \r\n","\r\n            Iteration\r\n            ":"\r\n            迭代\r\n            \r\n","\r\n            Charbonnier\r\n            ":"\r\n            夏博尼耶\r\n            \r\n","\r\n            Computes disparity/depth map for the specified stereo-pair. The function computes disparity or depth map depending on passed StereoOutputFormat argument.\r\n            ":"\r\n            计算指定立体对的视差/深度图。该函数根据传递的 StereoOutputFormat 参数计算视差或深度图。\r\n            \r\n","A single enumerable sorted in index ascending order":"按索引升序排序的单个枚举\r\n","\r\n            Stream Name\r\n            ":"\r\n            流名称\r\n            \r\n","If the array is IplImage and COI is set, the function processes the selected channel only and stores the average and standard deviation to the first compoenents of output scalars (M0 and S0).":"如果数组为 IplImage 且设置了 COI，则该函数仅处理选定的通道并将平均值和标准偏差存储到输出标量（M0 和 S0）的第一个分量。\r\n","\r\n            Create a new exposure compensator\r\n            ":"\r\n            创建一个新的曝光补偿器\r\n            \r\n","a crc64 random seed will get generated from this":"crc64 随机种子将从中生成\r\n","A new image that is the horizontal concatening of this image and ":"一个新的图像是这个图像的水平连接和\r\n","\r\n             kernel, depending on the image origin (origin field of IplImage structure). No scaling is done, so the destination image usually has larger by absolute value numbers than the source image. To avoid overflow, the function requires 16-bit destination image if the source image is 8-bit. The result can be converted back to 8-bit using cvConvertScale or cvConvertScaleAbs functions. Besides 8-bit images the function can process 32-bit floating-point images. Both source and destination must be single-channel images of equal size or ROI size\r\n             ":"\r\n             内核，取决于图像原点（IplImage 结构的原点字段）。没有进行缩放，因此目标图像的绝对值数字通常比源图像大。为避免溢出，如果源图像是 8 位，则该函数需要 16 位目标图像。可以使用 cvConvertScale 或 cvConvertScaleAbs 函数将结果转换回 8 位。除了 8 位图像外，该函数还可以处理 32 位浮点图像。源和目标必须是相同大小或 ROI 大小的单通道图像\r\n             \r\n","The source locations of a line bundle":"线束的源位置\r\n","\r\n            Page iterator level\r\n            ":"\r\n            页面迭代器级别\r\n            \r\n","Output pointer to the whole image origin or ROI origin if ROI is set":"如果设置了 ROI，则输出指向整个图像原点或 ROI 原点的指针\r\n"," The inpainted image ":" 修复的图像\r\n","\r\n            Pointer the the native cv::cuda::NvidiaOpticalFlow object.\r\n            ":"\r\n            指向本机 cv::cuda::NvidiaOpticalFlow 对象的指针。\r\n            \r\n","A copy if this matrix":"如果这个矩阵的副本\r\n","\r\n            Set up the matcher for computing the right-view disparity map that is required in case of filtering with confidence.\r\n            ":"\r\n            设置匹配器以计算在有信心过滤的情况下所需的右视图视差图。\r\n            \r\n","\r\n            Gaussian\r\n            ":"高斯\r\n            \r\n","\r\n            Max circularity\r\n            ":"\r\n            最大圆度\r\n            \r\n","\r\n            Convert BGR color to BGR565 color\r\n            ":"\r\n            将 BGR 颜色转换为 BGR565 颜色\r\n            \r\n","\r\n            Specify custom features of input image.\r\n            ":"\r\n            指定输入图像的自定义特征。\r\n            \r\n","An array of RotatedRect":"RotatedRect 数组\r\n","Full row length in bytes.":"以字节为单位的完整行长度。\r\n","\r\n            Video For Windows (obsolete, removed)\r\n            ":"\r\n            适用于 Windows 的视频（已过时，已删除）\r\n            \r\n","\r\n            Releases the header.\r\n            ":"\r\n            释放标题。\r\n            \r\n","\r\n            The number of devices\r\n            ":"\r\n            设备数量\r\n            \r\n","The depth of the normals (only CV_32F or CV_64F)":"法线的深度（仅 CV_32F 或 CV_64F）\r\n","The Mat where the result is read into":"读入结果的 Mat\r\n","\r\n            Performs the per-element comparison of two matrices checking if elements from first matrix are less or equal compare to elements in second.\r\n            ":"\r\n            执行两个矩阵的每个元素比较，检查第一个矩阵中的元素是否小于或等于第二个中的元素。\r\n            \r\n","\r\n            Release the unmanaged memory associated with this CaptureFrameSource\r\n            ":"\r\n            释放与此 CaptureFrameSource 关联的非托管内存\r\n            \r\n","Optional flag that conjugates the second input array before the multiplication (true) or not (false).":"在乘法 (true) 或不 (false) 之前共轭第二个输入数组的可选标志。\r\n","\r\n            The platform vendor\r\n            ":"\r\n            平台厂商\r\n            \r\n"," and save the result in ":" 并将结果保存在\r\n","One of the odometry type: \"RgbdOdometry\", \"ICPOdometry\", \"RgbdICPOdometry\" or \"FastICPOdometry\" ":"里程计类型之一：“RgbdOdometry”、“ICPOdometry”、“RgbdICPOdometry”或“FastICPOdometry”\r\n","Output vector (e.g. cv::Mat) corresponding to the rotation vector of the board":"对应棋盘旋转向量的输出向量（如cv::Mat）\r\n","the index of the row to be reterived":"要检索的行的索引\r\n","\r\n            Treat the image as a single word.\r\n            ":"\r\n            将图像视为单个词。\r\n            \r\n","\r\n            Relative position of the video file: 0=start of the film, 1=end of the film.\r\n            ":"\r\n            视频文件的相对位置：0=电影开始，1=电影结束。\r\n            \r\n",") columns of the GpuMat":") GpuMat 的列\r\n","Use a Stream to call the function asynchronously (non-blocking) or null to call the function synchronously (blocking).":"使用 Stream 异步调用函数（非阻塞）或使用 null 同步调用函数（阻塞）。\r\n","\r\n            Stub exposure compensator which does nothing.\r\n            ":"\r\n            什么都不做的存根曝光补偿器。\r\n            \r\n","Zero-based index of the ending row (exclusive) of the span":"跨度结束行（不包括）的从零开始的索引\r\n","\r\n            Gamma corrects this image inplace. The image must have a depth type of Byte.\r\n            ":"\r\n            Gamma 就地校正此图像。图像的深度类型必须为字节。\r\n            \r\n","The length of the arrow tip in relation to the arrow length":"箭尖的长度与箭长的关系\r\n","Specifies which kind of color sampling will be used":"指定将使用哪种颜色采样\r\n","\r\n            Constructs default planar circle centred at origin with plane normal along z-axis.\r\n            ":"\r\n            构造以原点为中心的默认平面圆，平面法线沿 z 轴。\r\n            \r\n","\r\n            Default constructor that creates empty Tonemap\r\n            ":"\r\n            创建空色调映射的默认构造函数\r\n            \r\n","Pixel extrapolation method.":"像素外推法。\r\n","\r\n            The detected barcode\r\n            ":"\r\n            检测到的条形码\r\n            \r\n","\r\n            The name of the device\r\n            ":"\r\n            设备名称\r\n            \r\n","\r\n            Left to RGB distance in cm\r\n            ":"\r\n            左到 RGB 距离（厘米）\r\n            \r\n","UTF8-encoded output vector of string or empty vector of string if the codes cannot be decoded.":"UTF8 编码的字符串输出向量或字符串的空向量（如果代码无法解码）。\r\n","\r\n            Convert Bayer RGGB to BGR (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 Bayer RGGB 转换为 BGR（边缘感知去马赛克）\r\n            \r\n","\r\n            DAISY descriptor.\r\n            ":"\r\n            雏菊描述符。\r\n            \r\n","\r\n            Pointer to the next ERStat\r\n            ":"\r\n            指向下一个 ERStat 的指针\r\n            \r\n","\r\n            Color Correction Matrix element [1][1]\r\n            ":"\r\n            颜色校正矩阵元素 [1][1]\r\n            \r\n","Y-coordinate of the baseline relative to the bottom-most text point.":"相对于最底部文本点的基线的 Y 坐标。\r\n","\r\n            Convert BayerGR to RGB (Edge-Aware Demosaicing)\r\n            ":"\r\n            将 BayerGR 转换为 RGB（边缘感知去马赛克）\r\n            \r\n","The Mat to be converted into Bitmap":"要转换为 Bitmap 的 Mat\r\n","The depth type of img2":"img2的深度类型\r\n","\r\n            Get a copy of the boxed region of the image\r\n            ":"\r\n            获取图像的盒装区域的副本\r\n            \r\n","\r\n            Invert Orientation\r\n            ":"\r\n            反转方向\r\n            \r\n","\r\n            GMS (Grid-based Motion Statistics) feature matching strategy\r\n            ":"GMS（Grid-based Motion Statistics）特征匹配策略\r\n            \r\n","\r\n            Convert the standard vector to an array of KeyLine\r\n            ":"\r\n            将标准向量转换为 KeyLine 数组\r\n            \r\n","\r\n            Concate the current image with another image horizontally. \r\n            ":"\r\n            将当前图像与另一图像水平连接。\r\n            \r\n"," \r\n            Defines a Hls (Hue Lightness Satuation) color\r\n            ":" \r\n            定义 Hls（色调亮度饱和度）颜色\r\n            \r\n","16-bit x derivative of input image":"输入图像的 16 位 x 导数\r\n","Anchor position within the kernel. The value (−1,−1) means that the anchor is at the kernel center.":"内核中的锚点位置。值 (-1,-1) 表示锚点位于内核中心。\r\n","\r\n            Resizes the image.\r\n            ":"\r\n            调整图像大小。\r\n            \r\n","\r\n            Fills the array with normally distributed random numbers.\r\n            ":"\r\n            用正态分布的随机数填充数组。\r\n            \r\n","\r\n             the vectors are stored as columns (i.e. values of a certain vector component are stored continuously)\r\n            ":"\r\n             向量存储为列（即连续存储某个向量分量的值）\r\n            \r\n"," Convert the current image to the specific depth, at the same time scale and shift the values of the pixel":" 将当前图像转换为特定深度，同时缩放和平移像素值\r\n","\r\n            Color Correction Matrix element [2][0]\r\n            ":"\r\n            颜色校正矩阵元素 [2][0]\r\n            \r\n","\r\n            Inverse camera response function is extracted for each brightness value by minimizing an objective function as linear system. This algorithm uses all image pixels.\r\n            ":"\r\n            通过最小化作为线性系统的目标函数，为每个亮度值提取逆相机响应函数。该算法使用所有图像像素。\r\n            \r\n","\r\n            Perform the convolution with ":"\r\n            执行卷积\r\n","Specifies output image channel.":"指定输出图像通道。\r\n","\r\n            Convert the standard vector to an array of DMatch\r\n            ":"\r\n            将标准向量转换为 DMatch 数组\r\n            \r\n","The inpainting method":"修补方法\r\n","Is focals estimated":"是焦点估计\r\n","\r\n            YUV444\r\n            ":"\r\n            YUV444\r\n            \r\n","Whenever non-maximum suppression is done over the branch probabilities.":"每当对分支概率进行非最大抑制时。\r\n","Type of the polygon boundaries.":"多边形边界的类型。\r\n","\r\n            Calculates a map using a gaussian pyramid\r\n            ":"\r\n            使用高斯金字塔计算地图\r\n            \r\n","The prediction results, should have the same # of rows as the ":"预测结果的行数应与\r\n","\r\n            Gentle AdaBoost\r\n            ":"\r\n            温和的 AdaBoost\r\n            \r\n","\r\n            Filters image using meanshift algorithm\r\n            ":"\r\n            使用 meanshift 算法过滤图像\r\n            \r\n","The second stage local adaptation area":"第二阶段局部适应区\r\n","\r\n            Returns true if the specified image can be decoded by OpenCV.\r\n            ":"\r\n            如果指定图像可以被 OpenCV 解码，则返回 true。\r\n            \r\n","The max difference.":"最大的区别。\r\n","\r\n            Get or Set a flag to indicate if the stitcher should apply wave correction\r\n            ":"\r\n            获取或设置一个标志以指示拼接器是否应应用波校正\r\n            \r\n","\r\n            The resulting HDR image is calculated as weighted average of the exposures considering exposure values and camera response.\r\n            ":"\r\n            考虑到曝光值和相机响应，生成的 HDR 图像计算为曝光的加权平均值。\r\n            \r\n","\r\n            The dense optical flow .\r\n            ":"\r\n            密密麻麻的光流。\r\n            \r\n","The data in this storage":"此存储中的数据\r\n","\r\n            The device version\r\n            ":"\r\n            设备版本\r\n            \r\n","input/output image. It must have 1 or 3 channels. The number of channels is not altered.":"输入/输出图像。它必须有 1 或 3 个通道。通道数没有改变。\r\n","\r\n            Extracts a diagonal from a matrix. The method makes a new header for the specified matrix diagonal. The new matrix is represented as a single-column matrix. Similarly to Mat::row and Mat::col, this is an O(1) operation.\r\n            ":"\r\n            从矩阵中提取对角线。该方法为指定的矩阵对角线创建一个新的标题。新矩阵表示为单列矩阵。与 Mat::row 和 Mat::col 类似，这是一个 O(1) 操作。\r\n            \r\n","\r\n            Release the unmanaged memory associated with this FisherFaceRecognizer\r\n            ":"\r\n            释放与此 FisherFaceRecognizer 关联的非托管内存\r\n            \r\n","\r\n            Draw the polylines defined by the array of array of 2D points\r\n            ":"\r\n            绘制由二维点数组定义的折线\r\n            \r\n","New number of rows. If the parameter is 0, the number of rows remains the same.":"新的行数。如果参数为 0，则行数保持不变。\r\n"," The structure IplImage":" 结构IplImage\r\n","\r\n            Generates an internal trigger. PRM_TRG_SOURCE must be set to TRG_SOFTWARE.\r\n            ":"\r\n            生成内部触发。 PRM_TRG_SOURCE 必须设置为 TRG_SOFTWARE。\r\n            \r\n","Bins in the histogram are not of equal size. Default value is 3*pi*pi. The one before \"histThresh\" value are smaller.":"直方图中的箱子大小不等。默认值为 3*pi*pi。 “histThresh”值之前的较小。\r\n","The initial pixel in the image equals zero":"图像中的初始像素等于零\r\n","The point the arrow points to.":"箭头指向的点。\r\n","\r\n            Release the memory associated with this shape context distance extractor\r\n            ":"\r\n            释放与此形状上下文距离提取器关联的内存\r\n            \r\n","\r\n            Set value from given matrix if the corresponding pixel value in mask matrix set to true, and set the matrix value to 0 otherwise.\r\n            ":"\r\n            如果掩码矩阵中的相应像素值设置为真，则从给定矩阵设置值，否则将矩阵值设置为 0。\r\n            \r\n","Output 3x3 orthogonal matrix.":"输出 3x3 正交矩阵。\r\n","The point to be added":"需要补充的点\r\n","Type of of source image. Only 8U images are supported for now.":"源图像的类型。目前仅支持 8U 图像。\r\n","\r\n            Create a GpuDisparityBilateralFilter\r\n            ":"\r\n            创建一个 GpuDisparityBilateralFilter\r\n            \r\n","\r\n            Convert Luv color to sRGB color\r\n            ":"\r\n            将 Luv 颜色转换为 sRGB 颜色\r\n            \r\n","\r\n            Finds centers in the grid of circles\r\n            ":"\r\n            在圆网格中找到中心\r\n            \r\n","4 dimensional array (images, channels, height, width) in floating point precision (CV_32F) from which you would like to extract the images.":"您要从中提取图像的浮点精度 (CV_32F) 的 4 维数组（图像、通道、高度、宽度）。\r\n","The double from the node.":"来自节点的双精度值。\r\n","\r\n            Convert Bayer RG color to BGR color\r\n            ":"\r\n            将 Bayer RG 颜色转换为 BGR 颜色\r\n            \r\n","\r\n            If set, always convert image to the 3 channel BGR color image and the image size reduced 1/8.\r\n            ":"\r\n            如果设置，则始终将图像转换为 3 通道 BGR 彩色图像并且图像尺寸缩小 1/8。\r\n            \r\n","These erase one-pixel junk blobs and merge almost-touching blobs. Default value is 1.":"这些擦除一个像素的垃圾斑点并合并几乎接触的斑点。默认值为 1。\r\n","\r\n            The sequence\r\n            ":"\r\n            序列\r\n            \r\n","Flag indicating whether to normalize (scale down) the filter coefficients or not.":"指示是否标准化（缩小）滤波器系数的标志。\r\n","Output covariance matrix of the type ctype and square size.":"类型为 ctype 和 square size 的输出协方差矩阵。\r\n","Position of the anchor within the element; default value (-1, -1) means that the anchor is at the element center.":"锚点在元素中的位置；默认值 (-1, -1) 表示锚点位于元素中心。\r\n","\r\n            Weight of the gradient constancy term\r\n            ":"\r\n            梯度恒常项的权重\r\n            \r\n","The attribute to be deleted.":"要删除的属性。\r\n","\r\n            Chooses random centers for k-Means initialization\r\n            ":"\r\n            为 k-Means 初始化选择随机中心\r\n            \r\n","Pointer to the GpuMat":"指向 GpuMat 的指针\r\n","\r\n            Release the unmanaged memory associated with this segment detector\r\n            ":"\r\n            释放与该段检测器关联的非托管内存\r\n            \r\n","Compute orientation":"计算方向\r\n","Matches array stored in GPU memory. Internal representation is not defined. Use DescriptorMatcher::knnMatchConvert method to retrieve results in standard representation.":"匹配存储在 GPU 内存中的数组。未定义内部表示。使用 DescriptorMatcher::knnMatchConvert 方法以标准表示形式检索结果。\r\n","\r\n            This class is presented high-level API for neural networks.\r\n            ":"\r\n            此类是神经网络的高级 API。\r\n            \r\n","\r\n            Used only when writing. Compact representation of a sequence or mapping. Used only by YAML writer\r\n            ":"\r\n            仅在写作时使用。序列或映射的紧凑表示。仅由 YAML 编写器使用\r\n            \r\n","\r\n            Transposes a matrix.\r\n            ":"\r\n            转置矩阵。\r\n            \r\n","\r\n            Create the standard vector of VectorOfPoint3D32F \r\n            ":"\r\n            创建 VectorOfPoint3D32F 的标准向量\r\n            \r\n","\r\n            The datapath must be the name of the directory of tessdata and\r\n            must end in / . Any name after the last / will be stripped.\r\n            ":"\r\n            数据路径必须是 tessdata 的目录名称和\r\n            必须以 / 结尾。最后一个 / 之后的任何名称都将被删除。\r\n            \r\n","\r\n            Re-project pixels on a 1-channel disparity map to array of 3D points.\r\n            ":"\r\n            将 1 通道视差图上的像素重新投影到 3D 点阵列。\r\n            \r\n","\r\n            Backend-specific value indicating the current capture mode.\r\n            ":"\r\n            指示当前捕获模式的后端特定值。\r\n            \r\n","\r\n            Creates an instance of PCAFlow\r\n            ":"\r\n            创建 PCAFlow 实例\r\n            \r\n","\r\n            The function add calculates sum of two matrices of the same size and the same number of channels\r\n            ":"\r\n            函数 add 计算相同大小和相同通道数的两个矩阵的总和\r\n            \r\n","\r\n            Input image range minimum value\r\n            ":"\r\n            输入图像范围最小值\r\n            \r\n","\r\n            Pointer to the native diaprty filter object\r\n            ":"\r\n            指向本机 diaprty 过滤器对象的指针\r\n            \r\n","First camera distortion parameters.":"首先是相机畸变参数。\r\n","The area of the whole contour or contour section":"整个轮廓或轮廓截面的面积\r\n","\r\n            Decomposes matrix A into a product of a diagonal matrix and two orthogonal matrices:\r\n            A=U*W*VT\r\n            Where W is diagonal matrix of singular values that can be coded as a 1D vector of singular values and U and V. All the singular values are non-negative and sorted (together with U and V columns) in descenting order.\r\n            ":"\r\n            将矩阵 A 分解为对角矩阵和两个正交矩阵的乘积：\r\n            A=U*W*VT\r\n            其中 W 是奇异值的对角矩阵，可以编码为奇异值和 U 和 V 的一维向量。所有奇异值都是非负的，并按降序排列（连同 U 和 V 列）。\r\n            \r\n","retryConfig is useful for debugging. If not NULL, you can fall back to an alternate configuration if a page fails for some reason.":"retryConfig 对于调试很有用。如果不是 NULL，如果页面由于某种原因失败，您可以回退到备用配置。\r\n","\r\n            Writes/appends one frame to video file.\r\n            ":"\r\n            将一帧写入/附加到视频文件。\r\n            \r\n","CV_8U1 image mask where -1 indicates that the pixel is a superpixel border, and 0 otherwise.":"CV_8U1 图像掩码，其中 -1 表示该像素是超像素边界，否则为 0。\r\n"," The value for this color ":" 这种颜色的价值\r\n","\r\n            The max number, do not use\r\n            ":"\r\n            最大数量，不要使用\r\n            \r\n","\r\n            Left to right\r\n            ":"\r\n            左到右\r\n            \r\n","the lineBundle":"线束\r\n"," kernel ":" 核心\r\n","\r\n            Initializes the matrix as following:\r\n            arr(i,j)=(end-start)*(i*cols(arr)+j)/(cols(arr)*rows(arr))\r\n            ":"\r\n            初始化矩阵如下：\r\n            arr(i,j)=(end-start)*(i*cols(arr)+j)/(cols(arr)*rows(arr))\r\n            \r\n"}